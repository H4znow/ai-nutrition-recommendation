{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Nutritional Agent\n",
    "\n",
    "This notebook will try to implement the AI nutritional model proposed in the paper *AI nutrition recommendation using a deep generative model and ChatGPT* by *Ilias Papastratis , Dimitrios Konstantinidis , Petros Daras & Kosmas Dimitropoulos*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Definition of the DataSet & Exemple of DataLoader Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MealPlanningDataset(Dataset):\n",
    "    \"Class to load dataset in a pytorch environnement and splitting dataset into training, validation and testing sets\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 csv_file: str | None=\"../datasets/synthetic_nutrition_data.csv\",\n",
    "                 split: str='train',\n",
    "                 train_split_ratio: float=0.7, \n",
    "                 val_split_ratio: float=0.15, \n",
    "                 test_split_ratio: float=0.15,\n",
    "                 random_seed: int=42):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (str | None): Path to the CSV file.\n",
    "            split (str): One of 'train', 'val', or 'test'. Determines which split to use.\n",
    "            train_pct (float): Fraction of data to use for training.\n",
    "            val_pct (float): Fraction of data to use for validation.\n",
    "            test_pct (float): Fraction of data to use for testing.\n",
    "            random_seed (int): Seed for shuffling the data.\n",
    "        \"\"\"\n",
    "        # Ensure the split percentages add up to 1.0\n",
    "        total_pct = train_split_ratio + val_split_ratio + test_split_ratio\n",
    "        if not np.isclose(total_pct, 1.0):\n",
    "            raise ValueError(\"train_pct + val_pct + test_pct must equal 1.0\")\n",
    "            \n",
    "        # Read the data from CSV\n",
    "        data = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Load data into numpy arrays with appropriate types\n",
    "        self.X = data[[\"weight\", \"height\", \"BMI\", \"BMR\", \"PAL\", \"has_CVD\", \"has_T2D\", \"has_iron_def\"]].values.astype('float32')\n",
    "        self.Y_meals = data[['meal_1', 'meal_2', 'meal_3', 'meal_4', 'meal_5', 'meal_6']].values.astype('long') # long : from int32 to int64\n",
    "        self.target_EI = data[['target_EI']].values.astype('float32')\n",
    "        self.min_macros = data[['min_prot', 'min_carb', 'min_fat', 'min_sfa']].values.astype('float32')\n",
    "        self.max_macros = data[['max_prot', 'max_carb', 'max_fat', 'max_sfa']].values.astype('float32')\n",
    "        \n",
    "        # Total number of samples\n",
    "        total_samples = len(self.X)\n",
    "        indices = np.arange(total_samples)\n",
    "        \n",
    "        # Shuffle indices for a random split (using a fixed seed for reproducibility)\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        # Compute split indices\n",
    "        train_end = int(train_split_ratio * total_samples)\n",
    "        val_end = int((train_split_ratio + val_split_ratio) * total_samples)\n",
    "    \n",
    "        if split == 'train':\n",
    "            self.indices = indices[:train_end]\n",
    "        elif split == 'val':\n",
    "            self.indices = indices[train_end:val_end]\n",
    "        elif split == 'test':\n",
    "            self.indices = indices[val_end:]\n",
    "        else:\n",
    "            raise ValueError(\"split must be 'train', 'val', or 'test'\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.indices[idx]\n",
    "        return (\n",
    "            torch.tensor(self.X[real_idx]),       # X_features\n",
    "            torch.tensor(self.Y_meals[real_idx]),     # Y_meals\n",
    "            torch.tensor(self.target_EI[real_idx]),   # target_EI\n",
    "            torch.tensor(self.min_macros[real_idx]),  # min_macros\n",
    "            torch.tensor(self.max_macros[real_idx])   # max_macros\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    train_dataset = MealPlanningDataset(csv_file=\"../datasets/synthetic_nutrition_data.csv\", split='train')\n",
    "    val_dataset = MealPlanningDataset(csv_file=\"../datasets/synthetic_nutrition_data.csv\", split='val')\n",
    "    test_dataset = MealPlanningDataset(csv_file=\"../datasets/synthetic_nutrition_data.csv\", split='test')\n",
    "except ValueError as e:\n",
    "    print(f\"Value error occured: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=dataloader_batch_size)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=dataloader_batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=dataloader_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loaded Data (short) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User information shape :  torch.Size([32, 8])\n",
      "User ground meal plan shape :  torch.Size([32, 6])\n",
      "Energy target shape :  torch.Size([32, 1])\n",
      "Minimum macronutriments shape :  torch.Size([32, 4])\n",
      "Maximum macronutriments shape :  torch.Size([32, 4])\n",
      "Number of 32 batches in training dataloader: 219\n",
      "Total number of samples in training dataset: 7008\n"
     ]
    }
   ],
   "source": [
    "# Check shapes\n",
    "for X_features, Y_meals, target_EIs, min_macros, max_macros in train_dataloader:\n",
    "    print(\"User information shape : \", X_features.size())\n",
    "    print(\"User ground meal plan shape : \", Y_meals.size())\n",
    "    print(\"Energy target shape : \", target_EIs.size())\n",
    "    print(\"Minimum macronutriments shape : \", min_macros.size())\n",
    "    print(\"Maximum macronutriments shape : \", max_macros.size())\n",
    "    break\n",
    "print(f\"Number of {dataloader_batch_size} batches in training dataloader: {len(train_dataloader)}\")\n",
    "print(f\"Total number of samples in training dataset: {len(train_dataloader) * dataloader_batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User information shape :  torch.Size([32, 8])\n",
      "User ground meal plan shape :  torch.Size([32, 6])\n",
      "Energy target shape :  torch.Size([32, 1])\n",
      "Minimum macronutriments shape :  torch.Size([32, 4])\n",
      "Maximum macronutriments shape :  torch.Size([32, 4])\n",
      "Number of 32 batches in testing dataloader: 47\n",
      "Total number of samples in testing dataset: 1504\n"
     ]
    }
   ],
   "source": [
    "for X_features, Y_meals, target_EIs, min_macros, max_macros in test_dataloader:\n",
    "    print(\"User information shape : \", X_features.size())\n",
    "    print(\"User ground meal plan shape : \", Y_meals.size())\n",
    "    print(\"Energy target shape : \", target_EIs.size())\n",
    "    print(\"Minimum macronutriments shape : \", min_macros.size())\n",
    "    print(\"Maximum macronutriments shape : \", max_macros.size())\n",
    "    break\n",
    "print(f\"Number of {dataloader_batch_size} batches in testing dataloader: {len(test_dataloader)}\")\n",
    "print(f\"Total number of samples in testing dataset: {len(test_dataloader) * dataloader_batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of data (e.g., X): <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Type of data (e.g., X): {type(X_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"Encoder model for the variational auto-encoder (vae).\"\n",
    "\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, latent_dim: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim (int): input dimension of encoder.\n",
    "            hidden_dim (int): hidden neurons dimensions.\n",
    "            latent_dim (int): generated latent space dimension.\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        # fc1: projects input features to a hidden representation.\n",
    "        #   Input: [batch_size, input_dim] → Output: [batch_size, hidden_dim]\n",
    "        self.fc1 = nn.Linear(in_features=input_dim, out_features=hidden_dim)\n",
    "        \n",
    "        # fc2: further processes the hidden representation.\n",
    "        #   Input: [batch_size, hidden_dim] → Output: [batch_size, hidden_dim]\n",
    "        self.fc2 = nn.Linear(in_features=hidden_dim, out_features=hidden_dim)\n",
    "\n",
    "        # fc_mu: computes the mean of the latent distribution.\n",
    "        #   Input: [batch_size, hidden_dim] → Output: [batch_size, latent_dim]\n",
    "        self.fc_mu = nn.Linear(in_features=hidden_dim, out_features=latent_dim)\n",
    "        \n",
    "        # fc_logvar: computes the log-variance of the latent distribution.\n",
    "        #   Input: [batch_size, hidden_dim] → Output: [batch_size, latent_dim]\n",
    "        self.fc_logvar = nn.Linear(in_features=hidden_dim, out_features=latent_dim)\n",
    "    \n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.Tensor): input tensor of encoder.\n",
    "        \"\"\"\n",
    "        # Apply fc1 with ReLU activation.\n",
    "        #   x: [batch_size, input_dim] → [batch_size, hidden_dim]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # Apply fc2 with ReLU activation.\n",
    "        #   x: [batch_size, hidden_dim] → h: [batch_size, hidden_dim]\n",
    "        h = F.relu(self.fc2(x))\n",
    "        \n",
    "        # Compute the latent mean.\n",
    "        #   h: [batch_size, hidden_dim] → mu: [batch_size, latent_dim]\n",
    "        mu = self.fc_mu(h)\n",
    "        \n",
    "        # Compute the latent log-variance.\n",
    "        #   h: [batch_size, hidden_dim] → logvar: [batch_size, latent_dim]\n",
    "        logvar = self.fc_logvar(h)\n",
    "        \n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 8\n",
    "hidden_units = 62\n",
    "input_dim = 16\n",
    "\n",
    "encoder = Encoder(input_dim, hidden_units, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "Encoder                                  [16]                      [16]                      --\n",
       "├─Linear: 1-1                            [16]                      [62]                      1,054\n",
       "├─Linear: 1-2                            [62]                      [62]                      3,906\n",
       "├─Linear: 1-3                            [62]                      [16]                      1,008\n",
       "├─Linear: 1-4                            [62]                      [16]                      1,008\n",
       "===================================================================================================================\n",
       "Total params: 6,976\n",
       "Trainable params: 6,976\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.34\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.03\n",
       "Estimated Total Size (MB): 0.03\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(encoder, (input_dim,), col_names=[\"input_size\", \"output_size\", \"num_params\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"Decoder model for the variation auto-encoder (vae)\"\n",
    "\n",
    "    def __init__(self, input_dim: int, hidden_units: int, num_classes: int, macro_dim: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim (int): Dimensionality of the decoder's input features.\n",
    "            hidden_units (int): Number of hidden units in the GRU layer, used as both input and output dimensions.\n",
    "            num_classes (int): Number of target classes to predict (i.e., number of unique meals in the dataset).\n",
    "            macro_dim (int): Number of macronutrient features in the data.\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_units = hidden_units\n",
    "        self.macro_dim = macro_dim\n",
    "\n",
    "        # Projects latent vector (shape: [batch_size, latent_dim]) to hidden space (shape: [batch_size, hidden_dim])\n",
    "        self.latent_to_hidden = nn.Linear(in_features=input_dim, out_features=hidden_units)\n",
    "\n",
    "        # GRUCell that takes an input of shape [batch_size, hidden_dim] and outputs a hidden state of the same shape\n",
    "        self.gru1 = nn.GRUCell(input_size=hidden_units, hidden_size=hidden_units)\n",
    "        self.gru2 = nn.GRUCell(input_size=hidden_units, hidden_size=hidden_units)\n",
    "\n",
    "        # Classifier head: maps hidden state [batch_size, hidden_dim] to class logits [batch_size, num_classes]\n",
    "        self.classifier = nn.Linear(in_features=hidden_units, out_features=num_classes)\n",
    "        # Energy head: maps hidden state [batch_size, hidden_dim] to a scalar energy [batch_size, 1]\n",
    "        self.energy_head = nn.Linear(in_features=hidden_units, out_features=1)\n",
    "        # Macro head: maps hidden state [batch_size, hidden_dim] to macro outputs [batch_size, macro_dim]\n",
    "        self.macro_head = nn.Linear(in_features=hidden_units, out_features=macro_dim) \n",
    "    \n",
    "    def forward(self, z: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            z (torch.Tensor): Latent vector generated by encoder.\n",
    "            \n",
    "        Returns:\n",
    "            class_logits_seq (torch.Tensor): Sequence of class logits, shape [batch_size, T, num_classes].\n",
    "            total_energy (torch.Tensor): Summed energy over T time steps, shape [batch_size, 1].\n",
    "            total_macros (torch.Tensor): Accumulated macro outputs over T time steps, shape [batch_size, macro_dim].\n",
    "            energies_tensor (torch.Tensor): Sequence of energy values, shape [batch_size, T, 1].\n",
    "        \"\"\"\n",
    "        batch_size = z.size(0)\n",
    "        T = 6  # Number of GRU time steps\n",
    "\n",
    "\n",
    "        # Initialize hidden state for GRUCell with zeros, shape: [batch_size, hidden_dim]\n",
    "        h1 = torch.zeros(size=(batch_size, self.hidden_units), device=z.device)\n",
    "        h2 = torch.zeros(size=(batch_size, self.hidden_units), device=z.device)\n",
    "        h_prev = h2\n",
    "\n",
    "        # Project latent vector to hidden space (input for GRU at t=0), shape: [batch_size, hidden_dim]\n",
    "        z_projected = self.latent_to_hidden(z)\n",
    "         \n",
    "        class_logits_seq = []\n",
    "        energies_list = []\n",
    "        # Initialize accumulation for macro outputs, shape: [batch_size, macro_dim]\n",
    "        total_macros = torch.zeros(batch_size, self.macro_dim, device=z.device)\n",
    "\n",
    "        for t in range(T):\n",
    "            # For t=0, use the projected latent vector; for t>0, use previous hidden state as input.\n",
    "            if t == 0:\n",
    "                z = z_projected\n",
    "            else:\n",
    "                z = h_prev\n",
    "\n",
    "            # GRUCell update: input z and previous hidden state h, both of shape [batch_size, hidden_dim]\n",
    "            h1 = self.gru1(z, h1)\n",
    "            h2 = self.gru2(h1, h2)\n",
    "\n",
    "            # Compute outputs from the current hidden state\n",
    "            logits = self.classifier(h2)    # Shape: [batch_size, num_classes]\n",
    "            energy = self.energy_head(h2)     # Shape: [batch_size, 1]\n",
    "            macros = self.macro_head(h2)      # Shape: [batch_size, macro_dim]\n",
    "\n",
    "            class_logits_seq.append(logits)\n",
    "            energies_list.append(energy)\n",
    "            total_macros += macros  # Accumulate macro outputs over time steps\n",
    "\n",
    "            h_prev = h2  # Save current hidden state for next iteration\n",
    "\n",
    "        # Stack list of tensors along a new time dimension: [batch_size, T, num_classes] and [batch_size, T, 1]\n",
    "        class_logits_seq = torch.stack(class_logits_seq, dim=1)\n",
    "        energies_tensor = torch.stack(energies_list, dim=1)\n",
    "        # Sum energy values over the time dimension, resulting in shape: [batch_size, 1]\n",
    "        total_energy = energies_tensor.sum(dim=1)\n",
    "\n",
    "        return class_logits_seq, total_energy, total_macros, energies_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 16\n",
    "hidden_units = 25\n",
    "num_classes = 140\n",
    "macro_dim = 5\n",
    "batch_size = 50\n",
    "\n",
    "decoder = Decoder(input_dim, hidden_units, num_classes, macro_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "Decoder                                  [50, 16]                  [50, 6, 140]              --\n",
       "├─Linear: 1-1                            [50, 16]                  [50, 25]                  425\n",
       "├─GRUCell: 1-2                           [50, 25]                  [50, 25]                  3,900\n",
       "├─GRUCell: 1-3                           [50, 25]                  [50, 25]                  3,900\n",
       "├─Linear: 1-4                            [50, 25]                  [50, 140]                 3,640\n",
       "├─Linear: 1-5                            [50, 25]                  [50, 1]                   26\n",
       "├─Linear: 1-6                            [50, 25]                  [50, 5]                   130\n",
       "├─GRUCell: 1-7                           [50, 25]                  [50, 25]                  (recursive)\n",
       "├─GRUCell: 1-8                           [50, 25]                  [50, 25]                  (recursive)\n",
       "├─Linear: 1-9                            [50, 25]                  [50, 140]                 (recursive)\n",
       "├─Linear: 1-10                           [50, 25]                  [50, 1]                   (recursive)\n",
       "├─Linear: 1-11                           [50, 25]                  [50, 5]                   (recursive)\n",
       "├─GRUCell: 1-12                          [50, 25]                  [50, 25]                  (recursive)\n",
       "├─GRUCell: 1-13                          [50, 25]                  [50, 25]                  (recursive)\n",
       "├─Linear: 1-14                           [50, 25]                  [50, 140]                 (recursive)\n",
       "├─Linear: 1-15                           [50, 25]                  [50, 1]                   (recursive)\n",
       "├─Linear: 1-16                           [50, 25]                  [50, 5]                   (recursive)\n",
       "├─GRUCell: 1-17                          [50, 25]                  [50, 25]                  (recursive)\n",
       "├─GRUCell: 1-18                          [50, 25]                  [50, 25]                  (recursive)\n",
       "├─Linear: 1-19                           [50, 25]                  [50, 140]                 (recursive)\n",
       "├─Linear: 1-20                           [50, 25]                  [50, 1]                   (recursive)\n",
       "├─Linear: 1-21                           [50, 25]                  [50, 5]                   (recursive)\n",
       "├─GRUCell: 1-22                          [50, 25]                  [50, 25]                  (recursive)\n",
       "├─GRUCell: 1-23                          [50, 25]                  [50, 25]                  (recursive)\n",
       "├─Linear: 1-24                           [50, 25]                  [50, 140]                 (recursive)\n",
       "├─Linear: 1-25                           [50, 25]                  [50, 1]                   (recursive)\n",
       "├─Linear: 1-26                           [50, 25]                  [50, 5]                   (recursive)\n",
       "├─GRUCell: 1-27                          [50, 25]                  [50, 25]                  (recursive)\n",
       "├─GRUCell: 1-28                          [50, 25]                  [50, 25]                  (recursive)\n",
       "├─Linear: 1-29                           [50, 25]                  [50, 140]                 (recursive)\n",
       "├─Linear: 1-30                           [50, 25]                  [50, 1]                   (recursive)\n",
       "├─Linear: 1-31                           [50, 25]                  [50, 5]                   (recursive)\n",
       "===================================================================================================================\n",
       "Total params: 12,021\n",
       "Trainable params: 12,021\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 59.66\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.48\n",
       "Params size (MB): 0.05\n",
       "Estimated Total Size (MB): 0.53\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(decoder, (batch_size, input_dim), col_names=[\"input_size\", \"output_size\", \"num_params\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same loss functions cited in the paper are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_meal_quantity(energies: torch.Tensor, batch_target_EI: torch.Tensor):\n",
    "    \"Optimizer function [will be used later]\"\n",
    "    pred_total_energy = energies.sum(dim=1)\n",
    "    d = (batch_target_EI - pred_total_energy) / pred_total_energy\n",
    "    d_expanded = d.unsqueeze(1)\n",
    "    adjusted_energies = energies * (1 + d_expanded)\n",
    "    new_total_energy = adjusted_energies.sum(dim=1)\n",
    "    return adjusted_energies, new_total_energy   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_L_macro(batch_min_macros: torch.Tensor, batch_max_macros: torch.Tensor, pred_macros: torch.Tensor):\n",
    "    \"Maconutriment penalty loss\"\n",
    "    diff_min = torch.abs(batch_min_macros - pred_macros)\n",
    "    diff_max = torch.abs(batch_max_macros - pred_macros)\n",
    "    macro_penalty = diff_min + diff_max\n",
    "    L_macro = macro_penalty.mean()\n",
    "    return L_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_L_energy(pred_energy: torch.Tensor, batch_target_EI: torch.Tensor):\n",
    "    \"Energy intake loss\"\n",
    "    L_energy = F.mse_loss(pred_energy, batch_target_EI)\n",
    "    return L_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_KLD(mu: torch.Tensor, logvar: torch.Tensor, batch_size: int):\n",
    "    \"Kullback-Leibler Divergence loss\"\n",
    "    KLD_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    KLD_loss = KLD_loss / batch_size\n",
    "    return KLD_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_L_MC(class_logits: torch.Tensor, batch_Y: torch.Tensor):\n",
    "    \"Cross entropy loss\"\n",
    "    T = class_logits.size(1)\n",
    "    CE_loss = 0.0\n",
    "    for t in range(T):\n",
    "        CE_loss += F.cross_entropy(class_logits[:, t, :], batch_Y[:, t])\n",
    "    CE_loss = CE_loss / T\n",
    "    return CE_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoderTrainer:\n",
    "    \"Variation Encoder class to train its two components : Encoder and Decoder.\"\n",
    "    def __init__(self, encoder: nn.Module, decoder: nn.Module, train_loader: DataLoader, val_loader: DataLoader, optimizer: Adam, device: str='cpu'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            encoder (nn.Module): Encoder network.\n",
    "            decoder (nn.Module): Decoder network.\n",
    "            train_loader (DataLoader): Training data loader.\n",
    "            val_loader (DataLoader): Validation data loader.\n",
    "            optimizer (Adam): Adam optimizer for both encoder and decoder.\n",
    "            device (str): device on which operations are performed.\n",
    "        \"\"\"\n",
    "        self.encoder = encoder.to(device)\n",
    "        self.decoder = decoder.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "\n",
    "    def _compute_loss(self, x_features: torch.Tensor, y_meals: torch.Tensor, target_EIs: torch.Tensor, min_macros: torch.Tensor, max_macros: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x_fatures (torch.Tensor): user informations tensor from the batch (encoder input).\n",
    "            y_meals (torch.Tensor): daily meals target tensor.\n",
    "            target_EIs (torch.Tensor): energy intakes target tensor.\n",
    "            min_macros (torch.Tensor): minimum targeted value of macronutriments.\n",
    "            max_macros (torch.Tensor): maximum targeted value of macronutriments.\n",
    "        \"\"\"\n",
    "        # Get batch size\n",
    "        batch_size = x_features.size(0)\n",
    "\n",
    "        # Forward pass through encoder\n",
    "        mu, logvar = self.encoder(x_features)\n",
    "        \n",
    "        # Reparameterization trick\n",
    "        epsilon = torch.randn_like(logvar)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        z = mu + std * epsilon\n",
    "        \n",
    "        # Forward pass through decoder\n",
    "        class_logits, pred_energy, pred_macros, energies_tensor = self.decoder(z)\n",
    "        \n",
    "        # Compute individual loss terms\n",
    "        L_macro = compute_L_macro(min_macros, max_macros, pred_macros)\n",
    "        L_energy = compute_L_energy(pred_energy, target_EIs)\n",
    "        L_kld = compute_KLD(mu, logvar, batch_size)\n",
    "        L_mc = compute_L_MC(class_logits, y_meals)\n",
    "        \n",
    "        total_loss = L_macro + L_energy + L_kld + L_mc\n",
    "        return total_loss, L_macro, L_energy, L_kld, L_mc, energies_tensor\n",
    "\n",
    "    def train_epoch(self):\n",
    "        \"\"\"\n",
    "        Performs one training epoch.\n",
    "        \"\"\"\n",
    "        self.encoder.train()\n",
    "        self.decoder.train()\n",
    "        total_loss = 0.0\n",
    "        total_batches = len(self.train_loader)\n",
    "        \n",
    "        for batch_idx, (x_features, y_meals, target_EIs, min_macros, max_macros) in enumerate(self.train_loader):\n",
    "            # Move data to device\n",
    "            x_features = x_features.to(self.device)\n",
    "            y_meals    = y_meals.to(self.device)\n",
    "            target_EIs = target_EIs.to(self.device)\n",
    "            min_macros = min_macros.to(self.device)\n",
    "            max_macros = max_macros.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            loss, L_macro, L_energy, L_kld, L_mc, energies_tensor = self._compute_loss(x_features, y_meals, target_EIs, min_macros, max_macros)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"Train Batch {batch_idx+1}/{total_batches} - Loss: {loss.item():.4f} \"\n",
    "                      f\"(Macro: {L_macro.item():.4f}, Energy: {L_energy.item():.4f}, \"\n",
    "                      f\"KLD: {L_kld.item():.4f}, MC: {L_mc.item():.4f})\")\n",
    "                \n",
    "        avg_loss = total_loss / total_batches\n",
    "        print(f\"Training epoch complete. Average Loss: {avg_loss:.4f}\\n\")\n",
    "        return avg_loss, energies_tensor\n",
    "\n",
    "    def validate_epoch(self):\n",
    "        \"\"\"\n",
    "        Evaluates the model on the validation set.\n",
    "        \"\"\"\n",
    "        self.encoder.eval()\n",
    "        self.decoder.eval()\n",
    "        total_loss = 0.0\n",
    "        total_batches = len(self.val_loader)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (x_features, y_meals, target_EIs, min_macros, max_macros) in enumerate(self.val_loader):\n",
    "                x_features = x_features.to(self.device)\n",
    "                y_meals    = y_meals.to(self.device)\n",
    "                target_EIs = target_EIs.to(self.device)\n",
    "                min_macros = min_macros.to(self.device)\n",
    "                max_macros = max_macros.to(self.device)\n",
    "                \n",
    "                loss, _, _, _, _, _ = self._compute_loss(x_features, y_meals, target_EIs, min_macros, max_macros)\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "        avg_loss = total_loss / total_batches\n",
    "        print(f\"Validation epoch complete. Average Loss: {avg_loss:.4f}\\n\")\n",
    "        return avg_loss\n",
    "\n",
    "    def train(self, num_epochs: int):\n",
    "        \"\"\"\n",
    "        Trains the model for the specified number of epochs.\n",
    "        Args:\n",
    "            num_epochs (int): number of epochs to run thrgouh.\n",
    "        Returns:\n",
    "            train_losses (list): List of average training losses.\n",
    "            val_losses (list): List of average validation losses.\n",
    "        \"\"\"\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            train_loss, energies_tensor = self.train_epoch()\n",
    "            val_loss = self.validate_epoch()\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "        return train_losses, val_losses\n",
    "\n",
    "    def predict(self, x_features):\n",
    "        \"\"\"\n",
    "        Generates predictions given input features.\n",
    "        Returns:\n",
    "            class_logits, pred_energy, pred_macros, energies_tensor\n",
    "        \"\"\"\n",
    "        self.encoder.eval()\n",
    "        self.decoder.eval()\n",
    "        with torch.no_grad():\n",
    "            x_features = x_features.to(self.device)\n",
    "            # For prediction we can use the mean (mu) as the latent representation\n",
    "            mu, _ = self.encoder(x_features)\n",
    "            class_logits, pred_energy, pred_macros, energies_tensor = self.decoder(mu)\n",
    "        return class_logits, pred_energy, pred_macros, energies_tensor\n",
    "    \n",
    "    def test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator() if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MealPlanningDataset(csv_file=\"../datasets/synthetic_nutrition_data.csv\", split='train')\n",
    "val_dataset = MealPlanningDataset(csv_file=\"../datasets/synthetic_nutrition_data.csv\", split='val')\n",
    "test_dataset = MealPlanningDataset(csv_file=\"../datasets/synthetic_nutrition_data.csv\", split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder args\n",
    "input_dim_enc = 8\n",
    "hidden_dim = 256\n",
    "input_dim = 256\n",
    "\n",
    "# Decoder args\n",
    "input_dim_dec = input_dim\n",
    "hidden_units = 512\n",
    "num_classes = 10\n",
    "macro_dim = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x12284f680>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1E-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_dim=input_dim_enc, hidden_dim=hidden_dim, latent_dim=input_dim)\n",
    "decoder = Decoder(input_dim=input_dim_dec, hidden_units=hidden_units, num_classes=num_classes, macro_dim=macro_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_trainer = VariationalAutoencoderTrainer(encoder, decoder, train_dataloader, val_dataloader,optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "Train Batch 10/110 - Loss: 7.1280 (Macro: 1.5737, Energy: 1.1409, KLD: 2.1149, MC: 2.2984)\n",
      "Train Batch 20/110 - Loss: 6.9358 (Macro: 1.4818, Energy: 1.0177, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0959 (Macro: 1.4522, Energy: 1.0336, KLD: 2.3073, MC: 2.3028)\n",
      "Train Batch 40/110 - Loss: 7.4414 (Macro: 1.5330, Energy: 1.2270, KLD: 2.3805, MC: 2.3009)\n",
      "Train Batch 50/110 - Loss: 7.0508 (Macro: 1.4963, Energy: 1.0129, KLD: 2.2381, MC: 2.3036)\n",
      "Train Batch 60/110 - Loss: 6.9041 (Macro: 1.3840, Energy: 0.9632, KLD: 2.2570, MC: 2.2998)\n",
      "Train Batch 70/110 - Loss: 6.9673 (Macro: 1.3662, Energy: 0.8591, KLD: 2.4378, MC: 2.3043)\n",
      "Train Batch 80/110 - Loss: 7.2928 (Macro: 1.4170, Energy: 1.0358, KLD: 2.5365, MC: 2.3035)\n",
      "Train Batch 90/110 - Loss: 6.7908 (Macro: 1.4705, Energy: 0.9961, KLD: 2.0241, MC: 2.3000)\n",
      "Train Batch 100/110 - Loss: 7.3117 (Macro: 1.6110, Energy: 1.1815, KLD: 2.2161, MC: 2.3031)\n",
      "Train Batch 110/110 - Loss: 6.6430 (Macro: 1.2625, Energy: 0.7407, KLD: 2.3414, MC: 2.2984)\n",
      "Training epoch complete. Average Loss: 7.0792\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0777\n",
      "\n",
      "Epoch 2/500\n",
      "Train Batch 10/110 - Loss: 7.1315 (Macro: 1.5642, Energy: 1.1535, KLD: 2.1149, MC: 2.2989)\n",
      "Train Batch 20/110 - Loss: 6.9670 (Macro: 1.4897, Energy: 1.0410, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.0997 (Macro: 1.4575, Energy: 1.0327, KLD: 2.3073, MC: 2.3022)\n",
      "Train Batch 40/110 - Loss: 7.4559 (Macro: 1.5463, Energy: 1.2277, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 6.9602 (Macro: 1.4767, Energy: 0.9427, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.9553 (Macro: 1.3973, Energy: 0.9999, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9455 (Macro: 1.3653, Energy: 0.8379, KLD: 2.4378, MC: 2.3045)\n",
      "Train Batch 80/110 - Loss: 7.3022 (Macro: 1.4136, Energy: 1.0510, KLD: 2.5365, MC: 2.3011)\n",
      "Train Batch 90/110 - Loss: 6.8540 (Macro: 1.4782, Energy: 1.0504, KLD: 2.0241, MC: 2.3013)\n",
      "Train Batch 100/110 - Loss: 7.3048 (Macro: 1.6087, Energy: 1.1788, KLD: 2.2161, MC: 2.3012)\n",
      "Train Batch 110/110 - Loss: 6.6384 (Macro: 1.2575, Energy: 0.7429, KLD: 2.3414, MC: 2.2967)\n",
      "Training epoch complete. Average Loss: 7.0797\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0495\n",
      "\n",
      "Epoch 3/500\n",
      "Train Batch 10/110 - Loss: 7.1154 (Macro: 1.5812, Energy: 1.1201, KLD: 2.1149, MC: 2.2992)\n",
      "Train Batch 20/110 - Loss: 6.9233 (Macro: 1.4692, Energy: 1.0165, KLD: 2.1345, MC: 2.3031)\n",
      "Train Batch 30/110 - Loss: 7.0864 (Macro: 1.4611, Energy: 1.0161, KLD: 2.3073, MC: 2.3018)\n",
      "Train Batch 40/110 - Loss: 7.4827 (Macro: 1.5732, Energy: 1.2285, KLD: 2.3805, MC: 2.3005)\n",
      "Train Batch 50/110 - Loss: 7.0642 (Macro: 1.4854, Energy: 1.0374, KLD: 2.2381, MC: 2.3034)\n",
      "Train Batch 60/110 - Loss: 6.9036 (Macro: 1.3761, Energy: 0.9672, KLD: 2.2570, MC: 2.3032)\n",
      "Train Batch 70/110 - Loss: 6.9451 (Macro: 1.3488, Energy: 0.8564, KLD: 2.4378, MC: 2.3022)\n",
      "Train Batch 80/110 - Loss: 7.3254 (Macro: 1.4205, Energy: 1.0649, KLD: 2.5365, MC: 2.3035)\n",
      "Train Batch 90/110 - Loss: 6.8028 (Macro: 1.4697, Energy: 1.0091, KLD: 2.0241, MC: 2.3000)\n",
      "Train Batch 100/110 - Loss: 7.2829 (Macro: 1.6258, Energy: 1.1408, KLD: 2.2161, MC: 2.3003)\n",
      "Train Batch 110/110 - Loss: 6.6312 (Macro: 1.2394, Energy: 0.7492, KLD: 2.3414, MC: 2.3013)\n",
      "Training epoch complete. Average Loss: 7.0797\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0578\n",
      "\n",
      "Epoch 4/500\n",
      "Train Batch 10/110 - Loss: 7.1256 (Macro: 1.5693, Energy: 1.1407, KLD: 2.1149, MC: 2.3007)\n",
      "Train Batch 20/110 - Loss: 6.9214 (Macro: 1.4813, Energy: 1.0041, KLD: 2.1345, MC: 2.3015)\n",
      "Train Batch 30/110 - Loss: 7.0970 (Macro: 1.4660, Energy: 1.0229, KLD: 2.3073, MC: 2.3008)\n",
      "Train Batch 40/110 - Loss: 7.4944 (Macro: 1.5715, Energy: 1.2399, KLD: 2.3805, MC: 2.3025)\n",
      "Train Batch 50/110 - Loss: 7.0146 (Macro: 1.4698, Energy: 1.0060, KLD: 2.2381, MC: 2.3008)\n",
      "Train Batch 60/110 - Loss: 6.8395 (Macro: 1.3543, Energy: 0.9261, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.9410 (Macro: 1.3535, Energy: 0.8466, KLD: 2.4378, MC: 2.3032)\n",
      "Train Batch 80/110 - Loss: 7.2981 (Macro: 1.4431, Energy: 1.0156, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.7765 (Macro: 1.4769, Energy: 0.9745, KLD: 2.0241, MC: 2.3010)\n",
      "Train Batch 100/110 - Loss: 7.3412 (Macro: 1.6086, Energy: 1.2131, KLD: 2.2161, MC: 2.3034)\n",
      "Train Batch 110/110 - Loss: 6.6878 (Macro: 1.2529, Energy: 0.7938, KLD: 2.3414, MC: 2.2997)\n",
      "Training epoch complete. Average Loss: 7.0795\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0658\n",
      "\n",
      "Epoch 5/500\n",
      "Train Batch 10/110 - Loss: 7.1039 (Macro: 1.5661, Energy: 1.1240, KLD: 2.1149, MC: 2.2989)\n",
      "Train Batch 20/110 - Loss: 6.9207 (Macro: 1.4830, Energy: 1.0003, KLD: 2.1345, MC: 2.3030)\n",
      "Train Batch 30/110 - Loss: 7.0653 (Macro: 1.4559, Energy: 1.0005, KLD: 2.3073, MC: 2.3017)\n",
      "Train Batch 40/110 - Loss: 7.4616 (Macro: 1.5607, Energy: 1.2179, KLD: 2.3805, MC: 2.3024)\n",
      "Train Batch 50/110 - Loss: 7.1057 (Macro: 1.5098, Energy: 1.0563, KLD: 2.2381, MC: 2.3015)\n",
      "Train Batch 60/110 - Loss: 6.9602 (Macro: 1.3959, Energy: 1.0077, KLD: 2.2570, MC: 2.2996)\n",
      "Train Batch 70/110 - Loss: 6.9437 (Macro: 1.3805, Energy: 0.8228, KLD: 2.4378, MC: 2.3027)\n",
      "Train Batch 80/110 - Loss: 7.3254 (Macro: 1.4245, Energy: 1.0612, KLD: 2.5365, MC: 2.3031)\n",
      "Train Batch 90/110 - Loss: 6.7966 (Macro: 1.4793, Energy: 0.9917, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.2784 (Macro: 1.6078, Energy: 1.1522, KLD: 2.2161, MC: 2.3023)\n",
      "Train Batch 110/110 - Loss: 6.6206 (Macro: 1.1992, Energy: 0.7828, KLD: 2.3414, MC: 2.2972)\n",
      "Training epoch complete. Average Loss: 7.0807\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0639\n",
      "\n",
      "Epoch 6/500\n",
      "Train Batch 10/110 - Loss: 7.1055 (Macro: 1.5618, Energy: 1.1279, KLD: 2.1149, MC: 2.3008)\n",
      "Train Batch 20/110 - Loss: 6.8522 (Macro: 1.4882, Energy: 0.9280, KLD: 2.1345, MC: 2.3014)\n",
      "Train Batch 30/110 - Loss: 7.0642 (Macro: 1.4389, Energy: 1.0151, KLD: 2.3073, MC: 2.3029)\n",
      "Train Batch 40/110 - Loss: 7.4319 (Macro: 1.5613, Energy: 1.1899, KLD: 2.3805, MC: 2.3001)\n",
      "Train Batch 50/110 - Loss: 7.0551 (Macro: 1.5265, Energy: 0.9883, KLD: 2.2381, MC: 2.3022)\n",
      "Train Batch 60/110 - Loss: 6.8600 (Macro: 1.3803, Energy: 0.9210, KLD: 2.2570, MC: 2.3016)\n",
      "Train Batch 70/110 - Loss: 6.9934 (Macro: 1.3734, Energy: 0.8777, KLD: 2.4378, MC: 2.3045)\n",
      "Train Batch 80/110 - Loss: 7.3163 (Macro: 1.4350, Energy: 1.0401, KLD: 2.5365, MC: 2.3047)\n",
      "Train Batch 90/110 - Loss: 6.7842 (Macro: 1.4758, Energy: 0.9826, KLD: 2.0241, MC: 2.3018)\n",
      "Train Batch 100/110 - Loss: 7.3192 (Macro: 1.6159, Energy: 1.1866, KLD: 2.2161, MC: 2.3006)\n",
      "Train Batch 110/110 - Loss: 6.6352 (Macro: 1.2177, Energy: 0.7768, KLD: 2.3414, MC: 2.2993)\n",
      "Training epoch complete. Average Loss: 7.0770\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0640\n",
      "\n",
      "Epoch 7/500\n",
      "Train Batch 10/110 - Loss: 7.1677 (Macro: 1.5742, Energy: 1.1777, KLD: 2.1149, MC: 2.3008)\n",
      "Train Batch 20/110 - Loss: 6.8677 (Macro: 1.4599, Energy: 0.9695, KLD: 2.1345, MC: 2.3038)\n",
      "Train Batch 30/110 - Loss: 7.0404 (Macro: 1.4381, Energy: 0.9931, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4477 (Macro: 1.5626, Energy: 1.2028, KLD: 2.3805, MC: 2.3017)\n",
      "Train Batch 50/110 - Loss: 7.1026 (Macro: 1.4950, Energy: 1.0664, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.8993 (Macro: 1.3801, Energy: 0.9604, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 6.9755 (Macro: 1.3765, Energy: 0.8590, KLD: 2.4378, MC: 2.3023)\n",
      "Train Batch 80/110 - Loss: 7.2989 (Macro: 1.4275, Energy: 1.0325, KLD: 2.5365, MC: 2.3024)\n",
      "Train Batch 90/110 - Loss: 6.7512 (Macro: 1.4652, Energy: 0.9593, KLD: 2.0241, MC: 2.3026)\n",
      "Train Batch 100/110 - Loss: 7.2802 (Macro: 1.5922, Energy: 1.1694, KLD: 2.2161, MC: 2.3025)\n",
      "Train Batch 110/110 - Loss: 6.6371 (Macro: 1.2481, Energy: 0.7518, KLD: 2.3414, MC: 2.2959)\n",
      "Training epoch complete. Average Loss: 7.0862\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0609\n",
      "\n",
      "Epoch 8/500\n",
      "Train Batch 10/110 - Loss: 7.0898 (Macro: 1.5756, Energy: 1.1001, KLD: 2.1149, MC: 2.2992)\n",
      "Train Batch 20/110 - Loss: 6.8995 (Macro: 1.4909, Energy: 0.9725, KLD: 2.1345, MC: 2.3016)\n",
      "Train Batch 30/110 - Loss: 7.0748 (Macro: 1.4476, Energy: 1.0187, KLD: 2.3073, MC: 2.3012)\n",
      "Train Batch 40/110 - Loss: 7.3835 (Macro: 1.5566, Energy: 1.1453, KLD: 2.3805, MC: 2.3012)\n",
      "Train Batch 50/110 - Loss: 7.1271 (Macro: 1.5252, Energy: 1.0614, KLD: 2.2381, MC: 2.3024)\n",
      "Train Batch 60/110 - Loss: 6.9062 (Macro: 1.3951, Energy: 0.9519, KLD: 2.2570, MC: 2.3022)\n",
      "Train Batch 70/110 - Loss: 6.9826 (Macro: 1.3838, Energy: 0.8587, KLD: 2.4378, MC: 2.3023)\n",
      "Train Batch 80/110 - Loss: 7.2094 (Macro: 1.4116, Energy: 0.9586, KLD: 2.5365, MC: 2.3027)\n",
      "Train Batch 90/110 - Loss: 6.7782 (Macro: 1.4833, Energy: 0.9689, KLD: 2.0241, MC: 2.3019)\n",
      "Train Batch 100/110 - Loss: 7.3385 (Macro: 1.6218, Energy: 1.1987, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.5503 (Macro: 1.1883, Energy: 0.7233, KLD: 2.3414, MC: 2.2973)\n",
      "Training epoch complete. Average Loss: 7.0802\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0619\n",
      "\n",
      "Epoch 9/500\n",
      "Train Batch 10/110 - Loss: 7.1308 (Macro: 1.5578, Energy: 1.1573, KLD: 2.1149, MC: 2.3008)\n",
      "Train Batch 20/110 - Loss: 6.9132 (Macro: 1.4865, Energy: 0.9920, KLD: 2.1345, MC: 2.3003)\n",
      "Train Batch 30/110 - Loss: 7.0581 (Macro: 1.4397, Energy: 1.0093, KLD: 2.3073, MC: 2.3018)\n",
      "Train Batch 40/110 - Loss: 7.3754 (Macro: 1.5271, Energy: 1.1644, KLD: 2.3805, MC: 2.3034)\n",
      "Train Batch 50/110 - Loss: 7.0862 (Macro: 1.5012, Energy: 1.0436, KLD: 2.2381, MC: 2.3033)\n",
      "Train Batch 60/110 - Loss: 6.8453 (Macro: 1.3736, Energy: 0.9137, KLD: 2.2570, MC: 2.3010)\n",
      "Train Batch 70/110 - Loss: 6.9349 (Macro: 1.3617, Energy: 0.8332, KLD: 2.4378, MC: 2.3023)\n",
      "Train Batch 80/110 - Loss: 7.3011 (Macro: 1.4451, Energy: 1.0172, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.8151 (Macro: 1.5031, Energy: 0.9844, KLD: 2.0241, MC: 2.3036)\n",
      "Train Batch 100/110 - Loss: 7.3025 (Macro: 1.6021, Energy: 1.1824, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.6252 (Macro: 1.2087, Energy: 0.7754, KLD: 2.3414, MC: 2.2998)\n",
      "Training epoch complete. Average Loss: 7.0819\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0596\n",
      "\n",
      "Epoch 10/500\n",
      "Train Batch 10/110 - Loss: 7.1191 (Macro: 1.5689, Energy: 1.1361, KLD: 2.1149, MC: 2.2991)\n",
      "Train Batch 20/110 - Loss: 6.8791 (Macro: 1.4696, Energy: 0.9744, KLD: 2.1345, MC: 2.3007)\n",
      "Train Batch 30/110 - Loss: 7.0613 (Macro: 1.4481, Energy: 1.0035, KLD: 2.3073, MC: 2.3024)\n",
      "Train Batch 40/110 - Loss: 7.5461 (Macro: 1.5691, Energy: 1.2944, KLD: 2.3805, MC: 2.3020)\n",
      "Train Batch 50/110 - Loss: 7.0673 (Macro: 1.5075, Energy: 1.0192, KLD: 2.2381, MC: 2.3026)\n",
      "Train Batch 60/110 - Loss: 6.9176 (Macro: 1.3769, Energy: 0.9824, KLD: 2.2570, MC: 2.3013)\n",
      "Train Batch 70/110 - Loss: 6.9787 (Macro: 1.3567, Energy: 0.8813, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.3312 (Macro: 1.4216, Energy: 1.0702, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.7728 (Macro: 1.4733, Energy: 0.9733, KLD: 2.0241, MC: 2.3022)\n",
      "Train Batch 100/110 - Loss: 7.3471 (Macro: 1.6225, Energy: 1.2055, KLD: 2.2161, MC: 2.3030)\n",
      "Train Batch 110/110 - Loss: 6.5761 (Macro: 1.2396, Energy: 0.6979, KLD: 2.3414, MC: 2.2972)\n",
      "Training epoch complete. Average Loss: 7.0795\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0687\n",
      "\n",
      "Epoch 11/500\n",
      "Train Batch 10/110 - Loss: 7.1060 (Macro: 1.5849, Energy: 1.1065, KLD: 2.1149, MC: 2.2998)\n",
      "Train Batch 20/110 - Loss: 6.8466 (Macro: 1.4617, Energy: 0.9468, KLD: 2.1345, MC: 2.3036)\n",
      "Train Batch 30/110 - Loss: 7.1140 (Macro: 1.4800, Energy: 1.0244, KLD: 2.3073, MC: 2.3023)\n",
      "Train Batch 40/110 - Loss: 7.4577 (Macro: 1.5584, Energy: 1.2169, KLD: 2.3805, MC: 2.3019)\n",
      "Train Batch 50/110 - Loss: 7.0254 (Macro: 1.5070, Energy: 0.9788, KLD: 2.2381, MC: 2.3015)\n",
      "Train Batch 60/110 - Loss: 6.9082 (Macro: 1.3867, Energy: 0.9640, KLD: 2.2570, MC: 2.3004)\n",
      "Train Batch 70/110 - Loss: 6.9820 (Macro: 1.3517, Energy: 0.8876, KLD: 2.4378, MC: 2.3050)\n",
      "Train Batch 80/110 - Loss: 7.3165 (Macro: 1.4270, Energy: 1.0515, KLD: 2.5365, MC: 2.3015)\n",
      "Train Batch 90/110 - Loss: 6.8108 (Macro: 1.4840, Energy: 1.0001, KLD: 2.0241, MC: 2.3026)\n",
      "Train Batch 100/110 - Loss: 7.2600 (Macro: 1.6055, Energy: 1.1370, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.5851 (Macro: 1.2060, Energy: 0.7391, KLD: 2.3414, MC: 2.2987)\n",
      "Training epoch complete. Average Loss: 7.0852\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0528\n",
      "\n",
      "Epoch 12/500\n",
      "Train Batch 10/110 - Loss: 7.1271 (Macro: 1.5775, Energy: 1.1361, KLD: 2.1149, MC: 2.2985)\n",
      "Train Batch 20/110 - Loss: 6.8835 (Macro: 1.4763, Energy: 0.9709, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0485 (Macro: 1.4576, Energy: 0.9834, KLD: 2.3073, MC: 2.3002)\n",
      "Train Batch 40/110 - Loss: 7.4449 (Macro: 1.5563, Energy: 1.2070, KLD: 2.3805, MC: 2.3011)\n",
      "Train Batch 50/110 - Loss: 7.0012 (Macro: 1.4955, Energy: 0.9653, KLD: 2.2381, MC: 2.3023)\n",
      "Train Batch 60/110 - Loss: 6.9272 (Macro: 1.3904, Energy: 0.9780, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 6.9229 (Macro: 1.3609, Energy: 0.8220, KLD: 2.4378, MC: 2.3022)\n",
      "Train Batch 80/110 - Loss: 7.3555 (Macro: 1.4353, Energy: 1.0817, KLD: 2.5365, MC: 2.3020)\n",
      "Train Batch 90/110 - Loss: 6.7647 (Macro: 1.4776, Energy: 0.9631, KLD: 2.0241, MC: 2.2999)\n",
      "Train Batch 100/110 - Loss: 7.3116 (Macro: 1.6001, Energy: 1.1938, KLD: 2.2161, MC: 2.3016)\n",
      "Train Batch 110/110 - Loss: 6.6368 (Macro: 1.2379, Energy: 0.7577, KLD: 2.3414, MC: 2.2999)\n",
      "Training epoch complete. Average Loss: 7.0840\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0506\n",
      "\n",
      "Epoch 13/500\n",
      "Train Batch 10/110 - Loss: 7.1305 (Macro: 1.5984, Energy: 1.1187, KLD: 2.1149, MC: 2.2984)\n",
      "Train Batch 20/110 - Loss: 6.8480 (Macro: 1.4700, Energy: 0.9414, KLD: 2.1345, MC: 2.3022)\n",
      "Train Batch 30/110 - Loss: 7.1613 (Macro: 1.4742, Energy: 1.0771, KLD: 2.3073, MC: 2.3026)\n",
      "Train Batch 40/110 - Loss: 7.4961 (Macro: 1.5708, Energy: 1.2434, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 6.9858 (Macro: 1.4770, Energy: 0.9676, KLD: 2.2381, MC: 2.3031)\n",
      "Train Batch 60/110 - Loss: 6.8676 (Macro: 1.3850, Energy: 0.9240, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9006 (Macro: 1.3331, Energy: 0.8262, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.3084 (Macro: 1.4099, Energy: 1.0585, KLD: 2.5365, MC: 2.3035)\n",
      "Train Batch 90/110 - Loss: 6.8361 (Macro: 1.4702, Energy: 1.0399, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.3183 (Macro: 1.6051, Energy: 1.1952, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.5834 (Macro: 1.2351, Energy: 0.7055, KLD: 2.3414, MC: 2.3014)\n",
      "Training epoch complete. Average Loss: 7.0733\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0554\n",
      "\n",
      "Epoch 14/500\n",
      "Train Batch 10/110 - Loss: 7.1243 (Macro: 1.5861, Energy: 1.1261, KLD: 2.1149, MC: 2.2972)\n",
      "Train Batch 20/110 - Loss: 6.8780 (Macro: 1.4847, Energy: 0.9576, KLD: 2.1345, MC: 2.3012)\n",
      "Train Batch 30/110 - Loss: 7.0817 (Macro: 1.4541, Energy: 1.0172, KLD: 2.3073, MC: 2.3030)\n",
      "Train Batch 40/110 - Loss: 7.4473 (Macro: 1.5450, Energy: 1.2205, KLD: 2.3805, MC: 2.3012)\n",
      "Train Batch 50/110 - Loss: 7.0403 (Macro: 1.4870, Energy: 1.0140, KLD: 2.2381, MC: 2.3013)\n",
      "Train Batch 60/110 - Loss: 6.9359 (Macro: 1.3869, Energy: 0.9909, KLD: 2.2570, MC: 2.3010)\n",
      "Train Batch 70/110 - Loss: 6.9521 (Macro: 1.3628, Energy: 0.8486, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.3010 (Macro: 1.4138, Energy: 1.0465, KLD: 2.5365, MC: 2.3042)\n",
      "Train Batch 90/110 - Loss: 6.7743 (Macro: 1.4738, Energy: 0.9758, KLD: 2.0241, MC: 2.3007)\n",
      "Train Batch 100/110 - Loss: 7.3194 (Macro: 1.6119, Energy: 1.1896, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.6403 (Macro: 1.2160, Energy: 0.7863, KLD: 2.3414, MC: 2.2966)\n",
      "Training epoch complete. Average Loss: 7.0840\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0559\n",
      "\n",
      "Epoch 15/500\n",
      "Train Batch 10/110 - Loss: 7.1002 (Macro: 1.5876, Energy: 1.0992, KLD: 2.1149, MC: 2.2984)\n",
      "Train Batch 20/110 - Loss: 6.8743 (Macro: 1.4907, Energy: 0.9474, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.0647 (Macro: 1.4305, Energy: 1.0238, KLD: 2.3073, MC: 2.3031)\n",
      "Train Batch 40/110 - Loss: 7.4752 (Macro: 1.5720, Energy: 1.2211, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0796 (Macro: 1.4977, Energy: 1.0410, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.9259 (Macro: 1.3926, Energy: 0.9743, KLD: 2.2570, MC: 2.3019)\n",
      "Train Batch 70/110 - Loss: 6.9310 (Macro: 1.3462, Energy: 0.8431, KLD: 2.4378, MC: 2.3039)\n",
      "Train Batch 80/110 - Loss: 7.3002 (Macro: 1.4182, Energy: 1.0413, KLD: 2.5365, MC: 2.3042)\n",
      "Train Batch 90/110 - Loss: 6.7615 (Macro: 1.4869, Energy: 0.9474, KLD: 2.0241, MC: 2.3031)\n",
      "Train Batch 100/110 - Loss: 7.2799 (Macro: 1.6061, Energy: 1.1551, KLD: 2.2161, MC: 2.3026)\n",
      "Train Batch 110/110 - Loss: 6.6304 (Macro: 1.2715, Energy: 0.7190, KLD: 2.3414, MC: 2.2985)\n",
      "Training epoch complete. Average Loss: 7.0813\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0544\n",
      "\n",
      "Epoch 16/500\n",
      "Train Batch 10/110 - Loss: 7.1246 (Macro: 1.5453, Energy: 1.1643, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.8935 (Macro: 1.4946, Energy: 0.9632, KLD: 2.1345, MC: 2.3011)\n",
      "Train Batch 30/110 - Loss: 7.0896 (Macro: 1.4522, Energy: 1.0281, KLD: 2.3073, MC: 2.3020)\n",
      "Train Batch 40/110 - Loss: 7.5106 (Macro: 1.5691, Energy: 1.2591, KLD: 2.3805, MC: 2.3018)\n",
      "Train Batch 50/110 - Loss: 7.0658 (Macro: 1.5153, Energy: 1.0092, KLD: 2.2381, MC: 2.3033)\n",
      "Train Batch 60/110 - Loss: 6.9133 (Macro: 1.3898, Energy: 0.9654, KLD: 2.2570, MC: 2.3010)\n",
      "Train Batch 70/110 - Loss: 6.9059 (Macro: 1.3522, Energy: 0.8129, KLD: 2.4378, MC: 2.3031)\n",
      "Train Batch 80/110 - Loss: 7.2456 (Macro: 1.4160, Energy: 0.9910, KLD: 2.5365, MC: 2.3020)\n",
      "Train Batch 90/110 - Loss: 6.7415 (Macro: 1.4767, Energy: 0.9395, KLD: 2.0241, MC: 2.3013)\n",
      "Train Batch 100/110 - Loss: 7.3144 (Macro: 1.6079, Energy: 1.1888, KLD: 2.2161, MC: 2.3016)\n",
      "Train Batch 110/110 - Loss: 6.6149 (Macro: 1.2166, Energy: 0.7564, KLD: 2.3414, MC: 2.3006)\n",
      "Training epoch complete. Average Loss: 7.0835\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0681\n",
      "\n",
      "Epoch 17/500\n",
      "Train Batch 10/110 - Loss: 7.1858 (Macro: 1.5824, Energy: 1.1887, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.9200 (Macro: 1.4914, Energy: 0.9912, KLD: 2.1345, MC: 2.3029)\n",
      "Train Batch 30/110 - Loss: 7.1331 (Macro: 1.4751, Energy: 1.0478, KLD: 2.3073, MC: 2.3030)\n",
      "Train Batch 40/110 - Loss: 7.4726 (Macro: 1.5684, Energy: 1.2222, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.1476 (Macro: 1.5109, Energy: 1.0963, KLD: 2.2381, MC: 2.3023)\n",
      "Train Batch 60/110 - Loss: 6.9581 (Macro: 1.3899, Energy: 1.0104, KLD: 2.2570, MC: 2.3008)\n",
      "Train Batch 70/110 - Loss: 6.9830 (Macro: 1.3633, Energy: 0.8766, KLD: 2.4378, MC: 2.3053)\n",
      "Train Batch 80/110 - Loss: 7.3050 (Macro: 1.4191, Energy: 1.0465, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.7801 (Macro: 1.4674, Energy: 0.9855, KLD: 2.0241, MC: 2.3031)\n",
      "Train Batch 100/110 - Loss: 7.2921 (Macro: 1.5894, Energy: 1.1843, KLD: 2.2161, MC: 2.3023)\n",
      "Train Batch 110/110 - Loss: 6.6009 (Macro: 1.2179, Energy: 0.7439, KLD: 2.3414, MC: 2.2978)\n",
      "Training epoch complete. Average Loss: 7.0802\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0663\n",
      "\n",
      "Epoch 18/500\n",
      "Train Batch 10/110 - Loss: 7.1303 (Macro: 1.6060, Energy: 1.1088, KLD: 2.1149, MC: 2.3006)\n",
      "Train Batch 20/110 - Loss: 6.8975 (Macro: 1.4797, Energy: 0.9814, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.1195 (Macro: 1.4595, Energy: 1.0493, KLD: 2.3073, MC: 2.3034)\n",
      "Train Batch 40/110 - Loss: 7.4912 (Macro: 1.5545, Energy: 1.2542, KLD: 2.3805, MC: 2.3020)\n",
      "Train Batch 50/110 - Loss: 7.1018 (Macro: 1.5120, Energy: 1.0478, KLD: 2.2381, MC: 2.3040)\n",
      "Train Batch 60/110 - Loss: 6.9744 (Macro: 1.4088, Energy: 1.0055, KLD: 2.2570, MC: 2.3030)\n",
      "Train Batch 70/110 - Loss: 6.9475 (Macro: 1.3644, Energy: 0.8449, KLD: 2.4378, MC: 2.3004)\n",
      "Train Batch 80/110 - Loss: 7.2838 (Macro: 1.4108, Energy: 1.0319, KLD: 2.5365, MC: 2.3047)\n",
      "Train Batch 90/110 - Loss: 6.8037 (Macro: 1.4589, Energy: 1.0202, KLD: 2.0241, MC: 2.3005)\n",
      "Train Batch 100/110 - Loss: 7.2617 (Macro: 1.5806, Energy: 1.1633, KLD: 2.2161, MC: 2.3016)\n",
      "Train Batch 110/110 - Loss: 6.6214 (Macro: 1.2473, Energy: 0.7330, KLD: 2.3414, MC: 2.2997)\n",
      "Training epoch complete. Average Loss: 7.0774\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0638\n",
      "\n",
      "Epoch 19/500\n",
      "Train Batch 10/110 - Loss: 7.1315 (Macro: 1.5708, Energy: 1.1446, KLD: 2.1149, MC: 2.3011)\n",
      "Train Batch 20/110 - Loss: 6.9035 (Macro: 1.4788, Energy: 0.9888, KLD: 2.1345, MC: 2.3014)\n",
      "Train Batch 30/110 - Loss: 7.0581 (Macro: 1.4485, Energy: 0.9984, KLD: 2.3073, MC: 2.3039)\n",
      "Train Batch 40/110 - Loss: 7.4922 (Macro: 1.5617, Energy: 1.2480, KLD: 2.3805, MC: 2.3020)\n",
      "Train Batch 50/110 - Loss: 7.0457 (Macro: 1.4884, Energy: 1.0145, KLD: 2.2381, MC: 2.3047)\n",
      "Train Batch 60/110 - Loss: 6.8863 (Macro: 1.3746, Energy: 0.9516, KLD: 2.2570, MC: 2.3030)\n",
      "Train Batch 70/110 - Loss: 6.9298 (Macro: 1.3636, Energy: 0.8246, KLD: 2.4378, MC: 2.3038)\n",
      "Train Batch 80/110 - Loss: 7.3363 (Macro: 1.4121, Energy: 1.0846, KLD: 2.5365, MC: 2.3030)\n",
      "Train Batch 90/110 - Loss: 6.8175 (Macro: 1.4671, Energy: 1.0235, KLD: 2.0241, MC: 2.3028)\n",
      "Train Batch 100/110 - Loss: 7.2642 (Macro: 1.6050, Energy: 1.1392, KLD: 2.2161, MC: 2.3039)\n",
      "Train Batch 110/110 - Loss: 6.6060 (Macro: 1.2167, Energy: 0.7480, KLD: 2.3414, MC: 2.3000)\n",
      "Training epoch complete. Average Loss: 7.0829\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0660\n",
      "\n",
      "Epoch 20/500\n",
      "Train Batch 10/110 - Loss: 7.1288 (Macro: 1.5846, Energy: 1.1312, KLD: 2.1149, MC: 2.2980)\n",
      "Train Batch 20/110 - Loss: 6.8624 (Macro: 1.4773, Energy: 0.9499, KLD: 2.1345, MC: 2.3008)\n",
      "Train Batch 30/110 - Loss: 7.0537 (Macro: 1.4432, Energy: 1.0005, KLD: 2.3073, MC: 2.3028)\n",
      "Train Batch 40/110 - Loss: 7.4791 (Macro: 1.5524, Energy: 1.2458, KLD: 2.3805, MC: 2.3004)\n",
      "Train Batch 50/110 - Loss: 7.0930 (Macro: 1.5020, Energy: 1.0496, KLD: 2.2381, MC: 2.3033)\n",
      "Train Batch 60/110 - Loss: 6.8005 (Macro: 1.3603, Energy: 0.8814, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 6.9332 (Macro: 1.3601, Energy: 0.8318, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.3195 (Macro: 1.4042, Energy: 1.0751, KLD: 2.5365, MC: 2.3038)\n",
      "Train Batch 90/110 - Loss: 6.8097 (Macro: 1.4816, Energy: 1.0025, KLD: 2.0241, MC: 2.3015)\n",
      "Train Batch 100/110 - Loss: 7.2738 (Macro: 1.5940, Energy: 1.1618, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.6973 (Macro: 1.2118, Energy: 0.8459, KLD: 2.3414, MC: 2.2981)\n",
      "Training epoch complete. Average Loss: 7.0759\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0577\n",
      "\n",
      "Epoch 21/500\n",
      "Train Batch 10/110 - Loss: 7.0504 (Macro: 1.5647, Energy: 1.0686, KLD: 2.1149, MC: 2.3022)\n",
      "Train Batch 20/110 - Loss: 6.9008 (Macro: 1.4976, Energy: 0.9659, KLD: 2.1345, MC: 2.3029)\n",
      "Train Batch 30/110 - Loss: 7.0802 (Macro: 1.4677, Energy: 1.0030, KLD: 2.3073, MC: 2.3022)\n",
      "Train Batch 40/110 - Loss: 7.4303 (Macro: 1.5138, Energy: 1.2330, KLD: 2.3805, MC: 2.3030)\n",
      "Train Batch 50/110 - Loss: 6.9757 (Macro: 1.4628, Energy: 0.9735, KLD: 2.2381, MC: 2.3013)\n",
      "Train Batch 60/110 - Loss: 6.8985 (Macro: 1.3829, Energy: 0.9575, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9497 (Macro: 1.3723, Energy: 0.8359, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.2968 (Macro: 1.4314, Energy: 1.0258, KLD: 2.5365, MC: 2.3031)\n",
      "Train Batch 90/110 - Loss: 6.7793 (Macro: 1.4943, Energy: 0.9584, KLD: 2.0241, MC: 2.3026)\n",
      "Train Batch 100/110 - Loss: 7.3038 (Macro: 1.6064, Energy: 1.1815, KLD: 2.2161, MC: 2.2998)\n",
      "Train Batch 110/110 - Loss: 6.6002 (Macro: 1.2035, Energy: 0.7565, KLD: 2.3414, MC: 2.2988)\n",
      "Training epoch complete. Average Loss: 7.0743\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0607\n",
      "\n",
      "Epoch 22/500\n",
      "Train Batch 10/110 - Loss: 7.0764 (Macro: 1.5637, Energy: 1.0962, KLD: 2.1149, MC: 2.3015)\n",
      "Train Batch 20/110 - Loss: 6.8727 (Macro: 1.4914, Energy: 0.9446, KLD: 2.1345, MC: 2.3022)\n",
      "Train Batch 30/110 - Loss: 7.0852 (Macro: 1.4594, Energy: 1.0163, KLD: 2.3073, MC: 2.3023)\n",
      "Train Batch 40/110 - Loss: 7.4283 (Macro: 1.5772, Energy: 1.1696, KLD: 2.3805, MC: 2.3010)\n",
      "Train Batch 50/110 - Loss: 7.0806 (Macro: 1.5039, Energy: 1.0365, KLD: 2.2381, MC: 2.3022)\n",
      "Train Batch 60/110 - Loss: 6.9341 (Macro: 1.3777, Energy: 0.9981, KLD: 2.2570, MC: 2.3012)\n",
      "Train Batch 70/110 - Loss: 6.9531 (Macro: 1.3561, Energy: 0.8565, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.3251 (Macro: 1.4315, Energy: 1.0554, KLD: 2.5365, MC: 2.3017)\n",
      "Train Batch 90/110 - Loss: 6.7765 (Macro: 1.4618, Energy: 0.9897, KLD: 2.0241, MC: 2.3008)\n",
      "Train Batch 100/110 - Loss: 7.2682 (Macro: 1.6046, Energy: 1.1468, KLD: 2.2161, MC: 2.3006)\n",
      "Train Batch 110/110 - Loss: 6.5730 (Macro: 1.1987, Energy: 0.7340, KLD: 2.3414, MC: 2.2989)\n",
      "Training epoch complete. Average Loss: 7.0774\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0632\n",
      "\n",
      "Epoch 23/500\n",
      "Train Batch 10/110 - Loss: 7.0872 (Macro: 1.5726, Energy: 1.0989, KLD: 2.1149, MC: 2.3007)\n",
      "Train Batch 20/110 - Loss: 6.8929 (Macro: 1.4856, Energy: 0.9725, KLD: 2.1345, MC: 2.3003)\n",
      "Train Batch 30/110 - Loss: 7.1165 (Macro: 1.4588, Energy: 1.0475, KLD: 2.3073, MC: 2.3029)\n",
      "Train Batch 40/110 - Loss: 7.4157 (Macro: 1.5408, Energy: 1.1932, KLD: 2.3805, MC: 2.3011)\n",
      "Train Batch 50/110 - Loss: 7.0551 (Macro: 1.5036, Energy: 1.0091, KLD: 2.2381, MC: 2.3043)\n",
      "Train Batch 60/110 - Loss: 6.9313 (Macro: 1.3726, Energy: 0.9989, KLD: 2.2570, MC: 2.3028)\n",
      "Train Batch 70/110 - Loss: 7.0298 (Macro: 1.3476, Energy: 0.9395, KLD: 2.4378, MC: 2.3049)\n",
      "Train Batch 80/110 - Loss: 7.3234 (Macro: 1.4227, Energy: 1.0604, KLD: 2.5365, MC: 2.3038)\n",
      "Train Batch 90/110 - Loss: 6.8083 (Macro: 1.4763, Energy: 1.0060, KLD: 2.0241, MC: 2.3018)\n",
      "Train Batch 100/110 - Loss: 7.3279 (Macro: 1.5884, Energy: 1.2208, KLD: 2.2161, MC: 2.3027)\n",
      "Train Batch 110/110 - Loss: 6.6788 (Macro: 1.2382, Energy: 0.7977, KLD: 2.3414, MC: 2.3016)\n",
      "Training epoch complete. Average Loss: 7.0875\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0588\n",
      "\n",
      "Epoch 24/500\n",
      "Train Batch 10/110 - Loss: 7.1177 (Macro: 1.5962, Energy: 1.1064, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.9425 (Macro: 1.4893, Energy: 1.0175, KLD: 2.1345, MC: 2.3012)\n",
      "Train Batch 30/110 - Loss: 7.0555 (Macro: 1.4495, Energy: 0.9963, KLD: 2.3073, MC: 2.3024)\n",
      "Train Batch 40/110 - Loss: 7.4515 (Macro: 1.5638, Energy: 1.2069, KLD: 2.3805, MC: 2.3003)\n",
      "Train Batch 50/110 - Loss: 7.0825 (Macro: 1.4842, Energy: 1.0567, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.8813 (Macro: 1.3933, Energy: 0.9289, KLD: 2.2570, MC: 2.3021)\n",
      "Train Batch 70/110 - Loss: 6.9420 (Macro: 1.3454, Energy: 0.8561, KLD: 2.4378, MC: 2.3027)\n",
      "Train Batch 80/110 - Loss: 7.3171 (Macro: 1.4310, Energy: 1.0470, KLD: 2.5365, MC: 2.3027)\n",
      "Train Batch 90/110 - Loss: 6.8097 (Macro: 1.4449, Energy: 1.0388, KLD: 2.0241, MC: 2.3019)\n",
      "Train Batch 100/110 - Loss: 7.2512 (Macro: 1.6062, Energy: 1.1292, KLD: 2.2161, MC: 2.2997)\n",
      "Train Batch 110/110 - Loss: 6.6083 (Macro: 1.2048, Energy: 0.7617, KLD: 2.3414, MC: 2.3005)\n",
      "Training epoch complete. Average Loss: 7.0755\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0761\n",
      "\n",
      "Epoch 25/500\n",
      "Train Batch 10/110 - Loss: 7.0851 (Macro: 1.5792, Energy: 1.0905, KLD: 2.1149, MC: 2.3004)\n",
      "Train Batch 20/110 - Loss: 6.9208 (Macro: 1.4921, Energy: 0.9933, KLD: 2.1345, MC: 2.3009)\n",
      "Train Batch 30/110 - Loss: 7.0665 (Macro: 1.4618, Energy: 0.9966, KLD: 2.3073, MC: 2.3008)\n",
      "Train Batch 40/110 - Loss: 7.4508 (Macro: 1.5494, Energy: 1.2199, KLD: 2.3805, MC: 2.3010)\n",
      "Train Batch 50/110 - Loss: 7.0673 (Macro: 1.4994, Energy: 1.0276, KLD: 2.2381, MC: 2.3023)\n",
      "Train Batch 60/110 - Loss: 6.9397 (Macro: 1.3901, Energy: 0.9898, KLD: 2.2570, MC: 2.3029)\n",
      "Train Batch 70/110 - Loss: 6.9652 (Macro: 1.3472, Energy: 0.8758, KLD: 2.4378, MC: 2.3045)\n",
      "Train Batch 80/110 - Loss: 7.3002 (Macro: 1.4175, Energy: 1.0435, KLD: 2.5365, MC: 2.3027)\n",
      "Train Batch 90/110 - Loss: 6.7208 (Macro: 1.4681, Energy: 0.9270, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.3189 (Macro: 1.5823, Energy: 1.2199, KLD: 2.2161, MC: 2.3007)\n",
      "Train Batch 110/110 - Loss: 6.5978 (Macro: 1.2449, Energy: 0.7143, KLD: 2.3414, MC: 2.2973)\n",
      "Training epoch complete. Average Loss: 7.0837\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0635\n",
      "\n",
      "Epoch 26/500\n",
      "Train Batch 10/110 - Loss: 7.1211 (Macro: 1.5855, Energy: 1.1203, KLD: 2.1149, MC: 2.3004)\n",
      "Train Batch 20/110 - Loss: 6.9286 (Macro: 1.4878, Energy: 1.0034, KLD: 2.1345, MC: 2.3029)\n",
      "Train Batch 30/110 - Loss: 7.0994 (Macro: 1.4498, Energy: 1.0399, KLD: 2.3073, MC: 2.3024)\n",
      "Train Batch 40/110 - Loss: 7.5053 (Macro: 1.5819, Energy: 1.2425, KLD: 2.3805, MC: 2.3004)\n",
      "Train Batch 50/110 - Loss: 7.1009 (Macro: 1.4968, Energy: 1.0628, KLD: 2.2381, MC: 2.3033)\n",
      "Train Batch 60/110 - Loss: 6.8793 (Macro: 1.3791, Energy: 0.9429, KLD: 2.2570, MC: 2.3003)\n",
      "Train Batch 70/110 - Loss: 6.9830 (Macro: 1.3548, Energy: 0.8851, KLD: 2.4378, MC: 2.3053)\n",
      "Train Batch 80/110 - Loss: 7.3232 (Macro: 1.4237, Energy: 1.0598, KLD: 2.5365, MC: 2.3032)\n",
      "Train Batch 90/110 - Loss: 6.7965 (Macro: 1.4826, Energy: 0.9895, KLD: 2.0241, MC: 2.3003)\n",
      "Train Batch 100/110 - Loss: 7.3584 (Macro: 1.6161, Energy: 1.2237, KLD: 2.2161, MC: 2.3025)\n",
      "Train Batch 110/110 - Loss: 6.6292 (Macro: 1.2347, Energy: 0.7536, KLD: 2.3414, MC: 2.2996)\n",
      "Training epoch complete. Average Loss: 7.0796\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0705\n",
      "\n",
      "Epoch 27/500\n",
      "Train Batch 10/110 - Loss: 7.1290 (Macro: 1.5858, Energy: 1.1278, KLD: 2.1149, MC: 2.3005)\n",
      "Train Batch 20/110 - Loss: 6.9008 (Macro: 1.4884, Energy: 0.9776, KLD: 2.1345, MC: 2.3003)\n",
      "Train Batch 30/110 - Loss: 7.0365 (Macro: 1.4308, Energy: 0.9974, KLD: 2.3073, MC: 2.3010)\n",
      "Train Batch 40/110 - Loss: 7.4717 (Macro: 1.5541, Energy: 1.2357, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0258 (Macro: 1.4914, Energy: 0.9922, KLD: 2.2381, MC: 2.3042)\n",
      "Train Batch 60/110 - Loss: 6.8909 (Macro: 1.3929, Energy: 0.9390, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.9710 (Macro: 1.3809, Energy: 0.8490, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.3462 (Macro: 1.4224, Energy: 1.0834, KLD: 2.5365, MC: 2.3039)\n",
      "Train Batch 90/110 - Loss: 6.8023 (Macro: 1.5019, Energy: 0.9740, KLD: 2.0241, MC: 2.3023)\n",
      "Train Batch 100/110 - Loss: 7.2984 (Macro: 1.6194, Energy: 1.1601, KLD: 2.2161, MC: 2.3028)\n",
      "Train Batch 110/110 - Loss: 6.5986 (Macro: 1.2272, Energy: 0.7300, KLD: 2.3414, MC: 2.3000)\n",
      "Training epoch complete. Average Loss: 7.0838\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0696\n",
      "\n",
      "Epoch 28/500\n",
      "Train Batch 10/110 - Loss: 7.1578 (Macro: 1.5916, Energy: 1.1510, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.9107 (Macro: 1.4956, Energy: 0.9774, KLD: 2.1345, MC: 2.3032)\n",
      "Train Batch 30/110 - Loss: 7.1832 (Macro: 1.4740, Energy: 1.1003, KLD: 2.3073, MC: 2.3016)\n",
      "Train Batch 40/110 - Loss: 7.4643 (Macro: 1.5652, Energy: 1.2174, KLD: 2.3805, MC: 2.3012)\n",
      "Train Batch 50/110 - Loss: 7.0183 (Macro: 1.4960, Energy: 0.9812, KLD: 2.2381, MC: 2.3031)\n",
      "Train Batch 60/110 - Loss: 6.9496 (Macro: 1.3892, Energy: 1.0040, KLD: 2.2570, MC: 2.2994)\n",
      "Train Batch 70/110 - Loss: 6.9254 (Macro: 1.3676, Energy: 0.8152, KLD: 2.4378, MC: 2.3048)\n",
      "Train Batch 80/110 - Loss: 7.2664 (Macro: 1.4148, Energy: 1.0116, KLD: 2.5365, MC: 2.3035)\n",
      "Train Batch 90/110 - Loss: 6.7680 (Macro: 1.4553, Energy: 0.9870, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.2658 (Macro: 1.5910, Energy: 1.1553, KLD: 2.2161, MC: 2.3034)\n",
      "Train Batch 110/110 - Loss: 6.6559 (Macro: 1.2467, Energy: 0.7715, KLD: 2.3414, MC: 2.2963)\n",
      "Training epoch complete. Average Loss: 7.0789\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0535\n",
      "\n",
      "Epoch 29/500\n",
      "Train Batch 10/110 - Loss: 7.1619 (Macro: 1.5739, Energy: 1.1735, KLD: 2.1149, MC: 2.2995)\n",
      "Train Batch 20/110 - Loss: 6.9508 (Macro: 1.4711, Energy: 1.0442, KLD: 2.1345, MC: 2.3010)\n",
      "Train Batch 30/110 - Loss: 7.0889 (Macro: 1.4546, Energy: 1.0244, KLD: 2.3073, MC: 2.3026)\n",
      "Train Batch 40/110 - Loss: 7.4092 (Macro: 1.5668, Energy: 1.1614, KLD: 2.3805, MC: 2.3005)\n",
      "Train Batch 50/110 - Loss: 7.0322 (Macro: 1.4815, Energy: 1.0081, KLD: 2.2381, MC: 2.3046)\n",
      "Train Batch 60/110 - Loss: 6.8907 (Macro: 1.3678, Energy: 0.9640, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 6.9484 (Macro: 1.3732, Energy: 0.8327, KLD: 2.4378, MC: 2.3048)\n",
      "Train Batch 80/110 - Loss: 7.3253 (Macro: 1.4204, Energy: 1.0649, KLD: 2.5365, MC: 2.3036)\n",
      "Train Batch 90/110 - Loss: 6.7984 (Macro: 1.4764, Energy: 0.9959, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.2369 (Macro: 1.5811, Energy: 1.1378, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.6717 (Macro: 1.2504, Energy: 0.7786, KLD: 2.3414, MC: 2.3013)\n",
      "Training epoch complete. Average Loss: 7.0740\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0740\n",
      "\n",
      "Epoch 30/500\n",
      "Train Batch 10/110 - Loss: 7.0815 (Macro: 1.5724, Energy: 1.0934, KLD: 2.1149, MC: 2.3008)\n",
      "Train Batch 20/110 - Loss: 6.8849 (Macro: 1.4634, Energy: 0.9851, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.0731 (Macro: 1.4525, Energy: 1.0120, KLD: 2.3073, MC: 2.3013)\n",
      "Train Batch 40/110 - Loss: 7.5087 (Macro: 1.5525, Energy: 1.2743, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0148 (Macro: 1.4826, Energy: 0.9925, KLD: 2.2381, MC: 2.3017)\n",
      "Train Batch 60/110 - Loss: 6.9452 (Macro: 1.3980, Energy: 0.9894, KLD: 2.2570, MC: 2.3008)\n",
      "Train Batch 70/110 - Loss: 6.9453 (Macro: 1.3636, Energy: 0.8410, KLD: 2.4378, MC: 2.3030)\n",
      "Train Batch 80/110 - Loss: 7.2987 (Macro: 1.4433, Energy: 1.0143, KLD: 2.5365, MC: 2.3046)\n",
      "Train Batch 90/110 - Loss: 6.7847 (Macro: 1.4774, Energy: 0.9831, KLD: 2.0241, MC: 2.3002)\n",
      "Train Batch 100/110 - Loss: 7.3198 (Macro: 1.6159, Energy: 1.1859, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.6327 (Macro: 1.2299, Energy: 0.7625, KLD: 2.3414, MC: 2.2989)\n",
      "Training epoch complete. Average Loss: 7.0772\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0641\n",
      "\n",
      "Epoch 31/500\n",
      "Train Batch 10/110 - Loss: 7.0743 (Macro: 1.5598, Energy: 1.1004, KLD: 2.1149, MC: 2.2992)\n",
      "Train Batch 20/110 - Loss: 6.8823 (Macro: 1.4788, Energy: 0.9683, KLD: 2.1345, MC: 2.3007)\n",
      "Train Batch 30/110 - Loss: 7.1364 (Macro: 1.4704, Energy: 1.0548, KLD: 2.3073, MC: 2.3038)\n",
      "Train Batch 40/110 - Loss: 7.4516 (Macro: 1.5548, Energy: 1.2135, KLD: 2.3805, MC: 2.3028)\n",
      "Train Batch 50/110 - Loss: 7.0482 (Macro: 1.5151, Energy: 0.9923, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.8627 (Macro: 1.3692, Energy: 0.9365, KLD: 2.2570, MC: 2.2999)\n",
      "Train Batch 70/110 - Loss: 6.9477 (Macro: 1.3608, Energy: 0.8464, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.3090 (Macro: 1.4324, Energy: 1.0382, KLD: 2.5365, MC: 2.3018)\n",
      "Train Batch 90/110 - Loss: 6.7783 (Macro: 1.4775, Energy: 0.9741, KLD: 2.0241, MC: 2.3026)\n",
      "Train Batch 100/110 - Loss: 7.3025 (Macro: 1.5892, Energy: 1.1957, KLD: 2.2161, MC: 2.3014)\n",
      "Train Batch 110/110 - Loss: 6.6253 (Macro: 1.2390, Energy: 0.7482, KLD: 2.3414, MC: 2.2968)\n",
      "Training epoch complete. Average Loss: 7.0810\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0634\n",
      "\n",
      "Epoch 32/500\n",
      "Train Batch 10/110 - Loss: 7.1029 (Macro: 1.5609, Energy: 1.1269, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.8992 (Macro: 1.4786, Energy: 0.9830, KLD: 2.1345, MC: 2.3031)\n",
      "Train Batch 30/110 - Loss: 7.0721 (Macro: 1.4534, Energy: 1.0100, KLD: 2.3073, MC: 2.3015)\n",
      "Train Batch 40/110 - Loss: 7.4800 (Macro: 1.5606, Energy: 1.2362, KLD: 2.3805, MC: 2.3026)\n",
      "Train Batch 50/110 - Loss: 7.0740 (Macro: 1.4993, Energy: 1.0336, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.9254 (Macro: 1.3929, Energy: 0.9729, KLD: 2.2570, MC: 2.3026)\n",
      "Train Batch 70/110 - Loss: 6.9551 (Macro: 1.3912, Energy: 0.8228, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.2731 (Macro: 1.4358, Energy: 0.9974, KLD: 2.5365, MC: 2.3034)\n",
      "Train Batch 90/110 - Loss: 6.7407 (Macro: 1.4807, Energy: 0.9320, KLD: 2.0241, MC: 2.3039)\n",
      "Train Batch 100/110 - Loss: 7.2954 (Macro: 1.5970, Energy: 1.1797, KLD: 2.2161, MC: 2.3026)\n",
      "Train Batch 110/110 - Loss: 6.6011 (Macro: 1.2138, Energy: 0.7476, KLD: 2.3414, MC: 2.2984)\n",
      "Training epoch complete. Average Loss: 7.0813\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0641\n",
      "\n",
      "Epoch 33/500\n",
      "Train Batch 10/110 - Loss: 7.1724 (Macro: 1.5822, Energy: 1.1751, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.9465 (Macro: 1.4998, Energy: 1.0108, KLD: 2.1345, MC: 2.3015)\n",
      "Train Batch 30/110 - Loss: 7.1053 (Macro: 1.4597, Energy: 1.0348, KLD: 2.3073, MC: 2.3036)\n",
      "Train Batch 40/110 - Loss: 7.4890 (Macro: 1.5752, Energy: 1.2316, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0502 (Macro: 1.4949, Energy: 1.0134, KLD: 2.2381, MC: 2.3038)\n",
      "Train Batch 60/110 - Loss: 6.9397 (Macro: 1.4004, Energy: 0.9800, KLD: 2.2570, MC: 2.3023)\n",
      "Train Batch 70/110 - Loss: 6.9645 (Macro: 1.3693, Energy: 0.8541, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.2805 (Macro: 1.4303, Energy: 1.0114, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.7160 (Macro: 1.4710, Energy: 0.9191, KLD: 2.0241, MC: 2.3018)\n",
      "Train Batch 100/110 - Loss: 7.3433 (Macro: 1.6093, Energy: 1.2146, KLD: 2.2161, MC: 2.3033)\n",
      "Train Batch 110/110 - Loss: 6.6412 (Macro: 1.2476, Energy: 0.7537, KLD: 2.3414, MC: 2.2985)\n",
      "Training epoch complete. Average Loss: 7.0773\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0724\n",
      "\n",
      "Epoch 34/500\n",
      "Train Batch 10/110 - Loss: 7.1226 (Macro: 1.5892, Energy: 1.1197, KLD: 2.1149, MC: 2.2987)\n",
      "Train Batch 20/110 - Loss: 6.9149 (Macro: 1.5025, Energy: 0.9762, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0910 (Macro: 1.4438, Energy: 1.0373, KLD: 2.3073, MC: 2.3027)\n",
      "Train Batch 40/110 - Loss: 7.4457 (Macro: 1.5365, Energy: 1.2284, KLD: 2.3805, MC: 2.3002)\n",
      "Train Batch 50/110 - Loss: 7.0843 (Macro: 1.5154, Energy: 1.0279, KLD: 2.2381, MC: 2.3031)\n",
      "Train Batch 60/110 - Loss: 6.9332 (Macro: 1.4037, Energy: 0.9720, KLD: 2.2570, MC: 2.3004)\n",
      "Train Batch 70/110 - Loss: 7.0014 (Macro: 1.3519, Energy: 0.9082, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.2724 (Macro: 1.4324, Energy: 1.0011, KLD: 2.5365, MC: 2.3025)\n",
      "Train Batch 90/110 - Loss: 6.8236 (Macro: 1.4941, Energy: 1.0044, KLD: 2.0241, MC: 2.3011)\n",
      "Train Batch 100/110 - Loss: 7.2585 (Macro: 1.5990, Energy: 1.1426, KLD: 2.2161, MC: 2.3008)\n",
      "Train Batch 110/110 - Loss: 6.6737 (Macro: 1.2294, Energy: 0.8045, KLD: 2.3414, MC: 2.2984)\n",
      "Training epoch complete. Average Loss: 7.0854\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0688\n",
      "\n",
      "Epoch 35/500\n",
      "Train Batch 10/110 - Loss: 7.1654 (Macro: 1.5973, Energy: 1.1526, KLD: 2.1149, MC: 2.3006)\n",
      "Train Batch 20/110 - Loss: 6.9060 (Macro: 1.4891, Energy: 0.9794, KLD: 2.1345, MC: 2.3030)\n",
      "Train Batch 30/110 - Loss: 7.0520 (Macro: 1.4605, Energy: 0.9816, KLD: 2.3073, MC: 2.3026)\n",
      "Train Batch 40/110 - Loss: 7.5115 (Macro: 1.5713, Energy: 1.2572, KLD: 2.3805, MC: 2.3025)\n",
      "Train Batch 50/110 - Loss: 7.0181 (Macro: 1.4752, Energy: 1.0010, KLD: 2.2381, MC: 2.3038)\n",
      "Train Batch 60/110 - Loss: 6.8479 (Macro: 1.3735, Energy: 0.9159, KLD: 2.2570, MC: 2.3014)\n",
      "Train Batch 70/110 - Loss: 6.9533 (Macro: 1.3469, Energy: 0.8671, KLD: 2.4378, MC: 2.3015)\n",
      "Train Batch 80/110 - Loss: 7.3341 (Macro: 1.4204, Energy: 1.0725, KLD: 2.5365, MC: 2.3047)\n",
      "Train Batch 90/110 - Loss: 6.7793 (Macro: 1.4682, Energy: 0.9849, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3173 (Macro: 1.5995, Energy: 1.2001, KLD: 2.2161, MC: 2.3017)\n",
      "Train Batch 110/110 - Loss: 6.6109 (Macro: 1.2283, Energy: 0.7428, KLD: 2.3414, MC: 2.2983)\n",
      "Training epoch complete. Average Loss: 7.0794\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0791\n",
      "\n",
      "Epoch 36/500\n",
      "Train Batch 10/110 - Loss: 7.1453 (Macro: 1.5690, Energy: 1.1614, KLD: 2.1149, MC: 2.2999)\n",
      "Train Batch 20/110 - Loss: 6.8618 (Macro: 1.4810, Energy: 0.9446, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.0698 (Macro: 1.4527, Energy: 1.0071, KLD: 2.3073, MC: 2.3028)\n",
      "Train Batch 40/110 - Loss: 7.4552 (Macro: 1.5810, Energy: 1.1918, KLD: 2.3805, MC: 2.3018)\n",
      "Train Batch 50/110 - Loss: 7.0273 (Macro: 1.4923, Energy: 0.9945, KLD: 2.2381, MC: 2.3024)\n",
      "Train Batch 60/110 - Loss: 6.9389 (Macro: 1.3810, Energy: 0.9985, KLD: 2.2570, MC: 2.3023)\n",
      "Train Batch 70/110 - Loss: 6.9748 (Macro: 1.3625, Energy: 0.8712, KLD: 2.4378, MC: 2.3033)\n",
      "Train Batch 80/110 - Loss: 7.2705 (Macro: 1.4161, Energy: 1.0151, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.7672 (Macro: 1.4624, Energy: 0.9794, KLD: 2.0241, MC: 2.3013)\n",
      "Train Batch 100/110 - Loss: 7.2124 (Macro: 1.5882, Energy: 1.1064, KLD: 2.2161, MC: 2.3017)\n",
      "Train Batch 110/110 - Loss: 6.6471 (Macro: 1.2479, Energy: 0.7585, KLD: 2.3414, MC: 2.2993)\n",
      "Training epoch complete. Average Loss: 7.0769\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0695\n",
      "\n",
      "Epoch 37/500\n",
      "Train Batch 10/110 - Loss: 7.1163 (Macro: 1.5581, Energy: 1.1433, KLD: 2.1149, MC: 2.3000)\n",
      "Train Batch 20/110 - Loss: 6.8322 (Macro: 1.4796, Energy: 0.9167, KLD: 2.1345, MC: 2.3014)\n",
      "Train Batch 30/110 - Loss: 7.0955 (Macro: 1.4603, Energy: 1.0253, KLD: 2.3073, MC: 2.3026)\n",
      "Train Batch 40/110 - Loss: 7.4336 (Macro: 1.5478, Energy: 1.2033, KLD: 2.3805, MC: 2.3020)\n",
      "Train Batch 50/110 - Loss: 7.0572 (Macro: 1.4967, Energy: 1.0197, KLD: 2.2381, MC: 2.3027)\n",
      "Train Batch 60/110 - Loss: 6.9054 (Macro: 1.3851, Energy: 0.9625, KLD: 2.2570, MC: 2.3007)\n",
      "Train Batch 70/110 - Loss: 6.9206 (Macro: 1.3537, Energy: 0.8253, KLD: 2.4378, MC: 2.3039)\n",
      "Train Batch 80/110 - Loss: 7.3406 (Macro: 1.4308, Energy: 1.0694, KLD: 2.5365, MC: 2.3039)\n",
      "Train Batch 90/110 - Loss: 6.7785 (Macro: 1.4670, Energy: 0.9839, KLD: 2.0241, MC: 2.3035)\n",
      "Train Batch 100/110 - Loss: 7.2955 (Macro: 1.5956, Energy: 1.1816, KLD: 2.2161, MC: 2.3022)\n",
      "Train Batch 110/110 - Loss: 6.6070 (Macro: 1.2232, Energy: 0.7445, KLD: 2.3414, MC: 2.2979)\n",
      "Training epoch complete. Average Loss: 7.0783\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0579\n",
      "\n",
      "Epoch 38/500\n",
      "Train Batch 10/110 - Loss: 7.1090 (Macro: 1.5601, Energy: 1.1344, KLD: 2.1149, MC: 2.2995)\n",
      "Train Batch 20/110 - Loss: 6.9087 (Macro: 1.4955, Energy: 0.9763, KLD: 2.1345, MC: 2.3024)\n",
      "Train Batch 30/110 - Loss: 7.0665 (Macro: 1.4547, Energy: 1.0012, KLD: 2.3073, MC: 2.3034)\n",
      "Train Batch 40/110 - Loss: 7.4173 (Macro: 1.5562, Energy: 1.1789, KLD: 2.3805, MC: 2.3017)\n",
      "Train Batch 50/110 - Loss: 7.0434 (Macro: 1.5103, Energy: 0.9919, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.8819 (Macro: 1.3988, Energy: 0.9243, KLD: 2.2570, MC: 2.3017)\n",
      "Train Batch 70/110 - Loss: 6.9277 (Macro: 1.3667, Energy: 0.8195, KLD: 2.4378, MC: 2.3038)\n",
      "Train Batch 80/110 - Loss: 7.2916 (Macro: 1.4185, Energy: 1.0341, KLD: 2.5365, MC: 2.3025)\n",
      "Train Batch 90/110 - Loss: 6.7695 (Macro: 1.4729, Energy: 0.9694, KLD: 2.0241, MC: 2.3032)\n",
      "Train Batch 100/110 - Loss: 7.3247 (Macro: 1.6043, Energy: 1.2025, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.6721 (Macro: 1.2615, Energy: 0.7705, KLD: 2.3414, MC: 2.2987)\n",
      "Training epoch complete. Average Loss: 7.0813\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0585\n",
      "\n",
      "Epoch 39/500\n",
      "Train Batch 10/110 - Loss: 7.1208 (Macro: 1.5644, Energy: 1.1437, KLD: 2.1149, MC: 2.2978)\n",
      "Train Batch 20/110 - Loss: 6.9235 (Macro: 1.4961, Energy: 0.9919, KLD: 2.1345, MC: 2.3011)\n",
      "Train Batch 30/110 - Loss: 7.0964 (Macro: 1.4485, Energy: 1.0408, KLD: 2.3073, MC: 2.2998)\n",
      "Train Batch 40/110 - Loss: 7.4149 (Macro: 1.5617, Energy: 1.1706, KLD: 2.3805, MC: 2.3022)\n",
      "Train Batch 50/110 - Loss: 7.0767 (Macro: 1.5233, Energy: 1.0124, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.9071 (Macro: 1.3860, Energy: 0.9612, KLD: 2.2570, MC: 2.3028)\n",
      "Train Batch 70/110 - Loss: 6.9549 (Macro: 1.3620, Energy: 0.8524, KLD: 2.4378, MC: 2.3027)\n",
      "Train Batch 80/110 - Loss: 7.3169 (Macro: 1.4027, Energy: 1.0744, KLD: 2.5365, MC: 2.3034)\n",
      "Train Batch 90/110 - Loss: 6.7718 (Macro: 1.4797, Energy: 0.9669, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.2875 (Macro: 1.6079, Energy: 1.1615, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.5505 (Macro: 1.2204, Energy: 0.6882, KLD: 2.3414, MC: 2.3006)\n",
      "Training epoch complete. Average Loss: 7.0763\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0597\n",
      "\n",
      "Epoch 40/500\n",
      "Train Batch 10/110 - Loss: 7.1734 (Macro: 1.5732, Energy: 1.1867, KLD: 2.1149, MC: 2.2985)\n",
      "Train Batch 20/110 - Loss: 6.8801 (Macro: 1.4826, Energy: 0.9610, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.0317 (Macro: 1.4372, Energy: 0.9867, KLD: 2.3073, MC: 2.3005)\n",
      "Train Batch 40/110 - Loss: 7.5133 (Macro: 1.5527, Energy: 1.2786, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0516 (Macro: 1.5180, Energy: 0.9913, KLD: 2.2381, MC: 2.3043)\n",
      "Train Batch 60/110 - Loss: 6.9140 (Macro: 1.3851, Energy: 0.9679, KLD: 2.2570, MC: 2.3039)\n",
      "Train Batch 70/110 - Loss: 6.9590 (Macro: 1.3572, Energy: 0.8621, KLD: 2.4378, MC: 2.3019)\n",
      "Train Batch 80/110 - Loss: 7.3018 (Macro: 1.4336, Energy: 1.0280, KLD: 2.5365, MC: 2.3038)\n",
      "Train Batch 90/110 - Loss: 6.8003 (Macro: 1.4679, Energy: 1.0073, KLD: 2.0241, MC: 2.3011)\n",
      "Train Batch 100/110 - Loss: 7.3034 (Macro: 1.6177, Energy: 1.1673, KLD: 2.2161, MC: 2.3023)\n",
      "Train Batch 110/110 - Loss: 6.6514 (Macro: 1.2665, Energy: 0.7448, KLD: 2.3414, MC: 2.2987)\n",
      "Training epoch complete. Average Loss: 7.0815\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0798\n",
      "\n",
      "Epoch 41/500\n",
      "Train Batch 10/110 - Loss: 7.1321 (Macro: 1.5755, Energy: 1.1431, KLD: 2.1149, MC: 2.2987)\n",
      "Train Batch 20/110 - Loss: 6.9182 (Macro: 1.4901, Energy: 0.9925, KLD: 2.1345, MC: 2.3011)\n",
      "Train Batch 30/110 - Loss: 7.0711 (Macro: 1.4298, Energy: 1.0326, KLD: 2.3073, MC: 2.3014)\n",
      "Train Batch 40/110 - Loss: 7.4903 (Macro: 1.5571, Energy: 1.2505, KLD: 2.3805, MC: 2.3022)\n",
      "Train Batch 50/110 - Loss: 7.0543 (Macro: 1.4975, Energy: 1.0150, KLD: 2.2381, MC: 2.3037)\n",
      "Train Batch 60/110 - Loss: 6.9416 (Macro: 1.4007, Energy: 0.9835, KLD: 2.2570, MC: 2.3003)\n",
      "Train Batch 70/110 - Loss: 6.9759 (Macro: 1.3787, Energy: 0.8574, KLD: 2.4378, MC: 2.3020)\n",
      "Train Batch 80/110 - Loss: 7.3054 (Macro: 1.4079, Energy: 1.0579, KLD: 2.5365, MC: 2.3030)\n",
      "Train Batch 90/110 - Loss: 6.8201 (Macro: 1.4801, Energy: 1.0142, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.3573 (Macro: 1.6040, Energy: 1.2369, KLD: 2.2161, MC: 2.3003)\n",
      "Train Batch 110/110 - Loss: 6.5994 (Macro: 1.2372, Energy: 0.7222, KLD: 2.3414, MC: 2.2986)\n",
      "Training epoch complete. Average Loss: 7.0834\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0601\n",
      "\n",
      "Epoch 42/500\n",
      "Train Batch 10/110 - Loss: 7.1495 (Macro: 1.5750, Energy: 1.1595, KLD: 2.1149, MC: 2.3000)\n",
      "Train Batch 20/110 - Loss: 6.8907 (Macro: 1.4781, Energy: 0.9760, KLD: 2.1345, MC: 2.3021)\n",
      "Train Batch 30/110 - Loss: 7.0356 (Macro: 1.4488, Energy: 0.9786, KLD: 2.3073, MC: 2.3010)\n",
      "Train Batch 40/110 - Loss: 7.4386 (Macro: 1.5610, Energy: 1.1967, KLD: 2.3805, MC: 2.3004)\n",
      "Train Batch 50/110 - Loss: 7.0280 (Macro: 1.4950, Energy: 0.9936, KLD: 2.2381, MC: 2.3014)\n",
      "Train Batch 60/110 - Loss: 6.9083 (Macro: 1.3819, Energy: 0.9671, KLD: 2.2570, MC: 2.3022)\n",
      "Train Batch 70/110 - Loss: 6.9771 (Macro: 1.3523, Energy: 0.8835, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.2639 (Macro: 1.4282, Energy: 0.9961, KLD: 2.5365, MC: 2.3031)\n",
      "Train Batch 90/110 - Loss: 6.7179 (Macro: 1.4723, Energy: 0.9198, KLD: 2.0241, MC: 2.3018)\n",
      "Train Batch 100/110 - Loss: 7.3629 (Macro: 1.6186, Energy: 1.2274, KLD: 2.2161, MC: 2.3007)\n",
      "Train Batch 110/110 - Loss: 6.7179 (Macro: 1.2550, Energy: 0.8223, KLD: 2.3414, MC: 2.2992)\n",
      "Training epoch complete. Average Loss: 7.0804\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0617\n",
      "\n",
      "Epoch 43/500\n",
      "Train Batch 10/110 - Loss: 7.1234 (Macro: 1.5889, Energy: 1.1202, KLD: 2.1149, MC: 2.2994)\n",
      "Train Batch 20/110 - Loss: 6.8779 (Macro: 1.4900, Energy: 0.9521, KLD: 2.1345, MC: 2.3013)\n",
      "Train Batch 30/110 - Loss: 7.0275 (Macro: 1.4461, Energy: 0.9746, KLD: 2.3073, MC: 2.2995)\n",
      "Train Batch 40/110 - Loss: 7.4778 (Macro: 1.5550, Energy: 1.2410, KLD: 2.3805, MC: 2.3013)\n",
      "Train Batch 50/110 - Loss: 7.0160 (Macro: 1.4818, Energy: 0.9929, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.8415 (Macro: 1.3891, Energy: 0.8962, KLD: 2.2570, MC: 2.2991)\n",
      "Train Batch 70/110 - Loss: 6.9304 (Macro: 1.3743, Energy: 0.8160, KLD: 2.4378, MC: 2.3024)\n",
      "Train Batch 80/110 - Loss: 7.3144 (Macro: 1.4092, Energy: 1.0645, KLD: 2.5365, MC: 2.3042)\n",
      "Train Batch 90/110 - Loss: 6.8529 (Macro: 1.4877, Energy: 1.0395, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.2530 (Macro: 1.6141, Energy: 1.1221, KLD: 2.2161, MC: 2.3007)\n",
      "Train Batch 110/110 - Loss: 6.7073 (Macro: 1.2622, Energy: 0.8044, KLD: 2.3414, MC: 2.2994)\n",
      "Training epoch complete. Average Loss: 7.0819\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0670\n",
      "\n",
      "Epoch 44/500\n",
      "Train Batch 10/110 - Loss: 7.1635 (Macro: 1.5689, Energy: 1.1785, KLD: 2.1149, MC: 2.3012)\n",
      "Train Batch 20/110 - Loss: 6.8957 (Macro: 1.4522, Energy: 1.0076, KLD: 2.1345, MC: 2.3014)\n",
      "Train Batch 30/110 - Loss: 7.1208 (Macro: 1.4479, Energy: 1.0631, KLD: 2.3073, MC: 2.3025)\n",
      "Train Batch 40/110 - Loss: 7.4236 (Macro: 1.5622, Energy: 1.1787, KLD: 2.3805, MC: 2.3021)\n",
      "Train Batch 50/110 - Loss: 7.0779 (Macro: 1.5044, Energy: 1.0323, KLD: 2.2381, MC: 2.3031)\n",
      "Train Batch 60/110 - Loss: 6.9144 (Macro: 1.3658, Energy: 0.9910, KLD: 2.2570, MC: 2.3005)\n",
      "Train Batch 70/110 - Loss: 6.9603 (Macro: 1.3631, Energy: 0.8559, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.3108 (Macro: 1.4210, Energy: 1.0493, KLD: 2.5365, MC: 2.3039)\n",
      "Train Batch 90/110 - Loss: 6.7500 (Macro: 1.4733, Energy: 0.9524, KLD: 2.0241, MC: 2.3002)\n",
      "Train Batch 100/110 - Loss: 7.2612 (Macro: 1.6034, Energy: 1.1400, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.6497 (Macro: 1.2331, Energy: 0.7745, KLD: 2.3414, MC: 2.3007)\n",
      "Training epoch complete. Average Loss: 7.0808\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0607\n",
      "\n",
      "Epoch 45/500\n",
      "Train Batch 10/110 - Loss: 7.1137 (Macro: 1.5756, Energy: 1.1235, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.9305 (Macro: 1.4825, Energy: 1.0109, KLD: 2.1345, MC: 2.3027)\n",
      "Train Batch 30/110 - Loss: 7.0953 (Macro: 1.4748, Energy: 1.0103, KLD: 2.3073, MC: 2.3029)\n",
      "Train Batch 40/110 - Loss: 7.4971 (Macro: 1.5405, Energy: 1.2749, KLD: 2.3805, MC: 2.3012)\n",
      "Train Batch 50/110 - Loss: 7.0333 (Macro: 1.4958, Energy: 0.9948, KLD: 2.2381, MC: 2.3047)\n",
      "Train Batch 60/110 - Loss: 6.9059 (Macro: 1.3892, Energy: 0.9588, KLD: 2.2570, MC: 2.3008)\n",
      "Train Batch 70/110 - Loss: 6.9666 (Macro: 1.3726, Energy: 0.8535, KLD: 2.4378, MC: 2.3027)\n",
      "Train Batch 80/110 - Loss: 7.3476 (Macro: 1.4159, Energy: 1.0921, KLD: 2.5365, MC: 2.3031)\n",
      "Train Batch 90/110 - Loss: 6.7643 (Macro: 1.4609, Energy: 0.9758, KLD: 2.0241, MC: 2.3035)\n",
      "Train Batch 100/110 - Loss: 7.3063 (Macro: 1.5964, Energy: 1.1931, KLD: 2.2161, MC: 2.3007)\n",
      "Train Batch 110/110 - Loss: 6.6103 (Macro: 1.2310, Energy: 0.7372, KLD: 2.3414, MC: 2.3007)\n",
      "Training epoch complete. Average Loss: 7.0808\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0610\n",
      "\n",
      "Epoch 46/500\n",
      "Train Batch 10/110 - Loss: 7.1280 (Macro: 1.5915, Energy: 1.1214, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.9044 (Macro: 1.4802, Energy: 0.9871, KLD: 2.1345, MC: 2.3026)\n",
      "Train Batch 30/110 - Loss: 7.0383 (Macro: 1.4605, Energy: 0.9682, KLD: 2.3073, MC: 2.3024)\n",
      "Train Batch 40/110 - Loss: 7.4424 (Macro: 1.5512, Energy: 1.2098, KLD: 2.3805, MC: 2.3009)\n",
      "Train Batch 50/110 - Loss: 7.0397 (Macro: 1.5098, Energy: 0.9899, KLD: 2.2381, MC: 2.3020)\n",
      "Train Batch 60/110 - Loss: 6.9894 (Macro: 1.3985, Energy: 1.0333, KLD: 2.2570, MC: 2.3005)\n",
      "Train Batch 70/110 - Loss: 6.9597 (Macro: 1.3608, Energy: 0.8569, KLD: 2.4378, MC: 2.3042)\n",
      "Train Batch 80/110 - Loss: 7.2981 (Macro: 1.4253, Energy: 1.0335, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.8373 (Macro: 1.4640, Energy: 1.0472, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.3540 (Macro: 1.6098, Energy: 1.2259, KLD: 2.2161, MC: 2.3021)\n",
      "Train Batch 110/110 - Loss: 6.6018 (Macro: 1.2280, Energy: 0.7321, KLD: 2.3414, MC: 2.3003)\n",
      "Training epoch complete. Average Loss: 7.0786\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0669\n",
      "\n",
      "Epoch 47/500\n",
      "Train Batch 10/110 - Loss: 7.1012 (Macro: 1.5806, Energy: 1.1037, KLD: 2.1149, MC: 2.3019)\n",
      "Train Batch 20/110 - Loss: 6.8653 (Macro: 1.4808, Energy: 0.9477, KLD: 2.1345, MC: 2.3023)\n",
      "Train Batch 30/110 - Loss: 7.1258 (Macro: 1.4664, Energy: 1.0517, KLD: 2.3073, MC: 2.3004)\n",
      "Train Batch 40/110 - Loss: 7.4136 (Macro: 1.5469, Energy: 1.1859, KLD: 2.3805, MC: 2.3003)\n",
      "Train Batch 50/110 - Loss: 7.0694 (Macro: 1.4981, Energy: 1.0314, KLD: 2.2381, MC: 2.3019)\n",
      "Train Batch 60/110 - Loss: 6.9172 (Macro: 1.3902, Energy: 0.9694, KLD: 2.2570, MC: 2.3006)\n",
      "Train Batch 70/110 - Loss: 6.9561 (Macro: 1.3539, Energy: 0.8609, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.2589 (Macro: 1.4125, Energy: 1.0093, KLD: 2.5365, MC: 2.3006)\n",
      "Train Batch 90/110 - Loss: 6.8038 (Macro: 1.4761, Energy: 1.0023, KLD: 2.0241, MC: 2.3013)\n",
      "Train Batch 100/110 - Loss: 7.3589 (Macro: 1.6286, Energy: 1.2121, KLD: 2.2161, MC: 2.3022)\n",
      "Train Batch 110/110 - Loss: 6.6261 (Macro: 1.2213, Energy: 0.7629, KLD: 2.3414, MC: 2.3005)\n",
      "Training epoch complete. Average Loss: 7.0825\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0620\n",
      "\n",
      "Epoch 48/500\n",
      "Train Batch 10/110 - Loss: 7.1179 (Macro: 1.6005, Energy: 1.1016, KLD: 2.1149, MC: 2.3009)\n",
      "Train Batch 20/110 - Loss: 6.9333 (Macro: 1.4955, Energy: 1.0026, KLD: 2.1345, MC: 2.3007)\n",
      "Train Batch 30/110 - Loss: 7.0998 (Macro: 1.4519, Energy: 1.0370, KLD: 2.3073, MC: 2.3036)\n",
      "Train Batch 40/110 - Loss: 7.4291 (Macro: 1.5433, Energy: 1.2043, KLD: 2.3805, MC: 2.3009)\n",
      "Train Batch 50/110 - Loss: 7.0894 (Macro: 1.5232, Energy: 1.0254, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.9500 (Macro: 1.4073, Energy: 0.9853, KLD: 2.2570, MC: 2.3003)\n",
      "Train Batch 70/110 - Loss: 6.9303 (Macro: 1.3615, Energy: 0.8276, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.3203 (Macro: 1.4265, Energy: 1.0546, KLD: 2.5365, MC: 2.3026)\n",
      "Train Batch 90/110 - Loss: 6.8085 (Macro: 1.4766, Energy: 1.0034, KLD: 2.0241, MC: 2.3044)\n",
      "Train Batch 100/110 - Loss: 7.3117 (Macro: 1.6058, Energy: 1.1875, KLD: 2.2161, MC: 2.3024)\n",
      "Train Batch 110/110 - Loss: 6.6639 (Macro: 1.2052, Energy: 0.8216, KLD: 2.3414, MC: 2.2958)\n",
      "Training epoch complete. Average Loss: 7.0775\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0670\n",
      "\n",
      "Epoch 49/500\n",
      "Train Batch 10/110 - Loss: 7.0709 (Macro: 1.5861, Energy: 1.0696, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.9045 (Macro: 1.5056, Energy: 0.9620, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.0309 (Macro: 1.4286, Energy: 0.9929, KLD: 2.3073, MC: 2.3022)\n",
      "Train Batch 40/110 - Loss: 7.3904 (Macro: 1.5504, Energy: 1.1596, KLD: 2.3805, MC: 2.2998)\n",
      "Train Batch 50/110 - Loss: 7.0411 (Macro: 1.4865, Energy: 1.0138, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.8807 (Macro: 1.3840, Energy: 0.9380, KLD: 2.2570, MC: 2.3016)\n",
      "Train Batch 70/110 - Loss: 6.9681 (Macro: 1.3656, Energy: 0.8624, KLD: 2.4378, MC: 2.3023)\n",
      "Train Batch 80/110 - Loss: 7.2945 (Macro: 1.4349, Energy: 1.0199, KLD: 2.5365, MC: 2.3032)\n",
      "Train Batch 90/110 - Loss: 6.8277 (Macro: 1.4776, Energy: 1.0230, KLD: 2.0241, MC: 2.3030)\n",
      "Train Batch 100/110 - Loss: 7.2489 (Macro: 1.5910, Energy: 1.1406, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.6259 (Macro: 1.2369, Energy: 0.7465, KLD: 2.3414, MC: 2.3011)\n",
      "Training epoch complete. Average Loss: 7.0818\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0672\n",
      "\n",
      "Epoch 50/500\n",
      "Train Batch 10/110 - Loss: 7.1405 (Macro: 1.5766, Energy: 1.1481, KLD: 2.1149, MC: 2.3009)\n",
      "Train Batch 20/110 - Loss: 6.8918 (Macro: 1.4732, Energy: 0.9792, KLD: 2.1345, MC: 2.3049)\n",
      "Train Batch 30/110 - Loss: 7.0415 (Macro: 1.4609, Energy: 0.9700, KLD: 2.3073, MC: 2.3032)\n",
      "Train Batch 40/110 - Loss: 7.4905 (Macro: 1.5569, Energy: 1.2512, KLD: 2.3805, MC: 2.3019)\n",
      "Train Batch 50/110 - Loss: 7.0736 (Macro: 1.5136, Energy: 1.0198, KLD: 2.2381, MC: 2.3020)\n",
      "Train Batch 60/110 - Loss: 6.9060 (Macro: 1.3782, Energy: 0.9703, KLD: 2.2570, MC: 2.3004)\n",
      "Train Batch 70/110 - Loss: 6.9767 (Macro: 1.3657, Energy: 0.8683, KLD: 2.4378, MC: 2.3049)\n",
      "Train Batch 80/110 - Loss: 7.3315 (Macro: 1.4254, Energy: 1.0667, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.7932 (Macro: 1.4709, Energy: 0.9977, KLD: 2.0241, MC: 2.3004)\n",
      "Train Batch 100/110 - Loss: 7.3264 (Macro: 1.5971, Energy: 1.2111, KLD: 2.2161, MC: 2.3021)\n",
      "Train Batch 110/110 - Loss: 6.5992 (Macro: 1.2104, Energy: 0.7481, KLD: 2.3414, MC: 2.2994)\n",
      "Training epoch complete. Average Loss: 7.0831\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0659\n",
      "\n",
      "Epoch 51/500\n",
      "Train Batch 10/110 - Loss: 7.0633 (Macro: 1.5620, Energy: 1.0861, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.8662 (Macro: 1.4794, Energy: 0.9498, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.0522 (Macro: 1.4588, Energy: 0.9838, KLD: 2.3073, MC: 2.3023)\n",
      "Train Batch 40/110 - Loss: 7.3836 (Macro: 1.5464, Energy: 1.1554, KLD: 2.3805, MC: 2.3013)\n",
      "Train Batch 50/110 - Loss: 7.0629 (Macro: 1.4897, Energy: 1.0319, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.9103 (Macro: 1.3899, Energy: 0.9616, KLD: 2.2570, MC: 2.3017)\n",
      "Train Batch 70/110 - Loss: 6.9580 (Macro: 1.3647, Energy: 0.8524, KLD: 2.4378, MC: 2.3031)\n",
      "Train Batch 80/110 - Loss: 7.3055 (Macro: 1.4317, Energy: 1.0349, KLD: 2.5365, MC: 2.3024)\n",
      "Train Batch 90/110 - Loss: 6.7572 (Macro: 1.4614, Energy: 0.9696, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3064 (Macro: 1.6166, Energy: 1.1722, KLD: 2.2161, MC: 2.3016)\n",
      "Train Batch 110/110 - Loss: 6.6433 (Macro: 1.2675, Energy: 0.7350, KLD: 2.3414, MC: 2.2994)\n",
      "Training epoch complete. Average Loss: 7.0778\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0673\n",
      "\n",
      "Epoch 52/500\n",
      "Train Batch 10/110 - Loss: 7.1707 (Macro: 1.5899, Energy: 1.1656, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.8837 (Macro: 1.4779, Energy: 0.9685, KLD: 2.1345, MC: 2.3028)\n",
      "Train Batch 30/110 - Loss: 7.0898 (Macro: 1.4635, Energy: 1.0179, KLD: 2.3073, MC: 2.3012)\n",
      "Train Batch 40/110 - Loss: 7.4393 (Macro: 1.5536, Energy: 1.2026, KLD: 2.3805, MC: 2.3026)\n",
      "Train Batch 50/110 - Loss: 7.0409 (Macro: 1.4963, Energy: 1.0047, KLD: 2.2381, MC: 2.3019)\n",
      "Train Batch 60/110 - Loss: 6.9031 (Macro: 1.4011, Energy: 0.9440, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 6.9532 (Macro: 1.3461, Energy: 0.8645, KLD: 2.4378, MC: 2.3049)\n",
      "Train Batch 80/110 - Loss: 7.3523 (Macro: 1.4409, Energy: 1.0714, KLD: 2.5365, MC: 2.3036)\n",
      "Train Batch 90/110 - Loss: 6.8259 (Macro: 1.4956, Energy: 1.0033, KLD: 2.0241, MC: 2.3029)\n",
      "Train Batch 100/110 - Loss: 7.3310 (Macro: 1.6048, Energy: 1.2073, KLD: 2.2161, MC: 2.3028)\n",
      "Train Batch 110/110 - Loss: 6.5719 (Macro: 1.1853, Energy: 0.7487, KLD: 2.3414, MC: 2.2965)\n",
      "Training epoch complete. Average Loss: 7.0766\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0728\n",
      "\n",
      "Epoch 53/500\n",
      "Train Batch 10/110 - Loss: 7.1495 (Macro: 1.5859, Energy: 1.1483, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.8616 (Macro: 1.4890, Energy: 0.9353, KLD: 2.1345, MC: 2.3028)\n",
      "Train Batch 30/110 - Loss: 7.0938 (Macro: 1.4308, Energy: 1.0544, KLD: 2.3073, MC: 2.3013)\n",
      "Train Batch 40/110 - Loss: 7.4223 (Macro: 1.5537, Energy: 1.1855, KLD: 2.3805, MC: 2.3025)\n",
      "Train Batch 50/110 - Loss: 7.0871 (Macro: 1.5134, Energy: 1.0329, KLD: 2.2381, MC: 2.3027)\n",
      "Train Batch 60/110 - Loss: 6.9345 (Macro: 1.4182, Energy: 0.9562, KLD: 2.2570, MC: 2.3030)\n",
      "Train Batch 70/110 - Loss: 6.9715 (Macro: 1.3684, Energy: 0.8617, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.2892 (Macro: 1.4304, Energy: 1.0196, KLD: 2.5365, MC: 2.3027)\n",
      "Train Batch 90/110 - Loss: 6.7693 (Macro: 1.4646, Energy: 0.9770, KLD: 2.0241, MC: 2.3036)\n",
      "Train Batch 100/110 - Loss: 7.3226 (Macro: 1.6094, Energy: 1.1941, KLD: 2.2161, MC: 2.3030)\n",
      "Train Batch 110/110 - Loss: 6.6544 (Macro: 1.2121, Energy: 0.8003, KLD: 2.3414, MC: 2.3006)\n",
      "Training epoch complete. Average Loss: 7.0778\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0593\n",
      "\n",
      "Epoch 54/500\n",
      "Train Batch 10/110 - Loss: 7.1389 (Macro: 1.5851, Energy: 1.1386, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.9203 (Macro: 1.4760, Energy: 1.0077, KLD: 2.1345, MC: 2.3022)\n",
      "Train Batch 30/110 - Loss: 7.0644 (Macro: 1.4512, Energy: 1.0034, KLD: 2.3073, MC: 2.3025)\n",
      "Train Batch 40/110 - Loss: 7.4673 (Macro: 1.5548, Energy: 1.2297, KLD: 2.3805, MC: 2.3022)\n",
      "Train Batch 50/110 - Loss: 7.0378 (Macro: 1.4920, Energy: 1.0064, KLD: 2.2381, MC: 2.3014)\n",
      "Train Batch 60/110 - Loss: 6.9106 (Macro: 1.3933, Energy: 0.9597, KLD: 2.2570, MC: 2.3005)\n",
      "Train Batch 70/110 - Loss: 6.9477 (Macro: 1.3580, Energy: 0.8491, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.3120 (Macro: 1.4355, Energy: 1.0389, KLD: 2.5365, MC: 2.3011)\n",
      "Train Batch 90/110 - Loss: 6.7672 (Macro: 1.4568, Energy: 0.9834, KLD: 2.0241, MC: 2.3029)\n",
      "Train Batch 100/110 - Loss: 7.3031 (Macro: 1.6291, Energy: 1.1560, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.6222 (Macro: 1.2079, Energy: 0.7743, KLD: 2.3414, MC: 2.2987)\n",
      "Training epoch complete. Average Loss: 7.0790\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0616\n",
      "\n",
      "Epoch 55/500\n",
      "Train Batch 10/110 - Loss: 7.1378 (Macro: 1.5758, Energy: 1.1456, KLD: 2.1149, MC: 2.3014)\n",
      "Train Batch 20/110 - Loss: 6.8894 (Macro: 1.4837, Energy: 0.9701, KLD: 2.1345, MC: 2.3012)\n",
      "Train Batch 30/110 - Loss: 7.1057 (Macro: 1.4452, Energy: 1.0503, KLD: 2.3073, MC: 2.3029)\n",
      "Train Batch 40/110 - Loss: 7.4187 (Macro: 1.5380, Energy: 1.1993, KLD: 2.3805, MC: 2.3009)\n",
      "Train Batch 50/110 - Loss: 7.0589 (Macro: 1.4842, Energy: 1.0339, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.9033 (Macro: 1.3805, Energy: 0.9636, KLD: 2.2570, MC: 2.3021)\n",
      "Train Batch 70/110 - Loss: 6.9757 (Macro: 1.3573, Energy: 0.8773, KLD: 2.4378, MC: 2.3033)\n",
      "Train Batch 80/110 - Loss: 7.3177 (Macro: 1.4324, Energy: 1.0447, KLD: 2.5365, MC: 2.3041)\n",
      "Train Batch 90/110 - Loss: 6.8024 (Macro: 1.4832, Energy: 0.9946, KLD: 2.0241, MC: 2.3006)\n",
      "Train Batch 100/110 - Loss: 7.2908 (Macro: 1.6086, Energy: 1.1652, KLD: 2.2161, MC: 2.3009)\n",
      "Train Batch 110/110 - Loss: 6.5749 (Macro: 1.2106, Energy: 0.7257, KLD: 2.3414, MC: 2.2972)\n",
      "Training epoch complete. Average Loss: 7.0756\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0703\n",
      "\n",
      "Epoch 56/500\n",
      "Train Batch 10/110 - Loss: 7.0995 (Macro: 1.5519, Energy: 1.1313, KLD: 2.1149, MC: 2.3013)\n",
      "Train Batch 20/110 - Loss: 6.9679 (Macro: 1.5039, Energy: 1.0277, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.1723 (Macro: 1.4452, Energy: 1.1185, KLD: 2.3073, MC: 2.3013)\n",
      "Train Batch 40/110 - Loss: 7.5036 (Macro: 1.5653, Energy: 1.2583, KLD: 2.3805, MC: 2.2995)\n",
      "Train Batch 50/110 - Loss: 7.0191 (Macro: 1.4991, Energy: 0.9789, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.8862 (Macro: 1.3751, Energy: 0.9524, KLD: 2.2570, MC: 2.3017)\n",
      "Train Batch 70/110 - Loss: 6.9995 (Macro: 1.3594, Energy: 0.8995, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.3221 (Macro: 1.4218, Energy: 1.0612, KLD: 2.5365, MC: 2.3025)\n",
      "Train Batch 90/110 - Loss: 6.7923 (Macro: 1.4747, Energy: 0.9913, KLD: 2.0241, MC: 2.3023)\n",
      "Train Batch 100/110 - Loss: 7.3152 (Macro: 1.6144, Energy: 1.1826, KLD: 2.2161, MC: 2.3021)\n",
      "Train Batch 110/110 - Loss: 6.5776 (Macro: 1.2108, Energy: 0.7278, KLD: 2.3414, MC: 2.2976)\n",
      "Training epoch complete. Average Loss: 7.0786\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0728\n",
      "\n",
      "Epoch 57/500\n",
      "Train Batch 10/110 - Loss: 7.1419 (Macro: 1.5963, Energy: 1.1304, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.9059 (Macro: 1.4945, Energy: 0.9740, KLD: 2.1345, MC: 2.3030)\n",
      "Train Batch 30/110 - Loss: 7.0831 (Macro: 1.4756, Energy: 0.9992, KLD: 2.3073, MC: 2.3011)\n",
      "Train Batch 40/110 - Loss: 7.5053 (Macro: 1.5538, Energy: 1.2687, KLD: 2.3805, MC: 2.3023)\n",
      "Train Batch 50/110 - Loss: 7.0920 (Macro: 1.5053, Energy: 1.0455, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.9320 (Macro: 1.3862, Energy: 0.9864, KLD: 2.2570, MC: 2.3024)\n",
      "Train Batch 70/110 - Loss: 6.9791 (Macro: 1.3819, Energy: 0.8552, KLD: 2.4378, MC: 2.3043)\n",
      "Train Batch 80/110 - Loss: 7.2851 (Macro: 1.4074, Energy: 1.0385, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.7546 (Macro: 1.4822, Energy: 0.9453, KLD: 2.0241, MC: 2.3030)\n",
      "Train Batch 100/110 - Loss: 7.3286 (Macro: 1.6193, Energy: 1.1913, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.6298 (Macro: 1.2115, Energy: 0.7810, KLD: 2.3414, MC: 2.2959)\n",
      "Training epoch complete. Average Loss: 7.0772\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0655\n",
      "\n",
      "Epoch 58/500\n",
      "Train Batch 10/110 - Loss: 7.1191 (Macro: 1.5744, Energy: 1.1295, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.8621 (Macro: 1.4714, Energy: 0.9537, KLD: 2.1345, MC: 2.3026)\n",
      "Train Batch 30/110 - Loss: 7.0549 (Macro: 1.4471, Energy: 0.9978, KLD: 2.3073, MC: 2.3027)\n",
      "Train Batch 40/110 - Loss: 7.4759 (Macro: 1.5811, Energy: 1.2130, KLD: 2.3805, MC: 2.3013)\n",
      "Train Batch 50/110 - Loss: 7.0706 (Macro: 1.5050, Energy: 1.0250, KLD: 2.2381, MC: 2.3026)\n",
      "Train Batch 60/110 - Loss: 6.8586 (Macro: 1.3768, Energy: 0.9221, KLD: 2.2570, MC: 2.3027)\n",
      "Train Batch 70/110 - Loss: 6.9571 (Macro: 1.3520, Energy: 0.8648, KLD: 2.4378, MC: 2.3025)\n",
      "Train Batch 80/110 - Loss: 7.2562 (Macro: 1.4234, Energy: 0.9938, KLD: 2.5365, MC: 2.3024)\n",
      "Train Batch 90/110 - Loss: 6.8158 (Macro: 1.4883, Energy: 1.0019, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.3109 (Macro: 1.6141, Energy: 1.1793, KLD: 2.2161, MC: 2.3014)\n",
      "Train Batch 110/110 - Loss: 6.5977 (Macro: 1.2196, Energy: 0.7386, KLD: 2.3414, MC: 2.2981)\n",
      "Training epoch complete. Average Loss: 7.0758\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0676\n",
      "\n",
      "Epoch 59/500\n",
      "Train Batch 10/110 - Loss: 7.1193 (Macro: 1.5860, Energy: 1.1182, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.8806 (Macro: 1.5076, Energy: 0.9379, KLD: 2.1345, MC: 2.3006)\n",
      "Train Batch 30/110 - Loss: 7.0788 (Macro: 1.4252, Energy: 1.0434, KLD: 2.3073, MC: 2.3030)\n",
      "Train Batch 40/110 - Loss: 7.4793 (Macro: 1.5416, Energy: 1.2556, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.0191 (Macro: 1.4860, Energy: 0.9922, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.9159 (Macro: 1.3624, Energy: 0.9954, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9570 (Macro: 1.3491, Energy: 0.8675, KLD: 2.4378, MC: 2.3027)\n",
      "Train Batch 80/110 - Loss: 7.2999 (Macro: 1.4054, Energy: 1.0545, KLD: 2.5365, MC: 2.3036)\n",
      "Train Batch 90/110 - Loss: 6.8540 (Macro: 1.4875, Energy: 1.0408, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.3064 (Macro: 1.6056, Energy: 1.1829, KLD: 2.2161, MC: 2.3017)\n",
      "Train Batch 110/110 - Loss: 6.6020 (Macro: 1.2307, Energy: 0.7282, KLD: 2.3414, MC: 2.3017)\n",
      "Training epoch complete. Average Loss: 7.0799\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0554\n",
      "\n",
      "Epoch 60/500\n",
      "Train Batch 10/110 - Loss: 7.1100 (Macro: 1.5779, Energy: 1.1159, KLD: 2.1149, MC: 2.3013)\n",
      "Train Batch 20/110 - Loss: 6.8795 (Macro: 1.4658, Energy: 0.9768, KLD: 2.1345, MC: 2.3024)\n",
      "Train Batch 30/110 - Loss: 7.0902 (Macro: 1.4344, Energy: 1.0470, KLD: 2.3073, MC: 2.3015)\n",
      "Train Batch 40/110 - Loss: 7.4900 (Macro: 1.5477, Energy: 1.2621, KLD: 2.3805, MC: 2.2998)\n",
      "Train Batch 50/110 - Loss: 7.0486 (Macro: 1.4921, Energy: 1.0157, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.9097 (Macro: 1.3795, Energy: 0.9715, KLD: 2.2570, MC: 2.3016)\n",
      "Train Batch 70/110 - Loss: 6.9533 (Macro: 1.3415, Energy: 0.8695, KLD: 2.4378, MC: 2.3045)\n",
      "Train Batch 80/110 - Loss: 7.3420 (Macro: 1.4410, Energy: 1.0626, KLD: 2.5365, MC: 2.3019)\n",
      "Train Batch 90/110 - Loss: 6.8092 (Macro: 1.4859, Energy: 0.9976, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.3675 (Macro: 1.6067, Energy: 1.2414, KLD: 2.2161, MC: 2.3032)\n",
      "Train Batch 110/110 - Loss: 6.5622 (Macro: 1.2057, Energy: 0.7161, KLD: 2.3414, MC: 2.2990)\n",
      "Training epoch complete. Average Loss: 7.0863\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0670\n",
      "\n",
      "Epoch 61/500\n",
      "Train Batch 10/110 - Loss: 7.0833 (Macro: 1.5714, Energy: 1.0974, KLD: 2.1149, MC: 2.2995)\n",
      "Train Batch 20/110 - Loss: 6.9246 (Macro: 1.4921, Energy: 0.9958, KLD: 2.1345, MC: 2.3022)\n",
      "Train Batch 30/110 - Loss: 7.0625 (Macro: 1.4597, Energy: 0.9940, KLD: 2.3073, MC: 2.3014)\n",
      "Train Batch 40/110 - Loss: 7.3965 (Macro: 1.5455, Energy: 1.1701, KLD: 2.3805, MC: 2.3003)\n",
      "Train Batch 50/110 - Loss: 7.0108 (Macro: 1.4882, Energy: 0.9822, KLD: 2.2381, MC: 2.3023)\n",
      "Train Batch 60/110 - Loss: 6.9578 (Macro: 1.3919, Energy: 1.0059, KLD: 2.2570, MC: 2.3030)\n",
      "Train Batch 70/110 - Loss: 6.9425 (Macro: 1.3675, Energy: 0.8337, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.3318 (Macro: 1.4314, Energy: 1.0620, KLD: 2.5365, MC: 2.3019)\n",
      "Train Batch 90/110 - Loss: 6.8042 (Macro: 1.4766, Energy: 1.0024, KLD: 2.0241, MC: 2.3011)\n",
      "Train Batch 100/110 - Loss: 7.3435 (Macro: 1.6042, Energy: 1.2218, KLD: 2.2161, MC: 2.3014)\n",
      "Train Batch 110/110 - Loss: 6.5705 (Macro: 1.2027, Energy: 0.7286, KLD: 2.3414, MC: 2.2978)\n",
      "Training epoch complete. Average Loss: 7.0786\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0767\n",
      "\n",
      "Epoch 62/500\n",
      "Train Batch 10/110 - Loss: 7.1802 (Macro: 1.5958, Energy: 1.1704, KLD: 2.1149, MC: 2.2990)\n",
      "Train Batch 20/110 - Loss: 6.8766 (Macro: 1.4979, Energy: 0.9425, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0613 (Macro: 1.4453, Energy: 1.0069, KLD: 2.3073, MC: 2.3017)\n",
      "Train Batch 40/110 - Loss: 7.4556 (Macro: 1.5518, Energy: 1.2210, KLD: 2.3805, MC: 2.3022)\n",
      "Train Batch 50/110 - Loss: 7.0783 (Macro: 1.4908, Energy: 1.0473, KLD: 2.2381, MC: 2.3022)\n",
      "Train Batch 60/110 - Loss: 6.9041 (Macro: 1.3662, Energy: 0.9786, KLD: 2.2570, MC: 2.3022)\n",
      "Train Batch 70/110 - Loss: 6.9223 (Macro: 1.3372, Energy: 0.8427, KLD: 2.4378, MC: 2.3047)\n",
      "Train Batch 80/110 - Loss: 7.3147 (Macro: 1.4116, Energy: 1.0639, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.7884 (Macro: 1.4569, Energy: 1.0069, KLD: 2.0241, MC: 2.3005)\n",
      "Train Batch 100/110 - Loss: 7.2731 (Macro: 1.5931, Energy: 1.1626, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.5868 (Macro: 1.1959, Energy: 0.7489, KLD: 2.3414, MC: 2.3006)\n",
      "Training epoch complete. Average Loss: 7.0761\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0580\n",
      "\n",
      "Epoch 63/500\n",
      "Train Batch 10/110 - Loss: 7.2033 (Macro: 1.5964, Energy: 1.1898, KLD: 2.1149, MC: 2.3022)\n",
      "Train Batch 20/110 - Loss: 6.9369 (Macro: 1.4662, Energy: 1.0355, KLD: 2.1345, MC: 2.3008)\n",
      "Train Batch 30/110 - Loss: 7.1305 (Macro: 1.4756, Energy: 1.0443, KLD: 2.3073, MC: 2.3032)\n",
      "Train Batch 40/110 - Loss: 7.4899 (Macro: 1.5435, Energy: 1.2644, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.0646 (Macro: 1.4879, Energy: 1.0358, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.8793 (Macro: 1.3719, Energy: 0.9476, KLD: 2.2570, MC: 2.3027)\n",
      "Train Batch 70/110 - Loss: 6.9477 (Macro: 1.3391, Energy: 0.8673, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.3087 (Macro: 1.4074, Energy: 1.0625, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.7694 (Macro: 1.4790, Energy: 0.9643, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.2910 (Macro: 1.5787, Energy: 1.1934, KLD: 2.2161, MC: 2.3028)\n",
      "Train Batch 110/110 - Loss: 6.5821 (Macro: 1.2431, Energy: 0.6978, KLD: 2.3414, MC: 2.2999)\n",
      "Training epoch complete. Average Loss: 7.0832\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0688\n",
      "\n",
      "Epoch 64/500\n",
      "Train Batch 10/110 - Loss: 7.1190 (Macro: 1.5664, Energy: 1.1379, KLD: 2.1149, MC: 2.2998)\n",
      "Train Batch 20/110 - Loss: 6.9067 (Macro: 1.4997, Energy: 0.9711, KLD: 2.1345, MC: 2.3014)\n",
      "Train Batch 30/110 - Loss: 7.0702 (Macro: 1.4417, Energy: 1.0191, KLD: 2.3073, MC: 2.3022)\n",
      "Train Batch 40/110 - Loss: 7.4518 (Macro: 1.5552, Energy: 1.2145, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0376 (Macro: 1.4991, Energy: 0.9968, KLD: 2.2381, MC: 2.3038)\n",
      "Train Batch 60/110 - Loss: 6.8948 (Macro: 1.3822, Energy: 0.9534, KLD: 2.2570, MC: 2.3022)\n",
      "Train Batch 70/110 - Loss: 7.0082 (Macro: 1.3634, Energy: 0.9044, KLD: 2.4378, MC: 2.3027)\n",
      "Train Batch 80/110 - Loss: 7.3230 (Macro: 1.4309, Energy: 1.0519, KLD: 2.5365, MC: 2.3037)\n",
      "Train Batch 90/110 - Loss: 6.8035 (Macro: 1.4778, Energy: 1.0004, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.3409 (Macro: 1.6172, Energy: 1.2055, KLD: 2.2161, MC: 2.3021)\n",
      "Train Batch 110/110 - Loss: 6.6148 (Macro: 1.1888, Energy: 0.7852, KLD: 2.3414, MC: 2.2995)\n",
      "Training epoch complete. Average Loss: 7.0749\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0630\n",
      "\n",
      "Epoch 65/500\n",
      "Train Batch 10/110 - Loss: 7.1053 (Macro: 1.5673, Energy: 1.1248, KLD: 2.1149, MC: 2.2983)\n",
      "Train Batch 20/110 - Loss: 6.9035 (Macro: 1.4814, Energy: 0.9847, KLD: 2.1345, MC: 2.3030)\n",
      "Train Batch 30/110 - Loss: 7.0931 (Macro: 1.4498, Energy: 1.0338, KLD: 2.3073, MC: 2.3021)\n",
      "Train Batch 40/110 - Loss: 7.5319 (Macro: 1.5577, Energy: 1.2935, KLD: 2.3805, MC: 2.3002)\n",
      "Train Batch 50/110 - Loss: 7.0440 (Macro: 1.4882, Energy: 1.0144, KLD: 2.2381, MC: 2.3034)\n",
      "Train Batch 60/110 - Loss: 6.8697 (Macro: 1.3758, Energy: 0.9359, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 6.9153 (Macro: 1.3449, Energy: 0.8288, KLD: 2.4378, MC: 2.3038)\n",
      "Train Batch 80/110 - Loss: 7.2596 (Macro: 1.4106, Energy: 1.0082, KLD: 2.5365, MC: 2.3042)\n",
      "Train Batch 90/110 - Loss: 6.7452 (Macro: 1.4599, Energy: 0.9601, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.3165 (Macro: 1.5907, Energy: 1.2083, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.6599 (Macro: 1.2894, Energy: 0.7331, KLD: 2.3414, MC: 2.2961)\n",
      "Training epoch complete. Average Loss: 7.0779\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0659\n",
      "\n",
      "Epoch 66/500\n",
      "Train Batch 10/110 - Loss: 7.1715 (Macro: 1.5887, Energy: 1.1683, KLD: 2.1149, MC: 2.2996)\n",
      "Train Batch 20/110 - Loss: 6.9291 (Macro: 1.5061, Energy: 0.9868, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.0248 (Macro: 1.4275, Energy: 0.9871, KLD: 2.3073, MC: 2.3030)\n",
      "Train Batch 40/110 - Loss: 7.3911 (Macro: 1.5231, Energy: 1.1839, KLD: 2.3805, MC: 2.3035)\n",
      "Train Batch 50/110 - Loss: 7.0517 (Macro: 1.4800, Energy: 1.0309, KLD: 2.2381, MC: 2.3027)\n",
      "Train Batch 60/110 - Loss: 6.9159 (Macro: 1.4218, Energy: 0.9358, KLD: 2.2570, MC: 2.3013)\n",
      "Train Batch 70/110 - Loss: 6.8890 (Macro: 1.3707, Energy: 0.7790, KLD: 2.4378, MC: 2.3016)\n",
      "Train Batch 80/110 - Loss: 7.3194 (Macro: 1.4284, Energy: 1.0504, KLD: 2.5365, MC: 2.3041)\n",
      "Train Batch 90/110 - Loss: 6.8082 (Macro: 1.4777, Energy: 1.0052, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.2886 (Macro: 1.6082, Energy: 1.1621, KLD: 2.2161, MC: 2.3022)\n",
      "Train Batch 110/110 - Loss: 6.6511 (Macro: 1.2162, Energy: 0.7961, KLD: 2.3414, MC: 2.2975)\n",
      "Training epoch complete. Average Loss: 7.0797\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0624\n",
      "\n",
      "Epoch 67/500\n",
      "Train Batch 10/110 - Loss: 7.1593 (Macro: 1.5639, Energy: 1.1794, KLD: 2.1149, MC: 2.3010)\n",
      "Train Batch 20/110 - Loss: 6.8956 (Macro: 1.4833, Energy: 0.9749, KLD: 2.1345, MC: 2.3029)\n",
      "Train Batch 30/110 - Loss: 7.0511 (Macro: 1.4543, Energy: 0.9887, KLD: 2.3073, MC: 2.3008)\n",
      "Train Batch 40/110 - Loss: 7.4589 (Macro: 1.5503, Energy: 1.2276, KLD: 2.3805, MC: 2.3004)\n",
      "Train Batch 50/110 - Loss: 7.0448 (Macro: 1.5244, Energy: 0.9798, KLD: 2.2381, MC: 2.3025)\n",
      "Train Batch 60/110 - Loss: 6.9041 (Macro: 1.3771, Energy: 0.9666, KLD: 2.2570, MC: 2.3034)\n",
      "Train Batch 70/110 - Loss: 6.9791 (Macro: 1.3781, Energy: 0.8585, KLD: 2.4378, MC: 2.3047)\n",
      "Train Batch 80/110 - Loss: 7.3002 (Macro: 1.4102, Energy: 1.0491, KLD: 2.5365, MC: 2.3044)\n",
      "Train Batch 90/110 - Loss: 6.7805 (Macro: 1.4812, Energy: 0.9741, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.3695 (Macro: 1.5953, Energy: 1.2550, KLD: 2.2161, MC: 2.3031)\n",
      "Train Batch 110/110 - Loss: 6.6194 (Macro: 1.2368, Energy: 0.7443, KLD: 2.3414, MC: 2.2970)\n",
      "Training epoch complete. Average Loss: 7.0831\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0599\n",
      "\n",
      "Epoch 68/500\n",
      "Train Batch 10/110 - Loss: 7.0964 (Macro: 1.5828, Energy: 1.0991, KLD: 2.1149, MC: 2.2996)\n",
      "Train Batch 20/110 - Loss: 6.9039 (Macro: 1.4805, Energy: 0.9869, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.1320 (Macro: 1.4726, Energy: 1.0497, KLD: 2.3073, MC: 2.3024)\n",
      "Train Batch 40/110 - Loss: 7.4896 (Macro: 1.5505, Energy: 1.2571, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0072 (Macro: 1.4866, Energy: 0.9785, KLD: 2.2381, MC: 2.3041)\n",
      "Train Batch 60/110 - Loss: 6.9366 (Macro: 1.3887, Energy: 0.9911, KLD: 2.2570, MC: 2.2997)\n",
      "Train Batch 70/110 - Loss: 6.9731 (Macro: 1.3545, Energy: 0.8786, KLD: 2.4378, MC: 2.3023)\n",
      "Train Batch 80/110 - Loss: 7.3094 (Macro: 1.4417, Energy: 1.0298, KLD: 2.5365, MC: 2.3014)\n",
      "Train Batch 90/110 - Loss: 6.8308 (Macro: 1.5019, Energy: 1.0043, KLD: 2.0241, MC: 2.3006)\n",
      "Train Batch 100/110 - Loss: 7.2872 (Macro: 1.6049, Energy: 1.1635, KLD: 2.2161, MC: 2.3027)\n",
      "Train Batch 110/110 - Loss: 6.6730 (Macro: 1.2180, Energy: 0.8165, KLD: 2.3414, MC: 2.2971)\n",
      "Training epoch complete. Average Loss: 7.0768\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0766\n",
      "\n",
      "Epoch 69/500\n",
      "Train Batch 10/110 - Loss: 7.1355 (Macro: 1.5738, Energy: 1.1461, KLD: 2.1149, MC: 2.3007)\n",
      "Train Batch 20/110 - Loss: 6.9607 (Macro: 1.4957, Energy: 1.0267, KLD: 2.1345, MC: 2.3038)\n",
      "Train Batch 30/110 - Loss: 7.0797 (Macro: 1.4624, Energy: 1.0081, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4908 (Macro: 1.5447, Energy: 1.2629, KLD: 2.3805, MC: 2.3028)\n",
      "Train Batch 50/110 - Loss: 7.0589 (Macro: 1.4858, Energy: 1.0305, KLD: 2.2381, MC: 2.3045)\n",
      "Train Batch 60/110 - Loss: 6.9528 (Macro: 1.3848, Energy: 1.0104, KLD: 2.2570, MC: 2.3005)\n",
      "Train Batch 70/110 - Loss: 6.9265 (Macro: 1.3358, Energy: 0.8493, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.3940 (Macro: 1.4377, Energy: 1.1158, KLD: 2.5365, MC: 2.3040)\n",
      "Train Batch 90/110 - Loss: 6.8536 (Macro: 1.5072, Energy: 1.0216, KLD: 2.0241, MC: 2.3007)\n",
      "Train Batch 100/110 - Loss: 7.3678 (Macro: 1.6120, Energy: 1.2386, KLD: 2.2161, MC: 2.3010)\n",
      "Train Batch 110/110 - Loss: 6.6391 (Macro: 1.2263, Energy: 0.7711, KLD: 2.3414, MC: 2.3003)\n",
      "Training epoch complete. Average Loss: 7.0836\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0640\n",
      "\n",
      "Epoch 70/500\n",
      "Train Batch 10/110 - Loss: 7.1072 (Macro: 1.5679, Energy: 1.1253, KLD: 2.1149, MC: 2.2991)\n",
      "Train Batch 20/110 - Loss: 6.9606 (Macro: 1.4976, Energy: 1.0255, KLD: 2.1345, MC: 2.3031)\n",
      "Train Batch 30/110 - Loss: 7.0640 (Macro: 1.4462, Energy: 1.0080, KLD: 2.3073, MC: 2.3025)\n",
      "Train Batch 40/110 - Loss: 7.4015 (Macro: 1.5586, Energy: 1.1621, KLD: 2.3805, MC: 2.3003)\n",
      "Train Batch 50/110 - Loss: 7.0543 (Macro: 1.4919, Energy: 1.0209, KLD: 2.2381, MC: 2.3034)\n",
      "Train Batch 60/110 - Loss: 6.9136 (Macro: 1.3867, Energy: 0.9706, KLD: 2.2570, MC: 2.2993)\n",
      "Train Batch 70/110 - Loss: 6.9658 (Macro: 1.3804, Energy: 0.8442, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.3195 (Macro: 1.4246, Energy: 1.0558, KLD: 2.5365, MC: 2.3026)\n",
      "Train Batch 90/110 - Loss: 6.7992 (Macro: 1.4918, Energy: 0.9821, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.3027 (Macro: 1.6114, Energy: 1.1741, KLD: 2.2161, MC: 2.3011)\n",
      "Train Batch 110/110 - Loss: 6.6831 (Macro: 1.2068, Energy: 0.8379, KLD: 2.3414, MC: 2.2969)\n",
      "Training epoch complete. Average Loss: 7.0769\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0629\n",
      "\n",
      "Epoch 71/500\n",
      "Train Batch 10/110 - Loss: 7.1168 (Macro: 1.5964, Energy: 1.1065, KLD: 2.1149, MC: 2.2990)\n",
      "Train Batch 20/110 - Loss: 6.8359 (Macro: 1.4709, Energy: 0.9292, KLD: 2.1345, MC: 2.3013)\n",
      "Train Batch 30/110 - Loss: 7.1239 (Macro: 1.4624, Energy: 1.0519, KLD: 2.3073, MC: 2.3023)\n",
      "Train Batch 40/110 - Loss: 7.4905 (Macro: 1.5467, Energy: 1.2626, KLD: 2.3805, MC: 2.3006)\n",
      "Train Batch 50/110 - Loss: 7.1120 (Macro: 1.5146, Energy: 1.0568, KLD: 2.2381, MC: 2.3025)\n",
      "Train Batch 60/110 - Loss: 6.9291 (Macro: 1.3983, Energy: 0.9734, KLD: 2.2570, MC: 2.3003)\n",
      "Train Batch 70/110 - Loss: 6.9466 (Macro: 1.3664, Energy: 0.8389, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.3007 (Macro: 1.4298, Energy: 1.0322, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.8352 (Macro: 1.4966, Energy: 1.0110, KLD: 2.0241, MC: 2.3035)\n",
      "Train Batch 100/110 - Loss: 7.3464 (Macro: 1.6111, Energy: 1.2175, KLD: 2.2161, MC: 2.3017)\n",
      "Train Batch 110/110 - Loss: 6.6501 (Macro: 1.2499, Energy: 0.7591, KLD: 2.3414, MC: 2.2997)\n",
      "Training epoch complete. Average Loss: 7.0803\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0623\n",
      "\n",
      "Epoch 72/500\n",
      "Train Batch 10/110 - Loss: 7.1089 (Macro: 1.5522, Energy: 1.1410, KLD: 2.1149, MC: 2.3008)\n",
      "Train Batch 20/110 - Loss: 6.9038 (Macro: 1.4960, Energy: 0.9696, KLD: 2.1345, MC: 2.3036)\n",
      "Train Batch 30/110 - Loss: 7.0896 (Macro: 1.4505, Energy: 1.0308, KLD: 2.3073, MC: 2.3010)\n",
      "Train Batch 40/110 - Loss: 7.4928 (Macro: 1.5662, Energy: 1.2434, KLD: 2.3805, MC: 2.3027)\n",
      "Train Batch 50/110 - Loss: 7.0109 (Macro: 1.4960, Energy: 0.9737, KLD: 2.2381, MC: 2.3031)\n",
      "Train Batch 60/110 - Loss: 6.8829 (Macro: 1.3870, Energy: 0.9391, KLD: 2.2570, MC: 2.2997)\n",
      "Train Batch 70/110 - Loss: 6.9482 (Macro: 1.3481, Energy: 0.8570, KLD: 2.4378, MC: 2.3054)\n",
      "Train Batch 80/110 - Loss: 7.3130 (Macro: 1.4141, Energy: 1.0595, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.8236 (Macro: 1.4712, Energy: 1.0267, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.2495 (Macro: 1.5811, Energy: 1.1501, KLD: 2.2161, MC: 2.3023)\n",
      "Train Batch 110/110 - Loss: 6.6067 (Macro: 1.2382, Energy: 0.7319, KLD: 2.3414, MC: 2.2953)\n",
      "Training epoch complete. Average Loss: 7.0819\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0635\n",
      "\n",
      "Epoch 73/500\n",
      "Train Batch 10/110 - Loss: 7.0770 (Macro: 1.5734, Energy: 1.0874, KLD: 2.1149, MC: 2.3013)\n",
      "Train Batch 20/110 - Loss: 6.8914 (Macro: 1.4888, Energy: 0.9663, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.1256 (Macro: 1.4517, Energy: 1.0638, KLD: 2.3073, MC: 2.3029)\n",
      "Train Batch 40/110 - Loss: 7.4379 (Macro: 1.5541, Energy: 1.2026, KLD: 2.3805, MC: 2.3007)\n",
      "Train Batch 50/110 - Loss: 6.9896 (Macro: 1.5001, Energy: 0.9488, KLD: 2.2381, MC: 2.3026)\n",
      "Train Batch 60/110 - Loss: 6.8746 (Macro: 1.3700, Energy: 0.9470, KLD: 2.2570, MC: 2.3006)\n",
      "Train Batch 70/110 - Loss: 6.8914 (Macro: 1.3439, Energy: 0.8073, KLD: 2.4378, MC: 2.3024)\n",
      "Train Batch 80/110 - Loss: 7.2854 (Macro: 1.4239, Energy: 1.0206, KLD: 2.5365, MC: 2.3045)\n",
      "Train Batch 90/110 - Loss: 6.8053 (Macro: 1.4929, Energy: 0.9874, KLD: 2.0241, MC: 2.3009)\n",
      "Train Batch 100/110 - Loss: 7.3265 (Macro: 1.5916, Energy: 1.2153, KLD: 2.2161, MC: 2.3035)\n",
      "Train Batch 110/110 - Loss: 6.6106 (Macro: 1.2419, Energy: 0.7310, KLD: 2.3414, MC: 2.2963)\n",
      "Training epoch complete. Average Loss: 7.0761\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0714\n",
      "\n",
      "Epoch 74/500\n",
      "Train Batch 10/110 - Loss: 7.1300 (Macro: 1.5913, Energy: 1.1233, KLD: 2.1149, MC: 2.3005)\n",
      "Train Batch 20/110 - Loss: 6.8985 (Macro: 1.4969, Energy: 0.9639, KLD: 2.1345, MC: 2.3033)\n",
      "Train Batch 30/110 - Loss: 7.1096 (Macro: 1.4507, Energy: 1.0482, KLD: 2.3073, MC: 2.3034)\n",
      "Train Batch 40/110 - Loss: 7.4241 (Macro: 1.5494, Energy: 1.1924, KLD: 2.3805, MC: 2.3018)\n",
      "Train Batch 50/110 - Loss: 7.0380 (Macro: 1.5024, Energy: 0.9956, KLD: 2.2381, MC: 2.3020)\n",
      "Train Batch 60/110 - Loss: 6.9837 (Macro: 1.3789, Energy: 1.0454, KLD: 2.2570, MC: 2.3024)\n",
      "Train Batch 70/110 - Loss: 7.0052 (Macro: 1.3798, Energy: 0.8818, KLD: 2.4378, MC: 2.3058)\n",
      "Train Batch 80/110 - Loss: 7.2777 (Macro: 1.4080, Energy: 1.0316, KLD: 2.5365, MC: 2.3017)\n",
      "Train Batch 90/110 - Loss: 6.7911 (Macro: 1.4810, Energy: 0.9844, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.2804 (Macro: 1.5909, Energy: 1.1733, KLD: 2.2161, MC: 2.3002)\n",
      "Train Batch 110/110 - Loss: 6.6973 (Macro: 1.2488, Energy: 0.8081, KLD: 2.3414, MC: 2.2991)\n",
      "Training epoch complete. Average Loss: 7.0775\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0619\n",
      "\n",
      "Epoch 75/500\n",
      "Train Batch 10/110 - Loss: 7.1466 (Macro: 1.5720, Energy: 1.1581, KLD: 2.1149, MC: 2.3015)\n",
      "Train Batch 20/110 - Loss: 6.9153 (Macro: 1.4932, Energy: 0.9851, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.1032 (Macro: 1.4418, Energy: 1.0539, KLD: 2.3073, MC: 2.3001)\n",
      "Train Batch 40/110 - Loss: 7.4192 (Macro: 1.5595, Energy: 1.1769, KLD: 2.3805, MC: 2.3023)\n",
      "Train Batch 50/110 - Loss: 7.0641 (Macro: 1.4826, Energy: 1.0411, KLD: 2.2381, MC: 2.3024)\n",
      "Train Batch 60/110 - Loss: 6.8837 (Macro: 1.3812, Energy: 0.9442, KLD: 2.2570, MC: 2.3012)\n",
      "Train Batch 70/110 - Loss: 6.9320 (Macro: 1.3470, Energy: 0.8456, KLD: 2.4378, MC: 2.3016)\n",
      "Train Batch 80/110 - Loss: 7.3599 (Macro: 1.4200, Energy: 1.1000, KLD: 2.5365, MC: 2.3033)\n",
      "Train Batch 90/110 - Loss: 6.8015 (Macro: 1.4720, Energy: 1.0034, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3439 (Macro: 1.6212, Energy: 1.2053, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.6308 (Macro: 1.2154, Energy: 0.7744, KLD: 2.3414, MC: 2.2996)\n",
      "Training epoch complete. Average Loss: 7.0750\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0684\n",
      "\n",
      "Epoch 76/500\n",
      "Train Batch 10/110 - Loss: 7.1156 (Macro: 1.6001, Energy: 1.0992, KLD: 2.1149, MC: 2.3013)\n",
      "Train Batch 20/110 - Loss: 6.8527 (Macro: 1.4707, Energy: 0.9472, KLD: 2.1345, MC: 2.3003)\n",
      "Train Batch 30/110 - Loss: 7.1106 (Macro: 1.4700, Energy: 1.0318, KLD: 2.3073, MC: 2.3014)\n",
      "Train Batch 40/110 - Loss: 7.3369 (Macro: 1.5354, Energy: 1.1172, KLD: 2.3805, MC: 2.3038)\n",
      "Train Batch 50/110 - Loss: 7.0862 (Macro: 1.5183, Energy: 1.0271, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.9606 (Macro: 1.3958, Energy: 1.0055, KLD: 2.2570, MC: 2.3022)\n",
      "Train Batch 70/110 - Loss: 6.9622 (Macro: 1.3522, Energy: 0.8680, KLD: 2.4378, MC: 2.3042)\n",
      "Train Batch 80/110 - Loss: 7.3381 (Macro: 1.4329, Energy: 1.0667, KLD: 2.5365, MC: 2.3020)\n",
      "Train Batch 90/110 - Loss: 6.8209 (Macro: 1.4975, Energy: 0.9997, KLD: 2.0241, MC: 2.2996)\n",
      "Train Batch 100/110 - Loss: 7.2446 (Macro: 1.5728, Energy: 1.1546, KLD: 2.2161, MC: 2.3010)\n",
      "Train Batch 110/110 - Loss: 6.7258 (Macro: 1.2526, Energy: 0.8301, KLD: 2.3414, MC: 2.3017)\n",
      "Training epoch complete. Average Loss: 7.0784\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0611\n",
      "\n",
      "Epoch 77/500\n",
      "Train Batch 10/110 - Loss: 7.1587 (Macro: 1.5799, Energy: 1.1655, KLD: 2.1149, MC: 2.2984)\n",
      "Train Batch 20/110 - Loss: 6.9549 (Macro: 1.4836, Energy: 1.0343, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.0747 (Macro: 1.4438, Energy: 1.0195, KLD: 2.3073, MC: 2.3042)\n",
      "Train Batch 40/110 - Loss: 7.4286 (Macro: 1.5543, Energy: 1.1908, KLD: 2.3805, MC: 2.3029)\n",
      "Train Batch 50/110 - Loss: 7.0862 (Macro: 1.4908, Energy: 1.0548, KLD: 2.2381, MC: 2.3026)\n",
      "Train Batch 60/110 - Loss: 6.9118 (Macro: 1.3645, Energy: 0.9884, KLD: 2.2570, MC: 2.3019)\n",
      "Train Batch 70/110 - Loss: 6.9777 (Macro: 1.3826, Energy: 0.8534, KLD: 2.4378, MC: 2.3040)\n",
      "Train Batch 80/110 - Loss: 7.2775 (Macro: 1.4295, Energy: 1.0083, KLD: 2.5365, MC: 2.3033)\n",
      "Train Batch 90/110 - Loss: 6.8211 (Macro: 1.4861, Energy: 1.0089, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3067 (Macro: 1.5986, Energy: 1.1914, KLD: 2.2161, MC: 2.3006)\n",
      "Train Batch 110/110 - Loss: 6.6519 (Macro: 1.2194, Energy: 0.7927, KLD: 2.3414, MC: 2.2985)\n",
      "Training epoch complete. Average Loss: 7.0807\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0655\n",
      "\n",
      "Epoch 78/500\n",
      "Train Batch 10/110 - Loss: 7.1140 (Macro: 1.5857, Energy: 1.1126, KLD: 2.1149, MC: 2.3007)\n",
      "Train Batch 20/110 - Loss: 6.8743 (Macro: 1.4934, Energy: 0.9447, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0917 (Macro: 1.4432, Energy: 1.0393, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4338 (Macro: 1.5340, Energy: 1.2176, KLD: 2.3805, MC: 2.3018)\n",
      "Train Batch 50/110 - Loss: 7.0515 (Macro: 1.5034, Energy: 1.0078, KLD: 2.2381, MC: 2.3023)\n",
      "Train Batch 60/110 - Loss: 6.8918 (Macro: 1.3860, Energy: 0.9474, KLD: 2.2570, MC: 2.3014)\n",
      "Train Batch 70/110 - Loss: 6.9730 (Macro: 1.3774, Energy: 0.8555, KLD: 2.4378, MC: 2.3023)\n",
      "Train Batch 80/110 - Loss: 7.3498 (Macro: 1.4348, Energy: 1.0777, KLD: 2.5365, MC: 2.3008)\n",
      "Train Batch 90/110 - Loss: 6.7948 (Macro: 1.4941, Energy: 0.9755, KLD: 2.0241, MC: 2.3011)\n",
      "Train Batch 100/110 - Loss: 7.2759 (Macro: 1.6044, Energy: 1.1541, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.5524 (Macro: 1.2398, Energy: 0.6736, KLD: 2.3414, MC: 2.2977)\n",
      "Training epoch complete. Average Loss: 7.0741\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0656\n",
      "\n",
      "Epoch 79/500\n",
      "Train Batch 10/110 - Loss: 7.1915 (Macro: 1.5869, Energy: 1.1904, KLD: 2.1149, MC: 2.2992)\n",
      "Train Batch 20/110 - Loss: 6.8510 (Macro: 1.4675, Energy: 0.9464, KLD: 2.1345, MC: 2.3026)\n",
      "Train Batch 30/110 - Loss: 7.0905 (Macro: 1.4522, Energy: 1.0292, KLD: 2.3073, MC: 2.3018)\n",
      "Train Batch 40/110 - Loss: 7.4821 (Macro: 1.5531, Energy: 1.2478, KLD: 2.3805, MC: 2.3007)\n",
      "Train Batch 50/110 - Loss: 7.0725 (Macro: 1.4975, Energy: 1.0320, KLD: 2.2381, MC: 2.3049)\n",
      "Train Batch 60/110 - Loss: 6.8842 (Macro: 1.3592, Energy: 0.9647, KLD: 2.2570, MC: 2.3032)\n",
      "Train Batch 70/110 - Loss: 6.9383 (Macro: 1.3472, Energy: 0.8514, KLD: 2.4378, MC: 2.3019)\n",
      "Train Batch 80/110 - Loss: 7.2584 (Macro: 1.4189, Energy: 0.9984, KLD: 2.5365, MC: 2.3046)\n",
      "Train Batch 90/110 - Loss: 6.7874 (Macro: 1.4805, Energy: 0.9804, KLD: 2.0241, MC: 2.3024)\n",
      "Train Batch 100/110 - Loss: 7.3154 (Macro: 1.5918, Energy: 1.2064, KLD: 2.2161, MC: 2.3011)\n",
      "Train Batch 110/110 - Loss: 6.6715 (Macro: 1.2497, Energy: 0.7825, KLD: 2.3414, MC: 2.2980)\n",
      "Training epoch complete. Average Loss: 7.0848\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0537\n",
      "\n",
      "Epoch 80/500\n",
      "Train Batch 10/110 - Loss: 7.1248 (Macro: 1.5810, Energy: 1.1281, KLD: 2.1149, MC: 2.3008)\n",
      "Train Batch 20/110 - Loss: 6.8883 (Macro: 1.4985, Energy: 0.9508, KLD: 2.1345, MC: 2.3046)\n",
      "Train Batch 30/110 - Loss: 7.0719 (Macro: 1.4466, Energy: 1.0159, KLD: 2.3073, MC: 2.3021)\n",
      "Train Batch 40/110 - Loss: 7.4370 (Macro: 1.5539, Energy: 1.2010, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0717 (Macro: 1.4995, Energy: 1.0304, KLD: 2.2381, MC: 2.3038)\n",
      "Train Batch 60/110 - Loss: 6.8924 (Macro: 1.4099, Energy: 0.9249, KLD: 2.2570, MC: 2.3005)\n",
      "Train Batch 70/110 - Loss: 6.9539 (Macro: 1.3576, Energy: 0.8540, KLD: 2.4378, MC: 2.3046)\n",
      "Train Batch 80/110 - Loss: 7.3157 (Macro: 1.4332, Energy: 1.0425, KLD: 2.5365, MC: 2.3035)\n",
      "Train Batch 90/110 - Loss: 6.8147 (Macro: 1.4776, Energy: 1.0107, KLD: 2.0241, MC: 2.3023)\n",
      "Train Batch 100/110 - Loss: 7.2715 (Macro: 1.6063, Energy: 1.1448, KLD: 2.2161, MC: 2.3042)\n",
      "Train Batch 110/110 - Loss: 6.6306 (Macro: 1.2441, Energy: 0.7473, KLD: 2.3414, MC: 2.2978)\n",
      "Training epoch complete. Average Loss: 7.0872\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0666\n",
      "\n",
      "Epoch 81/500\n",
      "Train Batch 10/110 - Loss: 7.1293 (Macro: 1.5769, Energy: 1.1382, KLD: 2.1149, MC: 2.2992)\n",
      "Train Batch 20/110 - Loss: 6.8872 (Macro: 1.4652, Energy: 0.9855, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.0689 (Macro: 1.4467, Energy: 1.0125, KLD: 2.3073, MC: 2.3024)\n",
      "Train Batch 40/110 - Loss: 7.5047 (Macro: 1.5503, Energy: 1.2742, KLD: 2.3805, MC: 2.2997)\n",
      "Train Batch 50/110 - Loss: 7.1165 (Macro: 1.5223, Energy: 1.0530, KLD: 2.2381, MC: 2.3031)\n",
      "Train Batch 60/110 - Loss: 6.9102 (Macro: 1.3784, Energy: 0.9733, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9609 (Macro: 1.3572, Energy: 0.8624, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.3541 (Macro: 1.4237, Energy: 1.0916, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.8367 (Macro: 1.4870, Energy: 1.0234, KLD: 2.0241, MC: 2.3023)\n",
      "Train Batch 100/110 - Loss: 7.3813 (Macro: 1.6097, Energy: 1.2550, KLD: 2.2161, MC: 2.3004)\n",
      "Train Batch 110/110 - Loss: 6.6129 (Macro: 1.2332, Energy: 0.7389, KLD: 2.3414, MC: 2.2995)\n",
      "Training epoch complete. Average Loss: 7.0788\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0831\n",
      "\n",
      "Epoch 82/500\n",
      "Train Batch 10/110 - Loss: 7.1342 (Macro: 1.5885, Energy: 1.1307, KLD: 2.1149, MC: 2.3000)\n",
      "Train Batch 20/110 - Loss: 6.9037 (Macro: 1.4715, Energy: 0.9958, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.1228 (Macro: 1.4577, Energy: 1.0555, KLD: 2.3073, MC: 2.3023)\n",
      "Train Batch 40/110 - Loss: 7.4742 (Macro: 1.5528, Energy: 1.2383, KLD: 2.3805, MC: 2.3026)\n",
      "Train Batch 50/110 - Loss: 7.0633 (Macro: 1.4909, Energy: 1.0304, KLD: 2.2381, MC: 2.3040)\n",
      "Train Batch 60/110 - Loss: 6.8673 (Macro: 1.3785, Energy: 0.9297, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.9539 (Macro: 1.3551, Energy: 0.8576, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.2654 (Macro: 1.4125, Energy: 1.0135, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.7620 (Macro: 1.4841, Energy: 0.9514, KLD: 2.0241, MC: 2.3025)\n",
      "Train Batch 100/110 - Loss: 7.3057 (Macro: 1.5904, Energy: 1.1983, KLD: 2.2161, MC: 2.3009)\n",
      "Train Batch 110/110 - Loss: 6.7019 (Macro: 1.2669, Energy: 0.7948, KLD: 2.3414, MC: 2.2988)\n",
      "Training epoch complete. Average Loss: 7.0795\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0554\n",
      "\n",
      "Epoch 83/500\n",
      "Train Batch 10/110 - Loss: 7.1333 (Macro: 1.5994, Energy: 1.1190, KLD: 2.1149, MC: 2.3000)\n",
      "Train Batch 20/110 - Loss: 6.8727 (Macro: 1.4975, Energy: 0.9380, KLD: 2.1345, MC: 2.3028)\n",
      "Train Batch 30/110 - Loss: 7.1166 (Macro: 1.4593, Energy: 1.0474, KLD: 2.3073, MC: 2.3027)\n",
      "Train Batch 40/110 - Loss: 7.4020 (Macro: 1.5549, Energy: 1.1639, KLD: 2.3805, MC: 2.3027)\n",
      "Train Batch 50/110 - Loss: 7.0490 (Macro: 1.5063, Energy: 1.0033, KLD: 2.2381, MC: 2.3014)\n",
      "Train Batch 60/110 - Loss: 6.9118 (Macro: 1.3969, Energy: 0.9558, KLD: 2.2570, MC: 2.3021)\n",
      "Train Batch 70/110 - Loss: 6.8605 (Macro: 1.3522, Energy: 0.7668, KLD: 2.4378, MC: 2.3038)\n",
      "Train Batch 80/110 - Loss: 7.3285 (Macro: 1.4188, Energy: 1.0708, KLD: 2.5365, MC: 2.3024)\n",
      "Train Batch 90/110 - Loss: 6.7399 (Macro: 1.4795, Energy: 0.9333, KLD: 2.0241, MC: 2.3030)\n",
      "Train Batch 100/110 - Loss: 7.3025 (Macro: 1.5989, Energy: 1.1855, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.5684 (Macro: 1.2183, Energy: 0.7098, KLD: 2.3414, MC: 2.2989)\n",
      "Training epoch complete. Average Loss: 7.0805\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0580\n",
      "\n",
      "Epoch 84/500\n",
      "Train Batch 10/110 - Loss: 7.1064 (Macro: 1.5717, Energy: 1.1177, KLD: 2.1149, MC: 2.3020)\n",
      "Train Batch 20/110 - Loss: 6.9440 (Macro: 1.4707, Energy: 1.0369, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.1174 (Macro: 1.4558, Energy: 1.0524, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4455 (Macro: 1.5496, Energy: 1.2149, KLD: 2.3805, MC: 2.3005)\n",
      "Train Batch 50/110 - Loss: 7.0583 (Macro: 1.5014, Energy: 1.0153, KLD: 2.2381, MC: 2.3036)\n",
      "Train Batch 60/110 - Loss: 6.9306 (Macro: 1.3842, Energy: 0.9881, KLD: 2.2570, MC: 2.3013)\n",
      "Train Batch 70/110 - Loss: 6.9614 (Macro: 1.3718, Energy: 0.8473, KLD: 2.4378, MC: 2.3045)\n",
      "Train Batch 80/110 - Loss: 7.3447 (Macro: 1.4199, Energy: 1.0844, KLD: 2.5365, MC: 2.3039)\n",
      "Train Batch 90/110 - Loss: 6.8286 (Macro: 1.5078, Energy: 0.9963, KLD: 2.0241, MC: 2.3004)\n",
      "Train Batch 100/110 - Loss: 7.3001 (Macro: 1.5864, Energy: 1.1945, KLD: 2.2161, MC: 2.3031)\n",
      "Train Batch 110/110 - Loss: 6.6803 (Macro: 1.2324, Energy: 0.8093, KLD: 2.3414, MC: 2.2972)\n",
      "Training epoch complete. Average Loss: 7.0767\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0660\n",
      "\n",
      "Epoch 85/500\n",
      "Train Batch 10/110 - Loss: 7.1054 (Macro: 1.5558, Energy: 1.1341, KLD: 2.1149, MC: 2.3005)\n",
      "Train Batch 20/110 - Loss: 6.8640 (Macro: 1.4697, Energy: 0.9566, KLD: 2.1345, MC: 2.3032)\n",
      "Train Batch 30/110 - Loss: 7.0170 (Macro: 1.4414, Energy: 0.9652, KLD: 2.3073, MC: 2.3031)\n",
      "Train Batch 40/110 - Loss: 7.4466 (Macro: 1.5623, Energy: 1.2006, KLD: 2.3805, MC: 2.3032)\n",
      "Train Batch 50/110 - Loss: 7.0387 (Macro: 1.4731, Energy: 1.0235, KLD: 2.2381, MC: 2.3041)\n",
      "Train Batch 60/110 - Loss: 6.9291 (Macro: 1.3979, Energy: 0.9747, KLD: 2.2570, MC: 2.2995)\n",
      "Train Batch 70/110 - Loss: 6.8975 (Macro: 1.3498, Energy: 0.8056, KLD: 2.4378, MC: 2.3042)\n",
      "Train Batch 80/110 - Loss: 7.3257 (Macro: 1.4257, Energy: 1.0607, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.7835 (Macro: 1.4731, Energy: 0.9845, KLD: 2.0241, MC: 2.3018)\n",
      "Train Batch 100/110 - Loss: 7.3854 (Macro: 1.6158, Energy: 1.2525, KLD: 2.2161, MC: 2.3010)\n",
      "Train Batch 110/110 - Loss: 6.5966 (Macro: 1.2423, Energy: 0.7134, KLD: 2.3414, MC: 2.2995)\n",
      "Training epoch complete. Average Loss: 7.0752\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0683\n",
      "\n",
      "Epoch 86/500\n",
      "Train Batch 10/110 - Loss: 7.1480 (Macro: 1.5623, Energy: 1.1687, KLD: 2.1149, MC: 2.3021)\n",
      "Train Batch 20/110 - Loss: 6.9067 (Macro: 1.4842, Energy: 0.9854, KLD: 2.1345, MC: 2.3026)\n",
      "Train Batch 30/110 - Loss: 7.0891 (Macro: 1.4406, Energy: 1.0409, KLD: 2.3073, MC: 2.3003)\n",
      "Train Batch 40/110 - Loss: 7.4016 (Macro: 1.5542, Energy: 1.1661, KLD: 2.3805, MC: 2.3008)\n",
      "Train Batch 50/110 - Loss: 7.0448 (Macro: 1.5061, Energy: 0.9972, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.8745 (Macro: 1.3775, Energy: 0.9393, KLD: 2.2570, MC: 2.3007)\n",
      "Train Batch 70/110 - Loss: 6.9046 (Macro: 1.3518, Energy: 0.8125, KLD: 2.4378, MC: 2.3024)\n",
      "Train Batch 80/110 - Loss: 7.2520 (Macro: 1.4106, Energy: 1.0019, KLD: 2.5365, MC: 2.3031)\n",
      "Train Batch 90/110 - Loss: 6.8115 (Macro: 1.4786, Energy: 1.0092, KLD: 2.0241, MC: 2.2996)\n",
      "Train Batch 100/110 - Loss: 7.4032 (Macro: 1.6156, Energy: 1.2707, KLD: 2.2161, MC: 2.3009)\n",
      "Train Batch 110/110 - Loss: 6.5908 (Macro: 1.2315, Energy: 0.7177, KLD: 2.3414, MC: 2.3002)\n",
      "Training epoch complete. Average Loss: 7.0774\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0634\n",
      "\n",
      "Epoch 87/500\n",
      "Train Batch 10/110 - Loss: 7.1074 (Macro: 1.5743, Energy: 1.1180, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.9414 (Macro: 1.5017, Energy: 1.0031, KLD: 2.1345, MC: 2.3021)\n",
      "Train Batch 30/110 - Loss: 7.0762 (Macro: 1.4508, Energy: 1.0157, KLD: 2.3073, MC: 2.3024)\n",
      "Train Batch 40/110 - Loss: 7.4686 (Macro: 1.5587, Energy: 1.2285, KLD: 2.3805, MC: 2.3009)\n",
      "Train Batch 50/110 - Loss: 7.0228 (Macro: 1.4908, Energy: 0.9905, KLD: 2.2381, MC: 2.3034)\n",
      "Train Batch 60/110 - Loss: 6.9116 (Macro: 1.3853, Energy: 0.9667, KLD: 2.2570, MC: 2.3026)\n",
      "Train Batch 70/110 - Loss: 6.9045 (Macro: 1.3655, Energy: 0.7982, KLD: 2.4378, MC: 2.3031)\n",
      "Train Batch 80/110 - Loss: 7.2711 (Macro: 1.4343, Energy: 0.9985, KLD: 2.5365, MC: 2.3019)\n",
      "Train Batch 90/110 - Loss: 6.7845 (Macro: 1.4827, Energy: 0.9780, KLD: 2.0241, MC: 2.2998)\n",
      "Train Batch 100/110 - Loss: 7.3080 (Macro: 1.6137, Energy: 1.1779, KLD: 2.2161, MC: 2.3003)\n",
      "Train Batch 110/110 - Loss: 6.5885 (Macro: 1.2476, Energy: 0.7016, KLD: 2.3414, MC: 2.2979)\n",
      "Training epoch complete. Average Loss: 7.0779\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0655\n",
      "\n",
      "Epoch 88/500\n",
      "Train Batch 10/110 - Loss: 7.1326 (Macro: 1.5921, Energy: 1.1233, KLD: 2.1149, MC: 2.3024)\n",
      "Train Batch 20/110 - Loss: 6.9469 (Macro: 1.5041, Energy: 1.0067, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.0518 (Macro: 1.4504, Energy: 0.9920, KLD: 2.3073, MC: 2.3022)\n",
      "Train Batch 40/110 - Loss: 7.4570 (Macro: 1.5473, Energy: 1.2275, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.1241 (Macro: 1.5194, Energy: 1.0633, KLD: 2.2381, MC: 2.3033)\n",
      "Train Batch 60/110 - Loss: 6.9403 (Macro: 1.4017, Energy: 0.9800, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9318 (Macro: 1.3595, Energy: 0.8312, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.2599 (Macro: 1.4206, Energy: 0.9994, KLD: 2.5365, MC: 2.3034)\n",
      "Train Batch 90/110 - Loss: 6.7803 (Macro: 1.4761, Energy: 0.9771, KLD: 2.0241, MC: 2.3030)\n",
      "Train Batch 100/110 - Loss: 7.2325 (Macro: 1.5848, Energy: 1.1299, KLD: 2.2161, MC: 2.3017)\n",
      "Train Batch 110/110 - Loss: 6.6202 (Macro: 1.2368, Energy: 0.7450, KLD: 2.3414, MC: 2.2971)\n",
      "Training epoch complete. Average Loss: 7.0789\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0670\n",
      "\n",
      "Epoch 89/500\n",
      "Train Batch 10/110 - Loss: 7.0739 (Macro: 1.5638, Energy: 1.0934, KLD: 2.1149, MC: 2.3017)\n",
      "Train Batch 20/110 - Loss: 6.8860 (Macro: 1.4853, Energy: 0.9631, KLD: 2.1345, MC: 2.3031)\n",
      "Train Batch 30/110 - Loss: 7.0523 (Macro: 1.4433, Energy: 0.9996, KLD: 2.3073, MC: 2.3020)\n",
      "Train Batch 40/110 - Loss: 7.4266 (Macro: 1.5551, Energy: 1.1906, KLD: 2.3805, MC: 2.3003)\n",
      "Train Batch 50/110 - Loss: 7.0132 (Macro: 1.4901, Energy: 0.9828, KLD: 2.2381, MC: 2.3022)\n",
      "Train Batch 60/110 - Loss: 6.8977 (Macro: 1.3906, Energy: 0.9472, KLD: 2.2570, MC: 2.3028)\n",
      "Train Batch 70/110 - Loss: 6.9703 (Macro: 1.3663, Energy: 0.8636, KLD: 2.4378, MC: 2.3026)\n",
      "Train Batch 80/110 - Loss: 7.2728 (Macro: 1.4144, Energy: 1.0189, KLD: 2.5365, MC: 2.3031)\n",
      "Train Batch 90/110 - Loss: 6.7644 (Macro: 1.4687, Energy: 0.9704, KLD: 2.0241, MC: 2.3014)\n",
      "Train Batch 100/110 - Loss: 7.3366 (Macro: 1.6129, Energy: 1.2057, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.6212 (Macro: 1.2291, Energy: 0.7493, KLD: 2.3414, MC: 2.3015)\n",
      "Training epoch complete. Average Loss: 7.0765\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0475\n",
      "\n",
      "Epoch 90/500\n",
      "Train Batch 10/110 - Loss: 7.1354 (Macro: 1.5881, Energy: 1.1333, KLD: 2.1149, MC: 2.2990)\n",
      "Train Batch 20/110 - Loss: 6.9317 (Macro: 1.4871, Energy: 1.0083, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0515 (Macro: 1.4547, Energy: 0.9870, KLD: 2.3073, MC: 2.3026)\n",
      "Train Batch 40/110 - Loss: 7.4790 (Macro: 1.5529, Energy: 1.2447, KLD: 2.3805, MC: 2.3009)\n",
      "Train Batch 50/110 - Loss: 7.0646 (Macro: 1.5073, Energy: 1.0167, KLD: 2.2381, MC: 2.3025)\n",
      "Train Batch 60/110 - Loss: 6.9674 (Macro: 1.4107, Energy: 0.9966, KLD: 2.2570, MC: 2.3031)\n",
      "Train Batch 70/110 - Loss: 6.9212 (Macro: 1.3561, Energy: 0.8261, KLD: 2.4378, MC: 2.3013)\n",
      "Train Batch 80/110 - Loss: 7.2699 (Macro: 1.4140, Energy: 1.0177, KLD: 2.5365, MC: 2.3017)\n",
      "Train Batch 90/110 - Loss: 6.7615 (Macro: 1.4760, Energy: 0.9587, KLD: 2.0241, MC: 2.3028)\n",
      "Train Batch 100/110 - Loss: 7.3340 (Macro: 1.6003, Energy: 1.2158, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.6071 (Macro: 1.2399, Energy: 0.7253, KLD: 2.3414, MC: 2.3005)\n",
      "Training epoch complete. Average Loss: 7.0850\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0687\n",
      "\n",
      "Epoch 91/500\n",
      "Train Batch 10/110 - Loss: 7.0793 (Macro: 1.5753, Energy: 1.0882, KLD: 2.1149, MC: 2.3010)\n",
      "Train Batch 20/110 - Loss: 6.9235 (Macro: 1.4869, Energy: 1.0002, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.1031 (Macro: 1.4600, Energy: 1.0342, KLD: 2.3073, MC: 2.3017)\n",
      "Train Batch 40/110 - Loss: 7.4574 (Macro: 1.5464, Energy: 1.2290, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.0640 (Macro: 1.4992, Energy: 1.0242, KLD: 2.2381, MC: 2.3026)\n",
      "Train Batch 60/110 - Loss: 6.9765 (Macro: 1.3814, Energy: 1.0367, KLD: 2.2570, MC: 2.3014)\n",
      "Train Batch 70/110 - Loss: 6.9211 (Macro: 1.3575, Energy: 0.8233, KLD: 2.4378, MC: 2.3026)\n",
      "Train Batch 80/110 - Loss: 7.3088 (Macro: 1.4387, Energy: 1.0309, KLD: 2.5365, MC: 2.3027)\n",
      "Train Batch 90/110 - Loss: 6.8309 (Macro: 1.4917, Energy: 1.0150, KLD: 2.0241, MC: 2.3002)\n",
      "Train Batch 100/110 - Loss: 7.3108 (Macro: 1.6063, Energy: 1.1862, KLD: 2.2161, MC: 2.3021)\n",
      "Train Batch 110/110 - Loss: 6.5425 (Macro: 1.2130, Energy: 0.6903, KLD: 2.3414, MC: 2.2978)\n",
      "Training epoch complete. Average Loss: 7.0811\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0541\n",
      "\n",
      "Epoch 92/500\n",
      "Train Batch 10/110 - Loss: 7.1432 (Macro: 1.5635, Energy: 1.1656, KLD: 2.1149, MC: 2.2992)\n",
      "Train Batch 20/110 - Loss: 6.8761 (Macro: 1.4811, Energy: 0.9587, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0600 (Macro: 1.4479, Energy: 1.0055, KLD: 2.3073, MC: 2.2993)\n",
      "Train Batch 40/110 - Loss: 7.4410 (Macro: 1.5646, Energy: 1.1954, KLD: 2.3805, MC: 2.3005)\n",
      "Train Batch 50/110 - Loss: 7.0805 (Macro: 1.5037, Energy: 1.0352, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.9170 (Macro: 1.3779, Energy: 0.9823, KLD: 2.2570, MC: 2.2998)\n",
      "Train Batch 70/110 - Loss: 6.9581 (Macro: 1.3716, Energy: 0.8463, KLD: 2.4378, MC: 2.3025)\n",
      "Train Batch 80/110 - Loss: 7.3034 (Macro: 1.4184, Energy: 1.0467, KLD: 2.5365, MC: 2.3018)\n",
      "Train Batch 90/110 - Loss: 6.8140 (Macro: 1.4815, Energy: 1.0059, KLD: 2.0241, MC: 2.3026)\n",
      "Train Batch 100/110 - Loss: 7.3367 (Macro: 1.6071, Energy: 1.2104, KLD: 2.2161, MC: 2.3031)\n",
      "Train Batch 110/110 - Loss: 6.6429 (Macro: 1.2451, Energy: 0.7571, KLD: 2.3414, MC: 2.2994)\n",
      "Training epoch complete. Average Loss: 7.0824\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0574\n",
      "\n",
      "Epoch 93/500\n",
      "Train Batch 10/110 - Loss: 7.1303 (Macro: 1.5678, Energy: 1.1486, KLD: 2.1149, MC: 2.2990)\n",
      "Train Batch 20/110 - Loss: 6.8744 (Macro: 1.5012, Energy: 0.9367, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.0937 (Macro: 1.4573, Energy: 1.0240, KLD: 2.3073, MC: 2.3051)\n",
      "Train Batch 40/110 - Loss: 7.4531 (Macro: 1.5576, Energy: 1.2148, KLD: 2.3805, MC: 2.3002)\n",
      "Train Batch 50/110 - Loss: 7.0534 (Macro: 1.4914, Energy: 1.0215, KLD: 2.2381, MC: 2.3024)\n",
      "Train Batch 60/110 - Loss: 6.9268 (Macro: 1.3943, Energy: 0.9739, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9489 (Macro: 1.3567, Energy: 0.8508, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.3365 (Macro: 1.4217, Energy: 1.0754, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.8245 (Macro: 1.4845, Energy: 1.0141, KLD: 2.0241, MC: 2.3018)\n",
      "Train Batch 100/110 - Loss: 7.3546 (Macro: 1.6283, Energy: 1.2078, KLD: 2.2161, MC: 2.3024)\n",
      "Train Batch 110/110 - Loss: 6.7104 (Macro: 1.2265, Energy: 0.8435, KLD: 2.3414, MC: 2.2989)\n",
      "Training epoch complete. Average Loss: 7.0782\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0697\n",
      "\n",
      "Epoch 94/500\n",
      "Train Batch 10/110 - Loss: 7.1208 (Macro: 1.5628, Energy: 1.1425, KLD: 2.1149, MC: 2.3005)\n",
      "Train Batch 20/110 - Loss: 6.8340 (Macro: 1.4794, Energy: 0.9184, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.0912 (Macro: 1.4547, Energy: 1.0293, KLD: 2.3073, MC: 2.2999)\n",
      "Train Batch 40/110 - Loss: 7.4229 (Macro: 1.5398, Energy: 1.2020, KLD: 2.3805, MC: 2.3005)\n",
      "Train Batch 50/110 - Loss: 7.0387 (Macro: 1.4800, Energy: 1.0159, KLD: 2.2381, MC: 2.3047)\n",
      "Train Batch 60/110 - Loss: 6.9459 (Macro: 1.4086, Energy: 0.9776, KLD: 2.2570, MC: 2.3027)\n",
      "Train Batch 70/110 - Loss: 6.9032 (Macro: 1.3269, Energy: 0.8333, KLD: 2.4378, MC: 2.3052)\n",
      "Train Batch 80/110 - Loss: 7.3022 (Macro: 1.4096, Energy: 1.0535, KLD: 2.5365, MC: 2.3026)\n",
      "Train Batch 90/110 - Loss: 6.7264 (Macro: 1.4672, Energy: 0.9339, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.3228 (Macro: 1.6036, Energy: 1.2021, KLD: 2.2161, MC: 2.3010)\n",
      "Train Batch 110/110 - Loss: 6.6069 (Macro: 1.2513, Energy: 0.7163, KLD: 2.3414, MC: 2.2979)\n",
      "Training epoch complete. Average Loss: 7.0740\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0640\n",
      "\n",
      "Epoch 95/500\n",
      "Train Batch 10/110 - Loss: 7.1554 (Macro: 1.5924, Energy: 1.1501, KLD: 2.1149, MC: 2.2979)\n",
      "Train Batch 20/110 - Loss: 6.9219 (Macro: 1.4927, Energy: 0.9937, KLD: 2.1345, MC: 2.3010)\n",
      "Train Batch 30/110 - Loss: 7.1145 (Macro: 1.4669, Energy: 1.0393, KLD: 2.3073, MC: 2.3010)\n",
      "Train Batch 40/110 - Loss: 7.3898 (Macro: 1.5318, Energy: 1.1752, KLD: 2.3805, MC: 2.3023)\n",
      "Train Batch 50/110 - Loss: 7.0926 (Macro: 1.5139, Energy: 1.0393, KLD: 2.2381, MC: 2.3014)\n",
      "Train Batch 60/110 - Loss: 6.9076 (Macro: 1.4038, Energy: 0.9443, KLD: 2.2570, MC: 2.3025)\n",
      "Train Batch 70/110 - Loss: 6.9718 (Macro: 1.3611, Energy: 0.8707, KLD: 2.4378, MC: 2.3022)\n",
      "Train Batch 80/110 - Loss: 7.3023 (Macro: 1.4276, Energy: 1.0352, KLD: 2.5365, MC: 2.3030)\n",
      "Train Batch 90/110 - Loss: 6.7327 (Macro: 1.4672, Energy: 0.9394, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3417 (Macro: 1.6136, Energy: 1.2117, KLD: 2.2161, MC: 2.3003)\n",
      "Train Batch 110/110 - Loss: 6.5861 (Macro: 1.2473, Energy: 0.6980, KLD: 2.3414, MC: 2.2995)\n",
      "Training epoch complete. Average Loss: 7.0762\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0659\n",
      "\n",
      "Epoch 96/500\n",
      "Train Batch 10/110 - Loss: 7.0630 (Macro: 1.5644, Energy: 1.0838, KLD: 2.1149, MC: 2.2999)\n",
      "Train Batch 20/110 - Loss: 6.8627 (Macro: 1.4776, Energy: 0.9494, KLD: 2.1345, MC: 2.3011)\n",
      "Train Batch 30/110 - Loss: 7.0629 (Macro: 1.4482, Energy: 1.0061, KLD: 2.3073, MC: 2.3013)\n",
      "Train Batch 40/110 - Loss: 7.4481 (Macro: 1.5558, Energy: 1.2091, KLD: 2.3805, MC: 2.3028)\n",
      "Train Batch 50/110 - Loss: 7.1240 (Macro: 1.5183, Energy: 1.0654, KLD: 2.2381, MC: 2.3023)\n",
      "Train Batch 60/110 - Loss: 6.9160 (Macro: 1.3991, Energy: 0.9591, KLD: 2.2570, MC: 2.3008)\n",
      "Train Batch 70/110 - Loss: 6.9694 (Macro: 1.3436, Energy: 0.8853, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.3056 (Macro: 1.4255, Energy: 1.0427, KLD: 2.5365, MC: 2.3009)\n",
      "Train Batch 90/110 - Loss: 6.7884 (Macro: 1.4899, Energy: 0.9733, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.2530 (Macro: 1.5971, Energy: 1.1378, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.5759 (Macro: 1.2420, Energy: 0.6970, KLD: 2.3414, MC: 2.2955)\n",
      "Training epoch complete. Average Loss: 7.0803\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0678\n",
      "\n",
      "Epoch 97/500\n",
      "Train Batch 10/110 - Loss: 7.1349 (Macro: 1.5707, Energy: 1.1488, KLD: 2.1149, MC: 2.3005)\n",
      "Train Batch 20/110 - Loss: 6.8634 (Macro: 1.4788, Energy: 0.9492, KLD: 2.1345, MC: 2.3010)\n",
      "Train Batch 30/110 - Loss: 7.1549 (Macro: 1.4573, Energy: 1.0891, KLD: 2.3073, MC: 2.3012)\n",
      "Train Batch 40/110 - Loss: 7.4729 (Macro: 1.5597, Energy: 1.2307, KLD: 2.3805, MC: 2.3020)\n",
      "Train Batch 50/110 - Loss: 7.0395 (Macro: 1.4727, Energy: 1.0251, KLD: 2.2381, MC: 2.3036)\n",
      "Train Batch 60/110 - Loss: 6.9331 (Macro: 1.3900, Energy: 0.9839, KLD: 2.2570, MC: 2.3022)\n",
      "Train Batch 70/110 - Loss: 6.9734 (Macro: 1.3661, Energy: 0.8653, KLD: 2.4378, MC: 2.3043)\n",
      "Train Batch 80/110 - Loss: 7.2764 (Macro: 1.4295, Energy: 1.0073, KLD: 2.5365, MC: 2.3032)\n",
      "Train Batch 90/110 - Loss: 6.7893 (Macro: 1.4665, Energy: 0.9983, KLD: 2.0241, MC: 2.3005)\n",
      "Train Batch 100/110 - Loss: 7.3032 (Macro: 1.6031, Energy: 1.1803, KLD: 2.2161, MC: 2.3037)\n",
      "Train Batch 110/110 - Loss: 6.6845 (Macro: 1.2438, Energy: 0.7986, KLD: 2.3414, MC: 2.3007)\n",
      "Training epoch complete. Average Loss: 7.0828\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0613\n",
      "\n",
      "Epoch 98/500\n",
      "Train Batch 10/110 - Loss: 7.1154 (Macro: 1.5821, Energy: 1.1194, KLD: 2.1149, MC: 2.2989)\n",
      "Train Batch 20/110 - Loss: 6.8514 (Macro: 1.4670, Energy: 0.9503, KLD: 2.1345, MC: 2.2996)\n",
      "Train Batch 30/110 - Loss: 7.0991 (Macro: 1.4695, Energy: 1.0211, KLD: 2.3073, MC: 2.3012)\n",
      "Train Batch 40/110 - Loss: 7.4481 (Macro: 1.5619, Energy: 1.2030, KLD: 2.3805, MC: 2.3027)\n",
      "Train Batch 50/110 - Loss: 7.0506 (Macro: 1.5041, Energy: 1.0068, KLD: 2.2381, MC: 2.3017)\n",
      "Train Batch 60/110 - Loss: 6.9289 (Macro: 1.3972, Energy: 0.9736, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9328 (Macro: 1.3515, Energy: 0.8402, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.3144 (Macro: 1.4012, Energy: 1.0732, KLD: 2.5365, MC: 2.3035)\n",
      "Train Batch 90/110 - Loss: 6.7488 (Macro: 1.4597, Energy: 0.9630, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3662 (Macro: 1.6095, Energy: 1.2374, KLD: 2.2161, MC: 2.3032)\n",
      "Train Batch 110/110 - Loss: 6.5998 (Macro: 1.2111, Energy: 0.7473, KLD: 2.3414, MC: 2.3000)\n",
      "Training epoch complete. Average Loss: 7.0848\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0548\n",
      "\n",
      "Epoch 99/500\n",
      "Train Batch 10/110 - Loss: 7.1383 (Macro: 1.5802, Energy: 1.1442, KLD: 2.1149, MC: 2.2989)\n",
      "Train Batch 20/110 - Loss: 6.8284 (Macro: 1.4811, Energy: 0.9124, KLD: 2.1345, MC: 2.3004)\n",
      "Train Batch 30/110 - Loss: 7.0931 (Macro: 1.4507, Energy: 1.0327, KLD: 2.3073, MC: 2.3025)\n",
      "Train Batch 40/110 - Loss: 7.4494 (Macro: 1.5419, Energy: 1.2254, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0672 (Macro: 1.4861, Energy: 1.0387, KLD: 2.2381, MC: 2.3043)\n",
      "Train Batch 60/110 - Loss: 6.8859 (Macro: 1.3793, Energy: 0.9475, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.9291 (Macro: 1.3586, Energy: 0.8286, KLD: 2.4378, MC: 2.3040)\n",
      "Train Batch 80/110 - Loss: 7.2681 (Macro: 1.4137, Energy: 1.0156, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.7836 (Macro: 1.4636, Energy: 0.9944, KLD: 2.0241, MC: 2.3015)\n",
      "Train Batch 100/110 - Loss: 7.3299 (Macro: 1.5937, Energy: 1.2164, KLD: 2.2161, MC: 2.3037)\n",
      "Train Batch 110/110 - Loss: 6.6472 (Macro: 1.2549, Energy: 0.7520, KLD: 2.3414, MC: 2.2989)\n",
      "Training epoch complete. Average Loss: 7.0860\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0555\n",
      "\n",
      "Epoch 100/500\n",
      "Train Batch 10/110 - Loss: 7.0679 (Macro: 1.5771, Energy: 1.0773, KLD: 2.1149, MC: 2.2986)\n",
      "Train Batch 20/110 - Loss: 6.8781 (Macro: 1.4719, Energy: 0.9700, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0654 (Macro: 1.4546, Energy: 1.0001, KLD: 2.3073, MC: 2.3034)\n",
      "Train Batch 40/110 - Loss: 7.4456 (Macro: 1.5422, Energy: 1.2231, KLD: 2.3805, MC: 2.2997)\n",
      "Train Batch 50/110 - Loss: 7.0517 (Macro: 1.4983, Energy: 1.0141, KLD: 2.2381, MC: 2.3012)\n",
      "Train Batch 60/110 - Loss: 6.9377 (Macro: 1.3897, Energy: 0.9906, KLD: 2.2570, MC: 2.3004)\n",
      "Train Batch 70/110 - Loss: 6.9452 (Macro: 1.3732, Energy: 0.8302, KLD: 2.4378, MC: 2.3040)\n",
      "Train Batch 80/110 - Loss: 7.2930 (Macro: 1.3955, Energy: 1.0583, KLD: 2.5365, MC: 2.3027)\n",
      "Train Batch 90/110 - Loss: 6.8150 (Macro: 1.4804, Energy: 1.0071, KLD: 2.0241, MC: 2.3035)\n",
      "Train Batch 100/110 - Loss: 7.3298 (Macro: 1.6044, Energy: 1.2075, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.6383 (Macro: 1.2355, Energy: 0.7604, KLD: 2.3414, MC: 2.3010)\n",
      "Training epoch complete. Average Loss: 7.0785\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0587\n",
      "\n",
      "Epoch 101/500\n",
      "Train Batch 10/110 - Loss: 7.1382 (Macro: 1.5775, Energy: 1.1452, KLD: 2.1149, MC: 2.3007)\n",
      "Train Batch 20/110 - Loss: 6.8865 (Macro: 1.4832, Energy: 0.9665, KLD: 2.1345, MC: 2.3023)\n",
      "Train Batch 30/110 - Loss: 7.0878 (Macro: 1.4324, Energy: 1.0456, KLD: 2.3073, MC: 2.3026)\n",
      "Train Batch 40/110 - Loss: 7.4314 (Macro: 1.5585, Energy: 1.1906, KLD: 2.3805, MC: 2.3017)\n",
      "Train Batch 50/110 - Loss: 7.0492 (Macro: 1.4904, Energy: 1.0182, KLD: 2.2381, MC: 2.3026)\n",
      "Train Batch 60/110 - Loss: 6.9097 (Macro: 1.3852, Energy: 0.9668, KLD: 2.2570, MC: 2.3007)\n",
      "Train Batch 70/110 - Loss: 6.9385 (Macro: 1.3538, Energy: 0.8420, KLD: 2.4378, MC: 2.3050)\n",
      "Train Batch 80/110 - Loss: 7.3255 (Macro: 1.4263, Energy: 1.0601, KLD: 2.5365, MC: 2.3027)\n",
      "Train Batch 90/110 - Loss: 6.7911 (Macro: 1.4744, Energy: 0.9914, KLD: 2.0241, MC: 2.3013)\n",
      "Train Batch 100/110 - Loss: 7.3107 (Macro: 1.5893, Energy: 1.2050, KLD: 2.2161, MC: 2.3003)\n",
      "Train Batch 110/110 - Loss: 6.6288 (Macro: 1.2329, Energy: 0.7537, KLD: 2.3414, MC: 2.3008)\n",
      "Training epoch complete. Average Loss: 7.0811\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0557\n",
      "\n",
      "Epoch 102/500\n",
      "Train Batch 10/110 - Loss: 7.1332 (Macro: 1.5780, Energy: 1.1411, KLD: 2.1149, MC: 2.2991)\n",
      "Train Batch 20/110 - Loss: 6.8968 (Macro: 1.4684, Energy: 0.9914, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.1004 (Macro: 1.4672, Energy: 1.0228, KLD: 2.3073, MC: 2.3031)\n",
      "Train Batch 40/110 - Loss: 7.4989 (Macro: 1.5576, Energy: 1.2596, KLD: 2.3805, MC: 2.3011)\n",
      "Train Batch 50/110 - Loss: 7.0461 (Macro: 1.5026, Energy: 1.0030, KLD: 2.2381, MC: 2.3024)\n",
      "Train Batch 60/110 - Loss: 6.8968 (Macro: 1.3853, Energy: 0.9520, KLD: 2.2570, MC: 2.3025)\n",
      "Train Batch 70/110 - Loss: 6.9358 (Macro: 1.3438, Energy: 0.8502, KLD: 2.4378, MC: 2.3040)\n",
      "Train Batch 80/110 - Loss: 7.3645 (Macro: 1.4358, Energy: 1.0886, KLD: 2.5365, MC: 2.3036)\n",
      "Train Batch 90/110 - Loss: 6.7883 (Macro: 1.4840, Energy: 0.9790, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.3145 (Macro: 1.6072, Energy: 1.1876, KLD: 2.2161, MC: 2.3036)\n",
      "Train Batch 110/110 - Loss: 6.6458 (Macro: 1.2350, Energy: 0.7697, KLD: 2.3414, MC: 2.2998)\n",
      "Training epoch complete. Average Loss: 7.0816\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0729\n",
      "\n",
      "Epoch 103/500\n",
      "Train Batch 10/110 - Loss: 7.1422 (Macro: 1.5809, Energy: 1.1466, KLD: 2.1149, MC: 2.2998)\n",
      "Train Batch 20/110 - Loss: 6.9116 (Macro: 1.4761, Energy: 0.9985, KLD: 2.1345, MC: 2.3026)\n",
      "Train Batch 30/110 - Loss: 7.0583 (Macro: 1.4463, Energy: 1.0014, KLD: 2.3073, MC: 2.3033)\n",
      "Train Batch 40/110 - Loss: 7.4341 (Macro: 1.5453, Energy: 1.2060, KLD: 2.3805, MC: 2.3023)\n",
      "Train Batch 50/110 - Loss: 7.0607 (Macro: 1.5009, Energy: 1.0185, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.8815 (Macro: 1.4087, Energy: 0.9141, KLD: 2.2570, MC: 2.3016)\n",
      "Train Batch 70/110 - Loss: 6.9221 (Macro: 1.3378, Energy: 0.8433, KLD: 2.4378, MC: 2.3032)\n",
      "Train Batch 80/110 - Loss: 7.3082 (Macro: 1.4274, Energy: 1.0393, KLD: 2.5365, MC: 2.3051)\n",
      "Train Batch 90/110 - Loss: 6.8080 (Macro: 1.4771, Energy: 1.0050, KLD: 2.0241, MC: 2.3019)\n",
      "Train Batch 100/110 - Loss: 7.3008 (Macro: 1.5861, Energy: 1.1966, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.5893 (Macro: 1.2316, Energy: 0.7189, KLD: 2.3414, MC: 2.2974)\n",
      "Training epoch complete. Average Loss: 7.0771\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0726\n",
      "\n",
      "Epoch 104/500\n",
      "Train Batch 10/110 - Loss: 7.1273 (Macro: 1.5601, Energy: 1.1514, KLD: 2.1149, MC: 2.3009)\n",
      "Train Batch 20/110 - Loss: 6.8382 (Macro: 1.4610, Energy: 0.9394, KLD: 2.1345, MC: 2.3033)\n",
      "Train Batch 30/110 - Loss: 7.0939 (Macro: 1.4561, Energy: 1.0279, KLD: 2.3073, MC: 2.3026)\n",
      "Train Batch 40/110 - Loss: 7.4502 (Macro: 1.5472, Energy: 1.2199, KLD: 2.3805, MC: 2.3025)\n",
      "Train Batch 50/110 - Loss: 7.0633 (Macro: 1.5088, Energy: 1.0127, KLD: 2.2381, MC: 2.3037)\n",
      "Train Batch 60/110 - Loss: 6.8898 (Macro: 1.3793, Energy: 0.9510, KLD: 2.2570, MC: 2.3025)\n",
      "Train Batch 70/110 - Loss: 6.9588 (Macro: 1.3542, Energy: 0.8639, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.3159 (Macro: 1.4299, Energy: 1.0474, KLD: 2.5365, MC: 2.3021)\n",
      "Train Batch 90/110 - Loss: 6.8095 (Macro: 1.4975, Energy: 0.9860, KLD: 2.0241, MC: 2.3019)\n",
      "Train Batch 100/110 - Loss: 7.2718 (Macro: 1.5915, Energy: 1.1607, KLD: 2.2161, MC: 2.3035)\n",
      "Train Batch 110/110 - Loss: 6.6386 (Macro: 1.2148, Energy: 0.7867, KLD: 2.3414, MC: 2.2958)\n",
      "Training epoch complete. Average Loss: 7.0830\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0686\n",
      "\n",
      "Epoch 105/500\n",
      "Train Batch 10/110 - Loss: 7.1210 (Macro: 1.5865, Energy: 1.1206, KLD: 2.1149, MC: 2.2990)\n",
      "Train Batch 20/110 - Loss: 6.9198 (Macro: 1.4919, Energy: 0.9909, KLD: 2.1345, MC: 2.3024)\n",
      "Train Batch 30/110 - Loss: 7.0418 (Macro: 1.4571, Energy: 0.9748, KLD: 2.3073, MC: 2.3026)\n",
      "Train Batch 40/110 - Loss: 7.5260 (Macro: 1.5501, Energy: 1.2925, KLD: 2.3805, MC: 2.3029)\n",
      "Train Batch 50/110 - Loss: 7.0667 (Macro: 1.5213, Energy: 1.0040, KLD: 2.2381, MC: 2.3033)\n",
      "Train Batch 60/110 - Loss: 6.9131 (Macro: 1.3644, Energy: 0.9889, KLD: 2.2570, MC: 2.3027)\n",
      "Train Batch 70/110 - Loss: 6.9817 (Macro: 1.3557, Energy: 0.8856, KLD: 2.4378, MC: 2.3027)\n",
      "Train Batch 80/110 - Loss: 7.3568 (Macro: 1.4433, Energy: 1.0760, KLD: 2.5365, MC: 2.3011)\n",
      "Train Batch 90/110 - Loss: 6.8053 (Macro: 1.4787, Energy: 0.9995, KLD: 2.0241, MC: 2.3030)\n",
      "Train Batch 100/110 - Loss: 7.2592 (Macro: 1.6036, Energy: 1.1388, KLD: 2.2161, MC: 2.3007)\n",
      "Train Batch 110/110 - Loss: 6.5298 (Macro: 1.2424, Energy: 0.6493, KLD: 2.3414, MC: 2.2968)\n",
      "Training epoch complete. Average Loss: 7.0831\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0668\n",
      "\n",
      "Epoch 106/500\n",
      "Train Batch 10/110 - Loss: 7.1301 (Macro: 1.5636, Energy: 1.1509, KLD: 2.1149, MC: 2.3006)\n",
      "Train Batch 20/110 - Loss: 6.8669 (Macro: 1.4935, Energy: 0.9376, KLD: 2.1345, MC: 2.3013)\n",
      "Train Batch 30/110 - Loss: 7.0527 (Macro: 1.4495, Energy: 0.9942, KLD: 2.3073, MC: 2.3017)\n",
      "Train Batch 40/110 - Loss: 7.4236 (Macro: 1.5548, Energy: 1.1869, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0763 (Macro: 1.4976, Energy: 1.0390, KLD: 2.2381, MC: 2.3017)\n",
      "Train Batch 60/110 - Loss: 6.9001 (Macro: 1.3862, Energy: 0.9559, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 7.0090 (Macro: 1.3654, Energy: 0.9023, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.2805 (Macro: 1.4238, Energy: 1.0177, KLD: 2.5365, MC: 2.3024)\n",
      "Train Batch 90/110 - Loss: 6.8136 (Macro: 1.4788, Energy: 1.0102, KLD: 2.0241, MC: 2.3006)\n",
      "Train Batch 100/110 - Loss: 7.3289 (Macro: 1.6160, Energy: 1.1945, KLD: 2.2161, MC: 2.3022)\n",
      "Train Batch 110/110 - Loss: 6.6562 (Macro: 1.2585, Energy: 0.7571, KLD: 2.3414, MC: 2.2992)\n",
      "Training epoch complete. Average Loss: 7.0856\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0700\n",
      "\n",
      "Epoch 107/500\n",
      "Train Batch 10/110 - Loss: 7.1100 (Macro: 1.5661, Energy: 1.1312, KLD: 2.1149, MC: 2.2978)\n",
      "Train Batch 20/110 - Loss: 6.8675 (Macro: 1.4759, Energy: 0.9542, KLD: 2.1345, MC: 2.3029)\n",
      "Train Batch 30/110 - Loss: 7.0176 (Macro: 1.4393, Energy: 0.9674, KLD: 2.3073, MC: 2.3036)\n",
      "Train Batch 40/110 - Loss: 7.4530 (Macro: 1.5312, Energy: 1.2394, KLD: 2.3805, MC: 2.3019)\n",
      "Train Batch 50/110 - Loss: 6.9989 (Macro: 1.4733, Energy: 0.9853, KLD: 2.2381, MC: 2.3022)\n",
      "Train Batch 60/110 - Loss: 6.8953 (Macro: 1.3938, Energy: 0.9445, KLD: 2.2570, MC: 2.2999)\n",
      "Train Batch 70/110 - Loss: 6.9065 (Macro: 1.3249, Energy: 0.8400, KLD: 2.4378, MC: 2.3038)\n",
      "Train Batch 80/110 - Loss: 7.3063 (Macro: 1.4323, Energy: 1.0340, KLD: 2.5365, MC: 2.3035)\n",
      "Train Batch 90/110 - Loss: 6.7630 (Macro: 1.4763, Energy: 0.9595, KLD: 2.0241, MC: 2.3032)\n",
      "Train Batch 100/110 - Loss: 7.3003 (Macro: 1.6000, Energy: 1.1826, KLD: 2.2161, MC: 2.3016)\n",
      "Train Batch 110/110 - Loss: 6.6721 (Macro: 1.2353, Energy: 0.7972, KLD: 2.3414, MC: 2.2982)\n",
      "Training epoch complete. Average Loss: 7.0772\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0615\n",
      "\n",
      "Epoch 108/500\n",
      "Train Batch 10/110 - Loss: 7.1038 (Macro: 1.5745, Energy: 1.1148, KLD: 2.1149, MC: 2.2995)\n",
      "Train Batch 20/110 - Loss: 6.9405 (Macro: 1.4534, Energy: 1.0517, KLD: 2.1345, MC: 2.3009)\n",
      "Train Batch 30/110 - Loss: 7.1153 (Macro: 1.4561, Energy: 1.0500, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4222 (Macro: 1.5205, Energy: 1.2201, KLD: 2.3805, MC: 2.3011)\n",
      "Train Batch 50/110 - Loss: 6.9880 (Macro: 1.4974, Energy: 0.9491, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.9529 (Macro: 1.3945, Energy: 0.9987, KLD: 2.2570, MC: 2.3026)\n",
      "Train Batch 70/110 - Loss: 6.9631 (Macro: 1.3789, Energy: 0.8435, KLD: 2.4378, MC: 2.3030)\n",
      "Train Batch 80/110 - Loss: 7.2918 (Macro: 1.4143, Energy: 1.0382, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.7807 (Macro: 1.4938, Energy: 0.9604, KLD: 2.0241, MC: 2.3024)\n",
      "Train Batch 100/110 - Loss: 7.3573 (Macro: 1.6090, Energy: 1.2310, KLD: 2.2161, MC: 2.3012)\n",
      "Train Batch 110/110 - Loss: 6.6650 (Macro: 1.2317, Energy: 0.7944, KLD: 2.3414, MC: 2.2975)\n",
      "Training epoch complete. Average Loss: 7.0798\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0666\n",
      "\n",
      "Epoch 109/500\n",
      "Train Batch 10/110 - Loss: 7.1095 (Macro: 1.5709, Energy: 1.1238, KLD: 2.1149, MC: 2.2999)\n",
      "Train Batch 20/110 - Loss: 6.8621 (Macro: 1.4858, Energy: 0.9400, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.0732 (Macro: 1.4545, Energy: 1.0101, KLD: 2.3073, MC: 2.3013)\n",
      "Train Batch 40/110 - Loss: 7.4747 (Macro: 1.5480, Energy: 1.2448, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0779 (Macro: 1.5037, Energy: 1.0341, KLD: 2.2381, MC: 2.3021)\n",
      "Train Batch 60/110 - Loss: 6.8866 (Macro: 1.3817, Energy: 0.9452, KLD: 2.2570, MC: 2.3027)\n",
      "Train Batch 70/110 - Loss: 7.0215 (Macro: 1.3594, Energy: 0.9193, KLD: 2.4378, MC: 2.3051)\n",
      "Train Batch 80/110 - Loss: 7.3355 (Macro: 1.4344, Energy: 1.0606, KLD: 2.5365, MC: 2.3039)\n",
      "Train Batch 90/110 - Loss: 6.7883 (Macro: 1.4648, Energy: 0.9948, KLD: 2.0241, MC: 2.3047)\n",
      "Train Batch 100/110 - Loss: 7.3278 (Macro: 1.6235, Energy: 1.1869, KLD: 2.2161, MC: 2.3014)\n",
      "Train Batch 110/110 - Loss: 6.5706 (Macro: 1.2197, Energy: 0.7077, KLD: 2.3414, MC: 2.3018)\n",
      "Training epoch complete. Average Loss: 7.0729\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0766\n",
      "\n",
      "Epoch 110/500\n",
      "Train Batch 10/110 - Loss: 7.1008 (Macro: 1.5844, Energy: 1.1020, KLD: 2.1149, MC: 2.2994)\n",
      "Train Batch 20/110 - Loss: 6.8175 (Macro: 1.4664, Energy: 0.9152, KLD: 2.1345, MC: 2.3014)\n",
      "Train Batch 30/110 - Loss: 7.0678 (Macro: 1.4800, Energy: 0.9793, KLD: 2.3073, MC: 2.3012)\n",
      "Train Batch 40/110 - Loss: 7.4910 (Macro: 1.5723, Energy: 1.2355, KLD: 2.3805, MC: 2.3027)\n",
      "Train Batch 50/110 - Loss: 7.0910 (Macro: 1.5118, Energy: 1.0384, KLD: 2.2381, MC: 2.3027)\n",
      "Train Batch 60/110 - Loss: 6.9611 (Macro: 1.3934, Energy: 1.0100, KLD: 2.2570, MC: 2.3007)\n",
      "Train Batch 70/110 - Loss: 6.9691 (Macro: 1.3577, Energy: 0.8685, KLD: 2.4378, MC: 2.3051)\n",
      "Train Batch 80/110 - Loss: 7.3259 (Macro: 1.4249, Energy: 1.0623, KLD: 2.5365, MC: 2.3021)\n",
      "Train Batch 90/110 - Loss: 6.7973 (Macro: 1.4858, Energy: 0.9875, KLD: 2.0241, MC: 2.2999)\n",
      "Train Batch 100/110 - Loss: 7.2831 (Macro: 1.6069, Energy: 1.1582, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.6448 (Macro: 1.2278, Energy: 0.7757, KLD: 2.3414, MC: 2.2999)\n",
      "Training epoch complete. Average Loss: 7.0777\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0697\n",
      "\n",
      "Epoch 111/500\n",
      "Train Batch 10/110 - Loss: 7.1015 (Macro: 1.5771, Energy: 1.1083, KLD: 2.1149, MC: 2.3011)\n",
      "Train Batch 20/110 - Loss: 6.9306 (Macro: 1.5036, Energy: 0.9919, KLD: 2.1345, MC: 2.3006)\n",
      "Train Batch 30/110 - Loss: 7.0379 (Macro: 1.4665, Energy: 0.9633, KLD: 2.3073, MC: 2.3008)\n",
      "Train Batch 40/110 - Loss: 7.4382 (Macro: 1.5582, Energy: 1.1984, KLD: 2.3805, MC: 2.3010)\n",
      "Train Batch 50/110 - Loss: 7.0772 (Macro: 1.4927, Energy: 1.0445, KLD: 2.2381, MC: 2.3019)\n",
      "Train Batch 60/110 - Loss: 6.8804 (Macro: 1.3717, Energy: 0.9516, KLD: 2.2570, MC: 2.3001)\n",
      "Train Batch 70/110 - Loss: 6.9631 (Macro: 1.3714, Energy: 0.8491, KLD: 2.4378, MC: 2.3048)\n",
      "Train Batch 80/110 - Loss: 7.3285 (Macro: 1.4158, Energy: 1.0739, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.7461 (Macro: 1.4780, Energy: 0.9421, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.2788 (Macro: 1.6068, Energy: 1.1529, KLD: 2.2161, MC: 2.3030)\n",
      "Train Batch 110/110 - Loss: 6.4959 (Macro: 1.2162, Energy: 0.6403, KLD: 2.3414, MC: 2.2980)\n",
      "Training epoch complete. Average Loss: 7.0756\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0616\n",
      "\n",
      "Epoch 112/500\n",
      "Train Batch 10/110 - Loss: 7.1511 (Macro: 1.5705, Energy: 1.1671, KLD: 2.1149, MC: 2.2986)\n",
      "Train Batch 20/110 - Loss: 6.8537 (Macro: 1.4659, Energy: 0.9510, KLD: 2.1345, MC: 2.3024)\n",
      "Train Batch 30/110 - Loss: 7.1005 (Macro: 1.4533, Energy: 1.0375, KLD: 2.3073, MC: 2.3024)\n",
      "Train Batch 40/110 - Loss: 7.4507 (Macro: 1.5603, Energy: 1.2066, KLD: 2.3805, MC: 2.3032)\n",
      "Train Batch 50/110 - Loss: 7.0709 (Macro: 1.4889, Energy: 1.0418, KLD: 2.2381, MC: 2.3022)\n",
      "Train Batch 60/110 - Loss: 6.9435 (Macro: 1.3903, Energy: 0.9955, KLD: 2.2570, MC: 2.3006)\n",
      "Train Batch 70/110 - Loss: 6.9167 (Macro: 1.3692, Energy: 0.8069, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.3143 (Macro: 1.4279, Energy: 1.0475, KLD: 2.5365, MC: 2.3025)\n",
      "Train Batch 90/110 - Loss: 6.7259 (Macro: 1.4708, Energy: 0.9292, KLD: 2.0241, MC: 2.3018)\n",
      "Train Batch 100/110 - Loss: 7.2941 (Macro: 1.6126, Energy: 1.1640, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.5921 (Macro: 1.2417, Energy: 0.7097, KLD: 2.3414, MC: 2.2994)\n",
      "Training epoch complete. Average Loss: 7.0796\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0627\n",
      "\n",
      "Epoch 113/500\n",
      "Train Batch 10/110 - Loss: 7.1458 (Macro: 1.6045, Energy: 1.1255, KLD: 2.1149, MC: 2.3009)\n",
      "Train Batch 20/110 - Loss: 6.8894 (Macro: 1.4873, Energy: 0.9656, KLD: 2.1345, MC: 2.3021)\n",
      "Train Batch 30/110 - Loss: 7.1030 (Macro: 1.4369, Energy: 1.0573, KLD: 2.3073, MC: 2.3016)\n",
      "Train Batch 40/110 - Loss: 7.4281 (Macro: 1.5455, Energy: 1.2001, KLD: 2.3805, MC: 2.3021)\n",
      "Train Batch 50/110 - Loss: 7.0470 (Macro: 1.5115, Energy: 0.9949, KLD: 2.2381, MC: 2.3026)\n",
      "Train Batch 60/110 - Loss: 6.9528 (Macro: 1.3942, Energy: 0.9986, KLD: 2.2570, MC: 2.3029)\n",
      "Train Batch 70/110 - Loss: 6.9606 (Macro: 1.3543, Energy: 0.8630, KLD: 2.4378, MC: 2.3055)\n",
      "Train Batch 80/110 - Loss: 7.2673 (Macro: 1.4245, Energy: 1.0040, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.7969 (Macro: 1.4666, Energy: 1.0047, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.3518 (Macro: 1.6188, Energy: 1.2165, KLD: 2.2161, MC: 2.3004)\n",
      "Train Batch 110/110 - Loss: 6.6635 (Macro: 1.2095, Energy: 0.8172, KLD: 2.3414, MC: 2.2954)\n",
      "Training epoch complete. Average Loss: 7.0775\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0604\n",
      "\n",
      "Epoch 114/500\n",
      "Train Batch 10/110 - Loss: 7.1414 (Macro: 1.5813, Energy: 1.1448, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.8796 (Macro: 1.4901, Energy: 0.9533, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.0915 (Macro: 1.4423, Energy: 1.0400, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4257 (Macro: 1.5640, Energy: 1.1812, KLD: 2.3805, MC: 2.2999)\n",
      "Train Batch 50/110 - Loss: 7.0986 (Macro: 1.5182, Energy: 1.0418, KLD: 2.2381, MC: 2.3006)\n",
      "Train Batch 60/110 - Loss: 6.9044 (Macro: 1.3778, Energy: 0.9691, KLD: 2.2570, MC: 2.3004)\n",
      "Train Batch 70/110 - Loss: 6.9691 (Macro: 1.3714, Energy: 0.8567, KLD: 2.4378, MC: 2.3032)\n",
      "Train Batch 80/110 - Loss: 7.3064 (Macro: 1.4389, Energy: 1.0284, KLD: 2.5365, MC: 2.3027)\n",
      "Train Batch 90/110 - Loss: 6.8034 (Macro: 1.4919, Energy: 0.9849, KLD: 2.0241, MC: 2.3026)\n",
      "Train Batch 100/110 - Loss: 7.2947 (Macro: 1.6032, Energy: 1.1729, KLD: 2.2161, MC: 2.3025)\n",
      "Train Batch 110/110 - Loss: 6.5932 (Macro: 1.2340, Energy: 0.7181, KLD: 2.3414, MC: 2.2998)\n",
      "Training epoch complete. Average Loss: 7.0785\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0634\n",
      "\n",
      "Epoch 115/500\n",
      "Train Batch 10/110 - Loss: 7.1673 (Macro: 1.5807, Energy: 1.1717, KLD: 2.1149, MC: 2.2999)\n",
      "Train Batch 20/110 - Loss: 6.8970 (Macro: 1.4939, Energy: 0.9673, KLD: 2.1345, MC: 2.3014)\n",
      "Train Batch 30/110 - Loss: 7.0661 (Macro: 1.4460, Energy: 1.0109, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4019 (Macro: 1.5361, Energy: 1.1848, KLD: 2.3805, MC: 2.3006)\n",
      "Train Batch 50/110 - Loss: 7.0853 (Macro: 1.5140, Energy: 1.0301, KLD: 2.2381, MC: 2.3031)\n",
      "Train Batch 60/110 - Loss: 6.8746 (Macro: 1.3918, Energy: 0.9257, KLD: 2.2570, MC: 2.3001)\n",
      "Train Batch 70/110 - Loss: 6.9733 (Macro: 1.3681, Energy: 0.8657, KLD: 2.4378, MC: 2.3018)\n",
      "Train Batch 80/110 - Loss: 7.2897 (Macro: 1.4329, Energy: 1.0181, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.7880 (Macro: 1.4648, Energy: 0.9962, KLD: 2.0241, MC: 2.3029)\n",
      "Train Batch 100/110 - Loss: 7.2940 (Macro: 1.6049, Energy: 1.1714, KLD: 2.2161, MC: 2.3016)\n",
      "Train Batch 110/110 - Loss: 6.6328 (Macro: 1.2164, Energy: 0.7778, KLD: 2.3414, MC: 2.2972)\n",
      "Training epoch complete. Average Loss: 7.0800\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0653\n",
      "\n",
      "Epoch 116/500\n",
      "Train Batch 10/110 - Loss: 7.1844 (Macro: 1.5931, Energy: 1.1764, KLD: 2.1149, MC: 2.3000)\n",
      "Train Batch 20/110 - Loss: 6.8687 (Macro: 1.4857, Energy: 0.9464, KLD: 2.1345, MC: 2.3021)\n",
      "Train Batch 30/110 - Loss: 7.1109 (Macro: 1.4456, Energy: 1.0551, KLD: 2.3073, MC: 2.3028)\n",
      "Train Batch 40/110 - Loss: 7.4664 (Macro: 1.5723, Energy: 1.2129, KLD: 2.3805, MC: 2.3007)\n",
      "Train Batch 50/110 - Loss: 7.0382 (Macro: 1.4995, Energy: 0.9959, KLD: 2.2381, MC: 2.3048)\n",
      "Train Batch 60/110 - Loss: 6.8802 (Macro: 1.3700, Energy: 0.9507, KLD: 2.2570, MC: 2.3024)\n",
      "Train Batch 70/110 - Loss: 6.9352 (Macro: 1.3478, Energy: 0.8460, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.2926 (Macro: 1.4184, Energy: 1.0360, KLD: 2.5365, MC: 2.3017)\n",
      "Train Batch 90/110 - Loss: 6.8572 (Macro: 1.4966, Energy: 1.0352, KLD: 2.0241, MC: 2.3013)\n",
      "Train Batch 100/110 - Loss: 7.2868 (Macro: 1.6133, Energy: 1.1567, KLD: 2.2161, MC: 2.3008)\n",
      "Train Batch 110/110 - Loss: 6.5670 (Macro: 1.2198, Energy: 0.7053, KLD: 2.3414, MC: 2.3005)\n",
      "Training epoch complete. Average Loss: 7.0798\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0668\n",
      "\n",
      "Epoch 117/500\n",
      "Train Batch 10/110 - Loss: 7.1838 (Macro: 1.5699, Energy: 1.1976, KLD: 2.1149, MC: 2.3014)\n",
      "Train Batch 20/110 - Loss: 6.9118 (Macro: 1.4734, Energy: 1.0038, KLD: 2.1345, MC: 2.3001)\n",
      "Train Batch 30/110 - Loss: 7.0959 (Macro: 1.4686, Energy: 1.0187, KLD: 2.3073, MC: 2.3012)\n",
      "Train Batch 40/110 - Loss: 7.4456 (Macro: 1.5689, Energy: 1.1937, KLD: 2.3805, MC: 2.3025)\n",
      "Train Batch 50/110 - Loss: 7.0405 (Macro: 1.5061, Energy: 0.9936, KLD: 2.2381, MC: 2.3027)\n",
      "Train Batch 60/110 - Loss: 6.8712 (Macro: 1.3938, Energy: 0.9186, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 6.9733 (Macro: 1.3713, Energy: 0.8606, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.2588 (Macro: 1.4141, Energy: 1.0051, KLD: 2.5365, MC: 2.3031)\n",
      "Train Batch 90/110 - Loss: 6.8186 (Macro: 1.4765, Energy: 1.0164, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.2867 (Macro: 1.6132, Energy: 1.1562, KLD: 2.2161, MC: 2.3012)\n",
      "Train Batch 110/110 - Loss: 6.6503 (Macro: 1.2650, Energy: 0.7450, KLD: 2.3414, MC: 2.2989)\n",
      "Training epoch complete. Average Loss: 7.0810\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0668\n",
      "\n",
      "Epoch 118/500\n",
      "Train Batch 10/110 - Loss: 7.2017 (Macro: 1.6076, Energy: 1.1800, KLD: 2.1149, MC: 2.2991)\n",
      "Train Batch 20/110 - Loss: 6.8655 (Macro: 1.4839, Energy: 0.9464, KLD: 2.1345, MC: 2.3007)\n",
      "Train Batch 30/110 - Loss: 7.1267 (Macro: 1.4591, Energy: 1.0586, KLD: 2.3073, MC: 2.3017)\n",
      "Train Batch 40/110 - Loss: 7.4340 (Macro: 1.5410, Energy: 1.2116, KLD: 2.3805, MC: 2.3009)\n",
      "Train Batch 50/110 - Loss: 7.0134 (Macro: 1.5009, Energy: 0.9718, KLD: 2.2381, MC: 2.3026)\n",
      "Train Batch 60/110 - Loss: 6.8750 (Macro: 1.3748, Energy: 0.9420, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9510 (Macro: 1.3638, Energy: 0.8450, KLD: 2.4378, MC: 2.3044)\n",
      "Train Batch 80/110 - Loss: 7.3822 (Macro: 1.4336, Energy: 1.1092, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.7709 (Macro: 1.4718, Energy: 0.9719, KLD: 2.0241, MC: 2.3032)\n",
      "Train Batch 100/110 - Loss: 7.2788 (Macro: 1.6063, Energy: 1.1528, KLD: 2.2161, MC: 2.3037)\n",
      "Train Batch 110/110 - Loss: 6.6096 (Macro: 1.2334, Energy: 0.7347, KLD: 2.3414, MC: 2.3001)\n",
      "Training epoch complete. Average Loss: 7.0811\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0663\n",
      "\n",
      "Epoch 119/500\n",
      "Train Batch 10/110 - Loss: 7.1423 (Macro: 1.5976, Energy: 1.1296, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.8820 (Macro: 1.4874, Energy: 0.9587, KLD: 2.1345, MC: 2.3014)\n",
      "Train Batch 30/110 - Loss: 7.1002 (Macro: 1.4630, Energy: 1.0257, KLD: 2.3073, MC: 2.3041)\n",
      "Train Batch 40/110 - Loss: 7.4442 (Macro: 1.5486, Energy: 1.2133, KLD: 2.3805, MC: 2.3018)\n",
      "Train Batch 50/110 - Loss: 7.0205 (Macro: 1.5055, Energy: 0.9765, KLD: 2.2381, MC: 2.3005)\n",
      "Train Batch 60/110 - Loss: 6.9403 (Macro: 1.3833, Energy: 0.9993, KLD: 2.2570, MC: 2.3006)\n",
      "Train Batch 70/110 - Loss: 6.9923 (Macro: 1.3998, Energy: 0.8526, KLD: 2.4378, MC: 2.3022)\n",
      "Train Batch 80/110 - Loss: 7.3207 (Macro: 1.4149, Energy: 1.0658, KLD: 2.5365, MC: 2.3035)\n",
      "Train Batch 90/110 - Loss: 6.7748 (Macro: 1.4795, Energy: 0.9692, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.3239 (Macro: 1.6000, Energy: 1.2058, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.7040 (Macro: 1.2466, Energy: 0.8166, KLD: 2.3414, MC: 2.2995)\n",
      "Training epoch complete. Average Loss: 7.0805\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0636\n",
      "\n",
      "Epoch 120/500\n",
      "Train Batch 10/110 - Loss: 7.1283 (Macro: 1.5867, Energy: 1.1254, KLD: 2.1149, MC: 2.3012)\n",
      "Train Batch 20/110 - Loss: 6.8841 (Macro: 1.4762, Energy: 0.9718, KLD: 2.1345, MC: 2.3016)\n",
      "Train Batch 30/110 - Loss: 7.0772 (Macro: 1.4334, Energy: 1.0352, KLD: 2.3073, MC: 2.3012)\n",
      "Train Batch 40/110 - Loss: 7.4809 (Macro: 1.5501, Energy: 1.2479, KLD: 2.3805, MC: 2.3024)\n",
      "Train Batch 50/110 - Loss: 7.0644 (Macro: 1.4952, Energy: 1.0282, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.9243 (Macro: 1.3819, Energy: 0.9839, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9296 (Macro: 1.3678, Energy: 0.8204, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.2745 (Macro: 1.4455, Energy: 0.9905, KLD: 2.5365, MC: 2.3021)\n",
      "Train Batch 90/110 - Loss: 6.7795 (Macro: 1.4747, Energy: 0.9794, KLD: 2.0241, MC: 2.3014)\n",
      "Train Batch 100/110 - Loss: 7.2944 (Macro: 1.6079, Energy: 1.1681, KLD: 2.2161, MC: 2.3024)\n",
      "Train Batch 110/110 - Loss: 6.6982 (Macro: 1.2233, Energy: 0.8344, KLD: 2.3414, MC: 2.2991)\n",
      "Training epoch complete. Average Loss: 7.0812\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0543\n",
      "\n",
      "Epoch 121/500\n",
      "Train Batch 10/110 - Loss: 7.1145 (Macro: 1.5692, Energy: 1.1290, KLD: 2.1149, MC: 2.3014)\n",
      "Train Batch 20/110 - Loss: 6.8662 (Macro: 1.4892, Energy: 0.9405, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.0551 (Macro: 1.4372, Energy: 1.0077, KLD: 2.3073, MC: 2.3029)\n",
      "Train Batch 40/110 - Loss: 7.4727 (Macro: 1.5624, Energy: 1.2315, KLD: 2.3805, MC: 2.2983)\n",
      "Train Batch 50/110 - Loss: 6.9892 (Macro: 1.4916, Energy: 0.9546, KLD: 2.2381, MC: 2.3050)\n",
      "Train Batch 60/110 - Loss: 6.9951 (Macro: 1.4032, Energy: 1.0321, KLD: 2.2570, MC: 2.3028)\n",
      "Train Batch 70/110 - Loss: 6.9330 (Macro: 1.3625, Energy: 0.8296, KLD: 2.4378, MC: 2.3032)\n",
      "Train Batch 80/110 - Loss: 7.3563 (Macro: 1.4180, Energy: 1.0988, KLD: 2.5365, MC: 2.3030)\n",
      "Train Batch 90/110 - Loss: 6.7410 (Macro: 1.4538, Energy: 0.9624, KLD: 2.0241, MC: 2.3008)\n",
      "Train Batch 100/110 - Loss: 7.3053 (Macro: 1.6231, Energy: 1.1637, KLD: 2.2161, MC: 2.3024)\n",
      "Train Batch 110/110 - Loss: 6.6599 (Macro: 1.2502, Energy: 0.7695, KLD: 2.3414, MC: 2.2988)\n",
      "Training epoch complete. Average Loss: 7.0807\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0722\n",
      "\n",
      "Epoch 122/500\n",
      "Train Batch 10/110 - Loss: 7.1388 (Macro: 1.5767, Energy: 1.1479, KLD: 2.1149, MC: 2.2993)\n",
      "Train Batch 20/110 - Loss: 6.8764 (Macro: 1.4740, Energy: 0.9672, KLD: 2.1345, MC: 2.3008)\n",
      "Train Batch 30/110 - Loss: 7.0695 (Macro: 1.4463, Energy: 1.0143, KLD: 2.3073, MC: 2.3016)\n",
      "Train Batch 40/110 - Loss: 7.4250 (Macro: 1.5577, Energy: 1.1858, KLD: 2.3805, MC: 2.3009)\n",
      "Train Batch 50/110 - Loss: 7.0920 (Macro: 1.5049, Energy: 1.0452, KLD: 2.2381, MC: 2.3039)\n",
      "Train Batch 60/110 - Loss: 6.9443 (Macro: 1.3813, Energy: 1.0035, KLD: 2.2570, MC: 2.3024)\n",
      "Train Batch 70/110 - Loss: 6.9642 (Macro: 1.3647, Energy: 0.8599, KLD: 2.4378, MC: 2.3018)\n",
      "Train Batch 80/110 - Loss: 7.3290 (Macro: 1.4321, Energy: 1.0573, KLD: 2.5365, MC: 2.3031)\n",
      "Train Batch 90/110 - Loss: 6.7932 (Macro: 1.4616, Energy: 1.0063, KLD: 2.0241, MC: 2.3013)\n",
      "Train Batch 100/110 - Loss: 7.2871 (Macro: 1.6021, Energy: 1.1679, KLD: 2.2161, MC: 2.3011)\n",
      "Train Batch 110/110 - Loss: 6.5915 (Macro: 1.2456, Energy: 0.7050, KLD: 2.3414, MC: 2.2996)\n",
      "Training epoch complete. Average Loss: 7.0744\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0812\n",
      "\n",
      "Epoch 123/500\n",
      "Train Batch 10/110 - Loss: 7.1860 (Macro: 1.5965, Energy: 1.1749, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.9298 (Macro: 1.4806, Energy: 1.0126, KLD: 2.1345, MC: 2.3021)\n",
      "Train Batch 30/110 - Loss: 7.0679 (Macro: 1.4476, Energy: 1.0118, KLD: 2.3073, MC: 2.3012)\n",
      "Train Batch 40/110 - Loss: 7.4167 (Macro: 1.5705, Energy: 1.1641, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0887 (Macro: 1.4934, Energy: 1.0547, KLD: 2.2381, MC: 2.3025)\n",
      "Train Batch 60/110 - Loss: 6.9155 (Macro: 1.3753, Energy: 0.9826, KLD: 2.2570, MC: 2.3005)\n",
      "Train Batch 70/110 - Loss: 6.9545 (Macro: 1.3623, Energy: 0.8518, KLD: 2.4378, MC: 2.3027)\n",
      "Train Batch 80/110 - Loss: 7.2733 (Macro: 1.4228, Energy: 1.0115, KLD: 2.5365, MC: 2.3025)\n",
      "Train Batch 90/110 - Loss: 6.8031 (Macro: 1.4695, Energy: 1.0091, KLD: 2.0241, MC: 2.3004)\n",
      "Train Batch 100/110 - Loss: 7.3402 (Macro: 1.6132, Energy: 1.2103, KLD: 2.2161, MC: 2.3006)\n",
      "Train Batch 110/110 - Loss: 6.6726 (Macro: 1.2353, Energy: 0.7985, KLD: 2.3414, MC: 2.2974)\n",
      "Training epoch complete. Average Loss: 7.0784\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0607\n",
      "\n",
      "Epoch 124/500\n",
      "Train Batch 10/110 - Loss: 7.1315 (Macro: 1.5617, Energy: 1.1528, KLD: 2.1149, MC: 2.3021)\n",
      "Train Batch 20/110 - Loss: 6.8985 (Macro: 1.4872, Energy: 0.9746, KLD: 2.1345, MC: 2.3022)\n",
      "Train Batch 30/110 - Loss: 7.1387 (Macro: 1.4602, Energy: 1.0680, KLD: 2.3073, MC: 2.3033)\n",
      "Train Batch 40/110 - Loss: 7.4802 (Macro: 1.5813, Energy: 1.2171, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0254 (Macro: 1.5001, Energy: 0.9850, KLD: 2.2381, MC: 2.3023)\n",
      "Train Batch 60/110 - Loss: 6.9405 (Macro: 1.3964, Energy: 0.9877, KLD: 2.2570, MC: 2.2993)\n",
      "Train Batch 70/110 - Loss: 6.9692 (Macro: 1.3442, Energy: 0.8836, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.2821 (Macro: 1.4161, Energy: 1.0282, KLD: 2.5365, MC: 2.3013)\n",
      "Train Batch 90/110 - Loss: 6.7563 (Macro: 1.4651, Energy: 0.9661, KLD: 2.0241, MC: 2.3010)\n",
      "Train Batch 100/110 - Loss: 7.2909 (Macro: 1.6080, Energy: 1.1652, KLD: 2.2161, MC: 2.3016)\n",
      "Train Batch 110/110 - Loss: 6.6575 (Macro: 1.2468, Energy: 0.7685, KLD: 2.3414, MC: 2.3008)\n",
      "Training epoch complete. Average Loss: 7.0833\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0637\n",
      "\n",
      "Epoch 125/500\n",
      "Train Batch 10/110 - Loss: 7.1256 (Macro: 1.5666, Energy: 1.1433, KLD: 2.1149, MC: 2.3008)\n",
      "Train Batch 20/110 - Loss: 6.9232 (Macro: 1.4951, Energy: 0.9932, KLD: 2.1345, MC: 2.3004)\n",
      "Train Batch 30/110 - Loss: 7.1036 (Macro: 1.4775, Energy: 1.0174, KLD: 2.3073, MC: 2.3014)\n",
      "Train Batch 40/110 - Loss: 7.4640 (Macro: 1.5337, Energy: 1.2489, KLD: 2.3805, MC: 2.3009)\n",
      "Train Batch 50/110 - Loss: 7.0402 (Macro: 1.4962, Energy: 1.0039, KLD: 2.2381, MC: 2.3021)\n",
      "Train Batch 60/110 - Loss: 6.8885 (Macro: 1.3755, Energy: 0.9541, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 6.9093 (Macro: 1.3496, Energy: 0.8186, KLD: 2.4378, MC: 2.3033)\n",
      "Train Batch 80/110 - Loss: 7.3277 (Macro: 1.4406, Energy: 1.0483, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.8060 (Macro: 1.5021, Energy: 0.9784, KLD: 2.0241, MC: 2.3015)\n",
      "Train Batch 100/110 - Loss: 7.3173 (Macro: 1.6048, Energy: 1.1938, KLD: 2.2161, MC: 2.3026)\n",
      "Train Batch 110/110 - Loss: 6.6817 (Macro: 1.2371, Energy: 0.8066, KLD: 2.3414, MC: 2.2966)\n",
      "Training epoch complete. Average Loss: 7.0795\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0581\n",
      "\n",
      "Epoch 126/500\n",
      "Train Batch 10/110 - Loss: 7.1291 (Macro: 1.5815, Energy: 1.1313, KLD: 2.1149, MC: 2.3013)\n",
      "Train Batch 20/110 - Loss: 6.8961 (Macro: 1.4948, Energy: 0.9655, KLD: 2.1345, MC: 2.3014)\n",
      "Train Batch 30/110 - Loss: 7.0400 (Macro: 1.4495, Energy: 0.9827, KLD: 2.3073, MC: 2.3004)\n",
      "Train Batch 40/110 - Loss: 7.4434 (Macro: 1.5536, Energy: 1.2097, KLD: 2.3805, MC: 2.2996)\n",
      "Train Batch 50/110 - Loss: 7.0387 (Macro: 1.4912, Energy: 1.0062, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.9400 (Macro: 1.3947, Energy: 0.9872, KLD: 2.2570, MC: 2.3010)\n",
      "Train Batch 70/110 - Loss: 6.9722 (Macro: 1.3647, Energy: 0.8660, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.4479 (Macro: 1.4536, Energy: 1.1551, KLD: 2.5365, MC: 2.3027)\n",
      "Train Batch 90/110 - Loss: 6.8185 (Macro: 1.4617, Energy: 1.0298, KLD: 2.0241, MC: 2.3029)\n",
      "Train Batch 100/110 - Loss: 7.3369 (Macro: 1.6056, Energy: 1.2112, KLD: 2.2161, MC: 2.3039)\n",
      "Train Batch 110/110 - Loss: 6.6430 (Macro: 1.2513, Energy: 0.7526, KLD: 2.3414, MC: 2.2977)\n",
      "Training epoch complete. Average Loss: 7.0839\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0721\n",
      "\n",
      "Epoch 127/500\n",
      "Train Batch 10/110 - Loss: 7.1221 (Macro: 1.5819, Energy: 1.1226, KLD: 2.1149, MC: 2.3027)\n",
      "Train Batch 20/110 - Loss: 6.8326 (Macro: 1.4721, Energy: 0.9248, KLD: 2.1345, MC: 2.3012)\n",
      "Train Batch 30/110 - Loss: 7.0758 (Macro: 1.4546, Energy: 1.0120, KLD: 2.3073, MC: 2.3020)\n",
      "Train Batch 40/110 - Loss: 7.4680 (Macro: 1.5397, Energy: 1.2456, KLD: 2.3805, MC: 2.3021)\n",
      "Train Batch 50/110 - Loss: 7.0407 (Macro: 1.4997, Energy: 0.9987, KLD: 2.2381, MC: 2.3044)\n",
      "Train Batch 60/110 - Loss: 6.8862 (Macro: 1.3908, Energy: 0.9383, KLD: 2.2570, MC: 2.3001)\n",
      "Train Batch 70/110 - Loss: 6.9742 (Macro: 1.3702, Energy: 0.8638, KLD: 2.4378, MC: 2.3024)\n",
      "Train Batch 80/110 - Loss: 7.3460 (Macro: 1.4431, Energy: 1.0655, KLD: 2.5365, MC: 2.3009)\n",
      "Train Batch 90/110 - Loss: 6.7896 (Macro: 1.4934, Energy: 0.9663, KLD: 2.0241, MC: 2.3058)\n",
      "Train Batch 100/110 - Loss: 7.3012 (Macro: 1.6083, Energy: 1.1754, KLD: 2.2161, MC: 2.3014)\n",
      "Train Batch 110/110 - Loss: 6.6402 (Macro: 1.2209, Energy: 0.7771, KLD: 2.3414, MC: 2.3008)\n",
      "Training epoch complete. Average Loss: 7.0759\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0619\n",
      "\n",
      "Epoch 128/500\n",
      "Train Batch 10/110 - Loss: 7.1278 (Macro: 1.5822, Energy: 1.1315, KLD: 2.1149, MC: 2.2992)\n",
      "Train Batch 20/110 - Loss: 6.8573 (Macro: 1.4803, Energy: 0.9419, KLD: 2.1345, MC: 2.3006)\n",
      "Train Batch 30/110 - Loss: 7.0407 (Macro: 1.4320, Energy: 1.0011, KLD: 2.3073, MC: 2.3004)\n",
      "Train Batch 40/110 - Loss: 7.4285 (Macro: 1.5427, Energy: 1.2021, KLD: 2.3805, MC: 2.3032)\n",
      "Train Batch 50/110 - Loss: 7.0740 (Macro: 1.5180, Energy: 1.0148, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.9206 (Macro: 1.3826, Energy: 0.9815, KLD: 2.2570, MC: 2.2994)\n",
      "Train Batch 70/110 - Loss: 6.9290 (Macro: 1.3574, Energy: 0.8291, KLD: 2.4378, MC: 2.3047)\n",
      "Train Batch 80/110 - Loss: 7.3045 (Macro: 1.4422, Energy: 1.0226, KLD: 2.5365, MC: 2.3032)\n",
      "Train Batch 90/110 - Loss: 6.7668 (Macro: 1.4753, Energy: 0.9654, KLD: 2.0241, MC: 2.3019)\n",
      "Train Batch 100/110 - Loss: 7.2932 (Macro: 1.5980, Energy: 1.1771, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.6500 (Macro: 1.2188, Energy: 0.7897, KLD: 2.3414, MC: 2.3002)\n",
      "Training epoch complete. Average Loss: 7.0779\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0710\n",
      "\n",
      "Epoch 129/500\n",
      "Train Batch 10/110 - Loss: 7.1005 (Macro: 1.5715, Energy: 1.1145, KLD: 2.1149, MC: 2.2996)\n",
      "Train Batch 20/110 - Loss: 6.8804 (Macro: 1.4755, Energy: 0.9682, KLD: 2.1345, MC: 2.3022)\n",
      "Train Batch 30/110 - Loss: 7.0706 (Macro: 1.4701, Energy: 0.9926, KLD: 2.3073, MC: 2.3006)\n",
      "Train Batch 40/110 - Loss: 7.4257 (Macro: 1.5626, Energy: 1.1834, KLD: 2.3805, MC: 2.2992)\n",
      "Train Batch 50/110 - Loss: 7.0469 (Macro: 1.4991, Energy: 1.0043, KLD: 2.2381, MC: 2.3053)\n",
      "Train Batch 60/110 - Loss: 6.9107 (Macro: 1.3950, Energy: 0.9567, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.9288 (Macro: 1.3397, Energy: 0.8488, KLD: 2.4378, MC: 2.3025)\n",
      "Train Batch 80/110 - Loss: 7.2459 (Macro: 1.4328, Energy: 0.9732, KLD: 2.5365, MC: 2.3034)\n",
      "Train Batch 90/110 - Loss: 6.8190 (Macro: 1.4752, Energy: 1.0166, KLD: 2.0241, MC: 2.3031)\n",
      "Train Batch 100/110 - Loss: 7.2980 (Macro: 1.6143, Energy: 1.1666, KLD: 2.2161, MC: 2.3009)\n",
      "Train Batch 110/110 - Loss: 6.6174 (Macro: 1.2395, Energy: 0.7369, KLD: 2.3414, MC: 2.2997)\n",
      "Training epoch complete. Average Loss: 7.0793\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0623\n",
      "\n",
      "Epoch 130/500\n",
      "Train Batch 10/110 - Loss: 7.1423 (Macro: 1.5888, Energy: 1.1392, KLD: 2.1149, MC: 2.2993)\n",
      "Train Batch 20/110 - Loss: 6.8340 (Macro: 1.4773, Energy: 0.9202, KLD: 2.1345, MC: 2.3021)\n",
      "Train Batch 30/110 - Loss: 7.1536 (Macro: 1.4575, Energy: 1.0867, KLD: 2.3073, MC: 2.3021)\n",
      "Train Batch 40/110 - Loss: 7.4421 (Macro: 1.5487, Energy: 1.2115, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0236 (Macro: 1.5020, Energy: 0.9813, KLD: 2.2381, MC: 2.3023)\n",
      "Train Batch 60/110 - Loss: 6.9037 (Macro: 1.3943, Energy: 0.9520, KLD: 2.2570, MC: 2.3004)\n",
      "Train Batch 70/110 - Loss: 6.9824 (Macro: 1.3847, Energy: 0.8563, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.2744 (Macro: 1.4168, Energy: 1.0193, KLD: 2.5365, MC: 2.3018)\n",
      "Train Batch 90/110 - Loss: 6.7378 (Macro: 1.4572, Energy: 0.9558, KLD: 2.0241, MC: 2.3008)\n",
      "Train Batch 100/110 - Loss: 7.3042 (Macro: 1.6203, Energy: 1.1653, KLD: 2.2161, MC: 2.3025)\n",
      "Train Batch 110/110 - Loss: 6.6424 (Macro: 1.2129, Energy: 0.7909, KLD: 2.3414, MC: 2.2973)\n",
      "Training epoch complete. Average Loss: 7.0793\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0576\n",
      "\n",
      "Epoch 131/500\n",
      "Train Batch 10/110 - Loss: 7.1100 (Macro: 1.5856, Energy: 1.1072, KLD: 2.1149, MC: 2.3022)\n",
      "Train Batch 20/110 - Loss: 6.8786 (Macro: 1.4677, Energy: 0.9748, KLD: 2.1345, MC: 2.3016)\n",
      "Train Batch 30/110 - Loss: 7.0951 (Macro: 1.4652, Energy: 1.0217, KLD: 2.3073, MC: 2.3010)\n",
      "Train Batch 40/110 - Loss: 7.3742 (Macro: 1.5288, Energy: 1.1630, KLD: 2.3805, MC: 2.3019)\n",
      "Train Batch 50/110 - Loss: 7.0914 (Macro: 1.5097, Energy: 1.0417, KLD: 2.2381, MC: 2.3019)\n",
      "Train Batch 60/110 - Loss: 6.9423 (Macro: 1.3928, Energy: 0.9922, KLD: 2.2570, MC: 2.3003)\n",
      "Train Batch 70/110 - Loss: 6.9488 (Macro: 1.3628, Energy: 0.8448, KLD: 2.4378, MC: 2.3033)\n",
      "Train Batch 80/110 - Loss: 7.3201 (Macro: 1.4276, Energy: 1.0517, KLD: 2.5365, MC: 2.3044)\n",
      "Train Batch 90/110 - Loss: 6.7604 (Macro: 1.4629, Energy: 0.9730, KLD: 2.0241, MC: 2.3004)\n",
      "Train Batch 100/110 - Loss: 7.2972 (Macro: 1.5965, Energy: 1.1822, KLD: 2.2161, MC: 2.3025)\n",
      "Train Batch 110/110 - Loss: 6.6028 (Macro: 1.2190, Energy: 0.7443, KLD: 2.3414, MC: 2.2981)\n",
      "Training epoch complete. Average Loss: 7.0813\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0638\n",
      "\n",
      "Epoch 132/500\n",
      "Train Batch 10/110 - Loss: 7.1867 (Macro: 1.5775, Energy: 1.1939, KLD: 2.1149, MC: 2.3004)\n",
      "Train Batch 20/110 - Loss: 6.9375 (Macro: 1.5124, Energy: 0.9875, KLD: 2.1345, MC: 2.3031)\n",
      "Train Batch 30/110 - Loss: 7.0725 (Macro: 1.4594, Energy: 1.0028, KLD: 2.3073, MC: 2.3030)\n",
      "Train Batch 40/110 - Loss: 7.4318 (Macro: 1.5224, Energy: 1.2261, KLD: 2.3805, MC: 2.3029)\n",
      "Train Batch 50/110 - Loss: 6.9879 (Macro: 1.5146, Energy: 0.9328, KLD: 2.2381, MC: 2.3025)\n",
      "Train Batch 60/110 - Loss: 6.9055 (Macro: 1.3764, Energy: 0.9723, KLD: 2.2570, MC: 2.2996)\n",
      "Train Batch 70/110 - Loss: 6.9564 (Macro: 1.3504, Energy: 0.8648, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.2863 (Macro: 1.4304, Energy: 1.0171, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.8065 (Macro: 1.4810, Energy: 0.9991, KLD: 2.0241, MC: 2.3023)\n",
      "Train Batch 100/110 - Loss: 7.3204 (Macro: 1.6262, Energy: 1.1753, KLD: 2.2161, MC: 2.3029)\n",
      "Train Batch 110/110 - Loss: 6.6241 (Macro: 1.1961, Energy: 0.7899, KLD: 2.3414, MC: 2.2967)\n",
      "Training epoch complete. Average Loss: 7.0823\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0720\n",
      "\n",
      "Epoch 133/500\n",
      "Train Batch 10/110 - Loss: 7.1703 (Macro: 1.5952, Energy: 1.1614, KLD: 2.1149, MC: 2.2988)\n",
      "Train Batch 20/110 - Loss: 6.8884 (Macro: 1.4723, Energy: 0.9796, KLD: 2.1345, MC: 2.3021)\n",
      "Train Batch 30/110 - Loss: 7.1314 (Macro: 1.4502, Energy: 1.0703, KLD: 2.3073, MC: 2.3036)\n",
      "Train Batch 40/110 - Loss: 7.3832 (Macro: 1.5607, Energy: 1.1404, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0344 (Macro: 1.4923, Energy: 1.0023, KLD: 2.2381, MC: 2.3017)\n",
      "Train Batch 60/110 - Loss: 6.9393 (Macro: 1.3691, Energy: 1.0111, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.9577 (Macro: 1.3612, Energy: 0.8549, KLD: 2.4378, MC: 2.3038)\n",
      "Train Batch 80/110 - Loss: 7.3565 (Macro: 1.4150, Energy: 1.1018, KLD: 2.5365, MC: 2.3033)\n",
      "Train Batch 90/110 - Loss: 6.7572 (Macro: 1.4801, Energy: 0.9522, KLD: 2.0241, MC: 2.3008)\n",
      "Train Batch 100/110 - Loss: 7.3561 (Macro: 1.6134, Energy: 1.2238, KLD: 2.2161, MC: 2.3028)\n",
      "Train Batch 110/110 - Loss: 6.6244 (Macro: 1.2631, Energy: 0.7211, KLD: 2.3414, MC: 2.2988)\n",
      "Training epoch complete. Average Loss: 7.0802\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0660\n",
      "\n",
      "Epoch 134/500\n",
      "Train Batch 10/110 - Loss: 7.0990 (Macro: 1.5718, Energy: 1.1102, KLD: 2.1149, MC: 2.3021)\n",
      "Train Batch 20/110 - Loss: 6.8649 (Macro: 1.4821, Energy: 0.9452, KLD: 2.1345, MC: 2.3031)\n",
      "Train Batch 30/110 - Loss: 7.0528 (Macro: 1.4606, Energy: 0.9837, KLD: 2.3073, MC: 2.3011)\n",
      "Train Batch 40/110 - Loss: 7.4597 (Macro: 1.5503, Energy: 1.2285, KLD: 2.3805, MC: 2.3004)\n",
      "Train Batch 50/110 - Loss: 7.0644 (Macro: 1.5043, Energy: 1.0196, KLD: 2.2381, MC: 2.3025)\n",
      "Train Batch 60/110 - Loss: 6.9023 (Macro: 1.3776, Energy: 0.9653, KLD: 2.2570, MC: 2.3024)\n",
      "Train Batch 70/110 - Loss: 6.9269 (Macro: 1.3553, Energy: 0.8310, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.2349 (Macro: 1.4052, Energy: 0.9913, KLD: 2.5365, MC: 2.3018)\n",
      "Train Batch 90/110 - Loss: 6.8037 (Macro: 1.4821, Energy: 0.9970, KLD: 2.0241, MC: 2.3005)\n",
      "Train Batch 100/110 - Loss: 7.2986 (Macro: 1.6172, Energy: 1.1639, KLD: 2.2161, MC: 2.3014)\n",
      "Train Batch 110/110 - Loss: 6.5990 (Macro: 1.2103, Energy: 0.7482, KLD: 2.3414, MC: 2.2992)\n",
      "Training epoch complete. Average Loss: 7.0762\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0628\n",
      "\n",
      "Epoch 135/500\n",
      "Train Batch 10/110 - Loss: 7.1709 (Macro: 1.5666, Energy: 1.1883, KLD: 2.1149, MC: 2.3011)\n",
      "Train Batch 20/110 - Loss: 6.8961 (Macro: 1.4773, Energy: 0.9817, KLD: 2.1345, MC: 2.3026)\n",
      "Train Batch 30/110 - Loss: 7.0991 (Macro: 1.4489, Energy: 1.0415, KLD: 2.3073, MC: 2.3014)\n",
      "Train Batch 40/110 - Loss: 7.4959 (Macro: 1.5588, Energy: 1.2559, KLD: 2.3805, MC: 2.3007)\n",
      "Train Batch 50/110 - Loss: 7.0703 (Macro: 1.4937, Energy: 1.0368, KLD: 2.2381, MC: 2.3018)\n",
      "Train Batch 60/110 - Loss: 6.9033 (Macro: 1.3988, Energy: 0.9463, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9659 (Macro: 1.3637, Energy: 0.8594, KLD: 2.4378, MC: 2.3050)\n",
      "Train Batch 80/110 - Loss: 7.2588 (Macro: 1.4116, Energy: 1.0082, KLD: 2.5365, MC: 2.3025)\n",
      "Train Batch 90/110 - Loss: 6.8169 (Macro: 1.4770, Energy: 1.0151, KLD: 2.0241, MC: 2.3007)\n",
      "Train Batch 100/110 - Loss: 7.3557 (Macro: 1.6136, Energy: 1.2247, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.5974 (Macro: 1.2541, Energy: 0.7054, KLD: 2.3414, MC: 2.2965)\n",
      "Training epoch complete. Average Loss: 7.0805\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0711\n",
      "\n",
      "Epoch 136/500\n",
      "Train Batch 10/110 - Loss: 7.0970 (Macro: 1.5957, Energy: 1.0880, KLD: 2.1149, MC: 2.2983)\n",
      "Train Batch 20/110 - Loss: 6.9042 (Macro: 1.4751, Energy: 0.9927, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.1182 (Macro: 1.4650, Energy: 1.0432, KLD: 2.3073, MC: 2.3028)\n",
      "Train Batch 40/110 - Loss: 7.4661 (Macro: 1.5592, Energy: 1.2257, KLD: 2.3805, MC: 2.3007)\n",
      "Train Batch 50/110 - Loss: 7.0098 (Macro: 1.5082, Energy: 0.9609, KLD: 2.2381, MC: 2.3026)\n",
      "Train Batch 60/110 - Loss: 6.9342 (Macro: 1.3899, Energy: 0.9866, KLD: 2.2570, MC: 2.3006)\n",
      "Train Batch 70/110 - Loss: 6.9608 (Macro: 1.3526, Energy: 0.8676, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.2950 (Macro: 1.4324, Energy: 1.0255, KLD: 2.5365, MC: 2.3006)\n",
      "Train Batch 90/110 - Loss: 6.7040 (Macro: 1.4691, Energy: 0.9095, KLD: 2.0241, MC: 2.3013)\n",
      "Train Batch 100/110 - Loss: 7.3323 (Macro: 1.6115, Energy: 1.2043, KLD: 2.2161, MC: 2.3004)\n",
      "Train Batch 110/110 - Loss: 6.6855 (Macro: 1.2506, Energy: 0.7960, KLD: 2.3414, MC: 2.2976)\n",
      "Training epoch complete. Average Loss: 7.0817\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0732\n",
      "\n",
      "Epoch 137/500\n",
      "Train Batch 10/110 - Loss: 7.0998 (Macro: 1.5689, Energy: 1.1164, KLD: 2.1149, MC: 2.2996)\n",
      "Train Batch 20/110 - Loss: 6.8735 (Macro: 1.4697, Energy: 0.9668, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.0652 (Macro: 1.4630, Energy: 0.9962, KLD: 2.3073, MC: 2.2987)\n",
      "Train Batch 40/110 - Loss: 7.4621 (Macro: 1.5542, Energy: 1.2255, KLD: 2.3805, MC: 2.3018)\n",
      "Train Batch 50/110 - Loss: 7.0400 (Macro: 1.5261, Energy: 0.9727, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.8707 (Macro: 1.4008, Energy: 0.9113, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9262 (Macro: 1.3534, Energy: 0.8312, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.3011 (Macro: 1.4091, Energy: 1.0522, KLD: 2.5365, MC: 2.3033)\n",
      "Train Batch 90/110 - Loss: 6.7955 (Macro: 1.4694, Energy: 1.0004, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.3449 (Macro: 1.6145, Energy: 1.2120, KLD: 2.2161, MC: 2.3022)\n",
      "Train Batch 110/110 - Loss: 6.6004 (Macro: 1.2222, Energy: 0.7373, KLD: 2.3414, MC: 2.2996)\n",
      "Training epoch complete. Average Loss: 7.0824\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0631\n",
      "\n",
      "Epoch 138/500\n",
      "Train Batch 10/110 - Loss: 7.1571 (Macro: 1.5877, Energy: 1.1539, KLD: 2.1149, MC: 2.3006)\n",
      "Train Batch 20/110 - Loss: 6.8623 (Macro: 1.4870, Energy: 0.9406, KLD: 2.1345, MC: 2.3002)\n",
      "Train Batch 30/110 - Loss: 7.0930 (Macro: 1.4522, Energy: 1.0327, KLD: 2.3073, MC: 2.3009)\n",
      "Train Batch 40/110 - Loss: 7.4482 (Macro: 1.5663, Energy: 1.1988, KLD: 2.3805, MC: 2.3026)\n",
      "Train Batch 50/110 - Loss: 7.0352 (Macro: 1.4885, Energy: 1.0053, KLD: 2.2381, MC: 2.3033)\n",
      "Train Batch 60/110 - Loss: 6.8603 (Macro: 1.3783, Energy: 0.9237, KLD: 2.2570, MC: 2.3012)\n",
      "Train Batch 70/110 - Loss: 6.9588 (Macro: 1.3367, Energy: 0.8818, KLD: 2.4378, MC: 2.3025)\n",
      "Train Batch 80/110 - Loss: 7.2716 (Macro: 1.4327, Energy: 0.9988, KLD: 2.5365, MC: 2.3035)\n",
      "Train Batch 90/110 - Loss: 6.7494 (Macro: 1.4646, Energy: 0.9582, KLD: 2.0241, MC: 2.3025)\n",
      "Train Batch 100/110 - Loss: 7.2410 (Macro: 1.5711, Energy: 1.1535, KLD: 2.2161, MC: 2.3002)\n",
      "Train Batch 110/110 - Loss: 6.6574 (Macro: 1.2585, Energy: 0.7596, KLD: 2.3414, MC: 2.2979)\n",
      "Training epoch complete. Average Loss: 7.0780\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0675\n",
      "\n",
      "Epoch 139/500\n",
      "Train Batch 10/110 - Loss: 7.1443 (Macro: 1.5890, Energy: 1.1406, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.9141 (Macro: 1.4713, Energy: 1.0065, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.1222 (Macro: 1.4629, Energy: 1.0501, KLD: 2.3073, MC: 2.3018)\n",
      "Train Batch 40/110 - Loss: 7.4893 (Macro: 1.5668, Energy: 1.2413, KLD: 2.3805, MC: 2.3008)\n",
      "Train Batch 50/110 - Loss: 7.0441 (Macro: 1.4855, Energy: 1.0173, KLD: 2.2381, MC: 2.3033)\n",
      "Train Batch 60/110 - Loss: 6.9187 (Macro: 1.3948, Energy: 0.9671, KLD: 2.2570, MC: 2.2997)\n",
      "Train Batch 70/110 - Loss: 6.9179 (Macro: 1.3652, Energy: 0.8130, KLD: 2.4378, MC: 2.3019)\n",
      "Train Batch 80/110 - Loss: 7.2989 (Macro: 1.4242, Energy: 1.0354, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.8034 (Macro: 1.4792, Energy: 0.9986, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.3152 (Macro: 1.6211, Energy: 1.1757, KLD: 2.2161, MC: 2.3023)\n",
      "Train Batch 110/110 - Loss: 6.5826 (Macro: 1.2388, Energy: 0.7035, KLD: 2.3414, MC: 2.2989)\n",
      "Training epoch complete. Average Loss: 7.0887\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0652\n",
      "\n",
      "Epoch 140/500\n",
      "Train Batch 10/110 - Loss: 7.1880 (Macro: 1.5772, Energy: 1.1982, KLD: 2.1149, MC: 2.2977)\n",
      "Train Batch 20/110 - Loss: 6.8676 (Macro: 1.4880, Energy: 0.9425, KLD: 2.1345, MC: 2.3027)\n",
      "Train Batch 30/110 - Loss: 7.1245 (Macro: 1.4553, Energy: 1.0593, KLD: 2.3073, MC: 2.3026)\n",
      "Train Batch 40/110 - Loss: 7.4275 (Macro: 1.5736, Energy: 1.1730, KLD: 2.3805, MC: 2.3004)\n",
      "Train Batch 50/110 - Loss: 7.0407 (Macro: 1.5150, Energy: 0.9840, KLD: 2.2381, MC: 2.3036)\n",
      "Train Batch 60/110 - Loss: 6.8850 (Macro: 1.3892, Energy: 0.9379, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 6.9751 (Macro: 1.3725, Energy: 0.8615, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.2807 (Macro: 1.4096, Energy: 1.0327, KLD: 2.5365, MC: 2.3019)\n",
      "Train Batch 90/110 - Loss: 6.7931 (Macro: 1.4800, Energy: 0.9865, KLD: 2.0241, MC: 2.3025)\n",
      "Train Batch 100/110 - Loss: 7.3496 (Macro: 1.6142, Energy: 1.2177, KLD: 2.2161, MC: 2.3017)\n",
      "Train Batch 110/110 - Loss: 6.6516 (Macro: 1.2774, Energy: 0.7353, KLD: 2.3414, MC: 2.2975)\n",
      "Training epoch complete. Average Loss: 7.0812\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0670\n",
      "\n",
      "Epoch 141/500\n",
      "Train Batch 10/110 - Loss: 7.0993 (Macro: 1.5870, Energy: 1.0986, KLD: 2.1149, MC: 2.2988)\n",
      "Train Batch 20/110 - Loss: 6.9528 (Macro: 1.5048, Energy: 1.0113, KLD: 2.1345, MC: 2.3022)\n",
      "Train Batch 30/110 - Loss: 7.1421 (Macro: 1.4566, Energy: 1.0757, KLD: 2.3073, MC: 2.3025)\n",
      "Train Batch 40/110 - Loss: 7.4255 (Macro: 1.5544, Energy: 1.1907, KLD: 2.3805, MC: 2.2999)\n",
      "Train Batch 50/110 - Loss: 7.0305 (Macro: 1.4816, Energy: 1.0087, KLD: 2.2381, MC: 2.3021)\n",
      "Train Batch 60/110 - Loss: 6.8644 (Macro: 1.3837, Energy: 0.9234, KLD: 2.2570, MC: 2.3002)\n",
      "Train Batch 70/110 - Loss: 6.9653 (Macro: 1.3876, Energy: 0.8362, KLD: 2.4378, MC: 2.3038)\n",
      "Train Batch 80/110 - Loss: 7.2943 (Macro: 1.4228, Energy: 1.0330, KLD: 2.5365, MC: 2.3020)\n",
      "Train Batch 90/110 - Loss: 6.7621 (Macro: 1.4858, Energy: 0.9501, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3146 (Macro: 1.6180, Energy: 1.1778, KLD: 2.2161, MC: 2.3027)\n",
      "Train Batch 110/110 - Loss: 6.6643 (Macro: 1.2601, Energy: 0.7631, KLD: 2.3414, MC: 2.2997)\n",
      "Training epoch complete. Average Loss: 7.0838\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0637\n",
      "\n",
      "Epoch 142/500\n",
      "Train Batch 10/110 - Loss: 7.0819 (Macro: 1.5795, Energy: 1.0872, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.8662 (Macro: 1.4915, Energy: 0.9389, KLD: 2.1345, MC: 2.3014)\n",
      "Train Batch 30/110 - Loss: 7.0482 (Macro: 1.4456, Energy: 0.9928, KLD: 2.3073, MC: 2.3025)\n",
      "Train Batch 40/110 - Loss: 7.3986 (Macro: 1.5460, Energy: 1.1721, KLD: 2.3805, MC: 2.3001)\n",
      "Train Batch 50/110 - Loss: 7.0256 (Macro: 1.5021, Energy: 0.9813, KLD: 2.2381, MC: 2.3041)\n",
      "Train Batch 60/110 - Loss: 6.8956 (Macro: 1.3844, Energy: 0.9529, KLD: 2.2570, MC: 2.3014)\n",
      "Train Batch 70/110 - Loss: 6.9608 (Macro: 1.3679, Energy: 0.8523, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.2887 (Macro: 1.4319, Energy: 1.0167, KLD: 2.5365, MC: 2.3036)\n",
      "Train Batch 90/110 - Loss: 6.8041 (Macro: 1.4773, Energy: 1.0023, KLD: 2.0241, MC: 2.3004)\n",
      "Train Batch 100/110 - Loss: 7.2816 (Macro: 1.6056, Energy: 1.1588, KLD: 2.2161, MC: 2.3011)\n",
      "Train Batch 110/110 - Loss: 6.6160 (Macro: 1.2324, Energy: 0.7449, KLD: 2.3414, MC: 2.2974)\n",
      "Training epoch complete. Average Loss: 7.0819\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0700\n",
      "\n",
      "Epoch 143/500\n",
      "Train Batch 10/110 - Loss: 7.1871 (Macro: 1.5805, Energy: 1.1901, KLD: 2.1149, MC: 2.3016)\n",
      "Train Batch 20/110 - Loss: 6.8633 (Macro: 1.4816, Energy: 0.9461, KLD: 2.1345, MC: 2.3011)\n",
      "Train Batch 30/110 - Loss: 7.1026 (Macro: 1.4530, Energy: 1.0403, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4566 (Macro: 1.5634, Energy: 1.2108, KLD: 2.3805, MC: 2.3019)\n",
      "Train Batch 50/110 - Loss: 7.0192 (Macro: 1.4950, Energy: 0.9833, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.8691 (Macro: 1.3789, Energy: 0.9331, KLD: 2.2570, MC: 2.3000)\n",
      "Train Batch 70/110 - Loss: 6.9395 (Macro: 1.3612, Energy: 0.8365, KLD: 2.4378, MC: 2.3040)\n",
      "Train Batch 80/110 - Loss: 7.2702 (Macro: 1.4282, Energy: 1.0017, KLD: 2.5365, MC: 2.3039)\n",
      "Train Batch 90/110 - Loss: 6.7950 (Macro: 1.4731, Energy: 0.9967, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.3372 (Macro: 1.6049, Energy: 1.2143, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.5214 (Macro: 1.1880, Energy: 0.6934, KLD: 2.3414, MC: 2.2986)\n",
      "Training epoch complete. Average Loss: 7.0786\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0675\n",
      "\n",
      "Epoch 144/500\n",
      "Train Batch 10/110 - Loss: 7.1025 (Macro: 1.5972, Energy: 1.0920, KLD: 2.1149, MC: 2.2985)\n",
      "Train Batch 20/110 - Loss: 6.8697 (Macro: 1.4631, Energy: 0.9716, KLD: 2.1345, MC: 2.3005)\n",
      "Train Batch 30/110 - Loss: 7.0577 (Macro: 1.4354, Energy: 1.0132, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4504 (Macro: 1.5752, Energy: 1.1940, KLD: 2.3805, MC: 2.3007)\n",
      "Train Batch 50/110 - Loss: 7.0112 (Macro: 1.4979, Energy: 0.9718, KLD: 2.2381, MC: 2.3034)\n",
      "Train Batch 60/110 - Loss: 6.8691 (Macro: 1.3819, Energy: 0.9292, KLD: 2.2570, MC: 2.3010)\n",
      "Train Batch 70/110 - Loss: 6.9140 (Macro: 1.3557, Energy: 0.8165, KLD: 2.4378, MC: 2.3040)\n",
      "Train Batch 80/110 - Loss: 7.3521 (Macro: 1.4389, Energy: 1.0725, KLD: 2.5365, MC: 2.3042)\n",
      "Train Batch 90/110 - Loss: 6.7907 (Macro: 1.4664, Energy: 0.9997, KLD: 2.0241, MC: 2.3005)\n",
      "Train Batch 100/110 - Loss: 7.2548 (Macro: 1.5961, Energy: 1.1405, KLD: 2.2161, MC: 2.3022)\n",
      "Train Batch 110/110 - Loss: 6.6208 (Macro: 1.2058, Energy: 0.7747, KLD: 2.3414, MC: 2.2990)\n",
      "Training epoch complete. Average Loss: 7.0800\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0717\n",
      "\n",
      "Epoch 145/500\n",
      "Train Batch 10/110 - Loss: 7.1127 (Macro: 1.5753, Energy: 1.1224, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.9107 (Macro: 1.4975, Energy: 0.9773, KLD: 2.1345, MC: 2.3014)\n",
      "Train Batch 30/110 - Loss: 7.0691 (Macro: 1.4313, Energy: 1.0306, KLD: 2.3073, MC: 2.2999)\n",
      "Train Batch 40/110 - Loss: 7.4541 (Macro: 1.5387, Energy: 1.2344, KLD: 2.3805, MC: 2.3005)\n",
      "Train Batch 50/110 - Loss: 7.0664 (Macro: 1.4893, Energy: 1.0360, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.9226 (Macro: 1.3894, Energy: 0.9743, KLD: 2.2570, MC: 2.3019)\n",
      "Train Batch 70/110 - Loss: 6.9820 (Macro: 1.3637, Energy: 0.8773, KLD: 2.4378, MC: 2.3033)\n",
      "Train Batch 80/110 - Loss: 7.2991 (Macro: 1.4222, Energy: 1.0370, KLD: 2.5365, MC: 2.3034)\n",
      "Train Batch 90/110 - Loss: 6.8322 (Macro: 1.4701, Energy: 1.0377, KLD: 2.0241, MC: 2.3003)\n",
      "Train Batch 100/110 - Loss: 7.3191 (Macro: 1.6035, Energy: 1.1978, KLD: 2.2161, MC: 2.3017)\n",
      "Train Batch 110/110 - Loss: 6.6074 (Macro: 1.2376, Energy: 0.7290, KLD: 2.3414, MC: 2.2995)\n",
      "Training epoch complete. Average Loss: 7.0774\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0705\n",
      "\n",
      "Epoch 146/500\n",
      "Train Batch 10/110 - Loss: 7.0780 (Macro: 1.5702, Energy: 1.0922, KLD: 2.1149, MC: 2.3006)\n",
      "Train Batch 20/110 - Loss: 6.8709 (Macro: 1.4655, Energy: 0.9688, KLD: 2.1345, MC: 2.3021)\n",
      "Train Batch 30/110 - Loss: 7.0694 (Macro: 1.4500, Energy: 1.0101, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4516 (Macro: 1.5502, Energy: 1.2184, KLD: 2.3805, MC: 2.3025)\n",
      "Train Batch 50/110 - Loss: 7.0648 (Macro: 1.5064, Energy: 1.0176, KLD: 2.2381, MC: 2.3027)\n",
      "Train Batch 60/110 - Loss: 6.9417 (Macro: 1.3817, Energy: 1.0014, KLD: 2.2570, MC: 2.3016)\n",
      "Train Batch 70/110 - Loss: 6.9589 (Macro: 1.3656, Energy: 0.8528, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.3913 (Macro: 1.4501, Energy: 1.1022, KLD: 2.5365, MC: 2.3026)\n",
      "Train Batch 90/110 - Loss: 6.8040 (Macro: 1.4807, Energy: 0.9962, KLD: 2.0241, MC: 2.3031)\n",
      "Train Batch 100/110 - Loss: 7.3264 (Macro: 1.6067, Energy: 1.2003, KLD: 2.2161, MC: 2.3033)\n",
      "Train Batch 110/110 - Loss: 6.6179 (Macro: 1.2022, Energy: 0.7754, KLD: 2.3414, MC: 2.2989)\n",
      "Training epoch complete. Average Loss: 7.0786\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0641\n",
      "\n",
      "Epoch 147/500\n",
      "Train Batch 10/110 - Loss: 7.1016 (Macro: 1.5981, Energy: 1.0872, KLD: 2.1149, MC: 2.3013)\n",
      "Train Batch 20/110 - Loss: 6.8842 (Macro: 1.4915, Energy: 0.9571, KLD: 2.1345, MC: 2.3012)\n",
      "Train Batch 30/110 - Loss: 7.0245 (Macro: 1.4393, Energy: 0.9765, KLD: 2.3073, MC: 2.3015)\n",
      "Train Batch 40/110 - Loss: 7.4682 (Macro: 1.5535, Energy: 1.2319, KLD: 2.3805, MC: 2.3023)\n",
      "Train Batch 50/110 - Loss: 6.9983 (Macro: 1.4967, Energy: 0.9614, KLD: 2.2381, MC: 2.3020)\n",
      "Train Batch 60/110 - Loss: 6.9164 (Macro: 1.3821, Energy: 0.9748, KLD: 2.2570, MC: 2.3025)\n",
      "Train Batch 70/110 - Loss: 6.9399 (Macro: 1.3610, Energy: 0.8376, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.2963 (Macro: 1.4338, Energy: 1.0215, KLD: 2.5365, MC: 2.3045)\n",
      "Train Batch 90/110 - Loss: 6.7421 (Macro: 1.4741, Energy: 0.9435, KLD: 2.0241, MC: 2.3005)\n",
      "Train Batch 100/110 - Loss: 7.2887 (Macro: 1.5873, Energy: 1.1840, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.5941 (Macro: 1.2085, Energy: 0.7453, KLD: 2.3414, MC: 2.2990)\n",
      "Training epoch complete. Average Loss: 7.0761\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0703\n",
      "\n",
      "Epoch 148/500\n",
      "Train Batch 10/110 - Loss: 7.1183 (Macro: 1.5794, Energy: 1.1239, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.8501 (Macro: 1.4577, Energy: 0.9568, KLD: 2.1345, MC: 2.3012)\n",
      "Train Batch 30/110 - Loss: 7.0528 (Macro: 1.4453, Energy: 0.9980, KLD: 2.3073, MC: 2.3022)\n",
      "Train Batch 40/110 - Loss: 7.4161 (Macro: 1.5343, Energy: 1.2000, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0440 (Macro: 1.5047, Energy: 0.9992, KLD: 2.2381, MC: 2.3020)\n",
      "Train Batch 60/110 - Loss: 6.9658 (Macro: 1.3848, Energy: 1.0228, KLD: 2.2570, MC: 2.3012)\n",
      "Train Batch 70/110 - Loss: 6.9153 (Macro: 1.3434, Energy: 0.8313, KLD: 2.4378, MC: 2.3027)\n",
      "Train Batch 80/110 - Loss: 7.3046 (Macro: 1.4097, Energy: 1.0560, KLD: 2.5365, MC: 2.3025)\n",
      "Train Batch 90/110 - Loss: 6.7979 (Macro: 1.4762, Energy: 0.9947, KLD: 2.0241, MC: 2.3029)\n",
      "Train Batch 100/110 - Loss: 7.3058 (Macro: 1.6168, Energy: 1.1721, KLD: 2.2161, MC: 2.3008)\n",
      "Train Batch 110/110 - Loss: 6.6126 (Macro: 1.2150, Energy: 0.7568, KLD: 2.3414, MC: 2.2993)\n",
      "Training epoch complete. Average Loss: 7.0786\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0612\n",
      "\n",
      "Epoch 149/500\n",
      "Train Batch 10/110 - Loss: 7.1785 (Macro: 1.6051, Energy: 1.1580, KLD: 2.1149, MC: 2.3005)\n",
      "Train Batch 20/110 - Loss: 6.8265 (Macro: 1.4622, Energy: 0.9277, KLD: 2.1345, MC: 2.3022)\n",
      "Train Batch 30/110 - Loss: 7.1159 (Macro: 1.4554, Energy: 1.0502, KLD: 2.3073, MC: 2.3031)\n",
      "Train Batch 40/110 - Loss: 7.4446 (Macro: 1.5605, Energy: 1.2021, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.0716 (Macro: 1.4972, Energy: 1.0334, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.8915 (Macro: 1.3884, Energy: 0.9448, KLD: 2.2570, MC: 2.3012)\n",
      "Train Batch 70/110 - Loss: 6.9574 (Macro: 1.3403, Energy: 0.8748, KLD: 2.4378, MC: 2.3046)\n",
      "Train Batch 80/110 - Loss: 7.2295 (Macro: 1.4143, Energy: 0.9763, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.8235 (Macro: 1.4722, Energy: 1.0248, KLD: 2.0241, MC: 2.3024)\n",
      "Train Batch 100/110 - Loss: 7.2846 (Macro: 1.5936, Energy: 1.1726, KLD: 2.2161, MC: 2.3023)\n",
      "Train Batch 110/110 - Loss: 6.6787 (Macro: 1.2452, Energy: 0.7918, KLD: 2.3414, MC: 2.3003)\n",
      "Training epoch complete. Average Loss: 7.0834\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0506\n",
      "\n",
      "Epoch 150/500\n",
      "Train Batch 10/110 - Loss: 7.1564 (Macro: 1.6075, Energy: 1.1342, KLD: 2.1149, MC: 2.2998)\n",
      "Train Batch 20/110 - Loss: 6.9012 (Macro: 1.4977, Energy: 0.9655, KLD: 2.1345, MC: 2.3036)\n",
      "Train Batch 30/110 - Loss: 7.0689 (Macro: 1.4617, Energy: 0.9973, KLD: 2.3073, MC: 2.3025)\n",
      "Train Batch 40/110 - Loss: 7.4909 (Macro: 1.5553, Energy: 1.2523, KLD: 2.3805, MC: 2.3029)\n",
      "Train Batch 50/110 - Loss: 7.0106 (Macro: 1.5031, Energy: 0.9654, KLD: 2.2381, MC: 2.3040)\n",
      "Train Batch 60/110 - Loss: 6.8649 (Macro: 1.3653, Energy: 0.9400, KLD: 2.2570, MC: 2.3024)\n",
      "Train Batch 70/110 - Loss: 6.9935 (Macro: 1.3506, Energy: 0.9030, KLD: 2.4378, MC: 2.3021)\n",
      "Train Batch 80/110 - Loss: 7.3251 (Macro: 1.4408, Energy: 1.0442, KLD: 2.5365, MC: 2.3036)\n",
      "Train Batch 90/110 - Loss: 6.7482 (Macro: 1.4630, Energy: 0.9599, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.3222 (Macro: 1.6268, Energy: 1.1767, KLD: 2.2161, MC: 2.3026)\n",
      "Train Batch 110/110 - Loss: 6.5779 (Macro: 1.2049, Energy: 0.7309, KLD: 2.3414, MC: 2.3007)\n",
      "Training epoch complete. Average Loss: 7.0828\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0583\n",
      "\n",
      "Epoch 151/500\n",
      "Train Batch 10/110 - Loss: 7.1531 (Macro: 1.5943, Energy: 1.1434, KLD: 2.1149, MC: 2.3005)\n",
      "Train Batch 20/110 - Loss: 6.9111 (Macro: 1.5078, Energy: 0.9678, KLD: 2.1345, MC: 2.3010)\n",
      "Train Batch 30/110 - Loss: 7.0688 (Macro: 1.4489, Energy: 1.0120, KLD: 2.3073, MC: 2.3006)\n",
      "Train Batch 40/110 - Loss: 7.4393 (Macro: 1.5593, Energy: 1.1958, KLD: 2.3805, MC: 2.3037)\n",
      "Train Batch 50/110 - Loss: 7.0563 (Macro: 1.5007, Energy: 1.0146, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.8907 (Macro: 1.3968, Energy: 0.9348, KLD: 2.2570, MC: 2.3021)\n",
      "Train Batch 70/110 - Loss: 6.9508 (Macro: 1.3666, Energy: 0.8436, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.3278 (Macro: 1.4084, Energy: 1.0807, KLD: 2.5365, MC: 2.3021)\n",
      "Train Batch 90/110 - Loss: 6.8620 (Macro: 1.4786, Energy: 1.0573, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3424 (Macro: 1.6240, Energy: 1.1993, KLD: 2.2161, MC: 2.3031)\n",
      "Train Batch 110/110 - Loss: 6.6569 (Macro: 1.2616, Energy: 0.7536, KLD: 2.3414, MC: 2.3002)\n",
      "Training epoch complete. Average Loss: 7.0793\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0639\n",
      "\n",
      "Epoch 152/500\n",
      "Train Batch 10/110 - Loss: 7.1298 (Macro: 1.5781, Energy: 1.1366, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.8698 (Macro: 1.4593, Energy: 0.9750, KLD: 2.1345, MC: 2.3010)\n",
      "Train Batch 30/110 - Loss: 7.0920 (Macro: 1.4421, Energy: 1.0408, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4053 (Macro: 1.5566, Energy: 1.1672, KLD: 2.3805, MC: 2.3010)\n",
      "Train Batch 50/110 - Loss: 7.0470 (Macro: 1.4945, Energy: 1.0104, KLD: 2.2381, MC: 2.3040)\n",
      "Train Batch 60/110 - Loss: 6.9149 (Macro: 1.3923, Energy: 0.9643, KLD: 2.2570, MC: 2.3012)\n",
      "Train Batch 70/110 - Loss: 6.9443 (Macro: 1.3622, Energy: 0.8408, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.3056 (Macro: 1.4515, Energy: 1.0146, KLD: 2.5365, MC: 2.3030)\n",
      "Train Batch 90/110 - Loss: 6.7700 (Macro: 1.5014, Energy: 0.9426, KLD: 2.0241, MC: 2.3019)\n",
      "Train Batch 100/110 - Loss: 7.3056 (Macro: 1.6005, Energy: 1.1878, KLD: 2.2161, MC: 2.3012)\n",
      "Train Batch 110/110 - Loss: 6.6184 (Macro: 1.2214, Energy: 0.7576, KLD: 2.3414, MC: 2.2980)\n",
      "Training epoch complete. Average Loss: 7.0781\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0638\n",
      "\n",
      "Epoch 153/500\n",
      "Train Batch 10/110 - Loss: 7.0792 (Macro: 1.5573, Energy: 1.1083, KLD: 2.1149, MC: 2.2987)\n",
      "Train Batch 20/110 - Loss: 6.8903 (Macro: 1.4775, Energy: 0.9762, KLD: 2.1345, MC: 2.3022)\n",
      "Train Batch 30/110 - Loss: 7.0636 (Macro: 1.4654, Energy: 0.9882, KLD: 2.3073, MC: 2.3027)\n",
      "Train Batch 40/110 - Loss: 7.4510 (Macro: 1.5275, Energy: 1.2417, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0823 (Macro: 1.5125, Energy: 1.0291, KLD: 2.2381, MC: 2.3027)\n",
      "Train Batch 60/110 - Loss: 6.8956 (Macro: 1.3856, Energy: 0.9492, KLD: 2.2570, MC: 2.3037)\n",
      "Train Batch 70/110 - Loss: 6.8986 (Macro: 1.3405, Energy: 0.8175, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.3851 (Macro: 1.4392, Energy: 1.1071, KLD: 2.5365, MC: 2.3024)\n",
      "Train Batch 90/110 - Loss: 6.7989 (Macro: 1.4751, Energy: 0.9967, KLD: 2.0241, MC: 2.3030)\n",
      "Train Batch 100/110 - Loss: 7.2900 (Macro: 1.6291, Energy: 1.1440, KLD: 2.2161, MC: 2.3008)\n",
      "Train Batch 110/110 - Loss: 6.6318 (Macro: 1.2163, Energy: 0.7738, KLD: 2.3414, MC: 2.3003)\n",
      "Training epoch complete. Average Loss: 7.0793\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0733\n",
      "\n",
      "Epoch 154/500\n",
      "Train Batch 10/110 - Loss: 7.1464 (Macro: 1.5745, Energy: 1.1570, KLD: 2.1149, MC: 2.2999)\n",
      "Train Batch 20/110 - Loss: 6.8635 (Macro: 1.4812, Energy: 0.9458, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.0634 (Macro: 1.4702, Energy: 0.9827, KLD: 2.3073, MC: 2.3033)\n",
      "Train Batch 40/110 - Loss: 7.4938 (Macro: 1.5702, Energy: 1.2418, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0905 (Macro: 1.5031, Energy: 1.0461, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.9284 (Macro: 1.3939, Energy: 0.9768, KLD: 2.2570, MC: 2.3006)\n",
      "Train Batch 70/110 - Loss: 6.9743 (Macro: 1.3660, Energy: 0.8654, KLD: 2.4378, MC: 2.3052)\n",
      "Train Batch 80/110 - Loss: 7.3131 (Macro: 1.4156, Energy: 1.0578, KLD: 2.5365, MC: 2.3032)\n",
      "Train Batch 90/110 - Loss: 6.7590 (Macro: 1.4640, Energy: 0.9692, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.3301 (Macro: 1.6261, Energy: 1.1868, KLD: 2.2161, MC: 2.3011)\n",
      "Train Batch 110/110 - Loss: 6.6371 (Macro: 1.2360, Energy: 0.7608, KLD: 2.3414, MC: 2.2990)\n",
      "Training epoch complete. Average Loss: 7.0797\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0782\n",
      "\n",
      "Epoch 155/500\n",
      "Train Batch 10/110 - Loss: 7.1835 (Macro: 1.5786, Energy: 1.1893, KLD: 2.1149, MC: 2.3006)\n",
      "Train Batch 20/110 - Loss: 6.9041 (Macro: 1.4727, Energy: 0.9965, KLD: 2.1345, MC: 2.3005)\n",
      "Train Batch 30/110 - Loss: 7.0619 (Macro: 1.4464, Energy: 1.0064, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4615 (Macro: 1.5531, Energy: 1.2271, KLD: 2.3805, MC: 2.3008)\n",
      "Train Batch 50/110 - Loss: 7.0754 (Macro: 1.5119, Energy: 1.0227, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.8514 (Macro: 1.3883, Energy: 0.9034, KLD: 2.2570, MC: 2.3027)\n",
      "Train Batch 70/110 - Loss: 6.9746 (Macro: 1.3456, Energy: 0.8878, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.2763 (Macro: 1.4237, Energy: 1.0138, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.8140 (Macro: 1.4598, Energy: 1.0268, KLD: 2.0241, MC: 2.3034)\n",
      "Train Batch 100/110 - Loss: 7.2891 (Macro: 1.5969, Energy: 1.1758, KLD: 2.2161, MC: 2.3003)\n",
      "Train Batch 110/110 - Loss: 6.7168 (Macro: 1.2353, Energy: 0.8398, KLD: 2.3414, MC: 2.3003)\n",
      "Training epoch complete. Average Loss: 7.0797\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0595\n",
      "\n",
      "Epoch 156/500\n",
      "Train Batch 10/110 - Loss: 7.1230 (Macro: 1.5764, Energy: 1.1307, KLD: 2.1149, MC: 2.3009)\n",
      "Train Batch 20/110 - Loss: 6.8950 (Macro: 1.4729, Energy: 0.9872, KLD: 2.1345, MC: 2.3004)\n",
      "Train Batch 30/110 - Loss: 7.0393 (Macro: 1.4532, Energy: 0.9753, KLD: 2.3073, MC: 2.3035)\n",
      "Train Batch 40/110 - Loss: 7.4072 (Macro: 1.5440, Energy: 1.1816, KLD: 2.3805, MC: 2.3011)\n",
      "Train Batch 50/110 - Loss: 7.0928 (Macro: 1.5007, Energy: 1.0514, KLD: 2.2381, MC: 2.3027)\n",
      "Train Batch 60/110 - Loss: 6.8907 (Macro: 1.3776, Energy: 0.9548, KLD: 2.2570, MC: 2.3012)\n",
      "Train Batch 70/110 - Loss: 6.9324 (Macro: 1.3597, Energy: 0.8311, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.3539 (Macro: 1.4370, Energy: 1.0795, KLD: 2.5365, MC: 2.3010)\n",
      "Train Batch 90/110 - Loss: 6.8632 (Macro: 1.4717, Energy: 1.0648, KLD: 2.0241, MC: 2.3026)\n",
      "Train Batch 100/110 - Loss: 7.3153 (Macro: 1.6136, Energy: 1.1831, KLD: 2.2161, MC: 2.3025)\n",
      "Train Batch 110/110 - Loss: 6.6110 (Macro: 1.2259, Energy: 0.7456, KLD: 2.3414, MC: 2.2981)\n",
      "Training epoch complete. Average Loss: 7.0789\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0681\n",
      "\n",
      "Epoch 157/500\n",
      "Train Batch 10/110 - Loss: 7.0923 (Macro: 1.5841, Energy: 1.0929, KLD: 2.1149, MC: 2.3004)\n",
      "Train Batch 20/110 - Loss: 6.8816 (Macro: 1.4787, Energy: 0.9656, KLD: 2.1345, MC: 2.3029)\n",
      "Train Batch 30/110 - Loss: 7.0619 (Macro: 1.4459, Energy: 1.0066, KLD: 2.3073, MC: 2.3021)\n",
      "Train Batch 40/110 - Loss: 7.5244 (Macro: 1.5593, Energy: 1.2827, KLD: 2.3805, MC: 2.3019)\n",
      "Train Batch 50/110 - Loss: 7.0863 (Macro: 1.5066, Energy: 1.0402, KLD: 2.2381, MC: 2.3015)\n",
      "Train Batch 60/110 - Loss: 6.8554 (Macro: 1.3675, Energy: 0.9296, KLD: 2.2570, MC: 2.3013)\n",
      "Train Batch 70/110 - Loss: 6.9230 (Macro: 1.3614, Energy: 0.8216, KLD: 2.4378, MC: 2.3023)\n",
      "Train Batch 80/110 - Loss: 7.3369 (Macro: 1.4172, Energy: 1.0801, KLD: 2.5365, MC: 2.3031)\n",
      "Train Batch 90/110 - Loss: 6.8139 (Macro: 1.4939, Energy: 0.9955, KLD: 2.0241, MC: 2.3005)\n",
      "Train Batch 100/110 - Loss: 7.3588 (Macro: 1.6004, Energy: 1.2390, KLD: 2.2161, MC: 2.3033)\n",
      "Train Batch 110/110 - Loss: 6.7365 (Macro: 1.2891, Energy: 0.8090, KLD: 2.3414, MC: 2.2970)\n",
      "Training epoch complete. Average Loss: 7.0784\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0681\n",
      "\n",
      "Epoch 158/500\n",
      "Train Batch 10/110 - Loss: 7.1225 (Macro: 1.5757, Energy: 1.1322, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.9032 (Macro: 1.4822, Energy: 0.9841, KLD: 2.1345, MC: 2.3024)\n",
      "Train Batch 30/110 - Loss: 7.0305 (Macro: 1.4635, Energy: 0.9568, KLD: 2.3073, MC: 2.3030)\n",
      "Train Batch 40/110 - Loss: 7.4824 (Macro: 1.5661, Energy: 1.2357, KLD: 2.3805, MC: 2.3001)\n",
      "Train Batch 50/110 - Loss: 6.9934 (Macro: 1.4883, Energy: 0.9646, KLD: 2.2381, MC: 2.3024)\n",
      "Train Batch 60/110 - Loss: 6.9048 (Macro: 1.3982, Energy: 0.9485, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9466 (Macro: 1.3570, Energy: 0.8494, KLD: 2.4378, MC: 2.3025)\n",
      "Train Batch 80/110 - Loss: 7.2489 (Macro: 1.4227, Energy: 0.9871, KLD: 2.5365, MC: 2.3026)\n",
      "Train Batch 90/110 - Loss: 6.8461 (Macro: 1.4729, Energy: 1.0483, KLD: 2.0241, MC: 2.3009)\n",
      "Train Batch 100/110 - Loss: 7.2899 (Macro: 1.5963, Energy: 1.1753, KLD: 2.2161, MC: 2.3022)\n",
      "Train Batch 110/110 - Loss: 6.5551 (Macro: 1.2142, Energy: 0.6984, KLD: 2.3414, MC: 2.3011)\n",
      "Training epoch complete. Average Loss: 7.0759\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0642\n",
      "\n",
      "Epoch 159/500\n",
      "Train Batch 10/110 - Loss: 7.0733 (Macro: 1.5861, Energy: 1.0729, KLD: 2.1149, MC: 2.2994)\n",
      "Train Batch 20/110 - Loss: 6.8994 (Macro: 1.4947, Energy: 0.9684, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.1052 (Macro: 1.4454, Energy: 1.0504, KLD: 2.3073, MC: 2.3022)\n",
      "Train Batch 40/110 - Loss: 7.4839 (Macro: 1.5644, Energy: 1.2380, KLD: 2.3805, MC: 2.3010)\n",
      "Train Batch 50/110 - Loss: 7.0983 (Macro: 1.5034, Energy: 1.0531, KLD: 2.2381, MC: 2.3037)\n",
      "Train Batch 60/110 - Loss: 6.8632 (Macro: 1.3913, Energy: 0.9129, KLD: 2.2570, MC: 2.3019)\n",
      "Train Batch 70/110 - Loss: 7.0054 (Macro: 1.3807, Energy: 0.8844, KLD: 2.4378, MC: 2.3026)\n",
      "Train Batch 80/110 - Loss: 7.2820 (Macro: 1.4314, Energy: 1.0109, KLD: 2.5365, MC: 2.3032)\n",
      "Train Batch 90/110 - Loss: 6.8495 (Macro: 1.4965, Energy: 1.0278, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.2964 (Macro: 1.5980, Energy: 1.1812, KLD: 2.2161, MC: 2.3011)\n",
      "Train Batch 110/110 - Loss: 6.5929 (Macro: 1.2526, Energy: 0.6988, KLD: 2.3414, MC: 2.3001)\n",
      "Training epoch complete. Average Loss: 7.0797\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0541\n",
      "\n",
      "Epoch 160/500\n",
      "Train Batch 10/110 - Loss: 7.1233 (Macro: 1.5810, Energy: 1.1277, KLD: 2.1149, MC: 2.2996)\n",
      "Train Batch 20/110 - Loss: 6.8930 (Macro: 1.4856, Energy: 0.9705, KLD: 2.1345, MC: 2.3024)\n",
      "Train Batch 30/110 - Loss: 7.0604 (Macro: 1.4423, Energy: 1.0078, KLD: 2.3073, MC: 2.3029)\n",
      "Train Batch 40/110 - Loss: 7.4121 (Macro: 1.5648, Energy: 1.1645, KLD: 2.3805, MC: 2.3023)\n",
      "Train Batch 50/110 - Loss: 7.0281 (Macro: 1.4776, Energy: 1.0115, KLD: 2.2381, MC: 2.3009)\n",
      "Train Batch 60/110 - Loss: 6.9042 (Macro: 1.3852, Energy: 0.9614, KLD: 2.2570, MC: 2.3006)\n",
      "Train Batch 70/110 - Loss: 6.9373 (Macro: 1.3668, Energy: 0.8297, KLD: 2.4378, MC: 2.3031)\n",
      "Train Batch 80/110 - Loss: 7.3240 (Macro: 1.4549, Energy: 1.0306, KLD: 2.5365, MC: 2.3020)\n",
      "Train Batch 90/110 - Loss: 6.7800 (Macro: 1.4747, Energy: 0.9794, KLD: 2.0241, MC: 2.3018)\n",
      "Train Batch 100/110 - Loss: 7.3417 (Macro: 1.6157, Energy: 1.2078, KLD: 2.2161, MC: 2.3021)\n",
      "Train Batch 110/110 - Loss: 6.6832 (Macro: 1.2672, Energy: 0.7744, KLD: 2.3414, MC: 2.3003)\n",
      "Training epoch complete. Average Loss: 7.0818\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0595\n",
      "\n",
      "Epoch 161/500\n",
      "Train Batch 10/110 - Loss: 7.1384 (Macro: 1.6056, Energy: 1.1177, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.9212 (Macro: 1.5062, Energy: 0.9788, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.0324 (Macro: 1.4477, Energy: 0.9771, KLD: 2.3073, MC: 2.3002)\n",
      "Train Batch 40/110 - Loss: 7.4310 (Macro: 1.5531, Energy: 1.1952, KLD: 2.3805, MC: 2.3021)\n",
      "Train Batch 50/110 - Loss: 7.0257 (Macro: 1.4945, Energy: 0.9892, KLD: 2.2381, MC: 2.3040)\n",
      "Train Batch 60/110 - Loss: 6.8876 (Macro: 1.3874, Energy: 0.9406, KLD: 2.2570, MC: 2.3025)\n",
      "Train Batch 70/110 - Loss: 6.9927 (Macro: 1.3643, Energy: 0.8878, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.3397 (Macro: 1.4345, Energy: 1.0680, KLD: 2.5365, MC: 2.3007)\n",
      "Train Batch 90/110 - Loss: 6.7755 (Macro: 1.4855, Energy: 0.9649, KLD: 2.0241, MC: 2.3011)\n",
      "Train Batch 100/110 - Loss: 7.3078 (Macro: 1.5996, Energy: 1.1903, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.5667 (Macro: 1.2098, Energy: 0.7175, KLD: 2.3414, MC: 2.2980)\n",
      "Training epoch complete. Average Loss: 7.0854\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0499\n",
      "\n",
      "Epoch 162/500\n",
      "Train Batch 10/110 - Loss: 7.0842 (Macro: 1.5754, Energy: 1.0927, KLD: 2.1149, MC: 2.3011)\n",
      "Train Batch 20/110 - Loss: 6.8485 (Macro: 1.4767, Energy: 0.9347, KLD: 2.1345, MC: 2.3026)\n",
      "Train Batch 30/110 - Loss: 7.0559 (Macro: 1.4349, Energy: 1.0094, KLD: 2.3073, MC: 2.3043)\n",
      "Train Batch 40/110 - Loss: 7.4449 (Macro: 1.5552, Energy: 1.2074, KLD: 2.3805, MC: 2.3017)\n",
      "Train Batch 50/110 - Loss: 7.0907 (Macro: 1.5064, Energy: 1.0424, KLD: 2.2381, MC: 2.3038)\n",
      "Train Batch 60/110 - Loss: 6.9397 (Macro: 1.3830, Energy: 0.9971, KLD: 2.2570, MC: 2.3025)\n",
      "Train Batch 70/110 - Loss: 6.9458 (Macro: 1.3655, Energy: 0.8394, KLD: 2.4378, MC: 2.3031)\n",
      "Train Batch 80/110 - Loss: 7.2721 (Macro: 1.4221, Energy: 1.0117, KLD: 2.5365, MC: 2.3018)\n",
      "Train Batch 90/110 - Loss: 6.7701 (Macro: 1.4683, Energy: 0.9748, KLD: 2.0241, MC: 2.3029)\n",
      "Train Batch 100/110 - Loss: 7.2769 (Macro: 1.5983, Energy: 1.1606, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.6150 (Macro: 1.2081, Energy: 0.7657, KLD: 2.3414, MC: 2.2999)\n",
      "Training epoch complete. Average Loss: 7.0793\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0695\n",
      "\n",
      "Epoch 163/500\n",
      "Train Batch 10/110 - Loss: 7.1035 (Macro: 1.5962, Energy: 1.0913, KLD: 2.1149, MC: 2.3011)\n",
      "Train Batch 20/110 - Loss: 6.9020 (Macro: 1.4823, Energy: 0.9824, KLD: 2.1345, MC: 2.3029)\n",
      "Train Batch 30/110 - Loss: 7.1546 (Macro: 1.4596, Energy: 1.0850, KLD: 2.3073, MC: 2.3027)\n",
      "Train Batch 40/110 - Loss: 7.4612 (Macro: 1.5689, Energy: 1.2111, KLD: 2.3805, MC: 2.3008)\n",
      "Train Batch 50/110 - Loss: 6.9919 (Macro: 1.4780, Energy: 0.9726, KLD: 2.2381, MC: 2.3033)\n",
      "Train Batch 60/110 - Loss: 6.8769 (Macro: 1.3692, Energy: 0.9477, KLD: 2.2570, MC: 2.3030)\n",
      "Train Batch 70/110 - Loss: 6.9749 (Macro: 1.3535, Energy: 0.8803, KLD: 2.4378, MC: 2.3033)\n",
      "Train Batch 80/110 - Loss: 7.3817 (Macro: 1.4195, Energy: 1.1219, KLD: 2.5365, MC: 2.3037)\n",
      "Train Batch 90/110 - Loss: 6.7960 (Macro: 1.4841, Energy: 0.9868, KLD: 2.0241, MC: 2.3010)\n",
      "Train Batch 100/110 - Loss: 7.2847 (Macro: 1.6288, Energy: 1.1391, KLD: 2.2161, MC: 2.3008)\n",
      "Train Batch 110/110 - Loss: 6.6091 (Macro: 1.1961, Energy: 0.7726, KLD: 2.3414, MC: 2.2990)\n",
      "Training epoch complete. Average Loss: 7.0767\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0502\n",
      "\n",
      "Epoch 164/500\n",
      "Train Batch 10/110 - Loss: 7.0871 (Macro: 1.5628, Energy: 1.1096, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.8762 (Macro: 1.4883, Energy: 0.9525, KLD: 2.1345, MC: 2.3009)\n",
      "Train Batch 30/110 - Loss: 7.0755 (Macro: 1.4507, Energy: 1.0157, KLD: 2.3073, MC: 2.3018)\n",
      "Train Batch 40/110 - Loss: 7.4648 (Macro: 1.5509, Energy: 1.2312, KLD: 2.3805, MC: 2.3022)\n",
      "Train Batch 50/110 - Loss: 7.0188 (Macro: 1.5049, Energy: 0.9745, KLD: 2.2381, MC: 2.3013)\n",
      "Train Batch 60/110 - Loss: 6.9068 (Macro: 1.3886, Energy: 0.9601, KLD: 2.2570, MC: 2.3010)\n",
      "Train Batch 70/110 - Loss: 6.9321 (Macro: 1.3716, Energy: 0.8180, KLD: 2.4378, MC: 2.3047)\n",
      "Train Batch 80/110 - Loss: 7.3163 (Macro: 1.4262, Energy: 1.0503, KLD: 2.5365, MC: 2.3034)\n",
      "Train Batch 90/110 - Loss: 6.7960 (Macro: 1.4898, Energy: 0.9802, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.3129 (Macro: 1.6031, Energy: 1.1921, KLD: 2.2161, MC: 2.3017)\n",
      "Train Batch 110/110 - Loss: 6.6494 (Macro: 1.2437, Energy: 0.7665, KLD: 2.3414, MC: 2.2977)\n",
      "Training epoch complete. Average Loss: 7.0785\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0678\n",
      "\n",
      "Epoch 165/500\n",
      "Train Batch 10/110 - Loss: 7.1190 (Macro: 1.5722, Energy: 1.1317, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.9071 (Macro: 1.4787, Energy: 0.9925, KLD: 2.1345, MC: 2.3013)\n",
      "Train Batch 30/110 - Loss: 7.1020 (Macro: 1.4549, Energy: 1.0389, KLD: 2.3073, MC: 2.3009)\n",
      "Train Batch 40/110 - Loss: 7.4626 (Macro: 1.5509, Energy: 1.2290, KLD: 2.3805, MC: 2.3022)\n",
      "Train Batch 50/110 - Loss: 7.0662 (Macro: 1.4931, Energy: 1.0300, KLD: 2.2381, MC: 2.3051)\n",
      "Train Batch 60/110 - Loss: 6.9096 (Macro: 1.3644, Energy: 0.9880, KLD: 2.2570, MC: 2.3002)\n",
      "Train Batch 70/110 - Loss: 6.9229 (Macro: 1.3605, Energy: 0.8202, KLD: 2.4378, MC: 2.3043)\n",
      "Train Batch 80/110 - Loss: 7.3196 (Macro: 1.4316, Energy: 1.0475, KLD: 2.5365, MC: 2.3040)\n",
      "Train Batch 90/110 - Loss: 6.7832 (Macro: 1.4826, Energy: 0.9757, KLD: 2.0241, MC: 2.3008)\n",
      "Train Batch 100/110 - Loss: 7.3209 (Macro: 1.6073, Energy: 1.1938, KLD: 2.2161, MC: 2.3037)\n",
      "Train Batch 110/110 - Loss: 6.7136 (Macro: 1.2378, Energy: 0.8343, KLD: 2.3414, MC: 2.3000)\n",
      "Training epoch complete. Average Loss: 7.0843\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0745\n",
      "\n",
      "Epoch 166/500\n",
      "Train Batch 10/110 - Loss: 7.1196 (Macro: 1.5697, Energy: 1.1363, KLD: 2.1149, MC: 2.2987)\n",
      "Train Batch 20/110 - Loss: 6.9498 (Macro: 1.5216, Energy: 0.9911, KLD: 2.1345, MC: 2.3027)\n",
      "Train Batch 30/110 - Loss: 7.0348 (Macro: 1.4472, Energy: 0.9785, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4727 (Macro: 1.5452, Energy: 1.2442, KLD: 2.3805, MC: 2.3028)\n",
      "Train Batch 50/110 - Loss: 7.0776 (Macro: 1.5049, Energy: 1.0308, KLD: 2.2381, MC: 2.3039)\n",
      "Train Batch 60/110 - Loss: 6.9308 (Macro: 1.3760, Energy: 0.9952, KLD: 2.2570, MC: 2.3025)\n",
      "Train Batch 70/110 - Loss: 6.9996 (Macro: 1.3741, Energy: 0.8841, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.3387 (Macro: 1.4533, Energy: 1.0478, KLD: 2.5365, MC: 2.3011)\n",
      "Train Batch 90/110 - Loss: 6.7797 (Macro: 1.4715, Energy: 0.9820, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.2958 (Macro: 1.5879, Energy: 1.1893, KLD: 2.2161, MC: 2.3024)\n",
      "Train Batch 110/110 - Loss: 6.6166 (Macro: 1.2683, Energy: 0.7072, KLD: 2.3414, MC: 2.2997)\n",
      "Training epoch complete. Average Loss: 7.0785\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0597\n",
      "\n",
      "Epoch 167/500\n",
      "Train Batch 10/110 - Loss: 7.1368 (Macro: 1.5991, Energy: 1.1199, KLD: 2.1149, MC: 2.3028)\n",
      "Train Batch 20/110 - Loss: 6.9087 (Macro: 1.4843, Energy: 0.9879, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.0817 (Macro: 1.4524, Energy: 1.0188, KLD: 2.3073, MC: 2.3031)\n",
      "Train Batch 40/110 - Loss: 7.5040 (Macro: 1.5716, Energy: 1.2512, KLD: 2.3805, MC: 2.3007)\n",
      "Train Batch 50/110 - Loss: 7.0058 (Macro: 1.4788, Energy: 0.9845, KLD: 2.2381, MC: 2.3044)\n",
      "Train Batch 60/110 - Loss: 6.8903 (Macro: 1.3754, Energy: 0.9569, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 6.9806 (Macro: 1.3715, Energy: 0.8687, KLD: 2.4378, MC: 2.3026)\n",
      "Train Batch 80/110 - Loss: 7.2178 (Macro: 1.3923, Energy: 0.9861, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.7902 (Macro: 1.4871, Energy: 0.9767, KLD: 2.0241, MC: 2.3023)\n",
      "Train Batch 100/110 - Loss: 7.3224 (Macro: 1.5987, Energy: 1.2047, KLD: 2.2161, MC: 2.3028)\n",
      "Train Batch 110/110 - Loss: 6.6444 (Macro: 1.2473, Energy: 0.7563, KLD: 2.3414, MC: 2.2995)\n",
      "Training epoch complete. Average Loss: 7.0752\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0686\n",
      "\n",
      "Epoch 168/500\n",
      "Train Batch 10/110 - Loss: 7.1541 (Macro: 1.5859, Energy: 1.1526, KLD: 2.1149, MC: 2.3007)\n",
      "Train Batch 20/110 - Loss: 6.8903 (Macro: 1.4848, Energy: 0.9719, KLD: 2.1345, MC: 2.2991)\n",
      "Train Batch 30/110 - Loss: 7.0721 (Macro: 1.4495, Energy: 1.0125, KLD: 2.3073, MC: 2.3027)\n",
      "Train Batch 40/110 - Loss: 7.5103 (Macro: 1.5561, Energy: 1.2698, KLD: 2.3805, MC: 2.3038)\n",
      "Train Batch 50/110 - Loss: 7.0808 (Macro: 1.4886, Energy: 1.0529, KLD: 2.2381, MC: 2.3013)\n",
      "Train Batch 60/110 - Loss: 6.9465 (Macro: 1.3876, Energy: 0.9999, KLD: 2.2570, MC: 2.3019)\n",
      "Train Batch 70/110 - Loss: 6.9724 (Macro: 1.3715, Energy: 0.8605, KLD: 2.4378, MC: 2.3026)\n",
      "Train Batch 80/110 - Loss: 7.2969 (Macro: 1.4245, Energy: 1.0341, KLD: 2.5365, MC: 2.3018)\n",
      "Train Batch 90/110 - Loss: 6.7874 (Macro: 1.4557, Energy: 1.0058, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.3229 (Macro: 1.5970, Energy: 1.2088, KLD: 2.2161, MC: 2.3010)\n",
      "Train Batch 110/110 - Loss: 6.6815 (Macro: 1.2687, Energy: 0.7736, KLD: 2.3414, MC: 2.2979)\n",
      "Training epoch complete. Average Loss: 7.0823\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0678\n",
      "\n",
      "Epoch 169/500\n",
      "Train Batch 10/110 - Loss: 7.1714 (Macro: 1.5747, Energy: 1.1818, KLD: 2.1149, MC: 2.3000)\n",
      "Train Batch 20/110 - Loss: 6.9040 (Macro: 1.4857, Energy: 0.9812, KLD: 2.1345, MC: 2.3026)\n",
      "Train Batch 30/110 - Loss: 7.0678 (Macro: 1.4373, Energy: 1.0219, KLD: 2.3073, MC: 2.3012)\n",
      "Train Batch 40/110 - Loss: 7.4589 (Macro: 1.5705, Energy: 1.2061, KLD: 2.3805, MC: 2.3018)\n",
      "Train Batch 50/110 - Loss: 7.0460 (Macro: 1.4825, Energy: 1.0239, KLD: 2.2381, MC: 2.3015)\n",
      "Train Batch 60/110 - Loss: 6.9364 (Macro: 1.3903, Energy: 0.9870, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.8943 (Macro: 1.3406, Energy: 0.8132, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.3096 (Macro: 1.4263, Energy: 1.0441, KLD: 2.5365, MC: 2.3026)\n",
      "Train Batch 90/110 - Loss: 6.8167 (Macro: 1.4982, Energy: 0.9916, KLD: 2.0241, MC: 2.3029)\n",
      "Train Batch 100/110 - Loss: 7.2953 (Macro: 1.6034, Energy: 1.1737, KLD: 2.2161, MC: 2.3022)\n",
      "Train Batch 110/110 - Loss: 6.6325 (Macro: 1.2435, Energy: 0.7476, KLD: 2.3414, MC: 2.3000)\n",
      "Training epoch complete. Average Loss: 7.0776\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0631\n",
      "\n",
      "Epoch 170/500\n",
      "Train Batch 10/110 - Loss: 7.1078 (Macro: 1.5797, Energy: 1.1133, KLD: 2.1149, MC: 2.2998)\n",
      "Train Batch 20/110 - Loss: 6.9055 (Macro: 1.4817, Energy: 0.9872, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.0402 (Macro: 1.4505, Energy: 0.9816, KLD: 2.3073, MC: 2.3007)\n",
      "Train Batch 40/110 - Loss: 7.4449 (Macro: 1.5535, Energy: 1.2083, KLD: 2.3805, MC: 2.3026)\n",
      "Train Batch 50/110 - Loss: 7.0410 (Macro: 1.5092, Energy: 0.9907, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.9310 (Macro: 1.3957, Energy: 0.9759, KLD: 2.2570, MC: 2.3023)\n",
      "Train Batch 70/110 - Loss: 6.9592 (Macro: 1.3745, Energy: 0.8439, KLD: 2.4378, MC: 2.3031)\n",
      "Train Batch 80/110 - Loss: 7.3521 (Macro: 1.4323, Energy: 1.0799, KLD: 2.5365, MC: 2.3034)\n",
      "Train Batch 90/110 - Loss: 6.7785 (Macro: 1.4636, Energy: 0.9889, KLD: 2.0241, MC: 2.3019)\n",
      "Train Batch 100/110 - Loss: 7.3377 (Macro: 1.6064, Energy: 1.2135, KLD: 2.2161, MC: 2.3017)\n",
      "Train Batch 110/110 - Loss: 6.6734 (Macro: 1.2533, Energy: 0.7791, KLD: 2.3414, MC: 2.2997)\n",
      "Training epoch complete. Average Loss: 7.0820\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0668\n",
      "\n",
      "Epoch 171/500\n",
      "Train Batch 10/110 - Loss: 7.1787 (Macro: 1.6009, Energy: 1.1612, KLD: 2.1149, MC: 2.3017)\n",
      "Train Batch 20/110 - Loss: 6.8474 (Macro: 1.4732, Energy: 0.9386, KLD: 2.1345, MC: 2.3012)\n",
      "Train Batch 30/110 - Loss: 7.0735 (Macro: 1.4660, Energy: 0.9980, KLD: 2.3073, MC: 2.3023)\n",
      "Train Batch 40/110 - Loss: 7.4566 (Macro: 1.5357, Energy: 1.2395, KLD: 2.3805, MC: 2.3009)\n",
      "Train Batch 50/110 - Loss: 7.0395 (Macro: 1.5031, Energy: 0.9959, KLD: 2.2381, MC: 2.3024)\n",
      "Train Batch 60/110 - Loss: 6.9116 (Macro: 1.3799, Energy: 0.9735, KLD: 2.2570, MC: 2.3012)\n",
      "Train Batch 70/110 - Loss: 6.9824 (Macro: 1.3743, Energy: 0.8678, KLD: 2.4378, MC: 2.3025)\n",
      "Train Batch 80/110 - Loss: 7.3124 (Macro: 1.4187, Energy: 1.0553, KLD: 2.5365, MC: 2.3018)\n",
      "Train Batch 90/110 - Loss: 6.8023 (Macro: 1.4832, Energy: 0.9921, KLD: 2.0241, MC: 2.3030)\n",
      "Train Batch 100/110 - Loss: 7.2973 (Macro: 1.6213, Energy: 1.1581, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.5766 (Macro: 1.2320, Energy: 0.7052, KLD: 2.3414, MC: 2.2981)\n",
      "Training epoch complete. Average Loss: 7.0779\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0797\n",
      "\n",
      "Epoch 172/500\n",
      "Train Batch 10/110 - Loss: 7.1760 (Macro: 1.5722, Energy: 1.1895, KLD: 2.1149, MC: 2.2994)\n",
      "Train Batch 20/110 - Loss: 6.9054 (Macro: 1.4804, Energy: 0.9897, KLD: 2.1345, MC: 2.3008)\n",
      "Train Batch 30/110 - Loss: 7.0926 (Macro: 1.4781, Energy: 1.0062, KLD: 2.3073, MC: 2.3009)\n",
      "Train Batch 40/110 - Loss: 7.4939 (Macro: 1.5682, Energy: 1.2427, KLD: 2.3805, MC: 2.3024)\n",
      "Train Batch 50/110 - Loss: 7.0601 (Macro: 1.5029, Energy: 1.0160, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.8751 (Macro: 1.3809, Energy: 0.9355, KLD: 2.2570, MC: 2.3016)\n",
      "Train Batch 70/110 - Loss: 6.9724 (Macro: 1.3733, Energy: 0.8560, KLD: 2.4378, MC: 2.3053)\n",
      "Train Batch 80/110 - Loss: 7.3163 (Macro: 1.4384, Energy: 1.0382, KLD: 2.5365, MC: 2.3032)\n",
      "Train Batch 90/110 - Loss: 6.8210 (Macro: 1.4788, Energy: 1.0164, KLD: 2.0241, MC: 2.3018)\n",
      "Train Batch 100/110 - Loss: 7.3880 (Macro: 1.6160, Energy: 1.2549, KLD: 2.2161, MC: 2.3010)\n",
      "Train Batch 110/110 - Loss: 6.6370 (Macro: 1.2244, Energy: 0.7714, KLD: 2.3414, MC: 2.2999)\n",
      "Training epoch complete. Average Loss: 7.0819\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0536\n",
      "\n",
      "Epoch 173/500\n",
      "Train Batch 10/110 - Loss: 7.1224 (Macro: 1.5808, Energy: 1.1278, KLD: 2.1149, MC: 2.2989)\n",
      "Train Batch 20/110 - Loss: 6.8866 (Macro: 1.4943, Energy: 0.9560, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.0759 (Macro: 1.4531, Energy: 1.0124, KLD: 2.3073, MC: 2.3031)\n",
      "Train Batch 40/110 - Loss: 7.4899 (Macro: 1.5622, Energy: 1.2438, KLD: 2.3805, MC: 2.3034)\n",
      "Train Batch 50/110 - Loss: 7.0418 (Macro: 1.4849, Energy: 1.0154, KLD: 2.2381, MC: 2.3034)\n",
      "Train Batch 60/110 - Loss: 6.9077 (Macro: 1.4108, Energy: 0.9389, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 6.9175 (Macro: 1.3485, Energy: 0.8287, KLD: 2.4378, MC: 2.3025)\n",
      "Train Batch 80/110 - Loss: 7.2752 (Macro: 1.4343, Energy: 1.0018, KLD: 2.5365, MC: 2.3026)\n",
      "Train Batch 90/110 - Loss: 6.7668 (Macro: 1.4646, Energy: 0.9770, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.3329 (Macro: 1.6138, Energy: 1.2008, KLD: 2.2161, MC: 2.3023)\n",
      "Train Batch 110/110 - Loss: 6.7010 (Macro: 1.2371, Energy: 0.8230, KLD: 2.3414, MC: 2.2994)\n",
      "Training epoch complete. Average Loss: 7.0788\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0509\n",
      "\n",
      "Epoch 174/500\n",
      "Train Batch 10/110 - Loss: 7.1122 (Macro: 1.5765, Energy: 1.1205, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.9153 (Macro: 1.4909, Energy: 0.9874, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.0827 (Macro: 1.4551, Energy: 1.0188, KLD: 2.3073, MC: 2.3015)\n",
      "Train Batch 40/110 - Loss: 7.4993 (Macro: 1.5547, Energy: 1.2605, KLD: 2.3805, MC: 2.3036)\n",
      "Train Batch 50/110 - Loss: 7.0742 (Macro: 1.4994, Energy: 1.0335, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.9195 (Macro: 1.3716, Energy: 0.9893, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9600 (Macro: 1.3600, Energy: 0.8595, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.3296 (Macro: 1.4208, Energy: 1.0685, KLD: 2.5365, MC: 2.3038)\n",
      "Train Batch 90/110 - Loss: 6.8616 (Macro: 1.4943, Energy: 1.0413, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.3104 (Macro: 1.5961, Energy: 1.1974, KLD: 2.2161, MC: 2.3008)\n",
      "Train Batch 110/110 - Loss: 6.6084 (Macro: 1.2503, Energy: 0.7171, KLD: 2.3414, MC: 2.2996)\n",
      "Training epoch complete. Average Loss: 7.0778\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0600\n",
      "\n",
      "Epoch 175/500\n",
      "Train Batch 10/110 - Loss: 7.1703 (Macro: 1.5644, Energy: 1.1917, KLD: 2.1149, MC: 2.2992)\n",
      "Train Batch 20/110 - Loss: 6.8916 (Macro: 1.4786, Energy: 0.9769, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.0507 (Macro: 1.4441, Energy: 0.9968, KLD: 2.3073, MC: 2.3025)\n",
      "Train Batch 40/110 - Loss: 7.4712 (Macro: 1.5476, Energy: 1.2405, KLD: 2.3805, MC: 2.3025)\n",
      "Train Batch 50/110 - Loss: 7.1115 (Macro: 1.5061, Energy: 1.0644, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.8803 (Macro: 1.3669, Energy: 0.9556, KLD: 2.2570, MC: 2.3008)\n",
      "Train Batch 70/110 - Loss: 7.0366 (Macro: 1.3507, Energy: 0.9423, KLD: 2.4378, MC: 2.3058)\n",
      "Train Batch 80/110 - Loss: 7.2899 (Macro: 1.4153, Energy: 1.0330, KLD: 2.5365, MC: 2.3050)\n",
      "Train Batch 90/110 - Loss: 6.7771 (Macro: 1.4732, Energy: 0.9775, KLD: 2.0241, MC: 2.3024)\n",
      "Train Batch 100/110 - Loss: 7.3501 (Macro: 1.5943, Energy: 1.2355, KLD: 2.2161, MC: 2.3042)\n",
      "Train Batch 110/110 - Loss: 6.5922 (Macro: 1.2384, Energy: 0.7152, KLD: 2.3414, MC: 2.2973)\n",
      "Training epoch complete. Average Loss: 7.0807\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0571\n",
      "\n",
      "Epoch 176/500\n",
      "Train Batch 10/110 - Loss: 7.1366 (Macro: 1.5830, Energy: 1.1386, KLD: 2.1149, MC: 2.3000)\n",
      "Train Batch 20/110 - Loss: 6.9103 (Macro: 1.4800, Energy: 0.9961, KLD: 2.1345, MC: 2.2997)\n",
      "Train Batch 30/110 - Loss: 7.0740 (Macro: 1.4560, Energy: 1.0078, KLD: 2.3073, MC: 2.3029)\n",
      "Train Batch 40/110 - Loss: 7.4776 (Macro: 1.5618, Energy: 1.2351, KLD: 2.3805, MC: 2.3002)\n",
      "Train Batch 50/110 - Loss: 7.0599 (Macro: 1.4946, Energy: 1.0241, KLD: 2.2381, MC: 2.3031)\n",
      "Train Batch 60/110 - Loss: 6.9271 (Macro: 1.3746, Energy: 0.9966, KLD: 2.2570, MC: 2.2988)\n",
      "Train Batch 70/110 - Loss: 6.9705 (Macro: 1.3561, Energy: 0.8726, KLD: 2.4378, MC: 2.3040)\n",
      "Train Batch 80/110 - Loss: 7.3264 (Macro: 1.4375, Energy: 1.0515, KLD: 2.5365, MC: 2.3010)\n",
      "Train Batch 90/110 - Loss: 6.8394 (Macro: 1.4846, Energy: 1.0284, KLD: 2.0241, MC: 2.3022)\n",
      "Train Batch 100/110 - Loss: 7.2805 (Macro: 1.5880, Energy: 1.1765, KLD: 2.2161, MC: 2.2999)\n",
      "Train Batch 110/110 - Loss: 6.6649 (Macro: 1.2473, Energy: 0.7788, KLD: 2.3414, MC: 2.2974)\n",
      "Training epoch complete. Average Loss: 7.0829\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0827\n",
      "\n",
      "Epoch 177/500\n",
      "Train Batch 10/110 - Loss: 7.1002 (Macro: 1.5720, Energy: 1.1135, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.9148 (Macro: 1.4979, Energy: 0.9785, KLD: 2.1345, MC: 2.3039)\n",
      "Train Batch 30/110 - Loss: 7.1088 (Macro: 1.4748, Energy: 1.0245, KLD: 2.3073, MC: 2.3022)\n",
      "Train Batch 40/110 - Loss: 7.4642 (Macro: 1.5550, Energy: 1.2275, KLD: 2.3805, MC: 2.3012)\n",
      "Train Batch 50/110 - Loss: 7.0655 (Macro: 1.4975, Energy: 1.0264, KLD: 2.2381, MC: 2.3036)\n",
      "Train Batch 60/110 - Loss: 6.9746 (Macro: 1.3812, Energy: 1.0345, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 6.9233 (Macro: 1.3543, Energy: 0.8285, KLD: 2.4378, MC: 2.3027)\n",
      "Train Batch 80/110 - Loss: 7.3161 (Macro: 1.4224, Energy: 1.0556, KLD: 2.5365, MC: 2.3015)\n",
      "Train Batch 90/110 - Loss: 6.7570 (Macro: 1.4966, Energy: 0.9341, KLD: 2.0241, MC: 2.3023)\n",
      "Train Batch 100/110 - Loss: 7.2976 (Macro: 1.6218, Energy: 1.1591, KLD: 2.2161, MC: 2.3006)\n",
      "Train Batch 110/110 - Loss: 6.5530 (Macro: 1.2246, Energy: 0.6866, KLD: 2.3414, MC: 2.3004)\n",
      "Training epoch complete. Average Loss: 7.0823\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0770\n",
      "\n",
      "Epoch 178/500\n",
      "Train Batch 10/110 - Loss: 7.0992 (Macro: 1.5603, Energy: 1.1267, KLD: 2.1149, MC: 2.2973)\n",
      "Train Batch 20/110 - Loss: 7.0017 (Macro: 1.4923, Energy: 1.0747, KLD: 2.1345, MC: 2.3003)\n",
      "Train Batch 30/110 - Loss: 7.0343 (Macro: 1.4641, Energy: 0.9604, KLD: 2.3073, MC: 2.3025)\n",
      "Train Batch 40/110 - Loss: 7.3949 (Macro: 1.5533, Energy: 1.1593, KLD: 2.3805, MC: 2.3017)\n",
      "Train Batch 50/110 - Loss: 7.0265 (Macro: 1.5073, Energy: 0.9777, KLD: 2.2381, MC: 2.3034)\n",
      "Train Batch 60/110 - Loss: 6.8916 (Macro: 1.3925, Energy: 0.9395, KLD: 2.2570, MC: 2.3025)\n",
      "Train Batch 70/110 - Loss: 6.9708 (Macro: 1.3653, Energy: 0.8640, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.3167 (Macro: 1.4411, Energy: 1.0379, KLD: 2.5365, MC: 2.3012)\n",
      "Train Batch 90/110 - Loss: 6.8023 (Macro: 1.4783, Energy: 0.9971, KLD: 2.0241, MC: 2.3028)\n",
      "Train Batch 100/110 - Loss: 7.2696 (Macro: 1.6062, Energy: 1.1454, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.6090 (Macro: 1.2480, Energy: 0.7221, KLD: 2.3414, MC: 2.2975)\n",
      "Training epoch complete. Average Loss: 7.0824\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0682\n",
      "\n",
      "Epoch 179/500\n",
      "Train Batch 10/110 - Loss: 7.1227 (Macro: 1.5909, Energy: 1.1165, KLD: 2.1149, MC: 2.3004)\n",
      "Train Batch 20/110 - Loss: 6.8823 (Macro: 1.5007, Energy: 0.9441, KLD: 2.1345, MC: 2.3030)\n",
      "Train Batch 30/110 - Loss: 7.0720 (Macro: 1.4521, Energy: 1.0120, KLD: 2.3073, MC: 2.3006)\n",
      "Train Batch 40/110 - Loss: 7.4606 (Macro: 1.5482, Energy: 1.2313, KLD: 2.3805, MC: 2.3006)\n",
      "Train Batch 50/110 - Loss: 6.9980 (Macro: 1.4995, Energy: 0.9567, KLD: 2.2381, MC: 2.3038)\n",
      "Train Batch 60/110 - Loss: 6.9019 (Macro: 1.3982, Energy: 0.9456, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9277 (Macro: 1.3593, Energy: 0.8265, KLD: 2.4378, MC: 2.3042)\n",
      "Train Batch 80/110 - Loss: 7.2863 (Macro: 1.4134, Energy: 1.0339, KLD: 2.5365, MC: 2.3025)\n",
      "Train Batch 90/110 - Loss: 6.7878 (Macro: 1.4581, Energy: 1.0038, KLD: 2.0241, MC: 2.3018)\n",
      "Train Batch 100/110 - Loss: 7.3319 (Macro: 1.6082, Energy: 1.2046, KLD: 2.2161, MC: 2.3030)\n",
      "Train Batch 110/110 - Loss: 6.7000 (Macro: 1.2673, Energy: 0.7925, KLD: 2.3414, MC: 2.2988)\n",
      "Training epoch complete. Average Loss: 7.0777\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0669\n",
      "\n",
      "Epoch 180/500\n",
      "Train Batch 10/110 - Loss: 7.1153 (Macro: 1.5933, Energy: 1.1074, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.9133 (Macro: 1.4906, Energy: 0.9884, KLD: 2.1345, MC: 2.2998)\n",
      "Train Batch 30/110 - Loss: 7.0232 (Macro: 1.4394, Energy: 0.9753, KLD: 2.3073, MC: 2.3013)\n",
      "Train Batch 40/110 - Loss: 7.4516 (Macro: 1.5367, Energy: 1.2345, KLD: 2.3805, MC: 2.2999)\n",
      "Train Batch 50/110 - Loss: 7.0583 (Macro: 1.5049, Energy: 1.0137, KLD: 2.2381, MC: 2.3016)\n",
      "Train Batch 60/110 - Loss: 6.9102 (Macro: 1.3815, Energy: 0.9689, KLD: 2.2570, MC: 2.3028)\n",
      "Train Batch 70/110 - Loss: 6.9244 (Macro: 1.3348, Energy: 0.8492, KLD: 2.4378, MC: 2.3026)\n",
      "Train Batch 80/110 - Loss: 7.3392 (Macro: 1.4428, Energy: 1.0577, KLD: 2.5365, MC: 2.3022)\n",
      "Train Batch 90/110 - Loss: 6.7878 (Macro: 1.4814, Energy: 0.9795, KLD: 2.0241, MC: 2.3027)\n",
      "Train Batch 100/110 - Loss: 7.2300 (Macro: 1.5888, Energy: 1.1215, KLD: 2.2161, MC: 2.3036)\n",
      "Train Batch 110/110 - Loss: 6.6285 (Macro: 1.2273, Energy: 0.7618, KLD: 2.3414, MC: 2.2980)\n",
      "Training epoch complete. Average Loss: 7.0775\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0719\n",
      "\n",
      "Epoch 181/500\n",
      "Train Batch 10/110 - Loss: 7.1163 (Macro: 1.5769, Energy: 1.1243, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.9155 (Macro: 1.4923, Energy: 0.9861, KLD: 2.1345, MC: 2.3026)\n",
      "Train Batch 30/110 - Loss: 7.0976 (Macro: 1.4466, Energy: 1.0424, KLD: 2.3073, MC: 2.3013)\n",
      "Train Batch 40/110 - Loss: 7.3906 (Macro: 1.5568, Energy: 1.1525, KLD: 2.3805, MC: 2.3007)\n",
      "Train Batch 50/110 - Loss: 7.1003 (Macro: 1.5062, Energy: 1.0549, KLD: 2.2381, MC: 2.3011)\n",
      "Train Batch 60/110 - Loss: 6.8722 (Macro: 1.3615, Energy: 0.9525, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9560 (Macro: 1.3631, Energy: 0.8511, KLD: 2.4378, MC: 2.3041)\n",
      "Train Batch 80/110 - Loss: 7.2855 (Macro: 1.4452, Energy: 1.0017, KLD: 2.5365, MC: 2.3021)\n",
      "Train Batch 90/110 - Loss: 6.8202 (Macro: 1.4868, Energy: 1.0072, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.3159 (Macro: 1.6043, Energy: 1.1928, KLD: 2.2161, MC: 2.3027)\n",
      "Train Batch 110/110 - Loss: 6.6458 (Macro: 1.2517, Energy: 0.7516, KLD: 2.3414, MC: 2.3011)\n",
      "Training epoch complete. Average Loss: 7.0823\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0619\n",
      "\n",
      "Epoch 182/500\n",
      "Train Batch 10/110 - Loss: 7.1264 (Macro: 1.5607, Energy: 1.1509, KLD: 2.1149, MC: 2.2998)\n",
      "Train Batch 20/110 - Loss: 6.8911 (Macro: 1.4931, Energy: 0.9609, KLD: 2.1345, MC: 2.3026)\n",
      "Train Batch 30/110 - Loss: 7.0246 (Macro: 1.4411, Energy: 0.9741, KLD: 2.3073, MC: 2.3020)\n",
      "Train Batch 40/110 - Loss: 7.4060 (Macro: 1.5233, Energy: 1.2016, KLD: 2.3805, MC: 2.3006)\n",
      "Train Batch 50/110 - Loss: 7.0580 (Macro: 1.5090, Energy: 1.0070, KLD: 2.2381, MC: 2.3040)\n",
      "Train Batch 60/110 - Loss: 6.8998 (Macro: 1.3973, Energy: 0.9433, KLD: 2.2570, MC: 2.3021)\n",
      "Train Batch 70/110 - Loss: 6.8975 (Macro: 1.3462, Energy: 0.8104, KLD: 2.4378, MC: 2.3030)\n",
      "Train Batch 80/110 - Loss: 7.2783 (Macro: 1.4489, Energy: 0.9905, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.7784 (Macro: 1.4735, Energy: 0.9792, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.2802 (Macro: 1.5969, Energy: 1.1646, KLD: 2.2161, MC: 2.3026)\n",
      "Train Batch 110/110 - Loss: 6.6518 (Macro: 1.2458, Energy: 0.7653, KLD: 2.3414, MC: 2.2993)\n",
      "Training epoch complete. Average Loss: 7.0803\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0780\n",
      "\n",
      "Epoch 183/500\n",
      "Train Batch 10/110 - Loss: 7.0993 (Macro: 1.5914, Energy: 1.0936, KLD: 2.1149, MC: 2.2994)\n",
      "Train Batch 20/110 - Loss: 6.8485 (Macro: 1.4825, Energy: 0.9286, KLD: 2.1345, MC: 2.3029)\n",
      "Train Batch 30/110 - Loss: 7.0451 (Macro: 1.4465, Energy: 0.9902, KLD: 2.3073, MC: 2.3011)\n",
      "Train Batch 40/110 - Loss: 7.4827 (Macro: 1.5531, Energy: 1.2480, KLD: 2.3805, MC: 2.3010)\n",
      "Train Batch 50/110 - Loss: 7.0611 (Macro: 1.4986, Energy: 1.0204, KLD: 2.2381, MC: 2.3040)\n",
      "Train Batch 60/110 - Loss: 6.9379 (Macro: 1.3802, Energy: 0.9981, KLD: 2.2570, MC: 2.3025)\n",
      "Train Batch 70/110 - Loss: 6.9387 (Macro: 1.3549, Energy: 0.8422, KLD: 2.4378, MC: 2.3038)\n",
      "Train Batch 80/110 - Loss: 7.3262 (Macro: 1.4305, Energy: 1.0568, KLD: 2.5365, MC: 2.3024)\n",
      "Train Batch 90/110 - Loss: 6.8111 (Macro: 1.4832, Energy: 1.0018, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3200 (Macro: 1.6025, Energy: 1.1988, KLD: 2.2161, MC: 2.3026)\n",
      "Train Batch 110/110 - Loss: 6.5556 (Macro: 1.2222, Energy: 0.6931, KLD: 2.3414, MC: 2.2989)\n",
      "Training epoch complete. Average Loss: 7.0771\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0700\n",
      "\n",
      "Epoch 184/500\n",
      "Train Batch 10/110 - Loss: 7.1312 (Macro: 1.6023, Energy: 1.1130, KLD: 2.1149, MC: 2.3010)\n",
      "Train Batch 20/110 - Loss: 6.8710 (Macro: 1.4820, Energy: 0.9521, KLD: 2.1345, MC: 2.3024)\n",
      "Train Batch 30/110 - Loss: 7.0377 (Macro: 1.4301, Energy: 0.9988, KLD: 2.3073, MC: 2.3015)\n",
      "Train Batch 40/110 - Loss: 7.4727 (Macro: 1.5577, Energy: 1.2327, KLD: 2.3805, MC: 2.3018)\n",
      "Train Batch 50/110 - Loss: 7.0310 (Macro: 1.4849, Energy: 1.0042, KLD: 2.2381, MC: 2.3038)\n",
      "Train Batch 60/110 - Loss: 6.8889 (Macro: 1.3823, Energy: 0.9488, KLD: 2.2570, MC: 2.3007)\n",
      "Train Batch 70/110 - Loss: 6.9596 (Macro: 1.3599, Energy: 0.8601, KLD: 2.4378, MC: 2.3018)\n",
      "Train Batch 80/110 - Loss: 7.3227 (Macro: 1.4219, Energy: 1.0614, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.7679 (Macro: 1.4735, Energy: 0.9685, KLD: 2.0241, MC: 2.3018)\n",
      "Train Batch 100/110 - Loss: 7.2660 (Macro: 1.5997, Energy: 1.1491, KLD: 2.2161, MC: 2.3011)\n",
      "Train Batch 110/110 - Loss: 6.6147 (Macro: 1.2340, Energy: 0.7387, KLD: 2.3414, MC: 2.3006)\n",
      "Training epoch complete. Average Loss: 7.0757\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0577\n",
      "\n",
      "Epoch 185/500\n",
      "Train Batch 10/110 - Loss: 7.1287 (Macro: 1.5755, Energy: 1.1377, KLD: 2.1149, MC: 2.3004)\n",
      "Train Batch 20/110 - Loss: 6.9151 (Macro: 1.5032, Energy: 0.9757, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0888 (Macro: 1.4579, Energy: 1.0228, KLD: 2.3073, MC: 2.3008)\n",
      "Train Batch 40/110 - Loss: 7.4247 (Macro: 1.5451, Energy: 1.1973, KLD: 2.3805, MC: 2.3018)\n",
      "Train Batch 50/110 - Loss: 7.0256 (Macro: 1.4941, Energy: 0.9909, KLD: 2.2381, MC: 2.3025)\n",
      "Train Batch 60/110 - Loss: 6.9219 (Macro: 1.3867, Energy: 0.9763, KLD: 2.2570, MC: 2.3019)\n",
      "Train Batch 70/110 - Loss: 6.9520 (Macro: 1.3528, Energy: 0.8573, KLD: 2.4378, MC: 2.3041)\n",
      "Train Batch 80/110 - Loss: 7.2975 (Macro: 1.4251, Energy: 1.0338, KLD: 2.5365, MC: 2.3020)\n",
      "Train Batch 90/110 - Loss: 6.7981 (Macro: 1.4890, Energy: 0.9828, KLD: 2.0241, MC: 2.3023)\n",
      "Train Batch 100/110 - Loss: 7.2510 (Macro: 1.5899, Energy: 1.1437, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.5472 (Macro: 1.2253, Energy: 0.6835, KLD: 2.3414, MC: 2.2969)\n",
      "Training epoch complete. Average Loss: 7.0789\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0629\n",
      "\n",
      "Epoch 186/500\n",
      "Train Batch 10/110 - Loss: 7.1571 (Macro: 1.5798, Energy: 1.1620, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.8510 (Macro: 1.4679, Energy: 0.9468, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.0423 (Macro: 1.4417, Energy: 0.9920, KLD: 2.3073, MC: 2.3013)\n",
      "Train Batch 40/110 - Loss: 7.3977 (Macro: 1.5815, Energy: 1.1351, KLD: 2.3805, MC: 2.3006)\n",
      "Train Batch 50/110 - Loss: 7.0860 (Macro: 1.5023, Energy: 1.0418, KLD: 2.2381, MC: 2.3039)\n",
      "Train Batch 60/110 - Loss: 6.9113 (Macro: 1.3786, Energy: 0.9727, KLD: 2.2570, MC: 2.3029)\n",
      "Train Batch 70/110 - Loss: 6.9733 (Macro: 1.3533, Energy: 0.8788, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.3281 (Macro: 1.4195, Energy: 1.0706, KLD: 2.5365, MC: 2.3015)\n",
      "Train Batch 90/110 - Loss: 6.7508 (Macro: 1.4561, Energy: 0.9686, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.2552 (Macro: 1.5872, Energy: 1.1493, KLD: 2.2161, MC: 2.3026)\n",
      "Train Batch 110/110 - Loss: 6.6346 (Macro: 1.2508, Energy: 0.7443, KLD: 2.3414, MC: 2.2982)\n",
      "Training epoch complete. Average Loss: 7.0811\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0569\n",
      "\n",
      "Epoch 187/500\n",
      "Train Batch 10/110 - Loss: 7.1248 (Macro: 1.6076, Energy: 1.1028, KLD: 2.1149, MC: 2.2994)\n",
      "Train Batch 20/110 - Loss: 6.8876 (Macro: 1.4887, Energy: 0.9619, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.1004 (Macro: 1.4415, Energy: 1.0484, KLD: 2.3073, MC: 2.3032)\n",
      "Train Batch 40/110 - Loss: 7.4054 (Macro: 1.5536, Energy: 1.1697, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0353 (Macro: 1.4952, Energy: 1.0009, KLD: 2.2381, MC: 2.3011)\n",
      "Train Batch 60/110 - Loss: 6.9242 (Macro: 1.3822, Energy: 0.9834, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9532 (Macro: 1.3811, Energy: 0.8301, KLD: 2.4378, MC: 2.3042)\n",
      "Train Batch 80/110 - Loss: 7.3059 (Macro: 1.4151, Energy: 1.0517, KLD: 2.5365, MC: 2.3026)\n",
      "Train Batch 90/110 - Loss: 6.7911 (Macro: 1.4714, Energy: 0.9942, KLD: 2.0241, MC: 2.3014)\n",
      "Train Batch 100/110 - Loss: 7.3062 (Macro: 1.5750, Energy: 1.2149, KLD: 2.2161, MC: 2.3002)\n",
      "Train Batch 110/110 - Loss: 6.6069 (Macro: 1.2316, Energy: 0.7337, KLD: 2.3414, MC: 2.3003)\n",
      "Training epoch complete. Average Loss: 7.0797\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0656\n",
      "\n",
      "Epoch 188/500\n",
      "Train Batch 10/110 - Loss: 7.1570 (Macro: 1.5845, Energy: 1.1590, KLD: 2.1149, MC: 2.2986)\n",
      "Train Batch 20/110 - Loss: 6.9140 (Macro: 1.4921, Energy: 0.9867, KLD: 2.1345, MC: 2.3007)\n",
      "Train Batch 30/110 - Loss: 7.0613 (Macro: 1.4536, Energy: 0.9967, KLD: 2.3073, MC: 2.3036)\n",
      "Train Batch 40/110 - Loss: 7.4134 (Macro: 1.5591, Energy: 1.1714, KLD: 2.3805, MC: 2.3024)\n",
      "Train Batch 50/110 - Loss: 7.0302 (Macro: 1.4937, Energy: 0.9975, KLD: 2.2381, MC: 2.3009)\n",
      "Train Batch 60/110 - Loss: 6.8885 (Macro: 1.3665, Energy: 0.9611, KLD: 2.2570, MC: 2.3039)\n",
      "Train Batch 70/110 - Loss: 6.9768 (Macro: 1.3538, Energy: 0.8841, KLD: 2.4378, MC: 2.3011)\n",
      "Train Batch 80/110 - Loss: 7.2905 (Macro: 1.4315, Energy: 1.0200, KLD: 2.5365, MC: 2.3026)\n",
      "Train Batch 90/110 - Loss: 6.7332 (Macro: 1.4517, Energy: 0.9564, KLD: 2.0241, MC: 2.3010)\n",
      "Train Batch 100/110 - Loss: 7.3084 (Macro: 1.6001, Energy: 1.1890, KLD: 2.2161, MC: 2.3032)\n",
      "Train Batch 110/110 - Loss: 6.5634 (Macro: 1.2119, Energy: 0.7123, KLD: 2.3414, MC: 2.2978)\n",
      "Training epoch complete. Average Loss: 7.0743\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0644\n",
      "\n",
      "Epoch 189/500\n",
      "Train Batch 10/110 - Loss: 7.1428 (Macro: 1.5865, Energy: 1.1399, KLD: 2.1149, MC: 2.3014)\n",
      "Train Batch 20/110 - Loss: 6.9321 (Macro: 1.4981, Energy: 0.9984, KLD: 2.1345, MC: 2.3011)\n",
      "Train Batch 30/110 - Loss: 7.0885 (Macro: 1.4365, Energy: 1.0440, KLD: 2.3073, MC: 2.3006)\n",
      "Train Batch 40/110 - Loss: 7.4396 (Macro: 1.5479, Energy: 1.2085, KLD: 2.3805, MC: 2.3027)\n",
      "Train Batch 50/110 - Loss: 7.0529 (Macro: 1.4923, Energy: 1.0201, KLD: 2.2381, MC: 2.3025)\n",
      "Train Batch 60/110 - Loss: 6.9392 (Macro: 1.3988, Energy: 0.9816, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 7.0072 (Macro: 1.3643, Energy: 0.9000, KLD: 2.4378, MC: 2.3051)\n",
      "Train Batch 80/110 - Loss: 7.3456 (Macro: 1.4235, Energy: 1.0835, KLD: 2.5365, MC: 2.3021)\n",
      "Train Batch 90/110 - Loss: 6.7365 (Macro: 1.4828, Energy: 0.9264, KLD: 2.0241, MC: 2.3032)\n",
      "Train Batch 100/110 - Loss: 7.3585 (Macro: 1.6132, Energy: 1.2299, KLD: 2.2161, MC: 2.2993)\n",
      "Train Batch 110/110 - Loss: 6.6661 (Macro: 1.2643, Energy: 0.7617, KLD: 2.3414, MC: 2.2987)\n",
      "Training epoch complete. Average Loss: 7.0795\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0580\n",
      "\n",
      "Epoch 190/500\n",
      "Train Batch 10/110 - Loss: 7.1084 (Macro: 1.5723, Energy: 1.1234, KLD: 2.1149, MC: 2.2977)\n",
      "Train Batch 20/110 - Loss: 6.9349 (Macro: 1.5055, Energy: 0.9927, KLD: 2.1345, MC: 2.3023)\n",
      "Train Batch 30/110 - Loss: 7.0771 (Macro: 1.4390, Energy: 1.0278, KLD: 2.3073, MC: 2.3030)\n",
      "Train Batch 40/110 - Loss: 7.4591 (Macro: 1.5667, Energy: 1.2119, KLD: 2.3805, MC: 2.2999)\n",
      "Train Batch 50/110 - Loss: 7.0364 (Macro: 1.4815, Energy: 1.0139, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.9064 (Macro: 1.3902, Energy: 0.9576, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9557 (Macro: 1.3712, Energy: 0.8437, KLD: 2.4378, MC: 2.3030)\n",
      "Train Batch 80/110 - Loss: 7.3309 (Macro: 1.4525, Energy: 1.0392, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.7667 (Macro: 1.4621, Energy: 0.9786, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.2936 (Macro: 1.6035, Energy: 1.1738, KLD: 2.2161, MC: 2.3002)\n",
      "Train Batch 110/110 - Loss: 6.5934 (Macro: 1.2268, Energy: 0.7248, KLD: 2.3414, MC: 2.3004)\n",
      "Training epoch complete. Average Loss: 7.0764\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0634\n",
      "\n",
      "Epoch 191/500\n",
      "Train Batch 10/110 - Loss: 7.1790 (Macro: 1.5868, Energy: 1.1753, KLD: 2.1149, MC: 2.3020)\n",
      "Train Batch 20/110 - Loss: 6.9417 (Macro: 1.4857, Energy: 1.0198, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.0580 (Macro: 1.4482, Energy: 1.0000, KLD: 2.3073, MC: 2.3026)\n",
      "Train Batch 40/110 - Loss: 7.4784 (Macro: 1.5532, Energy: 1.2440, KLD: 2.3805, MC: 2.3007)\n",
      "Train Batch 50/110 - Loss: 7.0459 (Macro: 1.5144, Energy: 0.9887, KLD: 2.2381, MC: 2.3049)\n",
      "Train Batch 60/110 - Loss: 6.9830 (Macro: 1.3906, Energy: 1.0345, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 6.9159 (Macro: 1.3612, Energy: 0.8119, KLD: 2.4378, MC: 2.3050)\n",
      "Train Batch 80/110 - Loss: 7.3018 (Macro: 1.4292, Energy: 1.0341, KLD: 2.5365, MC: 2.3020)\n",
      "Train Batch 90/110 - Loss: 6.7397 (Macro: 1.4628, Energy: 0.9522, KLD: 2.0241, MC: 2.3006)\n",
      "Train Batch 100/110 - Loss: 7.3104 (Macro: 1.6249, Energy: 1.1676, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.6767 (Macro: 1.2585, Energy: 0.7737, KLD: 2.3414, MC: 2.3031)\n",
      "Training epoch complete. Average Loss: 7.0893\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0576\n",
      "\n",
      "Epoch 192/500\n",
      "Train Batch 10/110 - Loss: 7.1836 (Macro: 1.5985, Energy: 1.1685, KLD: 2.1149, MC: 2.3017)\n",
      "Train Batch 20/110 - Loss: 6.8907 (Macro: 1.4790, Energy: 0.9755, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.1063 (Macro: 1.4393, Energy: 1.0587, KLD: 2.3073, MC: 2.3011)\n",
      "Train Batch 40/110 - Loss: 7.4306 (Macro: 1.5601, Energy: 1.1893, KLD: 2.3805, MC: 2.3007)\n",
      "Train Batch 50/110 - Loss: 7.0752 (Macro: 1.4992, Energy: 1.0354, KLD: 2.2381, MC: 2.3026)\n",
      "Train Batch 60/110 - Loss: 6.9293 (Macro: 1.3935, Energy: 0.9771, KLD: 2.2570, MC: 2.3017)\n",
      "Train Batch 70/110 - Loss: 6.9905 (Macro: 1.3552, Energy: 0.8947, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.2938 (Macro: 1.4338, Energy: 1.0220, KLD: 2.5365, MC: 2.3015)\n",
      "Train Batch 90/110 - Loss: 6.8684 (Macro: 1.4780, Energy: 1.0633, KLD: 2.0241, MC: 2.3031)\n",
      "Train Batch 100/110 - Loss: 7.3176 (Macro: 1.5982, Energy: 1.2012, KLD: 2.2161, MC: 2.3021)\n",
      "Train Batch 110/110 - Loss: 6.6216 (Macro: 1.2101, Energy: 0.7719, KLD: 2.3414, MC: 2.2982)\n",
      "Training epoch complete. Average Loss: 7.0845\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0662\n",
      "\n",
      "Epoch 193/500\n",
      "Train Batch 10/110 - Loss: 7.1508 (Macro: 1.5948, Energy: 1.1417, KLD: 2.1149, MC: 2.2992)\n",
      "Train Batch 20/110 - Loss: 6.8619 (Macro: 1.4911, Energy: 0.9359, KLD: 2.1345, MC: 2.3004)\n",
      "Train Batch 30/110 - Loss: 7.1382 (Macro: 1.4643, Energy: 1.0627, KLD: 2.3073, MC: 2.3040)\n",
      "Train Batch 40/110 - Loss: 7.4943 (Macro: 1.5683, Energy: 1.2451, KLD: 2.3805, MC: 2.3004)\n",
      "Train Batch 50/110 - Loss: 7.0657 (Macro: 1.4952, Energy: 1.0301, KLD: 2.2381, MC: 2.3023)\n",
      "Train Batch 60/110 - Loss: 6.9544 (Macro: 1.3885, Energy: 1.0072, KLD: 2.2570, MC: 2.3016)\n",
      "Train Batch 70/110 - Loss: 6.9671 (Macro: 1.3647, Energy: 0.8614, KLD: 2.4378, MC: 2.3033)\n",
      "Train Batch 80/110 - Loss: 7.2761 (Macro: 1.4117, Energy: 1.0246, KLD: 2.5365, MC: 2.3033)\n",
      "Train Batch 90/110 - Loss: 6.8056 (Macro: 1.4728, Energy: 1.0069, KLD: 2.0241, MC: 2.3019)\n",
      "Train Batch 100/110 - Loss: 7.2423 (Macro: 1.5941, Energy: 1.1294, KLD: 2.2161, MC: 2.3026)\n",
      "Train Batch 110/110 - Loss: 6.6776 (Macro: 1.2526, Energy: 0.7866, KLD: 2.3414, MC: 2.2970)\n",
      "Training epoch complete. Average Loss: 7.0786\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0691\n",
      "\n",
      "Epoch 194/500\n",
      "Train Batch 10/110 - Loss: 7.1905 (Macro: 1.5889, Energy: 1.1857, KLD: 2.1149, MC: 2.3010)\n",
      "Train Batch 20/110 - Loss: 6.9392 (Macro: 1.4903, Energy: 1.0128, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.0264 (Macro: 1.4553, Energy: 0.9606, KLD: 2.3073, MC: 2.3032)\n",
      "Train Batch 40/110 - Loss: 7.4812 (Macro: 1.5442, Energy: 1.2549, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0340 (Macro: 1.4988, Energy: 0.9941, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.9573 (Macro: 1.3967, Energy: 1.0030, KLD: 2.2570, MC: 2.3005)\n",
      "Train Batch 70/110 - Loss: 6.9292 (Macro: 1.3713, Energy: 0.8172, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.2872 (Macro: 1.4368, Energy: 1.0103, KLD: 2.5365, MC: 2.3036)\n",
      "Train Batch 90/110 - Loss: 6.8161 (Macro: 1.4637, Energy: 1.0256, KLD: 2.0241, MC: 2.3027)\n",
      "Train Batch 100/110 - Loss: 7.3232 (Macro: 1.6077, Energy: 1.1991, KLD: 2.2161, MC: 2.3003)\n",
      "Train Batch 110/110 - Loss: 6.6298 (Macro: 1.2524, Energy: 0.7366, KLD: 2.3414, MC: 2.2995)\n",
      "Training epoch complete. Average Loss: 7.0787\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0648\n",
      "\n",
      "Epoch 195/500\n",
      "Train Batch 10/110 - Loss: 7.1745 (Macro: 1.5895, Energy: 1.1697, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.9449 (Macro: 1.4997, Energy: 1.0083, KLD: 2.1345, MC: 2.3024)\n",
      "Train Batch 30/110 - Loss: 7.1100 (Macro: 1.4504, Energy: 1.0488, KLD: 2.3073, MC: 2.3034)\n",
      "Train Batch 40/110 - Loss: 7.4657 (Macro: 1.5588, Energy: 1.2246, KLD: 2.3805, MC: 2.3019)\n",
      "Train Batch 50/110 - Loss: 7.0351 (Macro: 1.4991, Energy: 0.9938, KLD: 2.2381, MC: 2.3041)\n",
      "Train Batch 60/110 - Loss: 6.9437 (Macro: 1.3882, Energy: 0.9965, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 7.0012 (Macro: 1.3845, Energy: 0.8734, KLD: 2.4378, MC: 2.3055)\n",
      "Train Batch 80/110 - Loss: 7.2966 (Macro: 1.4231, Energy: 1.0319, KLD: 2.5365, MC: 2.3051)\n",
      "Train Batch 90/110 - Loss: 6.8061 (Macro: 1.4714, Energy: 1.0080, KLD: 2.0241, MC: 2.3026)\n",
      "Train Batch 100/110 - Loss: 7.2911 (Macro: 1.5994, Energy: 1.1749, KLD: 2.2161, MC: 2.3006)\n",
      "Train Batch 110/110 - Loss: 6.6246 (Macro: 1.2225, Energy: 0.7625, KLD: 2.3414, MC: 2.2983)\n",
      "Training epoch complete. Average Loss: 7.0818\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0537\n",
      "\n",
      "Epoch 196/500\n",
      "Train Batch 10/110 - Loss: 7.0699 (Macro: 1.5472, Energy: 1.1077, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.9175 (Macro: 1.4936, Energy: 0.9890, KLD: 2.1345, MC: 2.3005)\n",
      "Train Batch 30/110 - Loss: 7.0646 (Macro: 1.4650, Energy: 0.9901, KLD: 2.3073, MC: 2.3022)\n",
      "Train Batch 40/110 - Loss: 7.4604 (Macro: 1.5581, Energy: 1.2210, KLD: 2.3805, MC: 2.3007)\n",
      "Train Batch 50/110 - Loss: 7.0459 (Macro: 1.5048, Energy: 0.9988, KLD: 2.2381, MC: 2.3043)\n",
      "Train Batch 60/110 - Loss: 6.8815 (Macro: 1.3908, Energy: 0.9316, KLD: 2.2570, MC: 2.3021)\n",
      "Train Batch 70/110 - Loss: 6.9263 (Macro: 1.3549, Energy: 0.8295, KLD: 2.4378, MC: 2.3041)\n",
      "Train Batch 80/110 - Loss: 7.2890 (Macro: 1.4379, Energy: 1.0108, KLD: 2.5365, MC: 2.3038)\n",
      "Train Batch 90/110 - Loss: 6.7341 (Macro: 1.4752, Energy: 0.9322, KLD: 2.0241, MC: 2.3027)\n",
      "Train Batch 100/110 - Loss: 7.3340 (Macro: 1.6088, Energy: 1.2067, KLD: 2.2161, MC: 2.3024)\n",
      "Train Batch 110/110 - Loss: 6.6803 (Macro: 1.2498, Energy: 0.7898, KLD: 2.3414, MC: 2.2993)\n",
      "Training epoch complete. Average Loss: 7.0747\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0585\n",
      "\n",
      "Epoch 197/500\n",
      "Train Batch 10/110 - Loss: 7.0724 (Macro: 1.5704, Energy: 1.0873, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.9201 (Macro: 1.4736, Energy: 1.0089, KLD: 2.1345, MC: 2.3031)\n",
      "Train Batch 30/110 - Loss: 7.1206 (Macro: 1.4630, Energy: 1.0477, KLD: 2.3073, MC: 2.3026)\n",
      "Train Batch 40/110 - Loss: 7.4320 (Macro: 1.5798, Energy: 1.1695, KLD: 2.3805, MC: 2.3022)\n",
      "Train Batch 50/110 - Loss: 7.0985 (Macro: 1.4920, Energy: 1.0671, KLD: 2.2381, MC: 2.3014)\n",
      "Train Batch 60/110 - Loss: 6.9223 (Macro: 1.3880, Energy: 0.9765, KLD: 2.2570, MC: 2.3008)\n",
      "Train Batch 70/110 - Loss: 6.9408 (Macro: 1.3592, Energy: 0.8394, KLD: 2.4378, MC: 2.3044)\n",
      "Train Batch 80/110 - Loss: 7.3479 (Macro: 1.4335, Energy: 1.0758, KLD: 2.5365, MC: 2.3021)\n",
      "Train Batch 90/110 - Loss: 6.7787 (Macro: 1.4767, Energy: 0.9744, KLD: 2.0241, MC: 2.3035)\n",
      "Train Batch 100/110 - Loss: 7.3324 (Macro: 1.5996, Energy: 1.2147, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.5784 (Macro: 1.1780, Energy: 0.7616, KLD: 2.3414, MC: 2.2974)\n",
      "Training epoch complete. Average Loss: 7.0818\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0687\n",
      "\n",
      "Epoch 198/500\n",
      "Train Batch 10/110 - Loss: 7.1634 (Macro: 1.5927, Energy: 1.1551, KLD: 2.1149, MC: 2.3006)\n",
      "Train Batch 20/110 - Loss: 6.9006 (Macro: 1.4672, Energy: 0.9960, KLD: 2.1345, MC: 2.3029)\n",
      "Train Batch 30/110 - Loss: 7.0808 (Macro: 1.4545, Energy: 1.0168, KLD: 2.3073, MC: 2.3022)\n",
      "Train Batch 40/110 - Loss: 7.4351 (Macro: 1.5425, Energy: 1.2109, KLD: 2.3805, MC: 2.3012)\n",
      "Train Batch 50/110 - Loss: 7.1275 (Macro: 1.4877, Energy: 1.0981, KLD: 2.2381, MC: 2.3036)\n",
      "Train Batch 60/110 - Loss: 6.9033 (Macro: 1.3766, Energy: 0.9687, KLD: 2.2570, MC: 2.3010)\n",
      "Train Batch 70/110 - Loss: 6.9662 (Macro: 1.3733, Energy: 0.8515, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.3049 (Macro: 1.4196, Energy: 1.0463, KLD: 2.5365, MC: 2.3025)\n",
      "Train Batch 90/110 - Loss: 6.7774 (Macro: 1.4800, Energy: 0.9722, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.3390 (Macro: 1.6043, Energy: 1.2162, KLD: 2.2161, MC: 2.3024)\n",
      "Train Batch 110/110 - Loss: 6.6417 (Macro: 1.2202, Energy: 0.7784, KLD: 2.3414, MC: 2.3017)\n",
      "Training epoch complete. Average Loss: 7.0769\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0710\n",
      "\n",
      "Epoch 199/500\n",
      "Train Batch 10/110 - Loss: 7.1633 (Macro: 1.5827, Energy: 1.1636, KLD: 2.1149, MC: 2.3020)\n",
      "Train Batch 20/110 - Loss: 6.8435 (Macro: 1.4814, Energy: 0.9261, KLD: 2.1345, MC: 2.3015)\n",
      "Train Batch 30/110 - Loss: 7.0320 (Macro: 1.4408, Energy: 0.9833, KLD: 2.3073, MC: 2.3006)\n",
      "Train Batch 40/110 - Loss: 7.4363 (Macro: 1.5524, Energy: 1.2028, KLD: 2.3805, MC: 2.3005)\n",
      "Train Batch 50/110 - Loss: 7.0558 (Macro: 1.4838, Energy: 1.0301, KLD: 2.2381, MC: 2.3039)\n",
      "Train Batch 60/110 - Loss: 6.8852 (Macro: 1.3816, Energy: 0.9450, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9220 (Macro: 1.3478, Energy: 0.8331, KLD: 2.4378, MC: 2.3033)\n",
      "Train Batch 80/110 - Loss: 7.3111 (Macro: 1.4357, Energy: 1.0358, KLD: 2.5365, MC: 2.3031)\n",
      "Train Batch 90/110 - Loss: 6.7329 (Macro: 1.4823, Energy: 0.9235, KLD: 2.0241, MC: 2.3030)\n",
      "Train Batch 100/110 - Loss: 7.3023 (Macro: 1.6197, Energy: 1.1643, KLD: 2.2161, MC: 2.3022)\n",
      "Train Batch 110/110 - Loss: 6.6514 (Macro: 1.2630, Energy: 0.7487, KLD: 2.3414, MC: 2.2983)\n",
      "Training epoch complete. Average Loss: 7.0755\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0695\n",
      "\n",
      "Epoch 200/500\n",
      "Train Batch 10/110 - Loss: 7.1072 (Macro: 1.5834, Energy: 1.1096, KLD: 2.1149, MC: 2.2993)\n",
      "Train Batch 20/110 - Loss: 6.9266 (Macro: 1.4780, Energy: 1.0129, KLD: 2.1345, MC: 2.3013)\n",
      "Train Batch 30/110 - Loss: 7.0459 (Macro: 1.4358, Energy: 1.0014, KLD: 2.3073, MC: 2.3014)\n",
      "Train Batch 40/110 - Loss: 7.4357 (Macro: 1.5581, Energy: 1.1956, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.0808 (Macro: 1.4985, Energy: 1.0404, KLD: 2.2381, MC: 2.3039)\n",
      "Train Batch 60/110 - Loss: 6.9035 (Macro: 1.3841, Energy: 0.9607, KLD: 2.2570, MC: 2.3017)\n",
      "Train Batch 70/110 - Loss: 7.0133 (Macro: 1.3614, Energy: 0.9114, KLD: 2.4378, MC: 2.3027)\n",
      "Train Batch 80/110 - Loss: 7.3027 (Macro: 1.4369, Energy: 1.0274, KLD: 2.5365, MC: 2.3019)\n",
      "Train Batch 90/110 - Loss: 6.8258 (Macro: 1.4679, Energy: 1.0313, KLD: 2.0241, MC: 2.3026)\n",
      "Train Batch 100/110 - Loss: 7.3251 (Macro: 1.5926, Energy: 1.2133, KLD: 2.2161, MC: 2.3031)\n",
      "Train Batch 110/110 - Loss: 6.5480 (Macro: 1.2409, Energy: 0.6647, KLD: 2.3414, MC: 2.3009)\n",
      "Training epoch complete. Average Loss: 7.0831\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0678\n",
      "\n",
      "Epoch 201/500\n",
      "Train Batch 10/110 - Loss: 7.1305 (Macro: 1.5742, Energy: 1.1403, KLD: 2.1149, MC: 2.3011)\n",
      "Train Batch 20/110 - Loss: 6.8697 (Macro: 1.4782, Energy: 0.9568, KLD: 2.1345, MC: 2.3003)\n",
      "Train Batch 30/110 - Loss: 7.0900 (Macro: 1.4527, Energy: 1.0285, KLD: 2.3073, MC: 2.3015)\n",
      "Train Batch 40/110 - Loss: 7.5172 (Macro: 1.5536, Energy: 1.2806, KLD: 2.3805, MC: 2.3025)\n",
      "Train Batch 50/110 - Loss: 7.0665 (Macro: 1.4901, Energy: 1.0355, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.9138 (Macro: 1.3861, Energy: 0.9683, KLD: 2.2570, MC: 2.3024)\n",
      "Train Batch 70/110 - Loss: 6.9767 (Macro: 1.3887, Energy: 0.8443, KLD: 2.4378, MC: 2.3059)\n",
      "Train Batch 80/110 - Loss: 7.2873 (Macro: 1.4281, Energy: 1.0207, KLD: 2.5365, MC: 2.3021)\n",
      "Train Batch 90/110 - Loss: 6.7580 (Macro: 1.4668, Energy: 0.9669, KLD: 2.0241, MC: 2.3003)\n",
      "Train Batch 100/110 - Loss: 7.3306 (Macro: 1.6129, Energy: 1.2008, KLD: 2.2161, MC: 2.3008)\n",
      "Train Batch 110/110 - Loss: 6.6859 (Macro: 1.2408, Energy: 0.8060, KLD: 2.3414, MC: 2.2978)\n",
      "Training epoch complete. Average Loss: 7.0793\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0581\n",
      "\n",
      "Epoch 202/500\n",
      "Train Batch 10/110 - Loss: 7.1432 (Macro: 1.5897, Energy: 1.1384, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.8844 (Macro: 1.5063, Energy: 0.9429, KLD: 2.1345, MC: 2.3007)\n",
      "Train Batch 30/110 - Loss: 7.1227 (Macro: 1.4693, Energy: 1.0445, KLD: 2.3073, MC: 2.3015)\n",
      "Train Batch 40/110 - Loss: 7.4793 (Macro: 1.5458, Energy: 1.2528, KLD: 2.3805, MC: 2.3001)\n",
      "Train Batch 50/110 - Loss: 7.0474 (Macro: 1.4934, Energy: 1.0146, KLD: 2.2381, MC: 2.3013)\n",
      "Train Batch 60/110 - Loss: 6.9345 (Macro: 1.4044, Energy: 0.9723, KLD: 2.2570, MC: 2.3008)\n",
      "Train Batch 70/110 - Loss: 6.9796 (Macro: 1.3891, Energy: 0.8499, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.3125 (Macro: 1.4236, Energy: 1.0503, KLD: 2.5365, MC: 2.3022)\n",
      "Train Batch 90/110 - Loss: 6.7979 (Macro: 1.4701, Energy: 1.0030, KLD: 2.0241, MC: 2.3007)\n",
      "Train Batch 100/110 - Loss: 7.2430 (Macro: 1.5916, Energy: 1.1333, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.5382 (Macro: 1.2152, Energy: 0.6826, KLD: 2.3414, MC: 2.2990)\n",
      "Training epoch complete. Average Loss: 7.0835\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0587\n",
      "\n",
      "Epoch 203/500\n",
      "Train Batch 10/110 - Loss: 7.0759 (Macro: 1.5724, Energy: 1.0860, KLD: 2.1149, MC: 2.3026)\n",
      "Train Batch 20/110 - Loss: 6.8653 (Macro: 1.4791, Energy: 0.9511, KLD: 2.1345, MC: 2.3007)\n",
      "Train Batch 30/110 - Loss: 7.0822 (Macro: 1.4527, Energy: 1.0202, KLD: 2.3073, MC: 2.3020)\n",
      "Train Batch 40/110 - Loss: 7.4688 (Macro: 1.5572, Energy: 1.2311, KLD: 2.3805, MC: 2.3000)\n",
      "Train Batch 50/110 - Loss: 7.0529 (Macro: 1.4932, Energy: 1.0174, KLD: 2.2381, MC: 2.3043)\n",
      "Train Batch 60/110 - Loss: 6.9152 (Macro: 1.3655, Energy: 0.9919, KLD: 2.2570, MC: 2.3008)\n",
      "Train Batch 70/110 - Loss: 6.9107 (Macro: 1.3575, Energy: 0.8113, KLD: 2.4378, MC: 2.3042)\n",
      "Train Batch 80/110 - Loss: 7.3006 (Macro: 1.4085, Energy: 1.0553, KLD: 2.5365, MC: 2.3003)\n",
      "Train Batch 90/110 - Loss: 6.8517 (Macro: 1.4933, Energy: 1.0309, KLD: 2.0241, MC: 2.3035)\n",
      "Train Batch 100/110 - Loss: 7.3457 (Macro: 1.5978, Energy: 1.2312, KLD: 2.2161, MC: 2.3006)\n",
      "Train Batch 110/110 - Loss: 6.5408 (Macro: 1.2022, Energy: 0.6951, KLD: 2.3414, MC: 2.3020)\n",
      "Training epoch complete. Average Loss: 7.0744\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0630\n",
      "\n",
      "Epoch 204/500\n",
      "Train Batch 10/110 - Loss: 7.0873 (Macro: 1.5669, Energy: 1.1046, KLD: 2.1149, MC: 2.3009)\n",
      "Train Batch 20/110 - Loss: 6.8897 (Macro: 1.4697, Energy: 0.9837, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0577 (Macro: 1.4559, Energy: 0.9935, KLD: 2.3073, MC: 2.3010)\n",
      "Train Batch 40/110 - Loss: 7.4820 (Macro: 1.5665, Energy: 1.2315, KLD: 2.3805, MC: 2.3035)\n",
      "Train Batch 50/110 - Loss: 7.0918 (Macro: 1.5331, Energy: 1.0186, KLD: 2.2381, MC: 2.3020)\n",
      "Train Batch 60/110 - Loss: 6.9291 (Macro: 1.3923, Energy: 0.9799, KLD: 2.2570, MC: 2.2999)\n",
      "Train Batch 70/110 - Loss: 6.9204 (Macro: 1.3525, Energy: 0.8271, KLD: 2.4378, MC: 2.3030)\n",
      "Train Batch 80/110 - Loss: 7.3126 (Macro: 1.4417, Energy: 1.0312, KLD: 2.5365, MC: 2.3031)\n",
      "Train Batch 90/110 - Loss: 6.7865 (Macro: 1.4807, Energy: 0.9792, KLD: 2.0241, MC: 2.3026)\n",
      "Train Batch 100/110 - Loss: 7.3005 (Macro: 1.5915, Energy: 1.1909, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.6357 (Macro: 1.2157, Energy: 0.7824, KLD: 2.3414, MC: 2.2962)\n",
      "Training epoch complete. Average Loss: 7.0792\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0586\n",
      "\n",
      "Epoch 205/500\n",
      "Train Batch 10/110 - Loss: 7.0742 (Macro: 1.5634, Energy: 1.0958, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.8768 (Macro: 1.4786, Energy: 0.9627, KLD: 2.1345, MC: 2.3011)\n",
      "Train Batch 30/110 - Loss: 7.0862 (Macro: 1.4525, Energy: 1.0247, KLD: 2.3073, MC: 2.3018)\n",
      "Train Batch 40/110 - Loss: 7.4836 (Macro: 1.5538, Energy: 1.2486, KLD: 2.3805, MC: 2.3007)\n",
      "Train Batch 50/110 - Loss: 7.0564 (Macro: 1.5011, Energy: 1.0150, KLD: 2.2381, MC: 2.3023)\n",
      "Train Batch 60/110 - Loss: 6.9076 (Macro: 1.3821, Energy: 0.9660, KLD: 2.2570, MC: 2.3024)\n",
      "Train Batch 70/110 - Loss: 6.9903 (Macro: 1.3725, Energy: 0.8777, KLD: 2.4378, MC: 2.3024)\n",
      "Train Batch 80/110 - Loss: 7.2779 (Macro: 1.4127, Energy: 1.0251, KLD: 2.5365, MC: 2.3036)\n",
      "Train Batch 90/110 - Loss: 6.7549 (Macro: 1.4686, Energy: 0.9601, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3291 (Macro: 1.6104, Energy: 1.2011, KLD: 2.2161, MC: 2.3016)\n",
      "Train Batch 110/110 - Loss: 6.6040 (Macro: 1.2333, Energy: 0.7315, KLD: 2.3414, MC: 2.2980)\n",
      "Training epoch complete. Average Loss: 7.0798\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0580\n",
      "\n",
      "Epoch 206/500\n",
      "Train Batch 10/110 - Loss: 7.0900 (Macro: 1.5761, Energy: 1.1002, KLD: 2.1149, MC: 2.2987)\n",
      "Train Batch 20/110 - Loss: 6.8965 (Macro: 1.4760, Energy: 0.9839, KLD: 2.1345, MC: 2.3022)\n",
      "Train Batch 30/110 - Loss: 7.0411 (Macro: 1.4387, Energy: 0.9935, KLD: 2.3073, MC: 2.3016)\n",
      "Train Batch 40/110 - Loss: 7.4204 (Macro: 1.5512, Energy: 1.1879, KLD: 2.3805, MC: 2.3009)\n",
      "Train Batch 50/110 - Loss: 7.0634 (Macro: 1.4942, Energy: 1.0286, KLD: 2.2381, MC: 2.3026)\n",
      "Train Batch 60/110 - Loss: 6.9079 (Macro: 1.3930, Energy: 0.9547, KLD: 2.2570, MC: 2.3031)\n",
      "Train Batch 70/110 - Loss: 6.9763 (Macro: 1.3622, Energy: 0.8761, KLD: 2.4378, MC: 2.3003)\n",
      "Train Batch 80/110 - Loss: 7.3599 (Macro: 1.4369, Energy: 1.0838, KLD: 2.5365, MC: 2.3026)\n",
      "Train Batch 90/110 - Loss: 6.7637 (Macro: 1.4569, Energy: 0.9803, KLD: 2.0241, MC: 2.3025)\n",
      "Train Batch 100/110 - Loss: 7.3457 (Macro: 1.6100, Energy: 1.2161, KLD: 2.2161, MC: 2.3035)\n",
      "Train Batch 110/110 - Loss: 6.5886 (Macro: 1.2440, Energy: 0.7057, KLD: 2.3414, MC: 2.2976)\n",
      "Training epoch complete. Average Loss: 7.0788\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0598\n",
      "\n",
      "Epoch 207/500\n",
      "Train Batch 10/110 - Loss: 7.1346 (Macro: 1.5847, Energy: 1.1357, KLD: 2.1149, MC: 2.2992)\n",
      "Train Batch 20/110 - Loss: 6.9044 (Macro: 1.4795, Energy: 0.9884, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.0674 (Macro: 1.4366, Energy: 1.0240, KLD: 2.3073, MC: 2.2996)\n",
      "Train Batch 40/110 - Loss: 7.4769 (Macro: 1.5651, Energy: 1.2307, KLD: 2.3805, MC: 2.3006)\n",
      "Train Batch 50/110 - Loss: 7.0915 (Macro: 1.5103, Energy: 1.0409, KLD: 2.2381, MC: 2.3023)\n",
      "Train Batch 60/110 - Loss: 6.9600 (Macro: 1.3836, Energy: 1.0191, KLD: 2.2570, MC: 2.3002)\n",
      "Train Batch 70/110 - Loss: 6.8994 (Macro: 1.3500, Energy: 0.8083, KLD: 2.4378, MC: 2.3033)\n",
      "Train Batch 80/110 - Loss: 7.2760 (Macro: 1.4287, Energy: 1.0060, KLD: 2.5365, MC: 2.3047)\n",
      "Train Batch 90/110 - Loss: 6.8550 (Macro: 1.4744, Energy: 1.0535, KLD: 2.0241, MC: 2.3030)\n",
      "Train Batch 100/110 - Loss: 7.3108 (Macro: 1.5933, Energy: 1.1994, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.6387 (Macro: 1.2054, Energy: 0.7950, KLD: 2.3414, MC: 2.2969)\n",
      "Training epoch complete. Average Loss: 7.0807\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0656\n",
      "\n",
      "Epoch 208/500\n",
      "Train Batch 10/110 - Loss: 7.1411 (Macro: 1.5713, Energy: 1.1538, KLD: 2.1149, MC: 2.3011)\n",
      "Train Batch 20/110 - Loss: 6.9108 (Macro: 1.5043, Energy: 0.9696, KLD: 2.1345, MC: 2.3024)\n",
      "Train Batch 30/110 - Loss: 7.0903 (Macro: 1.4422, Energy: 1.0391, KLD: 2.3073, MC: 2.3018)\n",
      "Train Batch 40/110 - Loss: 7.4465 (Macro: 1.5618, Energy: 1.2027, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0443 (Macro: 1.5111, Energy: 0.9926, KLD: 2.2381, MC: 2.3025)\n",
      "Train Batch 60/110 - Loss: 6.9116 (Macro: 1.4062, Energy: 0.9484, KLD: 2.2570, MC: 2.3000)\n",
      "Train Batch 70/110 - Loss: 6.9507 (Macro: 1.3760, Energy: 0.8333, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.2936 (Macro: 1.4327, Energy: 1.0216, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.8377 (Macro: 1.4845, Energy: 1.0293, KLD: 2.0241, MC: 2.2998)\n",
      "Train Batch 100/110 - Loss: 7.3624 (Macro: 1.6309, Energy: 1.2124, KLD: 2.2161, MC: 2.3030)\n",
      "Train Batch 110/110 - Loss: 6.6001 (Macro: 1.2151, Energy: 0.7462, KLD: 2.3414, MC: 2.2975)\n",
      "Training epoch complete. Average Loss: 7.0806\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0617\n",
      "\n",
      "Epoch 209/500\n",
      "Train Batch 10/110 - Loss: 7.1310 (Macro: 1.5943, Energy: 1.1214, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.8699 (Macro: 1.4784, Energy: 0.9537, KLD: 2.1345, MC: 2.3033)\n",
      "Train Batch 30/110 - Loss: 7.0980 (Macro: 1.4516, Energy: 1.0358, KLD: 2.3073, MC: 2.3034)\n",
      "Train Batch 40/110 - Loss: 7.4113 (Macro: 1.5447, Energy: 1.1838, KLD: 2.3805, MC: 2.3023)\n",
      "Train Batch 50/110 - Loss: 7.0938 (Macro: 1.4840, Energy: 1.0690, KLD: 2.2381, MC: 2.3027)\n",
      "Train Batch 60/110 - Loss: 6.9272 (Macro: 1.3865, Energy: 0.9833, KLD: 2.2570, MC: 2.3004)\n",
      "Train Batch 70/110 - Loss: 6.9837 (Macro: 1.3633, Energy: 0.8785, KLD: 2.4378, MC: 2.3041)\n",
      "Train Batch 80/110 - Loss: 7.2810 (Macro: 1.4070, Energy: 1.0356, KLD: 2.5365, MC: 2.3019)\n",
      "Train Batch 90/110 - Loss: 6.7723 (Macro: 1.4650, Energy: 0.9800, KLD: 2.0241, MC: 2.3032)\n",
      "Train Batch 100/110 - Loss: 7.2929 (Macro: 1.5969, Energy: 1.1795, KLD: 2.2161, MC: 2.3005)\n",
      "Train Batch 110/110 - Loss: 6.6654 (Macro: 1.2471, Energy: 0.7775, KLD: 2.3414, MC: 2.2995)\n",
      "Training epoch complete. Average Loss: 7.0805\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0684\n",
      "\n",
      "Epoch 210/500\n",
      "Train Batch 10/110 - Loss: 7.1270 (Macro: 1.5768, Energy: 1.1355, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.9198 (Macro: 1.4964, Energy: 0.9881, KLD: 2.1345, MC: 2.3008)\n",
      "Train Batch 30/110 - Loss: 7.0133 (Macro: 1.4230, Energy: 0.9800, KLD: 2.3073, MC: 2.3030)\n",
      "Train Batch 40/110 - Loss: 7.4425 (Macro: 1.5482, Energy: 1.2114, KLD: 2.3805, MC: 2.3023)\n",
      "Train Batch 50/110 - Loss: 7.0494 (Macro: 1.5090, Energy: 0.9979, KLD: 2.2381, MC: 2.3044)\n",
      "Train Batch 60/110 - Loss: 6.8839 (Macro: 1.3932, Energy: 0.9326, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 6.9494 (Macro: 1.3625, Energy: 0.8443, KLD: 2.4378, MC: 2.3049)\n",
      "Train Batch 80/110 - Loss: 7.3068 (Macro: 1.4135, Energy: 1.0524, KLD: 2.5365, MC: 2.3044)\n",
      "Train Batch 90/110 - Loss: 6.7614 (Macro: 1.4601, Energy: 0.9754, KLD: 2.0241, MC: 2.3018)\n",
      "Train Batch 100/110 - Loss: 7.3277 (Macro: 1.6017, Energy: 1.2086, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.5306 (Macro: 1.2083, Energy: 0.6845, KLD: 2.3414, MC: 2.2965)\n",
      "Training epoch complete. Average Loss: 7.0744\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0779\n",
      "\n",
      "Epoch 211/500\n",
      "Train Batch 10/110 - Loss: 7.1772 (Macro: 1.5860, Energy: 1.1767, KLD: 2.1149, MC: 2.2995)\n",
      "Train Batch 20/110 - Loss: 6.8497 (Macro: 1.4646, Energy: 0.9506, KLD: 2.1345, MC: 2.3000)\n",
      "Train Batch 30/110 - Loss: 7.0618 (Macro: 1.4524, Energy: 0.9999, KLD: 2.3073, MC: 2.3022)\n",
      "Train Batch 40/110 - Loss: 7.4771 (Macro: 1.5398, Energy: 1.2544, KLD: 2.3805, MC: 2.3024)\n",
      "Train Batch 50/110 - Loss: 7.1062 (Macro: 1.5061, Energy: 1.0576, KLD: 2.2381, MC: 2.3044)\n",
      "Train Batch 60/110 - Loss: 6.9068 (Macro: 1.3876, Energy: 0.9602, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.9256 (Macro: 1.3549, Energy: 0.8296, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.2873 (Macro: 1.4372, Energy: 1.0125, KLD: 2.5365, MC: 2.3011)\n",
      "Train Batch 90/110 - Loss: 6.7838 (Macro: 1.4874, Energy: 0.9707, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.3291 (Macro: 1.6032, Energy: 1.2083, KLD: 2.2161, MC: 2.3015)\n",
      "Train Batch 110/110 - Loss: 6.6574 (Macro: 1.2642, Energy: 0.7515, KLD: 2.3414, MC: 2.3003)\n",
      "Training epoch complete. Average Loss: 7.0797\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0662\n",
      "\n",
      "Epoch 212/500\n",
      "Train Batch 10/110 - Loss: 7.1512 (Macro: 1.5888, Energy: 1.1475, KLD: 2.1149, MC: 2.3000)\n",
      "Train Batch 20/110 - Loss: 6.9146 (Macro: 1.4846, Energy: 0.9938, KLD: 2.1345, MC: 2.3016)\n",
      "Train Batch 30/110 - Loss: 7.0965 (Macro: 1.4274, Energy: 1.0613, KLD: 2.3073, MC: 2.3006)\n",
      "Train Batch 40/110 - Loss: 7.4500 (Macro: 1.5581, Energy: 1.2101, KLD: 2.3805, MC: 2.3013)\n",
      "Train Batch 50/110 - Loss: 7.0399 (Macro: 1.4981, Energy: 0.9991, KLD: 2.2381, MC: 2.3047)\n",
      "Train Batch 60/110 - Loss: 6.8995 (Macro: 1.3742, Energy: 0.9666, KLD: 2.2570, MC: 2.3017)\n",
      "Train Batch 70/110 - Loss: 6.9406 (Macro: 1.3512, Energy: 0.8470, KLD: 2.4378, MC: 2.3046)\n",
      "Train Batch 80/110 - Loss: 7.3373 (Macro: 1.4437, Energy: 1.0544, KLD: 2.5365, MC: 2.3027)\n",
      "Train Batch 90/110 - Loss: 6.8030 (Macro: 1.4676, Energy: 1.0094, KLD: 2.0241, MC: 2.3019)\n",
      "Train Batch 100/110 - Loss: 7.3271 (Macro: 1.6334, Energy: 1.1755, KLD: 2.2161, MC: 2.3021)\n",
      "Train Batch 110/110 - Loss: 6.6461 (Macro: 1.2320, Energy: 0.7748, KLD: 2.3414, MC: 2.2979)\n",
      "Training epoch complete. Average Loss: 7.0813\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0745\n",
      "\n",
      "Epoch 213/500\n",
      "Train Batch 10/110 - Loss: 7.1433 (Macro: 1.5537, Energy: 1.1735, KLD: 2.1149, MC: 2.3012)\n",
      "Train Batch 20/110 - Loss: 6.8849 (Macro: 1.4748, Energy: 0.9722, KLD: 2.1345, MC: 2.3034)\n",
      "Train Batch 30/110 - Loss: 7.0913 (Macro: 1.4674, Energy: 1.0138, KLD: 2.3073, MC: 2.3028)\n",
      "Train Batch 40/110 - Loss: 7.4209 (Macro: 1.5668, Energy: 1.1718, KLD: 2.3805, MC: 2.3018)\n",
      "Train Batch 50/110 - Loss: 7.0852 (Macro: 1.5006, Energy: 1.0445, KLD: 2.2381, MC: 2.3021)\n",
      "Train Batch 60/110 - Loss: 6.8813 (Macro: 1.3889, Energy: 0.9347, KLD: 2.2570, MC: 2.3007)\n",
      "Train Batch 70/110 - Loss: 6.9342 (Macro: 1.3689, Energy: 0.8241, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.3045 (Macro: 1.4186, Energy: 1.0467, KLD: 2.5365, MC: 2.3027)\n",
      "Train Batch 90/110 - Loss: 6.7920 (Macro: 1.4765, Energy: 0.9904, KLD: 2.0241, MC: 2.3010)\n",
      "Train Batch 100/110 - Loss: 7.2867 (Macro: 1.6035, Energy: 1.1645, KLD: 2.2161, MC: 2.3026)\n",
      "Train Batch 110/110 - Loss: 6.5861 (Macro: 1.2246, Energy: 0.7187, KLD: 2.3414, MC: 2.3015)\n",
      "Training epoch complete. Average Loss: 7.0798\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0738\n",
      "\n",
      "Epoch 214/500\n",
      "Train Batch 10/110 - Loss: 7.1530 (Macro: 1.5727, Energy: 1.1652, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.9126 (Macro: 1.4861, Energy: 0.9904, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.1054 (Macro: 1.4694, Energy: 1.0270, KLD: 2.3073, MC: 2.3017)\n",
      "Train Batch 40/110 - Loss: 7.3989 (Macro: 1.5446, Energy: 1.1730, KLD: 2.3805, MC: 2.3008)\n",
      "Train Batch 50/110 - Loss: 7.0649 (Macro: 1.4869, Energy: 1.0387, KLD: 2.2381, MC: 2.3012)\n",
      "Train Batch 60/110 - Loss: 6.8773 (Macro: 1.3921, Energy: 0.9273, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 7.0288 (Macro: 1.3798, Energy: 0.9072, KLD: 2.4378, MC: 2.3040)\n",
      "Train Batch 80/110 - Loss: 7.3169 (Macro: 1.4222, Energy: 1.0553, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.8379 (Macro: 1.4796, Energy: 1.0315, KLD: 2.0241, MC: 2.3027)\n",
      "Train Batch 100/110 - Loss: 7.3238 (Macro: 1.6135, Energy: 1.1938, KLD: 2.2161, MC: 2.3004)\n",
      "Train Batch 110/110 - Loss: 6.6415 (Macro: 1.2380, Energy: 0.7621, KLD: 2.3414, MC: 2.3001)\n",
      "Training epoch complete. Average Loss: 7.0867\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0623\n",
      "\n",
      "Epoch 215/500\n",
      "Train Batch 10/110 - Loss: 7.1311 (Macro: 1.5922, Energy: 1.1236, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.9665 (Macro: 1.4837, Energy: 1.0483, KLD: 2.1345, MC: 2.3001)\n",
      "Train Batch 30/110 - Loss: 7.0939 (Macro: 1.4439, Energy: 1.0421, KLD: 2.3073, MC: 2.3006)\n",
      "Train Batch 40/110 - Loss: 7.4007 (Macro: 1.5336, Energy: 1.1843, KLD: 2.3805, MC: 2.3024)\n",
      "Train Batch 50/110 - Loss: 7.0268 (Macro: 1.4904, Energy: 0.9956, KLD: 2.2381, MC: 2.3027)\n",
      "Train Batch 60/110 - Loss: 6.9307 (Macro: 1.3875, Energy: 0.9826, KLD: 2.2570, MC: 2.3036)\n",
      "Train Batch 70/110 - Loss: 6.9760 (Macro: 1.3652, Energy: 0.8697, KLD: 2.4378, MC: 2.3033)\n",
      "Train Batch 80/110 - Loss: 7.3176 (Macro: 1.4409, Energy: 1.0379, KLD: 2.5365, MC: 2.3024)\n",
      "Train Batch 90/110 - Loss: 6.8056 (Macro: 1.4712, Energy: 1.0094, KLD: 2.0241, MC: 2.3009)\n",
      "Train Batch 100/110 - Loss: 7.2898 (Macro: 1.6138, Energy: 1.1574, KLD: 2.2161, MC: 2.3025)\n",
      "Train Batch 110/110 - Loss: 6.6132 (Macro: 1.2171, Energy: 0.7566, KLD: 2.3414, MC: 2.2982)\n",
      "Training epoch complete. Average Loss: 7.0824\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0633\n",
      "\n",
      "Epoch 216/500\n",
      "Train Batch 10/110 - Loss: 7.1173 (Macro: 1.5727, Energy: 1.1305, KLD: 2.1149, MC: 2.2991)\n",
      "Train Batch 20/110 - Loss: 6.8831 (Macro: 1.4923, Energy: 0.9531, KLD: 2.1345, MC: 2.3033)\n",
      "Train Batch 30/110 - Loss: 7.0993 (Macro: 1.4496, Energy: 1.0408, KLD: 2.3073, MC: 2.3016)\n",
      "Train Batch 40/110 - Loss: 7.4364 (Macro: 1.5643, Energy: 1.1919, KLD: 2.3805, MC: 2.2997)\n",
      "Train Batch 50/110 - Loss: 7.0574 (Macro: 1.5163, Energy: 1.0017, KLD: 2.2381, MC: 2.3012)\n",
      "Train Batch 60/110 - Loss: 6.9729 (Macro: 1.4248, Energy: 0.9908, KLD: 2.2570, MC: 2.3003)\n",
      "Train Batch 70/110 - Loss: 6.9420 (Macro: 1.3512, Energy: 0.8503, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.3258 (Macro: 1.4342, Energy: 1.0529, KLD: 2.5365, MC: 2.3022)\n",
      "Train Batch 90/110 - Loss: 6.7567 (Macro: 1.4609, Energy: 0.9701, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.3238 (Macro: 1.6154, Energy: 1.1883, KLD: 2.2161, MC: 2.3039)\n",
      "Train Batch 110/110 - Loss: 6.5023 (Macro: 1.2090, Energy: 0.6529, KLD: 2.3414, MC: 2.2990)\n",
      "Training epoch complete. Average Loss: 7.0818\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0610\n",
      "\n",
      "Epoch 217/500\n",
      "Train Batch 10/110 - Loss: 7.1386 (Macro: 1.5818, Energy: 1.1431, KLD: 2.1149, MC: 2.2988)\n",
      "Train Batch 20/110 - Loss: 6.8558 (Macro: 1.4781, Energy: 0.9411, KLD: 2.1345, MC: 2.3021)\n",
      "Train Batch 30/110 - Loss: 7.0574 (Macro: 1.4572, Energy: 0.9926, KLD: 2.3073, MC: 2.3003)\n",
      "Train Batch 40/110 - Loss: 7.3845 (Macro: 1.5529, Energy: 1.1512, KLD: 2.3805, MC: 2.2999)\n",
      "Train Batch 50/110 - Loss: 7.0612 (Macro: 1.5172, Energy: 1.0028, KLD: 2.2381, MC: 2.3031)\n",
      "Train Batch 60/110 - Loss: 6.9243 (Macro: 1.3883, Energy: 0.9778, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9617 (Macro: 1.3342, Energy: 0.8874, KLD: 2.4378, MC: 2.3024)\n",
      "Train Batch 80/110 - Loss: 7.3295 (Macro: 1.4257, Energy: 1.0649, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.8185 (Macro: 1.4637, Energy: 1.0288, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.2581 (Macro: 1.5943, Energy: 1.1451, KLD: 2.2161, MC: 2.3026)\n",
      "Train Batch 110/110 - Loss: 6.6709 (Macro: 1.2621, Energy: 0.7679, KLD: 2.3414, MC: 2.2996)\n",
      "Training epoch complete. Average Loss: 7.0798\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0630\n",
      "\n",
      "Epoch 218/500\n",
      "Train Batch 10/110 - Loss: 7.1275 (Macro: 1.5889, Energy: 1.1238, KLD: 2.1149, MC: 2.2999)\n",
      "Train Batch 20/110 - Loss: 6.9100 (Macro: 1.4846, Energy: 0.9885, KLD: 2.1345, MC: 2.3024)\n",
      "Train Batch 30/110 - Loss: 7.0354 (Macro: 1.4344, Energy: 0.9899, KLD: 2.3073, MC: 2.3038)\n",
      "Train Batch 40/110 - Loss: 7.4289 (Macro: 1.5622, Energy: 1.1848, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0178 (Macro: 1.4847, Energy: 0.9908, KLD: 2.2381, MC: 2.3043)\n",
      "Train Batch 60/110 - Loss: 6.9502 (Macro: 1.3860, Energy: 1.0051, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.9901 (Macro: 1.3875, Energy: 0.8607, KLD: 2.4378, MC: 2.3042)\n",
      "Train Batch 80/110 - Loss: 7.3318 (Macro: 1.4346, Energy: 1.0586, KLD: 2.5365, MC: 2.3021)\n",
      "Train Batch 90/110 - Loss: 6.7879 (Macro: 1.4755, Energy: 0.9851, KLD: 2.0241, MC: 2.3032)\n",
      "Train Batch 100/110 - Loss: 7.3509 (Macro: 1.5986, Energy: 1.2356, KLD: 2.2161, MC: 2.3006)\n",
      "Train Batch 110/110 - Loss: 6.5719 (Macro: 1.2153, Energy: 0.7174, KLD: 2.3414, MC: 2.2978)\n",
      "Training epoch complete. Average Loss: 7.0797\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0638\n",
      "\n",
      "Epoch 219/500\n",
      "Train Batch 10/110 - Loss: 7.1639 (Macro: 1.5921, Energy: 1.1550, KLD: 2.1149, MC: 2.3018)\n",
      "Train Batch 20/110 - Loss: 6.8498 (Macro: 1.4538, Energy: 0.9585, KLD: 2.1345, MC: 2.3030)\n",
      "Train Batch 30/110 - Loss: 7.0353 (Macro: 1.4378, Energy: 0.9886, KLD: 2.3073, MC: 2.3016)\n",
      "Train Batch 40/110 - Loss: 7.4281 (Macro: 1.5385, Energy: 1.2057, KLD: 2.3805, MC: 2.3033)\n",
      "Train Batch 50/110 - Loss: 7.0319 (Macro: 1.4871, Energy: 1.0037, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.8626 (Macro: 1.3721, Energy: 0.9313, KLD: 2.2570, MC: 2.3021)\n",
      "Train Batch 70/110 - Loss: 6.9304 (Macro: 1.3473, Energy: 0.8415, KLD: 2.4378, MC: 2.3040)\n",
      "Train Batch 80/110 - Loss: 7.3458 (Macro: 1.4124, Energy: 1.0944, KLD: 2.5365, MC: 2.3025)\n",
      "Train Batch 90/110 - Loss: 6.7674 (Macro: 1.4654, Energy: 0.9745, KLD: 2.0241, MC: 2.3033)\n",
      "Train Batch 100/110 - Loss: 7.2775 (Macro: 1.6156, Energy: 1.1444, KLD: 2.2161, MC: 2.3015)\n",
      "Train Batch 110/110 - Loss: 6.5718 (Macro: 1.1980, Energy: 0.7307, KLD: 2.3414, MC: 2.3017)\n",
      "Training epoch complete. Average Loss: 7.0733\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0645\n",
      "\n",
      "Epoch 220/500\n",
      "Train Batch 10/110 - Loss: 7.0893 (Macro: 1.5635, Energy: 1.1113, KLD: 2.1149, MC: 2.2996)\n",
      "Train Batch 20/110 - Loss: 6.9643 (Macro: 1.4940, Energy: 1.0344, KLD: 2.1345, MC: 2.3015)\n",
      "Train Batch 30/110 - Loss: 7.1117 (Macro: 1.4593, Energy: 1.0431, KLD: 2.3073, MC: 2.3020)\n",
      "Train Batch 40/110 - Loss: 7.4453 (Macro: 1.5492, Energy: 1.2128, KLD: 2.3805, MC: 2.3027)\n",
      "Train Batch 50/110 - Loss: 7.0659 (Macro: 1.5081, Energy: 1.0162, KLD: 2.2381, MC: 2.3036)\n",
      "Train Batch 60/110 - Loss: 6.9168 (Macro: 1.3851, Energy: 0.9738, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 6.9760 (Macro: 1.3745, Energy: 0.8604, KLD: 2.4378, MC: 2.3033)\n",
      "Train Batch 80/110 - Loss: 7.2912 (Macro: 1.4107, Energy: 1.0394, KLD: 2.5365, MC: 2.3046)\n",
      "Train Batch 90/110 - Loss: 6.8221 (Macro: 1.4814, Energy: 1.0135, KLD: 2.0241, MC: 2.3031)\n",
      "Train Batch 100/110 - Loss: 7.3064 (Macro: 1.5901, Energy: 1.1986, KLD: 2.2161, MC: 2.3017)\n",
      "Train Batch 110/110 - Loss: 6.6491 (Macro: 1.2546, Energy: 0.7555, KLD: 2.3414, MC: 2.2977)\n",
      "Training epoch complete. Average Loss: 7.0820\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0643\n",
      "\n",
      "Epoch 221/500\n",
      "Train Batch 10/110 - Loss: 7.1817 (Macro: 1.5873, Energy: 1.1806, KLD: 2.1149, MC: 2.2989)\n",
      "Train Batch 20/110 - Loss: 6.8574 (Macro: 1.4660, Energy: 0.9549, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.0731 (Macro: 1.4486, Energy: 1.0121, KLD: 2.3073, MC: 2.3051)\n",
      "Train Batch 40/110 - Loss: 7.4555 (Macro: 1.5449, Energy: 1.2301, KLD: 2.3805, MC: 2.2999)\n",
      "Train Batch 50/110 - Loss: 7.0714 (Macro: 1.4920, Energy: 1.0396, KLD: 2.2381, MC: 2.3017)\n",
      "Train Batch 60/110 - Loss: 6.9550 (Macro: 1.3828, Energy: 1.0136, KLD: 2.2570, MC: 2.3016)\n",
      "Train Batch 70/110 - Loss: 6.9186 (Macro: 1.3547, Energy: 0.8235, KLD: 2.4378, MC: 2.3026)\n",
      "Train Batch 80/110 - Loss: 7.2978 (Macro: 1.4282, Energy: 1.0308, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.7695 (Macro: 1.4749, Energy: 0.9694, KLD: 2.0241, MC: 2.3011)\n",
      "Train Batch 100/110 - Loss: 7.3107 (Macro: 1.6029, Energy: 1.1899, KLD: 2.2161, MC: 2.3017)\n",
      "Train Batch 110/110 - Loss: 6.5155 (Macro: 1.2010, Energy: 0.6761, KLD: 2.3414, MC: 2.2970)\n",
      "Training epoch complete. Average Loss: 7.0787\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0617\n",
      "\n",
      "Epoch 222/500\n",
      "Train Batch 10/110 - Loss: 7.1300 (Macro: 1.5963, Energy: 1.1175, KLD: 2.1149, MC: 2.3013)\n",
      "Train Batch 20/110 - Loss: 6.9019 (Macro: 1.4786, Energy: 0.9862, KLD: 2.1345, MC: 2.3026)\n",
      "Train Batch 30/110 - Loss: 7.0694 (Macro: 1.4430, Energy: 1.0165, KLD: 2.3073, MC: 2.3026)\n",
      "Train Batch 40/110 - Loss: 7.4028 (Macro: 1.5444, Energy: 1.1765, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 6.9987 (Macro: 1.4848, Energy: 0.9729, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.9112 (Macro: 1.3821, Energy: 0.9700, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.9548 (Macro: 1.3680, Energy: 0.8457, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.3091 (Macro: 1.4355, Energy: 1.0333, KLD: 2.5365, MC: 2.3038)\n",
      "Train Batch 90/110 - Loss: 6.7769 (Macro: 1.4610, Energy: 0.9891, KLD: 2.0241, MC: 2.3028)\n",
      "Train Batch 100/110 - Loss: 7.2741 (Macro: 1.5862, Energy: 1.1711, KLD: 2.2161, MC: 2.3006)\n",
      "Train Batch 110/110 - Loss: 6.6812 (Macro: 1.2588, Energy: 0.7843, KLD: 2.3414, MC: 2.2967)\n",
      "Training epoch complete. Average Loss: 7.0843\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0624\n",
      "\n",
      "Epoch 223/500\n",
      "Train Batch 10/110 - Loss: 7.1534 (Macro: 1.5655, Energy: 1.1720, KLD: 2.1149, MC: 2.3009)\n",
      "Train Batch 20/110 - Loss: 6.9422 (Macro: 1.4960, Energy: 1.0099, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0829 (Macro: 1.4564, Energy: 1.0181, KLD: 2.3073, MC: 2.3011)\n",
      "Train Batch 40/110 - Loss: 7.3967 (Macro: 1.5641, Energy: 1.1506, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.0364 (Macro: 1.4965, Energy: 0.9985, KLD: 2.2381, MC: 2.3034)\n",
      "Train Batch 60/110 - Loss: 6.8812 (Macro: 1.3999, Energy: 0.9212, KLD: 2.2570, MC: 2.3031)\n",
      "Train Batch 70/110 - Loss: 6.9742 (Macro: 1.3482, Energy: 0.8854, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.3011 (Macro: 1.4288, Energy: 1.0318, KLD: 2.5365, MC: 2.3040)\n",
      "Train Batch 90/110 - Loss: 6.7565 (Macro: 1.4844, Energy: 0.9457, KLD: 2.0241, MC: 2.3023)\n",
      "Train Batch 100/110 - Loss: 7.3195 (Macro: 1.6239, Energy: 1.1771, KLD: 2.2161, MC: 2.3024)\n",
      "Train Batch 110/110 - Loss: 6.6204 (Macro: 1.2711, Energy: 0.7101, KLD: 2.3414, MC: 2.2978)\n",
      "Training epoch complete. Average Loss: 7.0765\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0582\n",
      "\n",
      "Epoch 224/500\n",
      "Train Batch 10/110 - Loss: 7.0883 (Macro: 1.5780, Energy: 1.0931, KLD: 2.1149, MC: 2.3022)\n",
      "Train Batch 20/110 - Loss: 6.8760 (Macro: 1.4950, Energy: 0.9437, KLD: 2.1345, MC: 2.3028)\n",
      "Train Batch 30/110 - Loss: 7.1172 (Macro: 1.4704, Energy: 1.0378, KLD: 2.3073, MC: 2.3017)\n",
      "Train Batch 40/110 - Loss: 7.4675 (Macro: 1.5453, Energy: 1.2403, KLD: 2.3805, MC: 2.3013)\n",
      "Train Batch 50/110 - Loss: 7.0779 (Macro: 1.4921, Energy: 1.0449, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.9603 (Macro: 1.4020, Energy: 1.0001, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9360 (Macro: 1.3637, Energy: 0.8315, KLD: 2.4378, MC: 2.3030)\n",
      "Train Batch 80/110 - Loss: 7.2947 (Macro: 1.4290, Energy: 1.0259, KLD: 2.5365, MC: 2.3034)\n",
      "Train Batch 90/110 - Loss: 6.7561 (Macro: 1.4773, Energy: 0.9533, KLD: 2.0241, MC: 2.3015)\n",
      "Train Batch 100/110 - Loss: 7.2959 (Macro: 1.5753, Energy: 1.2025, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.6233 (Macro: 1.2479, Energy: 0.7387, KLD: 2.3414, MC: 2.2953)\n",
      "Training epoch complete. Average Loss: 7.0804\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0696\n",
      "\n",
      "Epoch 225/500\n",
      "Train Batch 10/110 - Loss: 7.1754 (Macro: 1.5860, Energy: 1.1749, KLD: 2.1149, MC: 2.2995)\n",
      "Train Batch 20/110 - Loss: 6.9117 (Macro: 1.4943, Energy: 0.9817, KLD: 2.1345, MC: 2.3013)\n",
      "Train Batch 30/110 - Loss: 7.0874 (Macro: 1.4682, Energy: 1.0098, KLD: 2.3073, MC: 2.3021)\n",
      "Train Batch 40/110 - Loss: 7.4515 (Macro: 1.5341, Energy: 1.2371, KLD: 2.3805, MC: 2.2998)\n",
      "Train Batch 50/110 - Loss: 7.0564 (Macro: 1.4913, Energy: 1.0250, KLD: 2.2381, MC: 2.3020)\n",
      "Train Batch 60/110 - Loss: 6.8951 (Macro: 1.3758, Energy: 0.9601, KLD: 2.2570, MC: 2.3022)\n",
      "Train Batch 70/110 - Loss: 6.9228 (Macro: 1.3653, Energy: 0.8165, KLD: 2.4378, MC: 2.3032)\n",
      "Train Batch 80/110 - Loss: 7.2831 (Macro: 1.4417, Energy: 1.0024, KLD: 2.5365, MC: 2.3026)\n",
      "Train Batch 90/110 - Loss: 6.7441 (Macro: 1.4645, Energy: 0.9539, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.3042 (Macro: 1.6115, Energy: 1.1755, KLD: 2.2161, MC: 2.3012)\n",
      "Train Batch 110/110 - Loss: 6.6983 (Macro: 1.2531, Energy: 0.8015, KLD: 2.3414, MC: 2.3023)\n",
      "Training epoch complete. Average Loss: 7.0773\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0618\n",
      "\n",
      "Epoch 226/500\n",
      "Train Batch 10/110 - Loss: 7.1088 (Macro: 1.5900, Energy: 1.1040, KLD: 2.1149, MC: 2.2998)\n",
      "Train Batch 20/110 - Loss: 6.8879 (Macro: 1.4761, Energy: 0.9759, KLD: 2.1345, MC: 2.3014)\n",
      "Train Batch 30/110 - Loss: 7.0485 (Macro: 1.4676, Energy: 0.9718, KLD: 2.3073, MC: 2.3017)\n",
      "Train Batch 40/110 - Loss: 7.3831 (Macro: 1.5641, Energy: 1.1363, KLD: 2.3805, MC: 2.3022)\n",
      "Train Batch 50/110 - Loss: 7.0645 (Macro: 1.5035, Energy: 1.0201, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.9350 (Macro: 1.3998, Energy: 0.9756, KLD: 2.2570, MC: 2.3027)\n",
      "Train Batch 70/110 - Loss: 6.9660 (Macro: 1.3470, Energy: 0.8783, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.3133 (Macro: 1.4284, Energy: 1.0441, KLD: 2.5365, MC: 2.3044)\n",
      "Train Batch 90/110 - Loss: 6.7518 (Macro: 1.4815, Energy: 0.9434, KLD: 2.0241, MC: 2.3029)\n",
      "Train Batch 100/110 - Loss: 7.2795 (Macro: 1.6258, Energy: 1.1348, KLD: 2.2161, MC: 2.3028)\n",
      "Train Batch 110/110 - Loss: 6.7710 (Macro: 1.2310, Energy: 0.8993, KLD: 2.3414, MC: 2.2992)\n",
      "Training epoch complete. Average Loss: 7.0814\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0605\n",
      "\n",
      "Epoch 227/500\n",
      "Train Batch 10/110 - Loss: 7.1385 (Macro: 1.5759, Energy: 1.1483, KLD: 2.1149, MC: 2.2994)\n",
      "Train Batch 20/110 - Loss: 6.9067 (Macro: 1.4809, Energy: 0.9901, KLD: 2.1345, MC: 2.3012)\n",
      "Train Batch 30/110 - Loss: 7.0084 (Macro: 1.4360, Energy: 0.9643, KLD: 2.3073, MC: 2.3009)\n",
      "Train Batch 40/110 - Loss: 7.4097 (Macro: 1.5573, Energy: 1.1703, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.1162 (Macro: 1.5044, Energy: 1.0720, KLD: 2.2381, MC: 2.3017)\n",
      "Train Batch 60/110 - Loss: 6.9586 (Macro: 1.3834, Energy: 1.0170, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9707 (Macro: 1.3741, Energy: 0.8545, KLD: 2.4378, MC: 2.3043)\n",
      "Train Batch 80/110 - Loss: 7.3045 (Macro: 1.4365, Energy: 1.0280, KLD: 2.5365, MC: 2.3036)\n",
      "Train Batch 90/110 - Loss: 6.8123 (Macro: 1.4868, Energy: 0.9993, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.2543 (Macro: 1.5957, Energy: 1.1402, KLD: 2.2161, MC: 2.3024)\n",
      "Train Batch 110/110 - Loss: 6.5154 (Macro: 1.2086, Energy: 0.6670, KLD: 2.3414, MC: 2.2985)\n",
      "Training epoch complete. Average Loss: 7.0776\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0706\n",
      "\n",
      "Epoch 228/500\n",
      "Train Batch 10/110 - Loss: 7.1628 (Macro: 1.5703, Energy: 1.1770, KLD: 2.1149, MC: 2.3006)\n",
      "Train Batch 20/110 - Loss: 6.8827 (Macro: 1.4839, Energy: 0.9621, KLD: 2.1345, MC: 2.3022)\n",
      "Train Batch 30/110 - Loss: 7.1273 (Macro: 1.4677, Energy: 1.0500, KLD: 2.3073, MC: 2.3024)\n",
      "Train Batch 40/110 - Loss: 7.4567 (Macro: 1.5562, Energy: 1.2189, KLD: 2.3805, MC: 2.3011)\n",
      "Train Batch 50/110 - Loss: 7.0522 (Macro: 1.4893, Energy: 1.0210, KLD: 2.2381, MC: 2.3039)\n",
      "Train Batch 60/110 - Loss: 6.9277 (Macro: 1.3997, Energy: 0.9710, KLD: 2.2570, MC: 2.3000)\n",
      "Train Batch 70/110 - Loss: 6.9530 (Macro: 1.3334, Energy: 0.8781, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.3401 (Macro: 1.4158, Energy: 1.0845, KLD: 2.5365, MC: 2.3033)\n",
      "Train Batch 90/110 - Loss: 6.7687 (Macro: 1.4634, Energy: 0.9789, KLD: 2.0241, MC: 2.3024)\n",
      "Train Batch 100/110 - Loss: 7.3539 (Macro: 1.5965, Energy: 1.2385, KLD: 2.2161, MC: 2.3027)\n",
      "Train Batch 110/110 - Loss: 6.6567 (Macro: 1.2611, Energy: 0.7568, KLD: 2.3414, MC: 2.2973)\n",
      "Training epoch complete. Average Loss: 7.0820\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0683\n",
      "\n",
      "Epoch 229/500\n",
      "Train Batch 10/110 - Loss: 7.0995 (Macro: 1.5633, Energy: 1.1201, KLD: 2.1149, MC: 2.3011)\n",
      "Train Batch 20/110 - Loss: 6.8635 (Macro: 1.4899, Energy: 0.9359, KLD: 2.1345, MC: 2.3032)\n",
      "Train Batch 30/110 - Loss: 7.1068 (Macro: 1.4582, Energy: 1.0379, KLD: 2.3073, MC: 2.3034)\n",
      "Train Batch 40/110 - Loss: 7.3902 (Macro: 1.5454, Energy: 1.1629, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0396 (Macro: 1.4964, Energy: 1.0013, KLD: 2.2381, MC: 2.3038)\n",
      "Train Batch 60/110 - Loss: 6.8385 (Macro: 1.3904, Energy: 0.8903, KLD: 2.2570, MC: 2.3007)\n",
      "Train Batch 70/110 - Loss: 6.9958 (Macro: 1.3884, Energy: 0.8651, KLD: 2.4378, MC: 2.3046)\n",
      "Train Batch 80/110 - Loss: 7.3183 (Macro: 1.4273, Energy: 1.0527, KLD: 2.5365, MC: 2.3018)\n",
      "Train Batch 90/110 - Loss: 6.7961 (Macro: 1.4838, Energy: 0.9868, KLD: 2.0241, MC: 2.3014)\n",
      "Train Batch 100/110 - Loss: 7.3371 (Macro: 1.5922, Energy: 1.2267, KLD: 2.2161, MC: 2.3021)\n",
      "Train Batch 110/110 - Loss: 6.6113 (Macro: 1.2302, Energy: 0.7408, KLD: 2.3414, MC: 2.2988)\n",
      "Training epoch complete. Average Loss: 7.0839\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0695\n",
      "\n",
      "Epoch 230/500\n",
      "Train Batch 10/110 - Loss: 7.1144 (Macro: 1.5639, Energy: 1.1377, KLD: 2.1149, MC: 2.2979)\n",
      "Train Batch 20/110 - Loss: 6.8408 (Macro: 1.4747, Energy: 0.9283, KLD: 2.1345, MC: 2.3033)\n",
      "Train Batch 30/110 - Loss: 7.0970 (Macro: 1.4489, Energy: 1.0385, KLD: 2.3073, MC: 2.3023)\n",
      "Train Batch 40/110 - Loss: 7.4310 (Macro: 1.5526, Energy: 1.1962, KLD: 2.3805, MC: 2.3017)\n",
      "Train Batch 50/110 - Loss: 7.0674 (Macro: 1.4815, Energy: 1.0440, KLD: 2.2381, MC: 2.3038)\n",
      "Train Batch 60/110 - Loss: 6.8844 (Macro: 1.3688, Energy: 0.9564, KLD: 2.2570, MC: 2.3022)\n",
      "Train Batch 70/110 - Loss: 6.9433 (Macro: 1.3608, Energy: 0.8418, KLD: 2.4378, MC: 2.3030)\n",
      "Train Batch 80/110 - Loss: 7.2501 (Macro: 1.4101, Energy: 1.0018, KLD: 2.5365, MC: 2.3017)\n",
      "Train Batch 90/110 - Loss: 6.7574 (Macro: 1.4839, Energy: 0.9468, KLD: 2.0241, MC: 2.3026)\n",
      "Train Batch 100/110 - Loss: 7.3351 (Macro: 1.6081, Energy: 1.2081, KLD: 2.2161, MC: 2.3029)\n",
      "Train Batch 110/110 - Loss: 6.5857 (Macro: 1.2118, Energy: 0.7340, KLD: 2.3414, MC: 2.2986)\n",
      "Training epoch complete. Average Loss: 7.0812\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0689\n",
      "\n",
      "Epoch 231/500\n",
      "Train Batch 10/110 - Loss: 7.0893 (Macro: 1.5972, Energy: 1.0763, KLD: 2.1149, MC: 2.3009)\n",
      "Train Batch 20/110 - Loss: 6.8515 (Macro: 1.4782, Energy: 0.9370, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0852 (Macro: 1.4444, Energy: 1.0323, KLD: 2.3073, MC: 2.3013)\n",
      "Train Batch 40/110 - Loss: 7.5051 (Macro: 1.5547, Energy: 1.2679, KLD: 2.3805, MC: 2.3019)\n",
      "Train Batch 50/110 - Loss: 7.0323 (Macro: 1.5072, Energy: 0.9839, KLD: 2.2381, MC: 2.3031)\n",
      "Train Batch 60/110 - Loss: 6.9567 (Macro: 1.3897, Energy: 1.0111, KLD: 2.2570, MC: 2.2988)\n",
      "Train Batch 70/110 - Loss: 6.9886 (Macro: 1.3703, Energy: 0.8760, KLD: 2.4378, MC: 2.3045)\n",
      "Train Batch 80/110 - Loss: 7.3228 (Macro: 1.4379, Energy: 1.0476, KLD: 2.5365, MC: 2.3008)\n",
      "Train Batch 90/110 - Loss: 6.8382 (Macro: 1.4964, Energy: 1.0149, KLD: 2.0241, MC: 2.3029)\n",
      "Train Batch 100/110 - Loss: 7.2635 (Macro: 1.6117, Energy: 1.1342, KLD: 2.2161, MC: 2.3014)\n",
      "Train Batch 110/110 - Loss: 6.5790 (Macro: 1.2063, Energy: 0.7325, KLD: 2.3414, MC: 2.2988)\n",
      "Training epoch complete. Average Loss: 7.0800\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0636\n",
      "\n",
      "Epoch 232/500\n",
      "Train Batch 10/110 - Loss: 7.1367 (Macro: 1.5905, Energy: 1.1309, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.9265 (Macro: 1.5064, Energy: 0.9838, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.1075 (Macro: 1.4679, Energy: 1.0307, KLD: 2.3073, MC: 2.3016)\n",
      "Train Batch 40/110 - Loss: 7.4509 (Macro: 1.5341, Energy: 1.2349, KLD: 2.3805, MC: 2.3013)\n",
      "Train Batch 50/110 - Loss: 7.0408 (Macro: 1.4930, Energy: 1.0045, KLD: 2.2381, MC: 2.3053)\n",
      "Train Batch 60/110 - Loss: 6.8794 (Macro: 1.3832, Energy: 0.9370, KLD: 2.2570, MC: 2.3021)\n",
      "Train Batch 70/110 - Loss: 6.9098 (Macro: 1.3588, Energy: 0.8109, KLD: 2.4378, MC: 2.3023)\n",
      "Train Batch 80/110 - Loss: 7.2427 (Macro: 1.4275, Energy: 0.9773, KLD: 2.5365, MC: 2.3014)\n",
      "Train Batch 90/110 - Loss: 6.8060 (Macro: 1.4817, Energy: 0.9978, KLD: 2.0241, MC: 2.3024)\n",
      "Train Batch 100/110 - Loss: 7.3282 (Macro: 1.6104, Energy: 1.2000, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.5981 (Macro: 1.2366, Energy: 0.7224, KLD: 2.3414, MC: 2.2978)\n",
      "Training epoch complete. Average Loss: 7.0799\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0670\n",
      "\n",
      "Epoch 233/500\n",
      "Train Batch 10/110 - Loss: 7.1407 (Macro: 1.5774, Energy: 1.1479, KLD: 2.1149, MC: 2.3004)\n",
      "Train Batch 20/110 - Loss: 6.8395 (Macro: 1.4849, Energy: 0.9181, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.0828 (Macro: 1.4583, Energy: 1.0146, KLD: 2.3073, MC: 2.3026)\n",
      "Train Batch 40/110 - Loss: 7.5064 (Macro: 1.5780, Energy: 1.2482, KLD: 2.3805, MC: 2.2997)\n",
      "Train Batch 50/110 - Loss: 7.0730 (Macro: 1.5053, Energy: 1.0262, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.9035 (Macro: 1.4057, Energy: 0.9394, KLD: 2.2570, MC: 2.3014)\n",
      "Train Batch 70/110 - Loss: 6.9550 (Macro: 1.3461, Energy: 0.8674, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.2785 (Macro: 1.4011, Energy: 1.0391, KLD: 2.5365, MC: 2.3018)\n",
      "Train Batch 90/110 - Loss: 6.7878 (Macro: 1.4753, Energy: 0.9871, KLD: 2.0241, MC: 2.3014)\n",
      "Train Batch 100/110 - Loss: 7.2949 (Macro: 1.6015, Energy: 1.1754, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.6274 (Macro: 1.2039, Energy: 0.7842, KLD: 2.3414, MC: 2.2979)\n",
      "Training epoch complete. Average Loss: 7.0800\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0677\n",
      "\n",
      "Epoch 234/500\n",
      "Train Batch 10/110 - Loss: 7.1525 (Macro: 1.5963, Energy: 1.1406, KLD: 2.1149, MC: 2.3007)\n",
      "Train Batch 20/110 - Loss: 6.8846 (Macro: 1.4839, Energy: 0.9639, KLD: 2.1345, MC: 2.3023)\n",
      "Train Batch 30/110 - Loss: 7.0683 (Macro: 1.4550, Energy: 1.0025, KLD: 2.3073, MC: 2.3035)\n",
      "Train Batch 40/110 - Loss: 7.4480 (Macro: 1.5402, Energy: 1.2257, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0788 (Macro: 1.5251, Energy: 1.0113, KLD: 2.2381, MC: 2.3043)\n",
      "Train Batch 60/110 - Loss: 6.9150 (Macro: 1.4258, Energy: 0.9312, KLD: 2.2570, MC: 2.3010)\n",
      "Train Batch 70/110 - Loss: 6.9902 (Macro: 1.3710, Energy: 0.8765, KLD: 2.4378, MC: 2.3049)\n",
      "Train Batch 80/110 - Loss: 7.2997 (Macro: 1.4121, Energy: 1.0477, KLD: 2.5365, MC: 2.3034)\n",
      "Train Batch 90/110 - Loss: 6.7833 (Macro: 1.4730, Energy: 0.9827, KLD: 2.0241, MC: 2.3036)\n",
      "Train Batch 100/110 - Loss: 7.2755 (Macro: 1.5968, Energy: 1.1618, KLD: 2.2161, MC: 2.3008)\n",
      "Train Batch 110/110 - Loss: 6.6096 (Macro: 1.2286, Energy: 0.7429, KLD: 2.3414, MC: 2.2967)\n",
      "Training epoch complete. Average Loss: 7.0809\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0726\n",
      "\n",
      "Epoch 235/500\n",
      "Train Batch 10/110 - Loss: 7.0414 (Macro: 1.5774, Energy: 1.0490, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.8362 (Macro: 1.4735, Energy: 0.9270, KLD: 2.1345, MC: 2.3013)\n",
      "Train Batch 30/110 - Loss: 7.0970 (Macro: 1.4717, Energy: 1.0143, KLD: 2.3073, MC: 2.3038)\n",
      "Train Batch 40/110 - Loss: 7.5187 (Macro: 1.5782, Energy: 1.2589, KLD: 2.3805, MC: 2.3011)\n",
      "Train Batch 50/110 - Loss: 7.0800 (Macro: 1.5033, Energy: 1.0355, KLD: 2.2381, MC: 2.3031)\n",
      "Train Batch 60/110 - Loss: 6.8709 (Macro: 1.3783, Energy: 0.9332, KLD: 2.2570, MC: 2.3024)\n",
      "Train Batch 70/110 - Loss: 6.9691 (Macro: 1.3472, Energy: 0.8816, KLD: 2.4378, MC: 2.3026)\n",
      "Train Batch 80/110 - Loss: 7.2863 (Macro: 1.4210, Energy: 1.0260, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.7520 (Macro: 1.4703, Energy: 0.9569, KLD: 2.0241, MC: 2.3008)\n",
      "Train Batch 100/110 - Loss: 7.2960 (Macro: 1.6089, Energy: 1.1696, KLD: 2.2161, MC: 2.3014)\n",
      "Train Batch 110/110 - Loss: 6.6531 (Macro: 1.2525, Energy: 0.7637, KLD: 2.3414, MC: 2.2956)\n",
      "Training epoch complete. Average Loss: 7.0786\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0756\n",
      "\n",
      "Epoch 236/500\n",
      "Train Batch 10/110 - Loss: 7.1511 (Macro: 1.5740, Energy: 1.1623, KLD: 2.1149, MC: 2.2998)\n",
      "Train Batch 20/110 - Loss: 6.9150 (Macro: 1.4876, Energy: 0.9919, KLD: 2.1345, MC: 2.3010)\n",
      "Train Batch 30/110 - Loss: 7.1196 (Macro: 1.4821, Energy: 1.0273, KLD: 2.3073, MC: 2.3029)\n",
      "Train Batch 40/110 - Loss: 7.4415 (Macro: 1.5463, Energy: 1.2121, KLD: 2.3805, MC: 2.3025)\n",
      "Train Batch 50/110 - Loss: 7.0459 (Macro: 1.4833, Energy: 1.0220, KLD: 2.2381, MC: 2.3025)\n",
      "Train Batch 60/110 - Loss: 6.9322 (Macro: 1.4165, Energy: 0.9553, KLD: 2.2570, MC: 2.3034)\n",
      "Train Batch 70/110 - Loss: 6.9671 (Macro: 1.3900, Energy: 0.8350, KLD: 2.4378, MC: 2.3044)\n",
      "Train Batch 80/110 - Loss: 7.2602 (Macro: 1.4110, Energy: 1.0105, KLD: 2.5365, MC: 2.3022)\n",
      "Train Batch 90/110 - Loss: 6.7815 (Macro: 1.4825, Energy: 0.9738, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.2897 (Macro: 1.5958, Energy: 1.1759, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.6031 (Macro: 1.2113, Energy: 0.7517, KLD: 2.3414, MC: 2.2987)\n",
      "Training epoch complete. Average Loss: 7.0776\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0758\n",
      "\n",
      "Epoch 237/500\n",
      "Train Batch 10/110 - Loss: 7.1223 (Macro: 1.5705, Energy: 1.1362, KLD: 2.1149, MC: 2.3007)\n",
      "Train Batch 20/110 - Loss: 6.8823 (Macro: 1.4653, Energy: 0.9800, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.1014 (Macro: 1.4617, Energy: 1.0287, KLD: 2.3073, MC: 2.3037)\n",
      "Train Batch 40/110 - Loss: 7.4267 (Macro: 1.5576, Energy: 1.1881, KLD: 2.3805, MC: 2.3005)\n",
      "Train Batch 50/110 - Loss: 7.0603 (Macro: 1.4922, Energy: 1.0279, KLD: 2.2381, MC: 2.3022)\n",
      "Train Batch 60/110 - Loss: 6.9194 (Macro: 1.3673, Energy: 0.9932, KLD: 2.2570, MC: 2.3019)\n",
      "Train Batch 70/110 - Loss: 6.9665 (Macro: 1.3569, Energy: 0.8676, KLD: 2.4378, MC: 2.3043)\n",
      "Train Batch 80/110 - Loss: 7.3044 (Macro: 1.4197, Energy: 1.0460, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.8055 (Macro: 1.4818, Energy: 0.9997, KLD: 2.0241, MC: 2.2999)\n",
      "Train Batch 100/110 - Loss: 7.2984 (Macro: 1.5992, Energy: 1.1815, KLD: 2.2161, MC: 2.3016)\n",
      "Train Batch 110/110 - Loss: 6.6130 (Macro: 1.2625, Energy: 0.7126, KLD: 2.3414, MC: 2.2966)\n",
      "Training epoch complete. Average Loss: 7.0766\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0609\n",
      "\n",
      "Epoch 238/500\n",
      "Train Batch 10/110 - Loss: 7.1731 (Macro: 1.5921, Energy: 1.1664, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.9513 (Macro: 1.5073, Energy: 1.0075, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.0278 (Macro: 1.4490, Energy: 0.9690, KLD: 2.3073, MC: 2.3025)\n",
      "Train Batch 40/110 - Loss: 7.4869 (Macro: 1.5513, Energy: 1.2516, KLD: 2.3805, MC: 2.3035)\n",
      "Train Batch 50/110 - Loss: 7.0517 (Macro: 1.5035, Energy: 1.0057, KLD: 2.2381, MC: 2.3045)\n",
      "Train Batch 60/110 - Loss: 6.9291 (Macro: 1.4045, Energy: 0.9664, KLD: 2.2570, MC: 2.3010)\n",
      "Train Batch 70/110 - Loss: 6.9896 (Macro: 1.3846, Energy: 0.8641, KLD: 2.4378, MC: 2.3032)\n",
      "Train Batch 80/110 - Loss: 7.3415 (Macro: 1.4306, Energy: 1.0711, KLD: 2.5365, MC: 2.3033)\n",
      "Train Batch 90/110 - Loss: 6.8915 (Macro: 1.5080, Energy: 1.0575, KLD: 2.0241, MC: 2.3019)\n",
      "Train Batch 100/110 - Loss: 7.2657 (Macro: 1.5762, Energy: 1.1731, KLD: 2.2161, MC: 2.3003)\n",
      "Train Batch 110/110 - Loss: 6.6149 (Macro: 1.2221, Energy: 0.7532, KLD: 2.3414, MC: 2.2982)\n",
      "Training epoch complete. Average Loss: 7.0801\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0584\n",
      "\n",
      "Epoch 239/500\n",
      "Train Batch 10/110 - Loss: 7.1577 (Macro: 1.5841, Energy: 1.1595, KLD: 2.1149, MC: 2.2992)\n",
      "Train Batch 20/110 - Loss: 6.8637 (Macro: 1.4612, Energy: 0.9662, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.0416 (Macro: 1.4241, Energy: 1.0074, KLD: 2.3073, MC: 2.3028)\n",
      "Train Batch 40/110 - Loss: 7.4242 (Macro: 1.5448, Energy: 1.1976, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0635 (Macro: 1.5047, Energy: 1.0178, KLD: 2.2381, MC: 2.3031)\n",
      "Train Batch 60/110 - Loss: 6.8745 (Macro: 1.3700, Energy: 0.9475, KLD: 2.2570, MC: 2.3000)\n",
      "Train Batch 70/110 - Loss: 6.9014 (Macro: 1.3757, Energy: 0.7857, KLD: 2.4378, MC: 2.3023)\n",
      "Train Batch 80/110 - Loss: 7.3570 (Macro: 1.4532, Energy: 1.0646, KLD: 2.5365, MC: 2.3027)\n",
      "Train Batch 90/110 - Loss: 6.8261 (Macro: 1.4745, Energy: 1.0262, KLD: 2.0241, MC: 2.3014)\n",
      "Train Batch 100/110 - Loss: 7.3090 (Macro: 1.6014, Energy: 1.1884, KLD: 2.2161, MC: 2.3031)\n",
      "Train Batch 110/110 - Loss: 6.5579 (Macro: 1.2023, Energy: 0.7165, KLD: 2.3414, MC: 2.2977)\n",
      "Training epoch complete. Average Loss: 7.0785\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0706\n",
      "\n",
      "Epoch 240/500\n",
      "Train Batch 10/110 - Loss: 7.0879 (Macro: 1.5702, Energy: 1.1030, KLD: 2.1149, MC: 2.2998)\n",
      "Train Batch 20/110 - Loss: 6.9087 (Macro: 1.4924, Energy: 0.9793, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.0666 (Macro: 1.4480, Energy: 1.0093, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4196 (Macro: 1.5570, Energy: 1.1800, KLD: 2.3805, MC: 2.3021)\n",
      "Train Batch 50/110 - Loss: 7.1204 (Macro: 1.5292, Energy: 1.0504, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.9140 (Macro: 1.3921, Energy: 0.9637, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9926 (Macro: 1.3667, Energy: 0.8859, KLD: 2.4378, MC: 2.3022)\n",
      "Train Batch 80/110 - Loss: 7.2981 (Macro: 1.4187, Energy: 1.0401, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.7767 (Macro: 1.4801, Energy: 0.9715, KLD: 2.0241, MC: 2.3010)\n",
      "Train Batch 100/110 - Loss: 7.3268 (Macro: 1.6367, Energy: 1.1718, KLD: 2.2161, MC: 2.3021)\n",
      "Train Batch 110/110 - Loss: 6.5954 (Macro: 1.2152, Energy: 0.7400, KLD: 2.3414, MC: 2.2988)\n",
      "Training epoch complete. Average Loss: 7.0790\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0638\n",
      "\n",
      "Epoch 241/500\n",
      "Train Batch 10/110 - Loss: 7.1297 (Macro: 1.5741, Energy: 1.1389, KLD: 2.1149, MC: 2.3017)\n",
      "Train Batch 20/110 - Loss: 6.9111 (Macro: 1.4857, Energy: 0.9879, KLD: 2.1345, MC: 2.3030)\n",
      "Train Batch 30/110 - Loss: 7.0472 (Macro: 1.4329, Energy: 1.0043, KLD: 2.3073, MC: 2.3027)\n",
      "Train Batch 40/110 - Loss: 7.4494 (Macro: 1.5725, Energy: 1.1929, KLD: 2.3805, MC: 2.3036)\n",
      "Train Batch 50/110 - Loss: 7.0640 (Macro: 1.5001, Energy: 1.0221, KLD: 2.2381, MC: 2.3037)\n",
      "Train Batch 60/110 - Loss: 6.9060 (Macro: 1.3830, Energy: 0.9642, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 6.8560 (Macro: 1.3577, Energy: 0.7563, KLD: 2.4378, MC: 2.3042)\n",
      "Train Batch 80/110 - Loss: 7.3008 (Macro: 1.4331, Energy: 1.0281, KLD: 2.5365, MC: 2.3030)\n",
      "Train Batch 90/110 - Loss: 6.7997 (Macro: 1.4722, Energy: 1.0007, KLD: 2.0241, MC: 2.3026)\n",
      "Train Batch 100/110 - Loss: 7.3064 (Macro: 1.6176, Energy: 1.1700, KLD: 2.2161, MC: 2.3026)\n",
      "Train Batch 110/110 - Loss: 6.6376 (Macro: 1.2326, Energy: 0.7652, KLD: 2.3414, MC: 2.2985)\n",
      "Training epoch complete. Average Loss: 7.0807\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0711\n",
      "\n",
      "Epoch 242/500\n",
      "Train Batch 10/110 - Loss: 7.1096 (Macro: 1.5934, Energy: 1.1015, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.8783 (Macro: 1.4888, Energy: 0.9522, KLD: 2.1345, MC: 2.3028)\n",
      "Train Batch 30/110 - Loss: 7.0455 (Macro: 1.4491, Energy: 0.9868, KLD: 2.3073, MC: 2.3022)\n",
      "Train Batch 40/110 - Loss: 7.4900 (Macro: 1.5587, Energy: 1.2480, KLD: 2.3805, MC: 2.3028)\n",
      "Train Batch 50/110 - Loss: 7.0235 (Macro: 1.5032, Energy: 0.9793, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.9635 (Macro: 1.4159, Energy: 0.9895, KLD: 2.2570, MC: 2.3010)\n",
      "Train Batch 70/110 - Loss: 6.9514 (Macro: 1.3649, Energy: 0.8463, KLD: 2.4378, MC: 2.3024)\n",
      "Train Batch 80/110 - Loss: 7.2995 (Macro: 1.4290, Energy: 1.0308, KLD: 2.5365, MC: 2.3033)\n",
      "Train Batch 90/110 - Loss: 6.7575 (Macro: 1.4790, Energy: 0.9523, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.2696 (Macro: 1.5473, Energy: 1.2034, KLD: 2.2161, MC: 2.3028)\n",
      "Train Batch 110/110 - Loss: 6.6068 (Macro: 1.2565, Energy: 0.7136, KLD: 2.3414, MC: 2.2954)\n",
      "Training epoch complete. Average Loss: 7.0767\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0635\n",
      "\n",
      "Epoch 243/500\n",
      "Train Batch 10/110 - Loss: 7.1013 (Macro: 1.5742, Energy: 1.1116, KLD: 2.1149, MC: 2.3005)\n",
      "Train Batch 20/110 - Loss: 6.9026 (Macro: 1.4718, Energy: 0.9938, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.0720 (Macro: 1.4539, Energy: 1.0084, KLD: 2.3073, MC: 2.3024)\n",
      "Train Batch 40/110 - Loss: 7.4226 (Macro: 1.5529, Energy: 1.1883, KLD: 2.3805, MC: 2.3009)\n",
      "Train Batch 50/110 - Loss: 7.1250 (Macro: 1.5126, Energy: 1.0721, KLD: 2.2381, MC: 2.3023)\n",
      "Train Batch 60/110 - Loss: 6.8776 (Macro: 1.4003, Energy: 0.9200, KLD: 2.2570, MC: 2.3003)\n",
      "Train Batch 70/110 - Loss: 6.9787 (Macro: 1.3462, Energy: 0.8926, KLD: 2.4378, MC: 2.3021)\n",
      "Train Batch 80/110 - Loss: 7.3082 (Macro: 1.4306, Energy: 1.0381, KLD: 2.5365, MC: 2.3031)\n",
      "Train Batch 90/110 - Loss: 6.7881 (Macro: 1.4704, Energy: 0.9911, KLD: 2.0241, MC: 2.3025)\n",
      "Train Batch 100/110 - Loss: 7.2994 (Macro: 1.5996, Energy: 1.1810, KLD: 2.2161, MC: 2.3027)\n",
      "Train Batch 110/110 - Loss: 6.6071 (Macro: 1.2281, Energy: 0.7391, KLD: 2.3414, MC: 2.2985)\n",
      "Training epoch complete. Average Loss: 7.0771\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0621\n",
      "\n",
      "Epoch 244/500\n",
      "Train Batch 10/110 - Loss: 7.1277 (Macro: 1.5865, Energy: 1.1273, KLD: 2.1149, MC: 2.2989)\n",
      "Train Batch 20/110 - Loss: 6.8823 (Macro: 1.4647, Energy: 0.9827, KLD: 2.1345, MC: 2.3004)\n",
      "Train Batch 30/110 - Loss: 7.0818 (Macro: 1.4620, Energy: 1.0121, KLD: 2.3073, MC: 2.3004)\n",
      "Train Batch 40/110 - Loss: 7.4242 (Macro: 1.5506, Energy: 1.1906, KLD: 2.3805, MC: 2.3025)\n",
      "Train Batch 50/110 - Loss: 7.0704 (Macro: 1.4908, Energy: 1.0385, KLD: 2.2381, MC: 2.3031)\n",
      "Train Batch 60/110 - Loss: 6.9120 (Macro: 1.3733, Energy: 0.9800, KLD: 2.2570, MC: 2.3016)\n",
      "Train Batch 70/110 - Loss: 6.9283 (Macro: 1.3381, Energy: 0.8487, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.3928 (Macro: 1.4456, Energy: 1.1080, KLD: 2.5365, MC: 2.3027)\n",
      "Train Batch 90/110 - Loss: 6.7952 (Macro: 1.4762, Energy: 0.9928, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.2957 (Macro: 1.5991, Energy: 1.1794, KLD: 2.2161, MC: 2.3011)\n",
      "Train Batch 110/110 - Loss: 6.6708 (Macro: 1.2296, Energy: 0.8045, KLD: 2.3414, MC: 2.2952)\n",
      "Training epoch complete. Average Loss: 7.0793\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0705\n",
      "\n",
      "Epoch 245/500\n",
      "Train Batch 10/110 - Loss: 7.1429 (Macro: 1.5912, Energy: 1.1367, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.9047 (Macro: 1.4971, Energy: 0.9734, KLD: 2.1345, MC: 2.2997)\n",
      "Train Batch 30/110 - Loss: 7.0626 (Macro: 1.4478, Energy: 1.0046, KLD: 2.3073, MC: 2.3029)\n",
      "Train Batch 40/110 - Loss: 7.4395 (Macro: 1.5464, Energy: 1.2108, KLD: 2.3805, MC: 2.3017)\n",
      "Train Batch 50/110 - Loss: 7.0252 (Macro: 1.4945, Energy: 0.9907, KLD: 2.2381, MC: 2.3020)\n",
      "Train Batch 60/110 - Loss: 6.9722 (Macro: 1.3950, Energy: 1.0199, KLD: 2.2570, MC: 2.3003)\n",
      "Train Batch 70/110 - Loss: 6.9451 (Macro: 1.3678, Energy: 0.8369, KLD: 2.4378, MC: 2.3026)\n",
      "Train Batch 80/110 - Loss: 7.2962 (Macro: 1.4138, Energy: 1.0411, KLD: 2.5365, MC: 2.3047)\n",
      "Train Batch 90/110 - Loss: 6.8157 (Macro: 1.4799, Energy: 1.0096, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3015 (Macro: 1.5858, Energy: 1.1985, KLD: 2.2161, MC: 2.3011)\n",
      "Train Batch 110/110 - Loss: 6.5708 (Macro: 1.2247, Energy: 0.7036, KLD: 2.3414, MC: 2.3011)\n",
      "Training epoch complete. Average Loss: 7.0760\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0558\n",
      "\n",
      "Epoch 246/500\n",
      "Train Batch 10/110 - Loss: 7.1176 (Macro: 1.5763, Energy: 1.1267, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.8800 (Macro: 1.4913, Energy: 0.9522, KLD: 2.1345, MC: 2.3021)\n",
      "Train Batch 30/110 - Loss: 7.0576 (Macro: 1.4505, Energy: 0.9969, KLD: 2.3073, MC: 2.3029)\n",
      "Train Batch 40/110 - Loss: 7.4674 (Macro: 1.5589, Energy: 1.2265, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.0345 (Macro: 1.4962, Energy: 0.9978, KLD: 2.2381, MC: 2.3025)\n",
      "Train Batch 60/110 - Loss: 6.9294 (Macro: 1.4070, Energy: 0.9636, KLD: 2.2570, MC: 2.3017)\n",
      "Train Batch 70/110 - Loss: 6.9986 (Macro: 1.3611, Energy: 0.8951, KLD: 2.4378, MC: 2.3046)\n",
      "Train Batch 80/110 - Loss: 7.3499 (Macro: 1.4416, Energy: 1.0683, KLD: 2.5365, MC: 2.3036)\n",
      "Train Batch 90/110 - Loss: 6.8029 (Macro: 1.4783, Energy: 0.9985, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3528 (Macro: 1.6108, Energy: 1.2241, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.6723 (Macro: 1.2150, Energy: 0.8187, KLD: 2.3414, MC: 2.2972)\n",
      "Training epoch complete. Average Loss: 7.0824\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0708\n",
      "\n",
      "Epoch 247/500\n",
      "Train Batch 10/110 - Loss: 7.1630 (Macro: 1.5676, Energy: 1.1790, KLD: 2.1149, MC: 2.3014)\n",
      "Train Batch 20/110 - Loss: 6.8320 (Macro: 1.4648, Energy: 0.9316, KLD: 2.1345, MC: 2.3011)\n",
      "Train Batch 30/110 - Loss: 7.1318 (Macro: 1.4337, Energy: 1.0890, KLD: 2.3073, MC: 2.3018)\n",
      "Train Batch 40/110 - Loss: 7.4525 (Macro: 1.5413, Energy: 1.2285, KLD: 2.3805, MC: 2.3022)\n",
      "Train Batch 50/110 - Loss: 7.0033 (Macro: 1.4990, Energy: 0.9634, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.9045 (Macro: 1.3902, Energy: 0.9537, KLD: 2.2570, MC: 2.3036)\n",
      "Train Batch 70/110 - Loss: 6.9360 (Macro: 1.3587, Energy: 0.8364, KLD: 2.4378, MC: 2.3031)\n",
      "Train Batch 80/110 - Loss: 7.3438 (Macro: 1.4262, Energy: 1.0785, KLD: 2.5365, MC: 2.3027)\n",
      "Train Batch 90/110 - Loss: 6.7788 (Macro: 1.4918, Energy: 0.9594, KLD: 2.0241, MC: 2.3035)\n",
      "Train Batch 100/110 - Loss: 7.3394 (Macro: 1.5974, Energy: 1.2259, KLD: 2.2161, MC: 2.3000)\n",
      "Train Batch 110/110 - Loss: 6.6846 (Macro: 1.2580, Energy: 0.7867, KLD: 2.3414, MC: 2.2985)\n",
      "Training epoch complete. Average Loss: 7.0781\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0674\n",
      "\n",
      "Epoch 248/500\n",
      "Train Batch 10/110 - Loss: 7.1273 (Macro: 1.5650, Energy: 1.1463, KLD: 2.1149, MC: 2.3011)\n",
      "Train Batch 20/110 - Loss: 6.9566 (Macro: 1.4865, Energy: 1.0341, KLD: 2.1345, MC: 2.3015)\n",
      "Train Batch 30/110 - Loss: 7.0566 (Macro: 1.4623, Energy: 0.9846, KLD: 2.3073, MC: 2.3025)\n",
      "Train Batch 40/110 - Loss: 7.4889 (Macro: 1.5609, Energy: 1.2473, KLD: 2.3805, MC: 2.3001)\n",
      "Train Batch 50/110 - Loss: 7.0591 (Macro: 1.4928, Energy: 1.0254, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.8932 (Macro: 1.4119, Energy: 0.9222, KLD: 2.2570, MC: 2.3021)\n",
      "Train Batch 70/110 - Loss: 6.9950 (Macro: 1.3683, Energy: 0.8855, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.3118 (Macro: 1.4377, Energy: 1.0361, KLD: 2.5365, MC: 2.3015)\n",
      "Train Batch 90/110 - Loss: 6.8216 (Macro: 1.4702, Energy: 1.0239, KLD: 2.0241, MC: 2.3035)\n",
      "Train Batch 100/110 - Loss: 7.2966 (Macro: 1.6122, Energy: 1.1661, KLD: 2.2161, MC: 2.3021)\n",
      "Train Batch 110/110 - Loss: 6.6480 (Macro: 1.2466, Energy: 0.7590, KLD: 2.3414, MC: 2.3010)\n",
      "Training epoch complete. Average Loss: 7.0791\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0696\n",
      "\n",
      "Epoch 249/500\n",
      "Train Batch 10/110 - Loss: 7.1252 (Macro: 1.5942, Energy: 1.1175, KLD: 2.1149, MC: 2.2985)\n",
      "Train Batch 20/110 - Loss: 6.8793 (Macro: 1.4816, Energy: 0.9613, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.1712 (Macro: 1.4665, Energy: 1.0963, KLD: 2.3073, MC: 2.3011)\n",
      "Train Batch 40/110 - Loss: 7.4911 (Macro: 1.5491, Energy: 1.2608, KLD: 2.3805, MC: 2.3007)\n",
      "Train Batch 50/110 - Loss: 7.0516 (Macro: 1.5055, Energy: 1.0067, KLD: 2.2381, MC: 2.3013)\n",
      "Train Batch 60/110 - Loss: 6.8812 (Macro: 1.3715, Energy: 0.9511, KLD: 2.2570, MC: 2.3016)\n",
      "Train Batch 70/110 - Loss: 6.9606 (Macro: 1.3585, Energy: 0.8601, KLD: 2.4378, MC: 2.3042)\n",
      "Train Batch 80/110 - Loss: 7.3114 (Macro: 1.4239, Energy: 1.0493, KLD: 2.5365, MC: 2.3016)\n",
      "Train Batch 90/110 - Loss: 6.7806 (Macro: 1.4968, Energy: 0.9569, KLD: 2.0241, MC: 2.3028)\n",
      "Train Batch 100/110 - Loss: 7.3109 (Macro: 1.6032, Energy: 1.1886, KLD: 2.2161, MC: 2.3030)\n",
      "Train Batch 110/110 - Loss: 6.6073 (Macro: 1.2179, Energy: 0.7485, KLD: 2.3414, MC: 2.2996)\n",
      "Training epoch complete. Average Loss: 7.0866\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0658\n",
      "\n",
      "Epoch 250/500\n",
      "Train Batch 10/110 - Loss: 7.0527 (Macro: 1.5776, Energy: 1.0606, KLD: 2.1149, MC: 2.2996)\n",
      "Train Batch 20/110 - Loss: 6.8873 (Macro: 1.4524, Energy: 0.9984, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.0840 (Macro: 1.4319, Energy: 1.0429, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4338 (Macro: 1.5379, Energy: 1.2140, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0251 (Macro: 1.5036, Energy: 0.9818, KLD: 2.2381, MC: 2.3017)\n",
      "Train Batch 60/110 - Loss: 6.8896 (Macro: 1.3758, Energy: 0.9553, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9707 (Macro: 1.3553, Energy: 0.8739, KLD: 2.4378, MC: 2.3038)\n",
      "Train Batch 80/110 - Loss: 7.2860 (Macro: 1.4217, Energy: 1.0255, KLD: 2.5365, MC: 2.3022)\n",
      "Train Batch 90/110 - Loss: 6.7579 (Macro: 1.4781, Energy: 0.9535, KLD: 2.0241, MC: 2.3023)\n",
      "Train Batch 100/110 - Loss: 7.3388 (Macro: 1.6032, Energy: 1.2186, KLD: 2.2161, MC: 2.3008)\n",
      "Train Batch 110/110 - Loss: 6.6302 (Macro: 1.2495, Energy: 0.7404, KLD: 2.3414, MC: 2.2989)\n",
      "Training epoch complete. Average Loss: 7.0757\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0642\n",
      "\n",
      "Epoch 251/500\n",
      "Train Batch 10/110 - Loss: 7.0910 (Macro: 1.5744, Energy: 1.1015, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.9079 (Macro: 1.4809, Energy: 0.9920, KLD: 2.1345, MC: 2.3005)\n",
      "Train Batch 30/110 - Loss: 7.1012 (Macro: 1.4516, Energy: 1.0397, KLD: 2.3073, MC: 2.3026)\n",
      "Train Batch 40/110 - Loss: 7.5108 (Macro: 1.5756, Energy: 1.2535, KLD: 2.3805, MC: 2.3011)\n",
      "Train Batch 50/110 - Loss: 7.0540 (Macro: 1.4925, Energy: 1.0194, KLD: 2.2381, MC: 2.3041)\n",
      "Train Batch 60/110 - Loss: 6.9117 (Macro: 1.3695, Energy: 0.9833, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 6.9363 (Macro: 1.3641, Energy: 0.8331, KLD: 2.4378, MC: 2.3014)\n",
      "Train Batch 80/110 - Loss: 7.3292 (Macro: 1.4098, Energy: 1.0803, KLD: 2.5365, MC: 2.3026)\n",
      "Train Batch 90/110 - Loss: 6.7792 (Macro: 1.4918, Energy: 0.9598, KLD: 2.0241, MC: 2.3034)\n",
      "Train Batch 100/110 - Loss: 7.3720 (Macro: 1.6199, Energy: 1.2350, KLD: 2.2161, MC: 2.3011)\n",
      "Train Batch 110/110 - Loss: 6.6325 (Macro: 1.2499, Energy: 0.7401, KLD: 2.3414, MC: 2.3011)\n",
      "Training epoch complete. Average Loss: 7.0850\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0794\n",
      "\n",
      "Epoch 252/500\n",
      "Train Batch 10/110 - Loss: 7.1376 (Macro: 1.5834, Energy: 1.1393, KLD: 2.1149, MC: 2.2999)\n",
      "Train Batch 20/110 - Loss: 6.8755 (Macro: 1.4644, Energy: 0.9757, KLD: 2.1345, MC: 2.3009)\n",
      "Train Batch 30/110 - Loss: 7.0246 (Macro: 1.4613, Energy: 0.9525, KLD: 2.3073, MC: 2.3035)\n",
      "Train Batch 40/110 - Loss: 7.4752 (Macro: 1.5625, Energy: 1.2323, KLD: 2.3805, MC: 2.2999)\n",
      "Train Batch 50/110 - Loss: 7.0552 (Macro: 1.5076, Energy: 1.0066, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.8921 (Macro: 1.3830, Energy: 0.9505, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9647 (Macro: 1.3828, Energy: 0.8417, KLD: 2.4378, MC: 2.3024)\n",
      "Train Batch 80/110 - Loss: 7.2754 (Macro: 1.4136, Energy: 1.0226, KLD: 2.5365, MC: 2.3026)\n",
      "Train Batch 90/110 - Loss: 6.8124 (Macro: 1.4752, Energy: 1.0122, KLD: 2.0241, MC: 2.3010)\n",
      "Train Batch 100/110 - Loss: 7.3132 (Macro: 1.5756, Energy: 1.2190, KLD: 2.2161, MC: 2.3025)\n",
      "Train Batch 110/110 - Loss: 6.5597 (Macro: 1.2020, Energy: 0.7175, KLD: 2.3414, MC: 2.2989)\n",
      "Training epoch complete. Average Loss: 7.0773\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0705\n",
      "\n",
      "Epoch 253/500\n",
      "Train Batch 10/110 - Loss: 7.1857 (Macro: 1.5780, Energy: 1.1928, KLD: 2.1149, MC: 2.2999)\n",
      "Train Batch 20/110 - Loss: 6.8996 (Macro: 1.4656, Energy: 0.9979, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.0487 (Macro: 1.4459, Energy: 0.9945, KLD: 2.3073, MC: 2.3011)\n",
      "Train Batch 40/110 - Loss: 7.5083 (Macro: 1.5612, Energy: 1.2648, KLD: 2.3805, MC: 2.3017)\n",
      "Train Batch 50/110 - Loss: 7.0721 (Macro: 1.4864, Energy: 1.0454, KLD: 2.2381, MC: 2.3022)\n",
      "Train Batch 60/110 - Loss: 6.8721 (Macro: 1.3674, Energy: 0.9461, KLD: 2.2570, MC: 2.3016)\n",
      "Train Batch 70/110 - Loss: 6.9965 (Macro: 1.3609, Energy: 0.8944, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.2906 (Macro: 1.4205, Energy: 1.0306, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.8195 (Macro: 1.4727, Energy: 1.0212, KLD: 2.0241, MC: 2.3015)\n",
      "Train Batch 100/110 - Loss: 7.2985 (Macro: 1.6069, Energy: 1.1724, KLD: 2.2161, MC: 2.3031)\n",
      "Train Batch 110/110 - Loss: 6.6319 (Macro: 1.2231, Energy: 0.7692, KLD: 2.3414, MC: 2.2982)\n",
      "Training epoch complete. Average Loss: 7.0774\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0700\n",
      "\n",
      "Epoch 254/500\n",
      "Train Batch 10/110 - Loss: 7.1019 (Macro: 1.5915, Energy: 1.0937, KLD: 2.1149, MC: 2.3017)\n",
      "Train Batch 20/110 - Loss: 6.8886 (Macro: 1.4956, Energy: 0.9583, KLD: 2.1345, MC: 2.3002)\n",
      "Train Batch 30/110 - Loss: 7.1215 (Macro: 1.4298, Energy: 1.0810, KLD: 2.3073, MC: 2.3034)\n",
      "Train Batch 40/110 - Loss: 7.4529 (Macro: 1.5471, Energy: 1.2212, KLD: 2.3805, MC: 2.3040)\n",
      "Train Batch 50/110 - Loss: 7.0730 (Macro: 1.5074, Energy: 1.0251, KLD: 2.2381, MC: 2.3024)\n",
      "Train Batch 60/110 - Loss: 6.9435 (Macro: 1.4044, Energy: 0.9790, KLD: 2.2570, MC: 2.3031)\n",
      "Train Batch 70/110 - Loss: 6.9615 (Macro: 1.3726, Energy: 0.8477, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.2848 (Macro: 1.4179, Energy: 1.0271, KLD: 2.5365, MC: 2.3033)\n",
      "Train Batch 90/110 - Loss: 6.8597 (Macro: 1.4790, Energy: 1.0561, KLD: 2.0241, MC: 2.3006)\n",
      "Train Batch 100/110 - Loss: 7.3471 (Macro: 1.6184, Energy: 1.2101, KLD: 2.2161, MC: 2.3026)\n",
      "Train Batch 110/110 - Loss: 6.5866 (Macro: 1.2165, Energy: 0.7286, KLD: 2.3414, MC: 2.3002)\n",
      "Training epoch complete. Average Loss: 7.0856\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0524\n",
      "\n",
      "Epoch 255/500\n",
      "Train Batch 10/110 - Loss: 7.1650 (Macro: 1.5717, Energy: 1.1768, KLD: 2.1149, MC: 2.3015)\n",
      "Train Batch 20/110 - Loss: 6.9045 (Macro: 1.4936, Energy: 0.9739, KLD: 2.1345, MC: 2.3026)\n",
      "Train Batch 30/110 - Loss: 7.0803 (Macro: 1.4619, Energy: 1.0093, KLD: 2.3073, MC: 2.3018)\n",
      "Train Batch 40/110 - Loss: 7.4320 (Macro: 1.5866, Energy: 1.1651, KLD: 2.3805, MC: 2.2998)\n",
      "Train Batch 50/110 - Loss: 7.0501 (Macro: 1.4853, Energy: 1.0238, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.9202 (Macro: 1.3899, Energy: 0.9696, KLD: 2.2570, MC: 2.3037)\n",
      "Train Batch 70/110 - Loss: 6.9266 (Macro: 1.3469, Energy: 0.8390, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.3428 (Macro: 1.4570, Energy: 1.0470, KLD: 2.5365, MC: 2.3024)\n",
      "Train Batch 90/110 - Loss: 6.8427 (Macro: 1.4834, Energy: 1.0336, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.2819 (Macro: 1.5933, Energy: 1.1711, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.6765 (Macro: 1.2689, Energy: 0.7680, KLD: 2.3414, MC: 2.2982)\n",
      "Training epoch complete. Average Loss: 7.0786\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0607\n",
      "\n",
      "Epoch 256/500\n",
      "Train Batch 10/110 - Loss: 7.1279 (Macro: 1.5758, Energy: 1.1353, KLD: 2.1149, MC: 2.3018)\n",
      "Train Batch 20/110 - Loss: 6.8688 (Macro: 1.4802, Energy: 0.9523, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0473 (Macro: 1.4546, Energy: 0.9849, KLD: 2.3073, MC: 2.3005)\n",
      "Train Batch 40/110 - Loss: 7.4399 (Macro: 1.5455, Energy: 1.2127, KLD: 2.3805, MC: 2.3012)\n",
      "Train Batch 50/110 - Loss: 7.0673 (Macro: 1.4829, Energy: 1.0441, KLD: 2.2381, MC: 2.3022)\n",
      "Train Batch 60/110 - Loss: 6.9351 (Macro: 1.3866, Energy: 0.9882, KLD: 2.2570, MC: 2.3033)\n",
      "Train Batch 70/110 - Loss: 6.9739 (Macro: 1.3561, Energy: 0.8753, KLD: 2.4378, MC: 2.3047)\n",
      "Train Batch 80/110 - Loss: 7.3309 (Macro: 1.4339, Energy: 1.0569, KLD: 2.5365, MC: 2.3036)\n",
      "Train Batch 90/110 - Loss: 6.7894 (Macro: 1.4918, Energy: 0.9721, KLD: 2.0241, MC: 2.3015)\n",
      "Train Batch 100/110 - Loss: 7.2681 (Macro: 1.6082, Energy: 1.1414, KLD: 2.2161, MC: 2.3024)\n",
      "Train Batch 110/110 - Loss: 6.5673 (Macro: 1.2220, Energy: 0.7027, KLD: 2.3414, MC: 2.3012)\n",
      "Training epoch complete. Average Loss: 7.0786\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0623\n",
      "\n",
      "Epoch 257/500\n",
      "Train Batch 10/110 - Loss: 7.1493 (Macro: 1.5911, Energy: 1.1443, KLD: 2.1149, MC: 2.2991)\n",
      "Train Batch 20/110 - Loss: 6.9053 (Macro: 1.4887, Energy: 0.9799, KLD: 2.1345, MC: 2.3022)\n",
      "Train Batch 30/110 - Loss: 7.1176 (Macro: 1.4497, Energy: 1.0591, KLD: 2.3073, MC: 2.3015)\n",
      "Train Batch 40/110 - Loss: 7.4113 (Macro: 1.5424, Energy: 1.1875, KLD: 2.3805, MC: 2.3009)\n",
      "Train Batch 50/110 - Loss: 7.1169 (Macro: 1.5284, Energy: 1.0477, KLD: 2.2381, MC: 2.3027)\n",
      "Train Batch 60/110 - Loss: 6.9125 (Macro: 1.3863, Energy: 0.9686, KLD: 2.2570, MC: 2.3005)\n",
      "Train Batch 70/110 - Loss: 6.9945 (Macro: 1.3706, Energy: 0.8838, KLD: 2.4378, MC: 2.3024)\n",
      "Train Batch 80/110 - Loss: 7.2837 (Macro: 1.4296, Energy: 1.0147, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.8147 (Macro: 1.4851, Energy: 1.0023, KLD: 2.0241, MC: 2.3032)\n",
      "Train Batch 100/110 - Loss: 7.2972 (Macro: 1.6172, Energy: 1.1613, KLD: 2.2161, MC: 2.3026)\n",
      "Train Batch 110/110 - Loss: 6.6542 (Macro: 1.2227, Energy: 0.7902, KLD: 2.3414, MC: 2.3000)\n",
      "Training epoch complete. Average Loss: 7.0796\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0588\n",
      "\n",
      "Epoch 258/500\n",
      "Train Batch 10/110 - Loss: 7.1763 (Macro: 1.5930, Energy: 1.1689, KLD: 2.1149, MC: 2.2996)\n",
      "Train Batch 20/110 - Loss: 6.9090 (Macro: 1.4947, Energy: 0.9771, KLD: 2.1345, MC: 2.3028)\n",
      "Train Batch 30/110 - Loss: 7.0812 (Macro: 1.4471, Energy: 1.0259, KLD: 2.3073, MC: 2.3009)\n",
      "Train Batch 40/110 - Loss: 7.5485 (Macro: 1.5797, Energy: 1.2859, KLD: 2.3805, MC: 2.3024)\n",
      "Train Batch 50/110 - Loss: 7.1069 (Macro: 1.5118, Energy: 1.0560, KLD: 2.2381, MC: 2.3012)\n",
      "Train Batch 60/110 - Loss: 6.8787 (Macro: 1.3730, Energy: 0.9478, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 6.9672 (Macro: 1.3546, Energy: 0.8712, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.2674 (Macro: 1.4235, Energy: 1.0043, KLD: 2.5365, MC: 2.3031)\n",
      "Train Batch 90/110 - Loss: 6.7807 (Macro: 1.4730, Energy: 0.9820, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.2623 (Macro: 1.6001, Energy: 1.1441, KLD: 2.2161, MC: 2.3021)\n",
      "Train Batch 110/110 - Loss: 6.5310 (Macro: 1.2162, Energy: 0.6754, KLD: 2.3414, MC: 2.2981)\n",
      "Training epoch complete. Average Loss: 7.0772\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0651\n",
      "\n",
      "Epoch 259/500\n",
      "Train Batch 10/110 - Loss: 7.1468 (Macro: 1.5683, Energy: 1.1639, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.8904 (Macro: 1.4944, Energy: 0.9603, KLD: 2.1345, MC: 2.3012)\n",
      "Train Batch 30/110 - Loss: 7.0827 (Macro: 1.4713, Energy: 1.0034, KLD: 2.3073, MC: 2.3007)\n",
      "Train Batch 40/110 - Loss: 7.4312 (Macro: 1.5266, Energy: 1.2238, KLD: 2.3805, MC: 2.3003)\n",
      "Train Batch 50/110 - Loss: 7.0478 (Macro: 1.4736, Energy: 1.0324, KLD: 2.2381, MC: 2.3037)\n",
      "Train Batch 60/110 - Loss: 6.9333 (Macro: 1.3808, Energy: 0.9929, KLD: 2.2570, MC: 2.3025)\n",
      "Train Batch 70/110 - Loss: 6.9772 (Macro: 1.3544, Energy: 0.8821, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.3255 (Macro: 1.4182, Energy: 1.0667, KLD: 2.5365, MC: 2.3042)\n",
      "Train Batch 90/110 - Loss: 6.7748 (Macro: 1.4618, Energy: 0.9869, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.3090 (Macro: 1.5984, Energy: 1.1911, KLD: 2.2161, MC: 2.3034)\n",
      "Train Batch 110/110 - Loss: 6.6997 (Macro: 1.2536, Energy: 0.8027, KLD: 2.3414, MC: 2.3021)\n",
      "Training epoch complete. Average Loss: 7.0819\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0594\n",
      "\n",
      "Epoch 260/500\n",
      "Train Batch 10/110 - Loss: 7.2102 (Macro: 1.5825, Energy: 1.2135, KLD: 2.1149, MC: 2.2992)\n",
      "Train Batch 20/110 - Loss: 6.9244 (Macro: 1.4791, Energy: 1.0079, KLD: 2.1345, MC: 2.3029)\n",
      "Train Batch 30/110 - Loss: 7.0907 (Macro: 1.4481, Energy: 1.0301, KLD: 2.3073, MC: 2.3052)\n",
      "Train Batch 40/110 - Loss: 7.4720 (Macro: 1.5512, Energy: 1.2400, KLD: 2.3805, MC: 2.3003)\n",
      "Train Batch 50/110 - Loss: 7.0529 (Macro: 1.5003, Energy: 1.0088, KLD: 2.2381, MC: 2.3058)\n",
      "Train Batch 60/110 - Loss: 6.8876 (Macro: 1.3848, Energy: 0.9456, KLD: 2.2570, MC: 2.3002)\n",
      "Train Batch 70/110 - Loss: 6.9701 (Macro: 1.3592, Energy: 0.8699, KLD: 2.4378, MC: 2.3032)\n",
      "Train Batch 80/110 - Loss: 7.2928 (Macro: 1.4186, Energy: 1.0356, KLD: 2.5365, MC: 2.3021)\n",
      "Train Batch 90/110 - Loss: 6.7513 (Macro: 1.4582, Energy: 0.9655, KLD: 2.0241, MC: 2.3035)\n",
      "Train Batch 100/110 - Loss: 7.2883 (Macro: 1.6011, Energy: 1.1688, KLD: 2.2161, MC: 2.3023)\n",
      "Train Batch 110/110 - Loss: 6.5980 (Macro: 1.2009, Energy: 0.7554, KLD: 2.3414, MC: 2.3003)\n",
      "Training epoch complete. Average Loss: 7.0783\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0710\n",
      "\n",
      "Epoch 261/500\n",
      "Train Batch 10/110 - Loss: 7.1143 (Macro: 1.5712, Energy: 1.1270, KLD: 2.1149, MC: 2.3011)\n",
      "Train Batch 20/110 - Loss: 6.9210 (Macro: 1.4737, Energy: 1.0104, KLD: 2.1345, MC: 2.3024)\n",
      "Train Batch 30/110 - Loss: 7.0744 (Macro: 1.4495, Energy: 1.0146, KLD: 2.3073, MC: 2.3029)\n",
      "Train Batch 40/110 - Loss: 7.4420 (Macro: 1.5338, Energy: 1.2255, KLD: 2.3805, MC: 2.3022)\n",
      "Train Batch 50/110 - Loss: 7.0478 (Macro: 1.4831, Energy: 1.0222, KLD: 2.2381, MC: 2.3045)\n",
      "Train Batch 60/110 - Loss: 6.8977 (Macro: 1.3769, Energy: 0.9633, KLD: 2.2570, MC: 2.3004)\n",
      "Train Batch 70/110 - Loss: 6.9762 (Macro: 1.3728, Energy: 0.8635, KLD: 2.4378, MC: 2.3022)\n",
      "Train Batch 80/110 - Loss: 7.2845 (Macro: 1.4247, Energy: 1.0203, KLD: 2.5365, MC: 2.3030)\n",
      "Train Batch 90/110 - Loss: 6.8516 (Macro: 1.4853, Energy: 1.0411, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.3327 (Macro: 1.6004, Energy: 1.2144, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.6073 (Macro: 1.2338, Energy: 0.7332, KLD: 2.3414, MC: 2.2989)\n",
      "Training epoch complete. Average Loss: 7.0795\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0506\n",
      "\n",
      "Epoch 262/500\n",
      "Train Batch 10/110 - Loss: 7.1482 (Macro: 1.5811, Energy: 1.1536, KLD: 2.1149, MC: 2.2986)\n",
      "Train Batch 20/110 - Loss: 6.8845 (Macro: 1.4791, Energy: 0.9677, KLD: 2.1345, MC: 2.3033)\n",
      "Train Batch 30/110 - Loss: 7.1333 (Macro: 1.4476, Energy: 1.0764, KLD: 2.3073, MC: 2.3020)\n",
      "Train Batch 40/110 - Loss: 7.4079 (Macro: 1.5544, Energy: 1.1713, KLD: 2.3805, MC: 2.3017)\n",
      "Train Batch 50/110 - Loss: 7.0063 (Macro: 1.4893, Energy: 0.9767, KLD: 2.2381, MC: 2.3023)\n",
      "Train Batch 60/110 - Loss: 6.8979 (Macro: 1.3662, Energy: 0.9725, KLD: 2.2570, MC: 2.3022)\n",
      "Train Batch 70/110 - Loss: 6.9890 (Macro: 1.3668, Energy: 0.8800, KLD: 2.4378, MC: 2.3044)\n",
      "Train Batch 80/110 - Loss: 7.3191 (Macro: 1.4238, Energy: 1.0569, KLD: 2.5365, MC: 2.3019)\n",
      "Train Batch 90/110 - Loss: 6.8322 (Macro: 1.4765, Energy: 1.0304, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.3142 (Macro: 1.6239, Energy: 1.1713, KLD: 2.2161, MC: 2.3029)\n",
      "Train Batch 110/110 - Loss: 6.6237 (Macro: 1.2211, Energy: 0.7627, KLD: 2.3414, MC: 2.2985)\n",
      "Training epoch complete. Average Loss: 7.0777\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0618\n",
      "\n",
      "Epoch 263/500\n",
      "Train Batch 10/110 - Loss: 7.1170 (Macro: 1.5795, Energy: 1.1215, KLD: 2.1149, MC: 2.3010)\n",
      "Train Batch 20/110 - Loss: 6.9423 (Macro: 1.4966, Energy: 1.0111, KLD: 2.1345, MC: 2.3002)\n",
      "Train Batch 30/110 - Loss: 7.0122 (Macro: 1.4152, Energy: 0.9888, KLD: 2.3073, MC: 2.3008)\n",
      "Train Batch 40/110 - Loss: 7.4899 (Macro: 1.5455, Energy: 1.2627, KLD: 2.3805, MC: 2.3012)\n",
      "Train Batch 50/110 - Loss: 7.0623 (Macro: 1.5125, Energy: 1.0097, KLD: 2.2381, MC: 2.3020)\n",
      "Train Batch 60/110 - Loss: 6.9153 (Macro: 1.3957, Energy: 0.9596, KLD: 2.2570, MC: 2.3029)\n",
      "Train Batch 70/110 - Loss: 6.9771 (Macro: 1.3599, Energy: 0.8768, KLD: 2.4378, MC: 2.3027)\n",
      "Train Batch 80/110 - Loss: 7.3157 (Macro: 1.4196, Energy: 1.0571, KLD: 2.5365, MC: 2.3025)\n",
      "Train Batch 90/110 - Loss: 6.8109 (Macro: 1.4744, Energy: 1.0088, KLD: 2.0241, MC: 2.3036)\n",
      "Train Batch 100/110 - Loss: 7.2598 (Macro: 1.5905, Energy: 1.1521, KLD: 2.2161, MC: 2.3011)\n",
      "Train Batch 110/110 - Loss: 6.7347 (Macro: 1.2659, Energy: 0.8294, KLD: 2.3414, MC: 2.2980)\n",
      "Training epoch complete. Average Loss: 7.0838\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0586\n",
      "\n",
      "Epoch 264/500\n",
      "Train Batch 10/110 - Loss: 7.1703 (Macro: 1.5648, Energy: 1.1901, KLD: 2.1149, MC: 2.3004)\n",
      "Train Batch 20/110 - Loss: 6.8722 (Macro: 1.4830, Energy: 0.9522, KLD: 2.1345, MC: 2.3024)\n",
      "Train Batch 30/110 - Loss: 7.1194 (Macro: 1.4568, Energy: 1.0525, KLD: 2.3073, MC: 2.3027)\n",
      "Train Batch 40/110 - Loss: 7.4016 (Macro: 1.5562, Energy: 1.1630, KLD: 2.3805, MC: 2.3020)\n",
      "Train Batch 50/110 - Loss: 7.0870 (Macro: 1.5074, Energy: 1.0395, KLD: 2.2381, MC: 2.3021)\n",
      "Train Batch 60/110 - Loss: 6.9316 (Macro: 1.4095, Energy: 0.9632, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 7.0086 (Macro: 1.3630, Energy: 0.9040, KLD: 2.4378, MC: 2.3038)\n",
      "Train Batch 80/110 - Loss: 7.2507 (Macro: 1.4026, Energy: 1.0083, KLD: 2.5365, MC: 2.3033)\n",
      "Train Batch 90/110 - Loss: 6.7983 (Macro: 1.4715, Energy: 1.0016, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.2908 (Macro: 1.5903, Energy: 1.1831, KLD: 2.2161, MC: 2.3014)\n",
      "Train Batch 110/110 - Loss: 6.6331 (Macro: 1.2286, Energy: 0.7634, KLD: 2.3414, MC: 2.2996)\n",
      "Training epoch complete. Average Loss: 7.0817\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0581\n",
      "\n",
      "Epoch 265/500\n",
      "Train Batch 10/110 - Loss: 7.1570 (Macro: 1.5930, Energy: 1.1492, KLD: 2.1149, MC: 2.2999)\n",
      "Train Batch 20/110 - Loss: 6.9523 (Macro: 1.5079, Energy: 1.0080, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.0540 (Macro: 1.4345, Energy: 1.0088, KLD: 2.3073, MC: 2.3035)\n",
      "Train Batch 40/110 - Loss: 7.4779 (Macro: 1.5430, Energy: 1.2536, KLD: 2.3805, MC: 2.3008)\n",
      "Train Batch 50/110 - Loss: 7.0392 (Macro: 1.5011, Energy: 0.9969, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.8984 (Macro: 1.3793, Energy: 0.9606, KLD: 2.2570, MC: 2.3014)\n",
      "Train Batch 70/110 - Loss: 6.9248 (Macro: 1.3394, Energy: 0.8439, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.2921 (Macro: 1.4182, Energy: 1.0345, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.7367 (Macro: 1.4814, Energy: 0.9314, KLD: 2.0241, MC: 2.2999)\n",
      "Train Batch 100/110 - Loss: 7.3514 (Macro: 1.6093, Energy: 1.2243, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.6143 (Macro: 1.2276, Energy: 0.7472, KLD: 2.3414, MC: 2.2981)\n",
      "Training epoch complete. Average Loss: 7.0791\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0531\n",
      "\n",
      "Epoch 266/500\n",
      "Train Batch 10/110 - Loss: 7.1491 (Macro: 1.5677, Energy: 1.1674, KLD: 2.1149, MC: 2.2991)\n",
      "Train Batch 20/110 - Loss: 6.8573 (Macro: 1.4732, Energy: 0.9468, KLD: 2.1345, MC: 2.3028)\n",
      "Train Batch 30/110 - Loss: 7.1293 (Macro: 1.4744, Energy: 1.0442, KLD: 2.3073, MC: 2.3034)\n",
      "Train Batch 40/110 - Loss: 7.4138 (Macro: 1.5466, Energy: 1.1851, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0609 (Macro: 1.4966, Energy: 1.0237, KLD: 2.2381, MC: 2.3026)\n",
      "Train Batch 60/110 - Loss: 6.9411 (Macro: 1.4026, Energy: 0.9800, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9208 (Macro: 1.3596, Energy: 0.8190, KLD: 2.4378, MC: 2.3045)\n",
      "Train Batch 80/110 - Loss: 7.3201 (Macro: 1.4296, Energy: 1.0525, KLD: 2.5365, MC: 2.3014)\n",
      "Train Batch 90/110 - Loss: 6.7773 (Macro: 1.4861, Energy: 0.9663, KLD: 2.0241, MC: 2.3008)\n",
      "Train Batch 100/110 - Loss: 7.3358 (Macro: 1.6164, Energy: 1.2000, KLD: 2.2161, MC: 2.3032)\n",
      "Train Batch 110/110 - Loss: 6.5845 (Macro: 1.2253, Energy: 0.7190, KLD: 2.3414, MC: 2.2989)\n",
      "Training epoch complete. Average Loss: 7.0852\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0720\n",
      "\n",
      "Epoch 267/500\n",
      "Train Batch 10/110 - Loss: 7.0998 (Macro: 1.5802, Energy: 1.1055, KLD: 2.1149, MC: 2.2991)\n",
      "Train Batch 20/110 - Loss: 6.9193 (Macro: 1.5132, Energy: 0.9688, KLD: 2.1345, MC: 2.3028)\n",
      "Train Batch 30/110 - Loss: 7.0743 (Macro: 1.4659, Energy: 0.9983, KLD: 2.3073, MC: 2.3028)\n",
      "Train Batch 40/110 - Loss: 7.4013 (Macro: 1.5409, Energy: 1.1780, KLD: 2.3805, MC: 2.3019)\n",
      "Train Batch 50/110 - Loss: 7.0655 (Macro: 1.5240, Energy: 0.9999, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.9106 (Macro: 1.3911, Energy: 0.9614, KLD: 2.2570, MC: 2.3012)\n",
      "Train Batch 70/110 - Loss: 7.0111 (Macro: 1.3625, Energy: 0.9062, KLD: 2.4378, MC: 2.3046)\n",
      "Train Batch 80/110 - Loss: 7.3560 (Macro: 1.4335, Energy: 1.0844, KLD: 2.5365, MC: 2.3016)\n",
      "Train Batch 90/110 - Loss: 6.7402 (Macro: 1.4832, Energy: 0.9304, KLD: 2.0241, MC: 2.3026)\n",
      "Train Batch 100/110 - Loss: 7.3325 (Macro: 1.6146, Energy: 1.1995, KLD: 2.2161, MC: 2.3023)\n",
      "Train Batch 110/110 - Loss: 6.5610 (Macro: 1.2287, Energy: 0.6936, KLD: 2.3414, MC: 2.2973)\n",
      "Training epoch complete. Average Loss: 7.0797\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0571\n",
      "\n",
      "Epoch 268/500\n",
      "Train Batch 10/110 - Loss: 7.0604 (Macro: 1.5578, Energy: 1.0871, KLD: 2.1149, MC: 2.3006)\n",
      "Train Batch 20/110 - Loss: 6.9273 (Macro: 1.5096, Energy: 0.9814, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0856 (Macro: 1.4567, Energy: 1.0189, KLD: 2.3073, MC: 2.3027)\n",
      "Train Batch 40/110 - Loss: 7.4724 (Macro: 1.5488, Energy: 1.2419, KLD: 2.3805, MC: 2.3012)\n",
      "Train Batch 50/110 - Loss: 7.0398 (Macro: 1.4879, Energy: 1.0099, KLD: 2.2381, MC: 2.3040)\n",
      "Train Batch 60/110 - Loss: 6.8456 (Macro: 1.3866, Energy: 0.9014, KLD: 2.2570, MC: 2.3006)\n",
      "Train Batch 70/110 - Loss: 6.9332 (Macro: 1.3500, Energy: 0.8444, KLD: 2.4378, MC: 2.3011)\n",
      "Train Batch 80/110 - Loss: 7.2868 (Macro: 1.4166, Energy: 1.0305, KLD: 2.5365, MC: 2.3031)\n",
      "Train Batch 90/110 - Loss: 6.7678 (Macro: 1.4614, Energy: 0.9810, KLD: 2.0241, MC: 2.3013)\n",
      "Train Batch 100/110 - Loss: 7.2739 (Macro: 1.5849, Energy: 1.1719, KLD: 2.2161, MC: 2.3010)\n",
      "Train Batch 110/110 - Loss: 6.6481 (Macro: 1.2767, Energy: 0.7303, KLD: 2.3414, MC: 2.2997)\n",
      "Training epoch complete. Average Loss: 7.0822\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0632\n",
      "\n",
      "Epoch 269/500\n",
      "Train Batch 10/110 - Loss: 7.0821 (Macro: 1.5737, Energy: 1.0935, KLD: 2.1149, MC: 2.2999)\n",
      "Train Batch 20/110 - Loss: 6.8736 (Macro: 1.4771, Energy: 0.9575, KLD: 2.1345, MC: 2.3045)\n",
      "Train Batch 30/110 - Loss: 7.0945 (Macro: 1.4365, Energy: 1.0492, KLD: 2.3073, MC: 2.3014)\n",
      "Train Batch 40/110 - Loss: 7.4621 (Macro: 1.5635, Energy: 1.2195, KLD: 2.3805, MC: 2.2986)\n",
      "Train Batch 50/110 - Loss: 7.0567 (Macro: 1.5006, Energy: 1.0149, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.9059 (Macro: 1.3793, Energy: 0.9686, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 6.9527 (Macro: 1.3765, Energy: 0.8344, KLD: 2.4378, MC: 2.3040)\n",
      "Train Batch 80/110 - Loss: 7.3110 (Macro: 1.4138, Energy: 1.0593, KLD: 2.5365, MC: 2.3014)\n",
      "Train Batch 90/110 - Loss: 6.8217 (Macro: 1.4901, Energy: 1.0048, KLD: 2.0241, MC: 2.3027)\n",
      "Train Batch 100/110 - Loss: 7.2581 (Macro: 1.5913, Energy: 1.1475, KLD: 2.2161, MC: 2.3032)\n",
      "Train Batch 110/110 - Loss: 6.6496 (Macro: 1.2327, Energy: 0.7750, KLD: 2.3414, MC: 2.3006)\n",
      "Training epoch complete. Average Loss: 7.0776\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0648\n",
      "\n",
      "Epoch 270/500\n",
      "Train Batch 10/110 - Loss: 7.0887 (Macro: 1.5749, Energy: 1.0985, KLD: 2.1149, MC: 2.3004)\n",
      "Train Batch 20/110 - Loss: 6.8880 (Macro: 1.4814, Energy: 0.9698, KLD: 2.1345, MC: 2.3023)\n",
      "Train Batch 30/110 - Loss: 7.0404 (Macro: 1.4428, Energy: 0.9889, KLD: 2.3073, MC: 2.3014)\n",
      "Train Batch 40/110 - Loss: 7.4703 (Macro: 1.5625, Energy: 1.2261, KLD: 2.3805, MC: 2.3013)\n",
      "Train Batch 50/110 - Loss: 7.0112 (Macro: 1.4749, Energy: 0.9944, KLD: 2.2381, MC: 2.3038)\n",
      "Train Batch 60/110 - Loss: 6.9758 (Macro: 1.4097, Energy: 1.0064, KLD: 2.2570, MC: 2.3026)\n",
      "Train Batch 70/110 - Loss: 6.9611 (Macro: 1.3662, Energy: 0.8538, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.3091 (Macro: 1.4193, Energy: 1.0495, KLD: 2.5365, MC: 2.3038)\n",
      "Train Batch 90/110 - Loss: 6.7718 (Macro: 1.4565, Energy: 0.9885, KLD: 2.0241, MC: 2.3026)\n",
      "Train Batch 100/110 - Loss: 7.2259 (Macro: 1.5915, Energy: 1.1162, KLD: 2.2161, MC: 2.3021)\n",
      "Train Batch 110/110 - Loss: 6.6069 (Macro: 1.2546, Energy: 0.7135, KLD: 2.3414, MC: 2.2974)\n",
      "Training epoch complete. Average Loss: 7.0731\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0650\n",
      "\n",
      "Epoch 271/500\n",
      "Train Batch 10/110 - Loss: 7.1800 (Macro: 1.6007, Energy: 1.1630, KLD: 2.1149, MC: 2.3013)\n",
      "Train Batch 20/110 - Loss: 6.8971 (Macro: 1.4642, Energy: 0.9968, KLD: 2.1345, MC: 2.3016)\n",
      "Train Batch 30/110 - Loss: 7.0710 (Macro: 1.4451, Energy: 1.0167, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4754 (Macro: 1.5812, Energy: 1.2122, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.0746 (Macro: 1.5001, Energy: 1.0345, KLD: 2.2381, MC: 2.3020)\n",
      "Train Batch 60/110 - Loss: 6.9304 (Macro: 1.3814, Energy: 0.9904, KLD: 2.2570, MC: 2.3017)\n",
      "Train Batch 70/110 - Loss: 6.9766 (Macro: 1.3572, Energy: 0.8783, KLD: 2.4378, MC: 2.3033)\n",
      "Train Batch 80/110 - Loss: 7.3164 (Macro: 1.4233, Energy: 1.0524, KLD: 2.5365, MC: 2.3042)\n",
      "Train Batch 90/110 - Loss: 6.8259 (Macro: 1.4978, Energy: 1.0029, KLD: 2.0241, MC: 2.3013)\n",
      "Train Batch 100/110 - Loss: 7.2527 (Macro: 1.5940, Energy: 1.1396, KLD: 2.2161, MC: 2.3030)\n",
      "Train Batch 110/110 - Loss: 6.5813 (Macro: 1.2279, Energy: 0.7149, KLD: 2.3414, MC: 2.2971)\n",
      "Training epoch complete. Average Loss: 7.0793\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0664\n",
      "\n",
      "Epoch 272/500\n",
      "Train Batch 10/110 - Loss: 7.1163 (Macro: 1.5578, Energy: 1.1427, KLD: 2.1149, MC: 2.3008)\n",
      "Train Batch 20/110 - Loss: 6.8636 (Macro: 1.4689, Energy: 0.9589, KLD: 2.1345, MC: 2.3013)\n",
      "Train Batch 30/110 - Loss: 7.1017 (Macro: 1.4520, Energy: 1.0406, KLD: 2.3073, MC: 2.3018)\n",
      "Train Batch 40/110 - Loss: 7.4579 (Macro: 1.5692, Energy: 1.2053, KLD: 2.3805, MC: 2.3029)\n",
      "Train Batch 50/110 - Loss: 7.0286 (Macro: 1.4873, Energy: 0.9999, KLD: 2.2381, MC: 2.3033)\n",
      "Train Batch 60/110 - Loss: 6.8997 (Macro: 1.4022, Energy: 0.9380, KLD: 2.2570, MC: 2.3025)\n",
      "Train Batch 70/110 - Loss: 6.9556 (Macro: 1.3561, Energy: 0.8566, KLD: 2.4378, MC: 2.3051)\n",
      "Train Batch 80/110 - Loss: 7.3144 (Macro: 1.4366, Energy: 1.0387, KLD: 2.5365, MC: 2.3026)\n",
      "Train Batch 90/110 - Loss: 6.7931 (Macro: 1.4551, Energy: 1.0113, KLD: 2.0241, MC: 2.3026)\n",
      "Train Batch 100/110 - Loss: 7.3010 (Macro: 1.6125, Energy: 1.1706, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.5882 (Macro: 1.2292, Energy: 0.7195, KLD: 2.3414, MC: 2.2982)\n",
      "Training epoch complete. Average Loss: 7.0803\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0720\n",
      "\n",
      "Epoch 273/500\n",
      "Train Batch 10/110 - Loss: 7.1222 (Macro: 1.5828, Energy: 1.1242, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.9065 (Macro: 1.5136, Energy: 0.9556, KLD: 2.1345, MC: 2.3028)\n",
      "Train Batch 30/110 - Loss: 7.0861 (Macro: 1.4680, Energy: 1.0102, KLD: 2.3073, MC: 2.3006)\n",
      "Train Batch 40/110 - Loss: 7.4041 (Macro: 1.5272, Energy: 1.1926, KLD: 2.3805, MC: 2.3037)\n",
      "Train Batch 50/110 - Loss: 7.0999 (Macro: 1.5046, Energy: 1.0545, KLD: 2.2381, MC: 2.3026)\n",
      "Train Batch 60/110 - Loss: 6.8952 (Macro: 1.3674, Energy: 0.9688, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.9418 (Macro: 1.3568, Energy: 0.8431, KLD: 2.4378, MC: 2.3041)\n",
      "Train Batch 80/110 - Loss: 7.2787 (Macro: 1.4132, Energy: 1.0253, KLD: 2.5365, MC: 2.3036)\n",
      "Train Batch 90/110 - Loss: 6.8479 (Macro: 1.4961, Energy: 1.0270, KLD: 2.0241, MC: 2.3008)\n",
      "Train Batch 100/110 - Loss: 7.2540 (Macro: 1.5916, Energy: 1.1433, KLD: 2.2161, MC: 2.3030)\n",
      "Train Batch 110/110 - Loss: 6.6387 (Macro: 1.2154, Energy: 0.7803, KLD: 2.3414, MC: 2.3017)\n",
      "Training epoch complete. Average Loss: 7.0825\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0601\n",
      "\n",
      "Epoch 274/500\n",
      "Train Batch 10/110 - Loss: 7.1668 (Macro: 1.5878, Energy: 1.1646, KLD: 2.1149, MC: 2.2995)\n",
      "Train Batch 20/110 - Loss: 6.9106 (Macro: 1.4802, Energy: 0.9940, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.0670 (Macro: 1.4482, Energy: 1.0097, KLD: 2.3073, MC: 2.3018)\n",
      "Train Batch 40/110 - Loss: 7.5300 (Macro: 1.5715, Energy: 1.2770, KLD: 2.3805, MC: 2.3010)\n",
      "Train Batch 50/110 - Loss: 7.0894 (Macro: 1.5097, Energy: 1.0400, KLD: 2.2381, MC: 2.3016)\n",
      "Train Batch 60/110 - Loss: 6.8744 (Macro: 1.3750, Energy: 0.9401, KLD: 2.2570, MC: 2.3022)\n",
      "Train Batch 70/110 - Loss: 6.9570 (Macro: 1.3536, Energy: 0.8621, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.2978 (Macro: 1.4162, Energy: 1.0423, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.8000 (Macro: 1.4829, Energy: 0.9927, KLD: 2.0241, MC: 2.3004)\n",
      "Train Batch 100/110 - Loss: 7.2720 (Macro: 1.5932, Energy: 1.1615, KLD: 2.2161, MC: 2.3012)\n",
      "Train Batch 110/110 - Loss: 6.6536 (Macro: 1.2320, Energy: 0.7807, KLD: 2.3414, MC: 2.2995)\n",
      "Training epoch complete. Average Loss: 7.0801\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0499\n",
      "\n",
      "Epoch 275/500\n",
      "Train Batch 10/110 - Loss: 7.1752 (Macro: 1.5830, Energy: 1.1777, KLD: 2.1149, MC: 2.2996)\n",
      "Train Batch 20/110 - Loss: 6.9476 (Macro: 1.5046, Energy: 1.0076, KLD: 2.1345, MC: 2.3009)\n",
      "Train Batch 30/110 - Loss: 7.0489 (Macro: 1.4487, Energy: 0.9919, KLD: 2.3073, MC: 2.3010)\n",
      "Train Batch 40/110 - Loss: 7.4244 (Macro: 1.5585, Energy: 1.1844, KLD: 2.3805, MC: 2.3010)\n",
      "Train Batch 50/110 - Loss: 7.0447 (Macro: 1.5088, Energy: 0.9930, KLD: 2.2381, MC: 2.3049)\n",
      "Train Batch 60/110 - Loss: 6.8742 (Macro: 1.3639, Energy: 0.9510, KLD: 2.2570, MC: 2.3023)\n",
      "Train Batch 70/110 - Loss: 6.9980 (Macro: 1.3654, Energy: 0.8939, KLD: 2.4378, MC: 2.3009)\n",
      "Train Batch 80/110 - Loss: 7.3074 (Macro: 1.4083, Energy: 1.0578, KLD: 2.5365, MC: 2.3048)\n",
      "Train Batch 90/110 - Loss: 6.7806 (Macro: 1.4739, Energy: 0.9806, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.3433 (Macro: 1.6132, Energy: 1.2118, KLD: 2.2161, MC: 2.3022)\n",
      "Train Batch 110/110 - Loss: 6.6324 (Macro: 1.2523, Energy: 0.7401, KLD: 2.3414, MC: 2.2986)\n",
      "Training epoch complete. Average Loss: 7.0844\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0631\n",
      "\n",
      "Epoch 276/500\n",
      "Train Batch 10/110 - Loss: 7.0621 (Macro: 1.5729, Energy: 1.0740, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.9015 (Macro: 1.4903, Energy: 0.9751, KLD: 2.1345, MC: 2.3016)\n",
      "Train Batch 30/110 - Loss: 7.1268 (Macro: 1.4594, Energy: 1.0584, KLD: 2.3073, MC: 2.3016)\n",
      "Train Batch 40/110 - Loss: 7.4301 (Macro: 1.5509, Energy: 1.1962, KLD: 2.3805, MC: 2.3025)\n",
      "Train Batch 50/110 - Loss: 7.0375 (Macro: 1.4895, Energy: 1.0067, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.9269 (Macro: 1.3893, Energy: 0.9800, KLD: 2.2570, MC: 2.3006)\n",
      "Train Batch 70/110 - Loss: 6.9486 (Macro: 1.3497, Energy: 0.8577, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.3146 (Macro: 1.4166, Energy: 1.0589, KLD: 2.5365, MC: 2.3027)\n",
      "Train Batch 90/110 - Loss: 6.7181 (Macro: 1.4496, Energy: 0.9412, KLD: 2.0241, MC: 2.3033)\n",
      "Train Batch 100/110 - Loss: 7.3373 (Macro: 1.5927, Energy: 1.2275, KLD: 2.2161, MC: 2.3010)\n",
      "Train Batch 110/110 - Loss: 6.6384 (Macro: 1.2269, Energy: 0.7717, KLD: 2.3414, MC: 2.2984)\n",
      "Training epoch complete. Average Loss: 7.0788\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0823\n",
      "\n",
      "Epoch 277/500\n",
      "Train Batch 10/110 - Loss: 7.1518 (Macro: 1.5682, Energy: 1.1693, KLD: 2.1149, MC: 2.2994)\n",
      "Train Batch 20/110 - Loss: 6.8946 (Macro: 1.4906, Energy: 0.9692, KLD: 2.1345, MC: 2.3003)\n",
      "Train Batch 30/110 - Loss: 7.0803 (Macro: 1.4414, Energy: 1.0313, KLD: 2.3073, MC: 2.3004)\n",
      "Train Batch 40/110 - Loss: 7.3947 (Macro: 1.5292, Energy: 1.1821, KLD: 2.3805, MC: 2.3028)\n",
      "Train Batch 50/110 - Loss: 7.0690 (Macro: 1.4989, Energy: 1.0286, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.9167 (Macro: 1.3861, Energy: 0.9745, KLD: 2.2570, MC: 2.2992)\n",
      "Train Batch 70/110 - Loss: 6.9245 (Macro: 1.3600, Energy: 0.8242, KLD: 2.4378, MC: 2.3025)\n",
      "Train Batch 80/110 - Loss: 7.3295 (Macro: 1.4178, Energy: 1.0706, KLD: 2.5365, MC: 2.3046)\n",
      "Train Batch 90/110 - Loss: 6.7794 (Macro: 1.4825, Energy: 0.9720, KLD: 2.0241, MC: 2.3009)\n",
      "Train Batch 100/110 - Loss: 7.3518 (Macro: 1.6116, Energy: 1.2225, KLD: 2.2161, MC: 2.3015)\n",
      "Train Batch 110/110 - Loss: 6.6530 (Macro: 1.2321, Energy: 0.7795, KLD: 2.3414, MC: 2.3000)\n",
      "Training epoch complete. Average Loss: 7.0785\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0659\n",
      "\n",
      "Epoch 278/500\n",
      "Train Batch 10/110 - Loss: 7.0739 (Macro: 1.5922, Energy: 1.0668, KLD: 2.1149, MC: 2.3000)\n",
      "Train Batch 20/110 - Loss: 6.9257 (Macro: 1.4911, Energy: 0.9978, KLD: 2.1345, MC: 2.3023)\n",
      "Train Batch 30/110 - Loss: 7.0716 (Macro: 1.4404, Energy: 1.0193, KLD: 2.3073, MC: 2.3046)\n",
      "Train Batch 40/110 - Loss: 7.4485 (Macro: 1.5375, Energy: 1.2279, KLD: 2.3805, MC: 2.3025)\n",
      "Train Batch 50/110 - Loss: 7.0171 (Macro: 1.4903, Energy: 0.9870, KLD: 2.2381, MC: 2.3018)\n",
      "Train Batch 60/110 - Loss: 6.9375 (Macro: 1.3952, Energy: 0.9832, KLD: 2.2570, MC: 2.3021)\n",
      "Train Batch 70/110 - Loss: 6.9467 (Macro: 1.3510, Energy: 0.8544, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.2742 (Macro: 1.4309, Energy: 1.0046, KLD: 2.5365, MC: 2.3022)\n",
      "Train Batch 90/110 - Loss: 6.8031 (Macro: 1.4757, Energy: 1.0016, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.3662 (Macro: 1.6279, Energy: 1.2200, KLD: 2.2161, MC: 2.3022)\n",
      "Train Batch 110/110 - Loss: 6.5656 (Macro: 1.2484, Energy: 0.6767, KLD: 2.3414, MC: 2.2992)\n",
      "Training epoch complete. Average Loss: 7.0778\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0572\n",
      "\n",
      "Epoch 279/500\n",
      "Train Batch 10/110 - Loss: 7.1304 (Macro: 1.5819, Energy: 1.1331, KLD: 2.1149, MC: 2.3005)\n",
      "Train Batch 20/110 - Loss: 6.9257 (Macro: 1.4976, Energy: 0.9922, KLD: 2.1345, MC: 2.3014)\n",
      "Train Batch 30/110 - Loss: 7.0280 (Macro: 1.4548, Energy: 0.9645, KLD: 2.3073, MC: 2.3015)\n",
      "Train Batch 40/110 - Loss: 7.4266 (Macro: 1.5438, Energy: 1.2009, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0431 (Macro: 1.5033, Energy: 1.0007, KLD: 2.2381, MC: 2.3011)\n",
      "Train Batch 60/110 - Loss: 6.8951 (Macro: 1.3921, Energy: 0.9439, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.9740 (Macro: 1.3513, Energy: 0.8828, KLD: 2.4378, MC: 2.3022)\n",
      "Train Batch 80/110 - Loss: 7.3355 (Macro: 1.4264, Energy: 1.0712, KLD: 2.5365, MC: 2.3014)\n",
      "Train Batch 90/110 - Loss: 6.7964 (Macro: 1.4569, Energy: 1.0150, KLD: 2.0241, MC: 2.3004)\n",
      "Train Batch 100/110 - Loss: 7.2669 (Macro: 1.5761, Energy: 1.1717, KLD: 2.2161, MC: 2.3029)\n",
      "Train Batch 110/110 - Loss: 6.5888 (Macro: 1.2191, Energy: 0.7257, KLD: 2.3414, MC: 2.3027)\n",
      "Training epoch complete. Average Loss: 7.0769\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0668\n",
      "\n",
      "Epoch 280/500\n",
      "Train Batch 10/110 - Loss: 7.1027 (Macro: 1.5796, Energy: 1.1106, KLD: 2.1149, MC: 2.2977)\n",
      "Train Batch 20/110 - Loss: 6.8823 (Macro: 1.4719, Energy: 0.9752, KLD: 2.1345, MC: 2.3008)\n",
      "Train Batch 30/110 - Loss: 7.1210 (Macro: 1.4395, Energy: 1.0730, KLD: 2.3073, MC: 2.3011)\n",
      "Train Batch 40/110 - Loss: 7.4537 (Macro: 1.5530, Energy: 1.2193, KLD: 2.3805, MC: 2.3008)\n",
      "Train Batch 50/110 - Loss: 7.0168 (Macro: 1.4948, Energy: 0.9800, KLD: 2.2381, MC: 2.3040)\n",
      "Train Batch 60/110 - Loss: 6.9559 (Macro: 1.3990, Energy: 0.9976, KLD: 2.2570, MC: 2.3022)\n",
      "Train Batch 70/110 - Loss: 7.0093 (Macro: 1.3567, Energy: 0.9111, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.2963 (Macro: 1.4177, Energy: 1.0395, KLD: 2.5365, MC: 2.3027)\n",
      "Train Batch 90/110 - Loss: 6.8112 (Macro: 1.4772, Energy: 1.0088, KLD: 2.0241, MC: 2.3011)\n",
      "Train Batch 100/110 - Loss: 7.2613 (Macro: 1.6072, Energy: 1.1368, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.5957 (Macro: 1.2061, Energy: 0.7482, KLD: 2.3414, MC: 2.3001)\n",
      "Training epoch complete. Average Loss: 7.0771\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0678\n",
      "\n",
      "Epoch 281/500\n",
      "Train Batch 10/110 - Loss: 7.1039 (Macro: 1.5759, Energy: 1.1131, KLD: 2.1149, MC: 2.3000)\n",
      "Train Batch 20/110 - Loss: 6.8912 (Macro: 1.4670, Energy: 0.9864, KLD: 2.1345, MC: 2.3033)\n",
      "Train Batch 30/110 - Loss: 7.0865 (Macro: 1.4344, Energy: 1.0422, KLD: 2.3073, MC: 2.3026)\n",
      "Train Batch 40/110 - Loss: 7.3847 (Macro: 1.5421, Energy: 1.1606, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.0442 (Macro: 1.4987, Energy: 1.0046, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.8807 (Macro: 1.3794, Energy: 0.9430, KLD: 2.2570, MC: 2.3012)\n",
      "Train Batch 70/110 - Loss: 6.9299 (Macro: 1.3651, Energy: 0.8241, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.2550 (Macro: 1.4161, Energy: 0.9984, KLD: 2.5365, MC: 2.3040)\n",
      "Train Batch 90/110 - Loss: 6.7650 (Macro: 1.4718, Energy: 0.9671, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.2678 (Macro: 1.5833, Energy: 1.1658, KLD: 2.2161, MC: 2.3027)\n",
      "Train Batch 110/110 - Loss: 6.6358 (Macro: 1.2413, Energy: 0.7562, KLD: 2.3414, MC: 2.2969)\n",
      "Training epoch complete. Average Loss: 7.0793\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0627\n",
      "\n",
      "Epoch 282/500\n",
      "Train Batch 10/110 - Loss: 7.1456 (Macro: 1.5657, Energy: 1.1649, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.9193 (Macro: 1.4969, Energy: 0.9875, KLD: 2.1345, MC: 2.3004)\n",
      "Train Batch 30/110 - Loss: 7.0775 (Macro: 1.4660, Energy: 1.0015, KLD: 2.3073, MC: 2.3027)\n",
      "Train Batch 40/110 - Loss: 7.4162 (Macro: 1.5414, Energy: 1.1910, KLD: 2.3805, MC: 2.3032)\n",
      "Train Batch 50/110 - Loss: 7.0447 (Macro: 1.4992, Energy: 1.0030, KLD: 2.2381, MC: 2.3044)\n",
      "Train Batch 60/110 - Loss: 6.9081 (Macro: 1.3709, Energy: 0.9782, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.9236 (Macro: 1.3468, Energy: 0.8361, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.3205 (Macro: 1.4177, Energy: 1.0651, KLD: 2.5365, MC: 2.3013)\n",
      "Train Batch 90/110 - Loss: 6.8491 (Macro: 1.4685, Energy: 1.0552, KLD: 2.0241, MC: 2.3014)\n",
      "Train Batch 100/110 - Loss: 7.3204 (Macro: 1.6062, Energy: 1.1970, KLD: 2.2161, MC: 2.3011)\n",
      "Train Batch 110/110 - Loss: 6.6456 (Macro: 1.2314, Energy: 0.7730, KLD: 2.3414, MC: 2.2999)\n",
      "Training epoch complete. Average Loss: 7.0804\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0690\n",
      "\n",
      "Epoch 283/500\n",
      "Train Batch 10/110 - Loss: 7.1459 (Macro: 1.5740, Energy: 1.1566, KLD: 2.1149, MC: 2.3004)\n",
      "Train Batch 20/110 - Loss: 6.9131 (Macro: 1.4897, Energy: 0.9877, KLD: 2.1345, MC: 2.3011)\n",
      "Train Batch 30/110 - Loss: 7.0914 (Macro: 1.4457, Energy: 1.0380, KLD: 2.3073, MC: 2.3005)\n",
      "Train Batch 40/110 - Loss: 7.4986 (Macro: 1.5702, Energy: 1.2443, KLD: 2.3805, MC: 2.3035)\n",
      "Train Batch 50/110 - Loss: 7.0871 (Macro: 1.5039, Energy: 1.0435, KLD: 2.2381, MC: 2.3017)\n",
      "Train Batch 60/110 - Loss: 6.8571 (Macro: 1.3785, Energy: 0.9210, KLD: 2.2570, MC: 2.3006)\n",
      "Train Batch 70/110 - Loss: 6.9630 (Macro: 1.3602, Energy: 0.8622, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.3400 (Macro: 1.4116, Energy: 1.0885, KLD: 2.5365, MC: 2.3034)\n",
      "Train Batch 90/110 - Loss: 6.8259 (Macro: 1.4916, Energy: 1.0088, KLD: 2.0241, MC: 2.3014)\n",
      "Train Batch 100/110 - Loss: 7.3328 (Macro: 1.6131, Energy: 1.2007, KLD: 2.2161, MC: 2.3029)\n",
      "Train Batch 110/110 - Loss: 6.6205 (Macro: 1.2210, Energy: 0.7578, KLD: 2.3414, MC: 2.3004)\n",
      "Training epoch complete. Average Loss: 7.0809\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0604\n",
      "\n",
      "Epoch 284/500\n",
      "Train Batch 10/110 - Loss: 7.1203 (Macro: 1.5927, Energy: 1.1143, KLD: 2.1149, MC: 2.2984)\n",
      "Train Batch 20/110 - Loss: 6.8925 (Macro: 1.5039, Energy: 0.9510, KLD: 2.1345, MC: 2.3032)\n",
      "Train Batch 30/110 - Loss: 7.0614 (Macro: 1.4366, Energy: 1.0146, KLD: 2.3073, MC: 2.3029)\n",
      "Train Batch 40/110 - Loss: 7.4519 (Macro: 1.5500, Energy: 1.2190, KLD: 2.3805, MC: 2.3025)\n",
      "Train Batch 50/110 - Loss: 7.0789 (Macro: 1.5147, Energy: 1.0229, KLD: 2.2381, MC: 2.3033)\n",
      "Train Batch 60/110 - Loss: 6.9441 (Macro: 1.3920, Energy: 0.9930, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.9845 (Macro: 1.3652, Energy: 0.8768, KLD: 2.4378, MC: 2.3047)\n",
      "Train Batch 80/110 - Loss: 7.2768 (Macro: 1.4222, Energy: 1.0156, KLD: 2.5365, MC: 2.3026)\n",
      "Train Batch 90/110 - Loss: 6.7864 (Macro: 1.4721, Energy: 0.9889, KLD: 2.0241, MC: 2.3013)\n",
      "Train Batch 100/110 - Loss: 7.2744 (Macro: 1.5948, Energy: 1.1629, KLD: 2.2161, MC: 2.3006)\n",
      "Train Batch 110/110 - Loss: 6.6980 (Macro: 1.2184, Energy: 0.8392, KLD: 2.3414, MC: 2.2990)\n",
      "Training epoch complete. Average Loss: 7.0822\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0481\n",
      "\n",
      "Epoch 285/500\n",
      "Train Batch 10/110 - Loss: 7.1229 (Macro: 1.5750, Energy: 1.1328, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.8695 (Macro: 1.4819, Energy: 0.9502, KLD: 2.1345, MC: 2.3029)\n",
      "Train Batch 30/110 - Loss: 7.0768 (Macro: 1.4436, Energy: 1.0250, KLD: 2.3073, MC: 2.3010)\n",
      "Train Batch 40/110 - Loss: 7.4936 (Macro: 1.5631, Energy: 1.2480, KLD: 2.3805, MC: 2.3020)\n",
      "Train Batch 50/110 - Loss: 7.0516 (Macro: 1.5181, Energy: 0.9931, KLD: 2.2381, MC: 2.3024)\n",
      "Train Batch 60/110 - Loss: 6.9403 (Macro: 1.3880, Energy: 0.9957, KLD: 2.2570, MC: 2.2995)\n",
      "Train Batch 70/110 - Loss: 6.9434 (Macro: 1.3541, Energy: 0.8478, KLD: 2.4378, MC: 2.3038)\n",
      "Train Batch 80/110 - Loss: 7.3146 (Macro: 1.4147, Energy: 1.0608, KLD: 2.5365, MC: 2.3026)\n",
      "Train Batch 90/110 - Loss: 6.8640 (Macro: 1.4939, Energy: 1.0434, KLD: 2.0241, MC: 2.3026)\n",
      "Train Batch 100/110 - Loss: 7.2940 (Macro: 1.5921, Energy: 1.1845, KLD: 2.2161, MC: 2.3012)\n",
      "Train Batch 110/110 - Loss: 6.5692 (Macro: 1.2196, Energy: 0.7094, KLD: 2.3414, MC: 2.2989)\n",
      "Training epoch complete. Average Loss: 7.0768\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0610\n",
      "\n",
      "Epoch 286/500\n",
      "Train Batch 10/110 - Loss: 7.0811 (Macro: 1.5731, Energy: 1.0935, KLD: 2.1149, MC: 2.2996)\n",
      "Train Batch 20/110 - Loss: 6.9282 (Macro: 1.5034, Energy: 0.9874, KLD: 2.1345, MC: 2.3029)\n",
      "Train Batch 30/110 - Loss: 7.0837 (Macro: 1.4531, Energy: 1.0206, KLD: 2.3073, MC: 2.3028)\n",
      "Train Batch 40/110 - Loss: 7.4308 (Macro: 1.5526, Energy: 1.1963, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0629 (Macro: 1.4969, Energy: 1.0250, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.9113 (Macro: 1.3903, Energy: 0.9624, KLD: 2.2570, MC: 2.3016)\n",
      "Train Batch 70/110 - Loss: 6.9927 (Macro: 1.3575, Energy: 0.8934, KLD: 2.4378, MC: 2.3040)\n",
      "Train Batch 80/110 - Loss: 7.2851 (Macro: 1.4108, Energy: 1.0367, KLD: 2.5365, MC: 2.3012)\n",
      "Train Batch 90/110 - Loss: 6.8084 (Macro: 1.4827, Energy: 0.9985, KLD: 2.0241, MC: 2.3031)\n",
      "Train Batch 100/110 - Loss: 7.3069 (Macro: 1.6123, Energy: 1.1779, KLD: 2.2161, MC: 2.3006)\n",
      "Train Batch 110/110 - Loss: 6.6954 (Macro: 1.2657, Energy: 0.7891, KLD: 2.3414, MC: 2.2993)\n",
      "Training epoch complete. Average Loss: 7.0853\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0615\n",
      "\n",
      "Epoch 287/500\n",
      "Train Batch 10/110 - Loss: 7.1738 (Macro: 1.5736, Energy: 1.1856, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.8927 (Macro: 1.4886, Energy: 0.9669, KLD: 2.1345, MC: 2.3027)\n",
      "Train Batch 30/110 - Loss: 7.0883 (Macro: 1.4515, Energy: 1.0263, KLD: 2.3073, MC: 2.3033)\n",
      "Train Batch 40/110 - Loss: 7.4397 (Macro: 1.5592, Energy: 1.1997, KLD: 2.3805, MC: 2.3002)\n",
      "Train Batch 50/110 - Loss: 7.0624 (Macro: 1.4845, Energy: 1.0369, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.9434 (Macro: 1.3995, Energy: 0.9835, KLD: 2.2570, MC: 2.3034)\n",
      "Train Batch 70/110 - Loss: 6.9774 (Macro: 1.3573, Energy: 0.8782, KLD: 2.4378, MC: 2.3040)\n",
      "Train Batch 80/110 - Loss: 7.2690 (Macro: 1.4128, Energy: 1.0171, KLD: 2.5365, MC: 2.3026)\n",
      "Train Batch 90/110 - Loss: 6.7391 (Macro: 1.4684, Energy: 0.9450, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.3276 (Macro: 1.6000, Energy: 1.2092, KLD: 2.2161, MC: 2.3023)\n",
      "Train Batch 110/110 - Loss: 6.6561 (Macro: 1.2355, Energy: 0.7779, KLD: 2.3414, MC: 2.3013)\n",
      "Training epoch complete. Average Loss: 7.0799\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0583\n",
      "\n",
      "Epoch 288/500\n",
      "Train Batch 10/110 - Loss: 7.0923 (Macro: 1.5912, Energy: 1.0879, KLD: 2.1149, MC: 2.2982)\n",
      "Train Batch 20/110 - Loss: 6.8660 (Macro: 1.4750, Energy: 0.9542, KLD: 2.1345, MC: 2.3024)\n",
      "Train Batch 30/110 - Loss: 7.0504 (Macro: 1.4620, Energy: 0.9776, KLD: 2.3073, MC: 2.3035)\n",
      "Train Batch 40/110 - Loss: 7.4365 (Macro: 1.5562, Energy: 1.1987, KLD: 2.3805, MC: 2.3011)\n",
      "Train Batch 50/110 - Loss: 7.0920 (Macro: 1.5179, Energy: 1.0318, KLD: 2.2381, MC: 2.3042)\n",
      "Train Batch 60/110 - Loss: 6.8891 (Macro: 1.3695, Energy: 0.9601, KLD: 2.2570, MC: 2.3024)\n",
      "Train Batch 70/110 - Loss: 6.9747 (Macro: 1.3764, Energy: 0.8584, KLD: 2.4378, MC: 2.3022)\n",
      "Train Batch 80/110 - Loss: 7.3573 (Macro: 1.4457, Energy: 1.0711, KLD: 2.5365, MC: 2.3040)\n",
      "Train Batch 90/110 - Loss: 6.7914 (Macro: 1.4637, Energy: 1.0031, KLD: 2.0241, MC: 2.3005)\n",
      "Train Batch 100/110 - Loss: 7.3047 (Macro: 1.6042, Energy: 1.1832, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.6479 (Macro: 1.2618, Energy: 0.7462, KLD: 2.3414, MC: 2.2986)\n",
      "Training epoch complete. Average Loss: 7.0772\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0663\n",
      "\n",
      "Epoch 289/500\n",
      "Train Batch 10/110 - Loss: 7.1832 (Macro: 1.5962, Energy: 1.1722, KLD: 2.1149, MC: 2.2999)\n",
      "Train Batch 20/110 - Loss: 6.9457 (Macro: 1.4871, Energy: 1.0229, KLD: 2.1345, MC: 2.3012)\n",
      "Train Batch 30/110 - Loss: 7.1200 (Macro: 1.4504, Energy: 1.0589, KLD: 2.3073, MC: 2.3034)\n",
      "Train Batch 40/110 - Loss: 7.3913 (Macro: 1.5340, Energy: 1.1738, KLD: 2.3805, MC: 2.3029)\n",
      "Train Batch 50/110 - Loss: 7.0411 (Macro: 1.4834, Energy: 1.0163, KLD: 2.2381, MC: 2.3034)\n",
      "Train Batch 60/110 - Loss: 6.9281 (Macro: 1.3829, Energy: 0.9861, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.9670 (Macro: 1.3753, Energy: 0.8511, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.2989 (Macro: 1.4228, Energy: 1.0363, KLD: 2.5365, MC: 2.3033)\n",
      "Train Batch 90/110 - Loss: 6.8127 (Macro: 1.4864, Energy: 0.9998, KLD: 2.0241, MC: 2.3024)\n",
      "Train Batch 100/110 - Loss: 7.3143 (Macro: 1.6203, Energy: 1.1750, KLD: 2.2161, MC: 2.3029)\n",
      "Train Batch 110/110 - Loss: 6.5645 (Macro: 1.2305, Energy: 0.6935, KLD: 2.3414, MC: 2.2991)\n",
      "Training epoch complete. Average Loss: 7.0770\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0561\n",
      "\n",
      "Epoch 290/500\n",
      "Train Batch 10/110 - Loss: 7.1421 (Macro: 1.5868, Energy: 1.1417, KLD: 2.1149, MC: 2.2987)\n",
      "Train Batch 20/110 - Loss: 6.8876 (Macro: 1.4905, Energy: 0.9612, KLD: 2.1345, MC: 2.3015)\n",
      "Train Batch 30/110 - Loss: 7.0541 (Macro: 1.4367, Energy: 1.0084, KLD: 2.3073, MC: 2.3016)\n",
      "Train Batch 40/110 - Loss: 7.4264 (Macro: 1.5594, Energy: 1.1863, KLD: 2.3805, MC: 2.3002)\n",
      "Train Batch 50/110 - Loss: 7.0598 (Macro: 1.4817, Energy: 1.0356, KLD: 2.2381, MC: 2.3044)\n",
      "Train Batch 60/110 - Loss: 6.9079 (Macro: 1.3817, Energy: 0.9670, KLD: 2.2570, MC: 2.3022)\n",
      "Train Batch 70/110 - Loss: 6.9334 (Macro: 1.3543, Energy: 0.8375, KLD: 2.4378, MC: 2.3038)\n",
      "Train Batch 80/110 - Loss: 7.2979 (Macro: 1.4406, Energy: 1.0166, KLD: 2.5365, MC: 2.3042)\n",
      "Train Batch 90/110 - Loss: 6.7912 (Macro: 1.4932, Energy: 0.9728, KLD: 2.0241, MC: 2.3011)\n",
      "Train Batch 100/110 - Loss: 7.3037 (Macro: 1.5896, Energy: 1.1963, KLD: 2.2161, MC: 2.3017)\n",
      "Train Batch 110/110 - Loss: 6.6008 (Macro: 1.2231, Energy: 0.7392, KLD: 2.3414, MC: 2.2972)\n",
      "Training epoch complete. Average Loss: 7.0728\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0561\n",
      "\n",
      "Epoch 291/500\n",
      "Train Batch 10/110 - Loss: 7.1115 (Macro: 1.5775, Energy: 1.1170, KLD: 2.1149, MC: 2.3020)\n",
      "Train Batch 20/110 - Loss: 6.8993 (Macro: 1.4809, Energy: 0.9832, KLD: 2.1345, MC: 2.3006)\n",
      "Train Batch 30/110 - Loss: 7.0554 (Macro: 1.4439, Energy: 1.0024, KLD: 2.3073, MC: 2.3018)\n",
      "Train Batch 40/110 - Loss: 7.4259 (Macro: 1.5508, Energy: 1.1924, KLD: 2.3805, MC: 2.3022)\n",
      "Train Batch 50/110 - Loss: 7.0770 (Macro: 1.5142, Energy: 1.0226, KLD: 2.2381, MC: 2.3021)\n",
      "Train Batch 60/110 - Loss: 6.9132 (Macro: 1.3906, Energy: 0.9630, KLD: 2.2570, MC: 2.3026)\n",
      "Train Batch 70/110 - Loss: 6.9540 (Macro: 1.3705, Energy: 0.8413, KLD: 2.4378, MC: 2.3044)\n",
      "Train Batch 80/110 - Loss: 7.2828 (Macro: 1.4214, Energy: 1.0228, KLD: 2.5365, MC: 2.3020)\n",
      "Train Batch 90/110 - Loss: 6.8536 (Macro: 1.4848, Energy: 1.0428, KLD: 2.0241, MC: 2.3019)\n",
      "Train Batch 100/110 - Loss: 7.3646 (Macro: 1.6074, Energy: 1.2382, KLD: 2.2161, MC: 2.3030)\n",
      "Train Batch 110/110 - Loss: 6.6246 (Macro: 1.2435, Energy: 0.7413, KLD: 2.3414, MC: 2.2984)\n",
      "Training epoch complete. Average Loss: 7.0778\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0632\n",
      "\n",
      "Epoch 292/500\n",
      "Train Batch 10/110 - Loss: 7.1440 (Macro: 1.5844, Energy: 1.1452, KLD: 2.1149, MC: 2.2994)\n",
      "Train Batch 20/110 - Loss: 6.8964 (Macro: 1.4855, Energy: 0.9760, KLD: 2.1345, MC: 2.3003)\n",
      "Train Batch 30/110 - Loss: 7.0448 (Macro: 1.4569, Energy: 0.9789, KLD: 2.3073, MC: 2.3017)\n",
      "Train Batch 40/110 - Loss: 7.4348 (Macro: 1.5465, Energy: 1.2070, KLD: 2.3805, MC: 2.3008)\n",
      "Train Batch 50/110 - Loss: 7.0601 (Macro: 1.4907, Energy: 1.0279, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.8559 (Macro: 1.3726, Energy: 0.9247, KLD: 2.2570, MC: 2.3016)\n",
      "Train Batch 70/110 - Loss: 6.9003 (Macro: 1.3466, Energy: 0.8144, KLD: 2.4378, MC: 2.3015)\n",
      "Train Batch 80/110 - Loss: 7.3266 (Macro: 1.4255, Energy: 1.0617, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.7458 (Macro: 1.4716, Energy: 0.9473, KLD: 2.0241, MC: 2.3029)\n",
      "Train Batch 100/110 - Loss: 7.3159 (Macro: 1.5910, Energy: 1.2060, KLD: 2.2161, MC: 2.3028)\n",
      "Train Batch 110/110 - Loss: 6.5962 (Macro: 1.2082, Energy: 0.7469, KLD: 2.3414, MC: 2.2997)\n",
      "Training epoch complete. Average Loss: 7.0831\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0725\n",
      "\n",
      "Epoch 293/500\n",
      "Train Batch 10/110 - Loss: 7.0548 (Macro: 1.5754, Energy: 1.0641, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.8820 (Macro: 1.4814, Energy: 0.9645, KLD: 2.1345, MC: 2.3016)\n",
      "Train Batch 30/110 - Loss: 7.0921 (Macro: 1.4431, Energy: 1.0407, KLD: 2.3073, MC: 2.3011)\n",
      "Train Batch 40/110 - Loss: 7.4597 (Macro: 1.5411, Energy: 1.2385, KLD: 2.3805, MC: 2.2996)\n",
      "Train Batch 50/110 - Loss: 7.0618 (Macro: 1.4954, Energy: 1.0273, KLD: 2.2381, MC: 2.3010)\n",
      "Train Batch 60/110 - Loss: 6.9117 (Macro: 1.3769, Energy: 0.9771, KLD: 2.2570, MC: 2.3007)\n",
      "Train Batch 70/110 - Loss: 6.9859 (Macro: 1.3757, Energy: 0.8687, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.2611 (Macro: 1.4275, Energy: 0.9939, KLD: 2.5365, MC: 2.3033)\n",
      "Train Batch 90/110 - Loss: 6.8032 (Macro: 1.4723, Energy: 1.0037, KLD: 2.0241, MC: 2.3031)\n",
      "Train Batch 100/110 - Loss: 7.3618 (Macro: 1.6120, Energy: 1.2324, KLD: 2.2161, MC: 2.3014)\n",
      "Train Batch 110/110 - Loss: 6.6012 (Macro: 1.2196, Energy: 0.7415, KLD: 2.3414, MC: 2.2987)\n",
      "Training epoch complete. Average Loss: 7.0776\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0529\n",
      "\n",
      "Epoch 294/500\n",
      "Train Batch 10/110 - Loss: 7.0653 (Macro: 1.5716, Energy: 1.0783, KLD: 2.1149, MC: 2.3005)\n",
      "Train Batch 20/110 - Loss: 6.8681 (Macro: 1.4941, Energy: 0.9374, KLD: 2.1345, MC: 2.3021)\n",
      "Train Batch 30/110 - Loss: 7.0327 (Macro: 1.4364, Energy: 0.9878, KLD: 2.3073, MC: 2.3013)\n",
      "Train Batch 40/110 - Loss: 7.4139 (Macro: 1.5523, Energy: 1.1792, KLD: 2.3805, MC: 2.3019)\n",
      "Train Batch 50/110 - Loss: 7.0243 (Macro: 1.5073, Energy: 0.9777, KLD: 2.2381, MC: 2.3013)\n",
      "Train Batch 60/110 - Loss: 6.9628 (Macro: 1.3806, Energy: 1.0234, KLD: 2.2570, MC: 2.3017)\n",
      "Train Batch 70/110 - Loss: 6.9677 (Macro: 1.3724, Energy: 0.8540, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.2677 (Macro: 1.4179, Energy: 1.0086, KLD: 2.5365, MC: 2.3047)\n",
      "Train Batch 90/110 - Loss: 6.7831 (Macro: 1.4708, Energy: 0.9870, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.3454 (Macro: 1.6200, Energy: 1.2070, KLD: 2.2161, MC: 2.3023)\n",
      "Train Batch 110/110 - Loss: 6.5762 (Macro: 1.2117, Energy: 0.7244, KLD: 2.3414, MC: 2.2987)\n",
      "Training epoch complete. Average Loss: 7.0795\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0650\n",
      "\n",
      "Epoch 295/500\n",
      "Train Batch 10/110 - Loss: 7.1053 (Macro: 1.5819, Energy: 1.1089, KLD: 2.1149, MC: 2.2996)\n",
      "Train Batch 20/110 - Loss: 6.9003 (Macro: 1.4898, Energy: 0.9744, KLD: 2.1345, MC: 2.3015)\n",
      "Train Batch 30/110 - Loss: 7.0948 (Macro: 1.4617, Energy: 1.0232, KLD: 2.3073, MC: 2.3026)\n",
      "Train Batch 40/110 - Loss: 7.4315 (Macro: 1.5573, Energy: 1.1925, KLD: 2.3805, MC: 2.3012)\n",
      "Train Batch 50/110 - Loss: 7.0113 (Macro: 1.5006, Energy: 0.9709, KLD: 2.2381, MC: 2.3019)\n",
      "Train Batch 60/110 - Loss: 6.9551 (Macro: 1.3846, Energy: 1.0136, KLD: 2.2570, MC: 2.2998)\n",
      "Train Batch 70/110 - Loss: 6.9682 (Macro: 1.3623, Energy: 0.8639, KLD: 2.4378, MC: 2.3042)\n",
      "Train Batch 80/110 - Loss: 7.3040 (Macro: 1.4171, Energy: 1.0476, KLD: 2.5365, MC: 2.3027)\n",
      "Train Batch 90/110 - Loss: 6.8152 (Macro: 1.4757, Energy: 1.0140, KLD: 2.0241, MC: 2.3015)\n",
      "Train Batch 100/110 - Loss: 7.2886 (Macro: 1.5898, Energy: 1.1828, KLD: 2.2161, MC: 2.3000)\n",
      "Train Batch 110/110 - Loss: 6.6340 (Macro: 1.2707, Energy: 0.7231, KLD: 2.3414, MC: 2.2987)\n",
      "Training epoch complete. Average Loss: 7.0758\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0710\n",
      "\n",
      "Epoch 296/500\n",
      "Train Batch 10/110 - Loss: 7.0961 (Macro: 1.5654, Energy: 1.1163, KLD: 2.1149, MC: 2.2995)\n",
      "Train Batch 20/110 - Loss: 6.8624 (Macro: 1.4610, Energy: 0.9643, KLD: 2.1345, MC: 2.3027)\n",
      "Train Batch 30/110 - Loss: 7.0730 (Macro: 1.4355, Energy: 1.0287, KLD: 2.3073, MC: 2.3015)\n",
      "Train Batch 40/110 - Loss: 7.3733 (Macro: 1.5477, Energy: 1.1427, KLD: 2.3805, MC: 2.3023)\n",
      "Train Batch 50/110 - Loss: 7.0210 (Macro: 1.4897, Energy: 0.9904, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.9386 (Macro: 1.3884, Energy: 0.9914, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 6.9877 (Macro: 1.3748, Energy: 0.8706, KLD: 2.4378, MC: 2.3045)\n",
      "Train Batch 80/110 - Loss: 7.3307 (Macro: 1.4394, Energy: 1.0506, KLD: 2.5365, MC: 2.3042)\n",
      "Train Batch 90/110 - Loss: 6.7919 (Macro: 1.4685, Energy: 0.9997, KLD: 2.0241, MC: 2.2997)\n",
      "Train Batch 100/110 - Loss: 7.3122 (Macro: 1.5887, Energy: 1.2068, KLD: 2.2161, MC: 2.3006)\n",
      "Train Batch 110/110 - Loss: 6.6027 (Macro: 1.2380, Energy: 0.7250, KLD: 2.3414, MC: 2.2984)\n",
      "Training epoch complete. Average Loss: 7.0735\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0698\n",
      "\n",
      "Epoch 297/500\n",
      "Train Batch 10/110 - Loss: 7.1301 (Macro: 1.5742, Energy: 1.1403, KLD: 2.1149, MC: 2.3006)\n",
      "Train Batch 20/110 - Loss: 6.9343 (Macro: 1.4523, Energy: 1.0447, KLD: 2.1345, MC: 2.3028)\n",
      "Train Batch 30/110 - Loss: 7.0715 (Macro: 1.4562, Energy: 1.0062, KLD: 2.3073, MC: 2.3018)\n",
      "Train Batch 40/110 - Loss: 7.4694 (Macro: 1.5509, Energy: 1.2357, KLD: 2.3805, MC: 2.3023)\n",
      "Train Batch 50/110 - Loss: 7.0949 (Macro: 1.4893, Energy: 1.0643, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.8707 (Macro: 1.3831, Energy: 0.9300, KLD: 2.2570, MC: 2.3006)\n",
      "Train Batch 70/110 - Loss: 6.9711 (Macro: 1.3505, Energy: 0.8790, KLD: 2.4378, MC: 2.3038)\n",
      "Train Batch 80/110 - Loss: 7.2842 (Macro: 1.4241, Energy: 1.0223, KLD: 2.5365, MC: 2.3014)\n",
      "Train Batch 90/110 - Loss: 6.8689 (Macro: 1.4943, Energy: 1.0484, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3243 (Macro: 1.5936, Energy: 1.2148, KLD: 2.2161, MC: 2.2999)\n",
      "Train Batch 110/110 - Loss: 6.6220 (Macro: 1.2450, Energy: 0.7370, KLD: 2.3414, MC: 2.2987)\n",
      "Training epoch complete. Average Loss: 7.0821\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0594\n",
      "\n",
      "Epoch 298/500\n",
      "Train Batch 10/110 - Loss: 7.0639 (Macro: 1.5741, Energy: 1.0758, KLD: 2.1149, MC: 2.2991)\n",
      "Train Batch 20/110 - Loss: 6.8983 (Macro: 1.4681, Energy: 0.9939, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0652 (Macro: 1.4361, Energy: 1.0214, KLD: 2.3073, MC: 2.3004)\n",
      "Train Batch 40/110 - Loss: 7.4517 (Macro: 1.5497, Energy: 1.2206, KLD: 2.3805, MC: 2.3009)\n",
      "Train Batch 50/110 - Loss: 7.0467 (Macro: 1.5045, Energy: 1.0007, KLD: 2.2381, MC: 2.3034)\n",
      "Train Batch 60/110 - Loss: 6.8666 (Macro: 1.3960, Energy: 0.9102, KLD: 2.2570, MC: 2.3033)\n",
      "Train Batch 70/110 - Loss: 7.0028 (Macro: 1.3767, Energy: 0.8861, KLD: 2.4378, MC: 2.3023)\n",
      "Train Batch 80/110 - Loss: 7.2912 (Macro: 1.3917, Energy: 1.0599, KLD: 2.5365, MC: 2.3031)\n",
      "Train Batch 90/110 - Loss: 6.7434 (Macro: 1.4675, Energy: 0.9498, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.3163 (Macro: 1.5994, Energy: 1.1974, KLD: 2.2161, MC: 2.3034)\n",
      "Train Batch 110/110 - Loss: 6.6379 (Macro: 1.2525, Energy: 0.7447, KLD: 2.3414, MC: 2.2993)\n",
      "Training epoch complete. Average Loss: 7.0793\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0598\n",
      "\n",
      "Epoch 299/500\n",
      "Train Batch 10/110 - Loss: 7.1246 (Macro: 1.5843, Energy: 1.1249, KLD: 2.1149, MC: 2.3005)\n",
      "Train Batch 20/110 - Loss: 6.8507 (Macro: 1.4708, Energy: 0.9424, KLD: 2.1345, MC: 2.3030)\n",
      "Train Batch 30/110 - Loss: 7.0815 (Macro: 1.4285, Energy: 1.0435, KLD: 2.3073, MC: 2.3022)\n",
      "Train Batch 40/110 - Loss: 7.3971 (Macro: 1.5572, Energy: 1.1576, KLD: 2.3805, MC: 2.3018)\n",
      "Train Batch 50/110 - Loss: 7.0684 (Macro: 1.4954, Energy: 1.0309, KLD: 2.2381, MC: 2.3041)\n",
      "Train Batch 60/110 - Loss: 6.9397 (Macro: 1.4026, Energy: 0.9791, KLD: 2.2570, MC: 2.3010)\n",
      "Train Batch 70/110 - Loss: 6.9605 (Macro: 1.3543, Energy: 0.8634, KLD: 2.4378, MC: 2.3050)\n",
      "Train Batch 80/110 - Loss: 7.2459 (Macro: 1.4132, Energy: 0.9919, KLD: 2.5365, MC: 2.3043)\n",
      "Train Batch 90/110 - Loss: 6.7526 (Macro: 1.4734, Energy: 0.9526, KLD: 2.0241, MC: 2.3025)\n",
      "Train Batch 100/110 - Loss: 7.2671 (Macro: 1.5958, Energy: 1.1516, KLD: 2.2161, MC: 2.3037)\n",
      "Train Batch 110/110 - Loss: 6.6445 (Macro: 1.2591, Energy: 0.7469, KLD: 2.3414, MC: 2.2971)\n",
      "Training epoch complete. Average Loss: 7.0825\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0691\n",
      "\n",
      "Epoch 300/500\n",
      "Train Batch 10/110 - Loss: 7.1367 (Macro: 1.5808, Energy: 1.1413, KLD: 2.1149, MC: 2.2996)\n",
      "Train Batch 20/110 - Loss: 6.8592 (Macro: 1.4816, Energy: 0.9421, KLD: 2.1345, MC: 2.3011)\n",
      "Train Batch 30/110 - Loss: 7.1059 (Macro: 1.4501, Energy: 1.0464, KLD: 2.3073, MC: 2.3021)\n",
      "Train Batch 40/110 - Loss: 7.4120 (Macro: 1.5585, Energy: 1.1709, KLD: 2.3805, MC: 2.3022)\n",
      "Train Batch 50/110 - Loss: 7.1090 (Macro: 1.4960, Energy: 1.0735, KLD: 2.2381, MC: 2.3014)\n",
      "Train Batch 60/110 - Loss: 6.9805 (Macro: 1.3949, Energy: 1.0285, KLD: 2.2570, MC: 2.3000)\n",
      "Train Batch 70/110 - Loss: 6.9911 (Macro: 1.3590, Energy: 0.8895, KLD: 2.4378, MC: 2.3048)\n",
      "Train Batch 80/110 - Loss: 7.3127 (Macro: 1.4222, Energy: 1.0503, KLD: 2.5365, MC: 2.3038)\n",
      "Train Batch 90/110 - Loss: 6.7999 (Macro: 1.4730, Energy: 1.0014, KLD: 2.0241, MC: 2.3014)\n",
      "Train Batch 100/110 - Loss: 7.3317 (Macro: 1.6078, Energy: 1.2084, KLD: 2.2161, MC: 2.2994)\n",
      "Train Batch 110/110 - Loss: 6.6438 (Macro: 1.2247, Energy: 0.7778, KLD: 2.3414, MC: 2.2999)\n",
      "Training epoch complete. Average Loss: 7.0872\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0667\n",
      "\n",
      "Epoch 301/500\n",
      "Train Batch 10/110 - Loss: 7.0976 (Macro: 1.5684, Energy: 1.1142, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.9175 (Macro: 1.4839, Energy: 0.9991, KLD: 2.1345, MC: 2.3000)\n",
      "Train Batch 30/110 - Loss: 7.0351 (Macro: 1.4417, Energy: 0.9821, KLD: 2.3073, MC: 2.3040)\n",
      "Train Batch 40/110 - Loss: 7.4619 (Macro: 1.5636, Energy: 1.2161, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0719 (Macro: 1.5221, Energy: 1.0083, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.9168 (Macro: 1.3913, Energy: 0.9688, KLD: 2.2570, MC: 2.2997)\n",
      "Train Batch 70/110 - Loss: 7.0046 (Macro: 1.3800, Energy: 0.8818, KLD: 2.4378, MC: 2.3051)\n",
      "Train Batch 80/110 - Loss: 7.3292 (Macro: 1.4221, Energy: 1.0687, KLD: 2.5365, MC: 2.3019)\n",
      "Train Batch 90/110 - Loss: 6.7973 (Macro: 1.4917, Energy: 0.9771, KLD: 2.0241, MC: 2.3044)\n",
      "Train Batch 100/110 - Loss: 7.3090 (Macro: 1.5923, Energy: 1.2000, KLD: 2.2161, MC: 2.3007)\n",
      "Train Batch 110/110 - Loss: 6.6728 (Macro: 1.2314, Energy: 0.8011, KLD: 2.3414, MC: 2.2988)\n",
      "Training epoch complete. Average Loss: 7.0794\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0654\n",
      "\n",
      "Epoch 302/500\n",
      "Train Batch 10/110 - Loss: 7.1463 (Macro: 1.5857, Energy: 1.1464, KLD: 2.1149, MC: 2.2993)\n",
      "Train Batch 20/110 - Loss: 6.8631 (Macro: 1.4718, Energy: 0.9524, KLD: 2.1345, MC: 2.3045)\n",
      "Train Batch 30/110 - Loss: 7.1529 (Macro: 1.4646, Energy: 1.0782, KLD: 2.3073, MC: 2.3028)\n",
      "Train Batch 40/110 - Loss: 7.4546 (Macro: 1.5553, Energy: 1.2166, KLD: 2.3805, MC: 2.3023)\n",
      "Train Batch 50/110 - Loss: 7.0528 (Macro: 1.4812, Energy: 1.0308, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.9263 (Macro: 1.3841, Energy: 0.9838, KLD: 2.2570, MC: 2.3013)\n",
      "Train Batch 70/110 - Loss: 6.9145 (Macro: 1.3416, Energy: 0.8304, KLD: 2.4378, MC: 2.3047)\n",
      "Train Batch 80/110 - Loss: 7.3083 (Macro: 1.4432, Energy: 1.0256, KLD: 2.5365, MC: 2.3031)\n",
      "Train Batch 90/110 - Loss: 6.8074 (Macro: 1.4712, Energy: 1.0104, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.2707 (Macro: 1.6033, Energy: 1.1485, KLD: 2.2161, MC: 2.3028)\n",
      "Train Batch 110/110 - Loss: 6.6343 (Macro: 1.2696, Energy: 0.7224, KLD: 2.3414, MC: 2.3009)\n",
      "Training epoch complete. Average Loss: 7.0808\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0554\n",
      "\n",
      "Epoch 303/500\n",
      "Train Batch 10/110 - Loss: 7.0961 (Macro: 1.5739, Energy: 1.1062, KLD: 2.1149, MC: 2.3010)\n",
      "Train Batch 20/110 - Loss: 6.8881 (Macro: 1.4965, Energy: 0.9550, KLD: 2.1345, MC: 2.3022)\n",
      "Train Batch 30/110 - Loss: 7.0869 (Macro: 1.4841, Energy: 0.9952, KLD: 2.3073, MC: 2.3003)\n",
      "Train Batch 40/110 - Loss: 7.4096 (Macro: 1.5639, Energy: 1.1627, KLD: 2.3805, MC: 2.3024)\n",
      "Train Batch 50/110 - Loss: 7.0569 (Macro: 1.4979, Energy: 1.0174, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.9076 (Macro: 1.3710, Energy: 0.9798, KLD: 2.2570, MC: 2.2998)\n",
      "Train Batch 70/110 - Loss: 6.9694 (Macro: 1.3577, Energy: 0.8698, KLD: 2.4378, MC: 2.3041)\n",
      "Train Batch 80/110 - Loss: 7.3007 (Macro: 1.4397, Energy: 1.0226, KLD: 2.5365, MC: 2.3020)\n",
      "Train Batch 90/110 - Loss: 6.7541 (Macro: 1.4690, Energy: 0.9596, KLD: 2.0241, MC: 2.3014)\n",
      "Train Batch 100/110 - Loss: 7.2991 (Macro: 1.6015, Energy: 1.1813, KLD: 2.2161, MC: 2.3002)\n",
      "Train Batch 110/110 - Loss: 6.6183 (Macro: 1.2169, Energy: 0.7619, KLD: 2.3414, MC: 2.2981)\n",
      "Training epoch complete. Average Loss: 7.0783\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0734\n",
      "\n",
      "Epoch 304/500\n",
      "Train Batch 10/110 - Loss: 7.1487 (Macro: 1.5822, Energy: 1.1502, KLD: 2.1149, MC: 2.3013)\n",
      "Train Batch 20/110 - Loss: 6.8788 (Macro: 1.4755, Energy: 0.9684, KLD: 2.1345, MC: 2.3005)\n",
      "Train Batch 30/110 - Loss: 7.0689 (Macro: 1.4544, Energy: 1.0040, KLD: 2.3073, MC: 2.3032)\n",
      "Train Batch 40/110 - Loss: 7.4181 (Macro: 1.5668, Energy: 1.1715, KLD: 2.3805, MC: 2.2993)\n",
      "Train Batch 50/110 - Loss: 7.0553 (Macro: 1.5052, Energy: 1.0085, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.9723 (Macro: 1.3888, Energy: 1.0251, KLD: 2.2570, MC: 2.3014)\n",
      "Train Batch 70/110 - Loss: 6.9853 (Macro: 1.3753, Energy: 0.8704, KLD: 2.4378, MC: 2.3018)\n",
      "Train Batch 80/110 - Loss: 7.2719 (Macro: 1.4454, Energy: 0.9865, KLD: 2.5365, MC: 2.3036)\n",
      "Train Batch 90/110 - Loss: 6.8034 (Macro: 1.4743, Energy: 1.0031, KLD: 2.0241, MC: 2.3019)\n",
      "Train Batch 100/110 - Loss: 7.2851 (Macro: 1.6110, Energy: 1.1564, KLD: 2.2161, MC: 2.3016)\n",
      "Train Batch 110/110 - Loss: 6.6014 (Macro: 1.2422, Energy: 0.7191, KLD: 2.3414, MC: 2.2986)\n",
      "Training epoch complete. Average Loss: 7.0751\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0674\n",
      "\n",
      "Epoch 305/500\n",
      "Train Batch 10/110 - Loss: 7.0925 (Macro: 1.5750, Energy: 1.1043, KLD: 2.1149, MC: 2.2983)\n",
      "Train Batch 20/110 - Loss: 6.9019 (Macro: 1.4850, Energy: 0.9796, KLD: 2.1345, MC: 2.3028)\n",
      "Train Batch 30/110 - Loss: 7.1115 (Macro: 1.4686, Energy: 1.0327, KLD: 2.3073, MC: 2.3029)\n",
      "Train Batch 40/110 - Loss: 7.4480 (Macro: 1.5448, Energy: 1.2209, KLD: 2.3805, MC: 2.3018)\n",
      "Train Batch 50/110 - Loss: 7.0842 (Macro: 1.4994, Energy: 1.0438, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.8970 (Macro: 1.3844, Energy: 0.9535, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.9371 (Macro: 1.3503, Energy: 0.8460, KLD: 2.4378, MC: 2.3030)\n",
      "Train Batch 80/110 - Loss: 7.2856 (Macro: 1.4276, Energy: 1.0199, KLD: 2.5365, MC: 2.3016)\n",
      "Train Batch 90/110 - Loss: 6.8147 (Macro: 1.4778, Energy: 1.0106, KLD: 2.0241, MC: 2.3024)\n",
      "Train Batch 100/110 - Loss: 7.3306 (Macro: 1.6006, Energy: 1.2113, KLD: 2.2161, MC: 2.3026)\n",
      "Train Batch 110/110 - Loss: 6.6623 (Macro: 1.2374, Energy: 0.7858, KLD: 2.3414, MC: 2.2977)\n",
      "Training epoch complete. Average Loss: 7.0728\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0656\n",
      "\n",
      "Epoch 306/500\n",
      "Train Batch 10/110 - Loss: 7.1547 (Macro: 1.5772, Energy: 1.1626, KLD: 2.1149, MC: 2.2999)\n",
      "Train Batch 20/110 - Loss: 6.8926 (Macro: 1.4775, Energy: 0.9798, KLD: 2.1345, MC: 2.3008)\n",
      "Train Batch 30/110 - Loss: 7.0426 (Macro: 1.4768, Energy: 0.9596, KLD: 2.3073, MC: 2.2989)\n",
      "Train Batch 40/110 - Loss: 7.4306 (Macro: 1.5590, Energy: 1.1902, KLD: 2.3805, MC: 2.3010)\n",
      "Train Batch 50/110 - Loss: 7.0485 (Macro: 1.5085, Energy: 0.9985, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.9184 (Macro: 1.3890, Energy: 0.9718, KLD: 2.2570, MC: 2.3005)\n",
      "Train Batch 70/110 - Loss: 6.9029 (Macro: 1.3539, Energy: 0.8078, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.2793 (Macro: 1.4227, Energy: 1.0171, KLD: 2.5365, MC: 2.3030)\n",
      "Train Batch 90/110 - Loss: 6.7778 (Macro: 1.4926, Energy: 0.9605, KLD: 2.0241, MC: 2.3006)\n",
      "Train Batch 100/110 - Loss: 7.2927 (Macro: 1.6127, Energy: 1.1617, KLD: 2.2161, MC: 2.3021)\n",
      "Train Batch 110/110 - Loss: 6.5592 (Macro: 1.2120, Energy: 0.7056, KLD: 2.3414, MC: 2.3002)\n",
      "Training epoch complete. Average Loss: 7.0775\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0600\n",
      "\n",
      "Epoch 307/500\n",
      "Train Batch 10/110 - Loss: 7.1032 (Macro: 1.5648, Energy: 1.1235, KLD: 2.1149, MC: 2.2999)\n",
      "Train Batch 20/110 - Loss: 6.9272 (Macro: 1.4816, Energy: 1.0087, KLD: 2.1345, MC: 2.3024)\n",
      "Train Batch 30/110 - Loss: 7.0927 (Macro: 1.4618, Energy: 1.0226, KLD: 2.3073, MC: 2.3009)\n",
      "Train Batch 40/110 - Loss: 7.4924 (Macro: 1.5445, Energy: 1.2657, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0320 (Macro: 1.4980, Energy: 0.9941, KLD: 2.2381, MC: 2.3019)\n",
      "Train Batch 60/110 - Loss: 6.8964 (Macro: 1.3740, Energy: 0.9647, KLD: 2.2570, MC: 2.3006)\n",
      "Train Batch 70/110 - Loss: 6.9417 (Macro: 1.3581, Energy: 0.8419, KLD: 2.4378, MC: 2.3039)\n",
      "Train Batch 80/110 - Loss: 7.3398 (Macro: 1.4304, Energy: 1.0683, KLD: 2.5365, MC: 2.3047)\n",
      "Train Batch 90/110 - Loss: 6.7793 (Macro: 1.4777, Energy: 0.9752, KLD: 2.0241, MC: 2.3023)\n",
      "Train Batch 100/110 - Loss: 7.3027 (Macro: 1.6065, Energy: 1.1789, KLD: 2.2161, MC: 2.3012)\n",
      "Train Batch 110/110 - Loss: 6.5968 (Macro: 1.2046, Energy: 0.7470, KLD: 2.3414, MC: 2.3038)\n",
      "Training epoch complete. Average Loss: 7.0849\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0597\n",
      "\n",
      "Epoch 308/500\n",
      "Train Batch 10/110 - Loss: 7.1546 (Macro: 1.5923, Energy: 1.1486, KLD: 2.1149, MC: 2.2988)\n",
      "Train Batch 20/110 - Loss: 6.9253 (Macro: 1.5038, Energy: 0.9822, KLD: 2.1345, MC: 2.3049)\n",
      "Train Batch 30/110 - Loss: 7.1325 (Macro: 1.4538, Energy: 1.0698, KLD: 2.3073, MC: 2.3017)\n",
      "Train Batch 40/110 - Loss: 7.4644 (Macro: 1.5489, Energy: 1.2338, KLD: 2.3805, MC: 2.3012)\n",
      "Train Batch 50/110 - Loss: 7.0340 (Macro: 1.4937, Energy: 0.9990, KLD: 2.2381, MC: 2.3033)\n",
      "Train Batch 60/110 - Loss: 6.9321 (Macro: 1.3978, Energy: 0.9764, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 6.9638 (Macro: 1.3665, Energy: 0.8579, KLD: 2.4378, MC: 2.3016)\n",
      "Train Batch 80/110 - Loss: 7.3593 (Macro: 1.4314, Energy: 1.0885, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.8393 (Macro: 1.4898, Energy: 1.0221, KLD: 2.0241, MC: 2.3034)\n",
      "Train Batch 100/110 - Loss: 7.2961 (Macro: 1.5980, Energy: 1.1807, KLD: 2.2161, MC: 2.3014)\n",
      "Train Batch 110/110 - Loss: 6.6365 (Macro: 1.2469, Energy: 0.7498, KLD: 2.3414, MC: 2.2985)\n",
      "Training epoch complete. Average Loss: 7.0835\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0537\n",
      "\n",
      "Epoch 309/500\n",
      "Train Batch 10/110 - Loss: 7.1063 (Macro: 1.5688, Energy: 1.1240, KLD: 2.1149, MC: 2.2985)\n",
      "Train Batch 20/110 - Loss: 6.8954 (Macro: 1.4834, Energy: 0.9761, KLD: 2.1345, MC: 2.3014)\n",
      "Train Batch 30/110 - Loss: 7.0263 (Macro: 1.4434, Energy: 0.9729, KLD: 2.3073, MC: 2.3027)\n",
      "Train Batch 40/110 - Loss: 7.4720 (Macro: 1.5678, Energy: 1.2226, KLD: 2.3805, MC: 2.3011)\n",
      "Train Batch 50/110 - Loss: 7.0605 (Macro: 1.4946, Energy: 1.0262, KLD: 2.2381, MC: 2.3016)\n",
      "Train Batch 60/110 - Loss: 6.9610 (Macro: 1.3984, Energy: 1.0031, KLD: 2.2570, MC: 2.3024)\n",
      "Train Batch 70/110 - Loss: 6.9078 (Macro: 1.3655, Energy: 0.8016, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.3244 (Macro: 1.4274, Energy: 1.0570, KLD: 2.5365, MC: 2.3035)\n",
      "Train Batch 90/110 - Loss: 6.8275 (Macro: 1.4646, Energy: 1.0378, KLD: 2.0241, MC: 2.3010)\n",
      "Train Batch 100/110 - Loss: 7.3950 (Macro: 1.6346, Energy: 1.2415, KLD: 2.2161, MC: 2.3028)\n",
      "Train Batch 110/110 - Loss: 6.5242 (Macro: 1.2030, Energy: 0.6790, KLD: 2.3414, MC: 2.3007)\n",
      "Training epoch complete. Average Loss: 7.0747\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0736\n",
      "\n",
      "Epoch 310/500\n",
      "Train Batch 10/110 - Loss: 7.1323 (Macro: 1.5662, Energy: 1.1511, KLD: 2.1149, MC: 2.3000)\n",
      "Train Batch 20/110 - Loss: 6.9255 (Macro: 1.5005, Energy: 0.9876, KLD: 2.1345, MC: 2.3029)\n",
      "Train Batch 30/110 - Loss: 7.1097 (Macro: 1.4469, Energy: 1.0523, KLD: 2.3073, MC: 2.3032)\n",
      "Train Batch 40/110 - Loss: 7.5075 (Macro: 1.5695, Energy: 1.2566, KLD: 2.3805, MC: 2.3008)\n",
      "Train Batch 50/110 - Loss: 7.0698 (Macro: 1.4994, Energy: 1.0308, KLD: 2.2381, MC: 2.3016)\n",
      "Train Batch 60/110 - Loss: 6.8564 (Macro: 1.3542, Energy: 0.9437, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9205 (Macro: 1.3399, Energy: 0.8402, KLD: 2.4378, MC: 2.3026)\n",
      "Train Batch 80/110 - Loss: 7.3123 (Macro: 1.4176, Energy: 1.0553, KLD: 2.5365, MC: 2.3030)\n",
      "Train Batch 90/110 - Loss: 6.8274 (Macro: 1.4649, Energy: 1.0374, KLD: 2.0241, MC: 2.3011)\n",
      "Train Batch 100/110 - Loss: 7.3338 (Macro: 1.6096, Energy: 1.2064, KLD: 2.2161, MC: 2.3017)\n",
      "Train Batch 110/110 - Loss: 6.6062 (Macro: 1.2094, Energy: 0.7581, KLD: 2.3414, MC: 2.2973)\n",
      "Training epoch complete. Average Loss: 7.0817\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0567\n",
      "\n",
      "Epoch 311/500\n",
      "Train Batch 10/110 - Loss: 7.1797 (Macro: 1.5857, Energy: 1.1795, KLD: 2.1149, MC: 2.2996)\n",
      "Train Batch 20/110 - Loss: 6.8799 (Macro: 1.4897, Energy: 0.9522, KLD: 2.1345, MC: 2.3036)\n",
      "Train Batch 30/110 - Loss: 7.0568 (Macro: 1.4469, Energy: 1.0016, KLD: 2.3073, MC: 2.3011)\n",
      "Train Batch 40/110 - Loss: 7.4261 (Macro: 1.5551, Energy: 1.1890, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0705 (Macro: 1.5108, Energy: 1.0183, KLD: 2.2381, MC: 2.3034)\n",
      "Train Batch 60/110 - Loss: 6.9031 (Macro: 1.3783, Energy: 0.9657, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.9871 (Macro: 1.3594, Energy: 0.8864, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.3007 (Macro: 1.4307, Energy: 1.0312, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.7971 (Macro: 1.4683, Energy: 1.0024, KLD: 2.0241, MC: 2.3023)\n",
      "Train Batch 100/110 - Loss: 7.3397 (Macro: 1.6068, Energy: 1.2157, KLD: 2.2161, MC: 2.3010)\n",
      "Train Batch 110/110 - Loss: 6.6107 (Macro: 1.1966, Energy: 0.7731, KLD: 2.3414, MC: 2.2996)\n",
      "Training epoch complete. Average Loss: 7.0803\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0658\n",
      "\n",
      "Epoch 312/500\n",
      "Train Batch 10/110 - Loss: 7.0957 (Macro: 1.5790, Energy: 1.1017, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.8546 (Macro: 1.4859, Energy: 0.9321, KLD: 2.1345, MC: 2.3022)\n",
      "Train Batch 30/110 - Loss: 7.0962 (Macro: 1.4439, Energy: 1.0435, KLD: 2.3073, MC: 2.3015)\n",
      "Train Batch 40/110 - Loss: 7.4402 (Macro: 1.5416, Energy: 1.2169, KLD: 2.3805, MC: 2.3011)\n",
      "Train Batch 50/110 - Loss: 7.0538 (Macro: 1.5017, Energy: 1.0104, KLD: 2.2381, MC: 2.3036)\n",
      "Train Batch 60/110 - Loss: 6.8966 (Macro: 1.3926, Energy: 0.9457, KLD: 2.2570, MC: 2.3013)\n",
      "Train Batch 70/110 - Loss: 6.9257 (Macro: 1.3524, Energy: 0.8331, KLD: 2.4378, MC: 2.3023)\n",
      "Train Batch 80/110 - Loss: 7.2901 (Macro: 1.4259, Energy: 1.0260, KLD: 2.5365, MC: 2.3018)\n",
      "Train Batch 90/110 - Loss: 6.7968 (Macro: 1.4814, Energy: 0.9882, KLD: 2.0241, MC: 2.3031)\n",
      "Train Batch 100/110 - Loss: 7.2996 (Macro: 1.5835, Energy: 1.1975, KLD: 2.2161, MC: 2.3025)\n",
      "Train Batch 110/110 - Loss: 6.6071 (Macro: 1.2002, Energy: 0.7654, KLD: 2.3414, MC: 2.3001)\n",
      "Training epoch complete. Average Loss: 7.0844\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0702\n",
      "\n",
      "Epoch 313/500\n",
      "Train Batch 10/110 - Loss: 7.1056 (Macro: 1.5644, Energy: 1.1255, KLD: 2.1149, MC: 2.3008)\n",
      "Train Batch 20/110 - Loss: 6.8886 (Macro: 1.4680, Energy: 0.9852, KLD: 2.1345, MC: 2.3008)\n",
      "Train Batch 30/110 - Loss: 7.0899 (Macro: 1.4470, Energy: 1.0333, KLD: 2.3073, MC: 2.3023)\n",
      "Train Batch 40/110 - Loss: 7.4427 (Macro: 1.5720, Energy: 1.1885, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0335 (Macro: 1.4816, Energy: 1.0108, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.9113 (Macro: 1.3759, Energy: 0.9767, KLD: 2.2570, MC: 2.3016)\n",
      "Train Batch 70/110 - Loss: 6.9539 (Macro: 1.3418, Energy: 0.8700, KLD: 2.4378, MC: 2.3044)\n",
      "Train Batch 80/110 - Loss: 7.3170 (Macro: 1.4236, Energy: 1.0530, KLD: 2.5365, MC: 2.3039)\n",
      "Train Batch 90/110 - Loss: 6.8128 (Macro: 1.4720, Energy: 1.0142, KLD: 2.0241, MC: 2.3025)\n",
      "Train Batch 100/110 - Loss: 7.2635 (Macro: 1.5937, Energy: 1.1518, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.5801 (Macro: 1.1915, Energy: 0.7482, KLD: 2.3414, MC: 2.2990)\n",
      "Training epoch complete. Average Loss: 7.0779\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0711\n",
      "\n",
      "Epoch 314/500\n",
      "Train Batch 10/110 - Loss: 7.1129 (Macro: 1.5798, Energy: 1.1169, KLD: 2.1149, MC: 2.3012)\n",
      "Train Batch 20/110 - Loss: 6.8978 (Macro: 1.4721, Energy: 0.9896, KLD: 2.1345, MC: 2.3016)\n",
      "Train Batch 30/110 - Loss: 7.0452 (Macro: 1.4461, Energy: 0.9897, KLD: 2.3073, MC: 2.3021)\n",
      "Train Batch 40/110 - Loss: 7.4512 (Macro: 1.5627, Energy: 1.2066, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0728 (Macro: 1.4995, Energy: 1.0318, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.9043 (Macro: 1.3937, Energy: 0.9527, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 6.9400 (Macro: 1.3470, Energy: 0.8532, KLD: 2.4378, MC: 2.3020)\n",
      "Train Batch 80/110 - Loss: 7.3317 (Macro: 1.4249, Energy: 1.0665, KLD: 2.5365, MC: 2.3038)\n",
      "Train Batch 90/110 - Loss: 6.7851 (Macro: 1.4637, Energy: 0.9957, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.2747 (Macro: 1.5813, Energy: 1.1769, KLD: 2.2161, MC: 2.3003)\n",
      "Train Batch 110/110 - Loss: 6.6658 (Macro: 1.2254, Energy: 0.8017, KLD: 2.3414, MC: 2.2973)\n",
      "Training epoch complete. Average Loss: 7.0790\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0660\n",
      "\n",
      "Epoch 315/500\n",
      "Train Batch 10/110 - Loss: 7.0948 (Macro: 1.5836, Energy: 1.0962, KLD: 2.1149, MC: 2.3000)\n",
      "Train Batch 20/110 - Loss: 6.8871 (Macro: 1.4754, Energy: 0.9766, KLD: 2.1345, MC: 2.3006)\n",
      "Train Batch 30/110 - Loss: 7.0379 (Macro: 1.4543, Energy: 0.9758, KLD: 2.3073, MC: 2.3005)\n",
      "Train Batch 40/110 - Loss: 7.4622 (Macro: 1.5443, Energy: 1.2341, KLD: 2.3805, MC: 2.3033)\n",
      "Train Batch 50/110 - Loss: 7.0450 (Macro: 1.4847, Energy: 1.0193, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.9267 (Macro: 1.3882, Energy: 0.9805, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 6.9940 (Macro: 1.3824, Energy: 0.8706, KLD: 2.4378, MC: 2.3032)\n",
      "Train Batch 80/110 - Loss: 7.2822 (Macro: 1.4160, Energy: 1.0275, KLD: 2.5365, MC: 2.3022)\n",
      "Train Batch 90/110 - Loss: 6.8222 (Macro: 1.4720, Energy: 1.0225, KLD: 2.0241, MC: 2.3036)\n",
      "Train Batch 100/110 - Loss: 7.2921 (Macro: 1.6167, Energy: 1.1575, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.6250 (Macro: 1.2464, Energy: 0.7386, KLD: 2.3414, MC: 2.2986)\n",
      "Training epoch complete. Average Loss: 7.0789\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0646\n",
      "\n",
      "Epoch 316/500\n",
      "Train Batch 10/110 - Loss: 7.1088 (Macro: 1.5581, Energy: 1.1372, KLD: 2.1149, MC: 2.2986)\n",
      "Train Batch 20/110 - Loss: 6.9060 (Macro: 1.4909, Energy: 0.9791, KLD: 2.1345, MC: 2.3015)\n",
      "Train Batch 30/110 - Loss: 7.0731 (Macro: 1.4474, Energy: 1.0163, KLD: 2.3073, MC: 2.3021)\n",
      "Train Batch 40/110 - Loss: 7.4587 (Macro: 1.5526, Energy: 1.2257, KLD: 2.3805, MC: 2.2999)\n",
      "Train Batch 50/110 - Loss: 7.0517 (Macro: 1.4828, Energy: 1.0272, KLD: 2.2381, MC: 2.3037)\n",
      "Train Batch 60/110 - Loss: 6.9154 (Macro: 1.3805, Energy: 0.9764, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9583 (Macro: 1.3574, Energy: 0.8589, KLD: 2.4378, MC: 2.3043)\n",
      "Train Batch 80/110 - Loss: 7.3130 (Macro: 1.4309, Energy: 1.0427, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.8187 (Macro: 1.4971, Energy: 0.9944, KLD: 2.0241, MC: 2.3032)\n",
      "Train Batch 100/110 - Loss: 7.3534 (Macro: 1.6194, Energy: 1.2166, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.5957 (Macro: 1.2158, Energy: 0.7397, KLD: 2.3414, MC: 2.2988)\n",
      "Training epoch complete. Average Loss: 7.0794\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0672\n",
      "\n",
      "Epoch 317/500\n",
      "Train Batch 10/110 - Loss: 7.0779 (Macro: 1.5655, Energy: 1.0984, KLD: 2.1149, MC: 2.2991)\n",
      "Train Batch 20/110 - Loss: 6.9021 (Macro: 1.4769, Energy: 0.9890, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.0777 (Macro: 1.4476, Energy: 1.0218, KLD: 2.3073, MC: 2.3010)\n",
      "Train Batch 40/110 - Loss: 7.4505 (Macro: 1.5375, Energy: 1.2307, KLD: 2.3805, MC: 2.3018)\n",
      "Train Batch 50/110 - Loss: 7.0647 (Macro: 1.5014, Energy: 1.0233, KLD: 2.2381, MC: 2.3019)\n",
      "Train Batch 60/110 - Loss: 7.0354 (Macro: 1.3919, Energy: 1.0859, KLD: 2.2570, MC: 2.3005)\n",
      "Train Batch 70/110 - Loss: 6.9966 (Macro: 1.3709, Energy: 0.8842, KLD: 2.4378, MC: 2.3038)\n",
      "Train Batch 80/110 - Loss: 7.3083 (Macro: 1.4396, Energy: 1.0290, KLD: 2.5365, MC: 2.3033)\n",
      "Train Batch 90/110 - Loss: 6.8036 (Macro: 1.4903, Energy: 0.9856, KLD: 2.0241, MC: 2.3037)\n",
      "Train Batch 100/110 - Loss: 7.3092 (Macro: 1.5919, Energy: 1.2001, KLD: 2.2161, MC: 2.3012)\n",
      "Train Batch 110/110 - Loss: 6.6795 (Macro: 1.2199, Energy: 0.8200, KLD: 2.3414, MC: 2.2982)\n",
      "Training epoch complete. Average Loss: 7.0794\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0770\n",
      "\n",
      "Epoch 318/500\n",
      "Train Batch 10/110 - Loss: 7.1850 (Macro: 1.6062, Energy: 1.1635, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.8923 (Macro: 1.4856, Energy: 0.9690, KLD: 2.1345, MC: 2.3031)\n",
      "Train Batch 30/110 - Loss: 7.0666 (Macro: 1.4433, Energy: 1.0130, KLD: 2.3073, MC: 2.3030)\n",
      "Train Batch 40/110 - Loss: 7.4221 (Macro: 1.5524, Energy: 1.1875, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0462 (Macro: 1.5038, Energy: 1.0007, KLD: 2.2381, MC: 2.3036)\n",
      "Train Batch 60/110 - Loss: 6.9146 (Macro: 1.3906, Energy: 0.9670, KLD: 2.2570, MC: 2.3000)\n",
      "Train Batch 70/110 - Loss: 6.9309 (Macro: 1.3412, Energy: 0.8488, KLD: 2.4378, MC: 2.3031)\n",
      "Train Batch 80/110 - Loss: 7.3022 (Macro: 1.4225, Energy: 1.0380, KLD: 2.5365, MC: 2.3053)\n",
      "Train Batch 90/110 - Loss: 6.7248 (Macro: 1.4531, Energy: 0.9451, KLD: 2.0241, MC: 2.3025)\n",
      "Train Batch 100/110 - Loss: 7.3138 (Macro: 1.6121, Energy: 1.1830, KLD: 2.2161, MC: 2.3026)\n",
      "Train Batch 110/110 - Loss: 6.5830 (Macro: 1.2478, Energy: 0.6950, KLD: 2.3414, MC: 2.2987)\n",
      "Training epoch complete. Average Loss: 7.0777\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0734\n",
      "\n",
      "Epoch 319/500\n",
      "Train Batch 10/110 - Loss: 7.0986 (Macro: 1.5881, Energy: 1.0966, KLD: 2.1149, MC: 2.2990)\n",
      "Train Batch 20/110 - Loss: 6.8736 (Macro: 1.4854, Energy: 0.9508, KLD: 2.1345, MC: 2.3029)\n",
      "Train Batch 30/110 - Loss: 7.1273 (Macro: 1.4688, Energy: 1.0515, KLD: 2.3073, MC: 2.2998)\n",
      "Train Batch 40/110 - Loss: 7.4260 (Macro: 1.5467, Energy: 1.1961, KLD: 2.3805, MC: 2.3026)\n",
      "Train Batch 50/110 - Loss: 7.0227 (Macro: 1.4974, Energy: 0.9832, KLD: 2.2381, MC: 2.3040)\n",
      "Train Batch 60/110 - Loss: 6.9353 (Macro: 1.3780, Energy: 0.9993, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 6.9611 (Macro: 1.3526, Energy: 0.8665, KLD: 2.4378, MC: 2.3043)\n",
      "Train Batch 80/110 - Loss: 7.2906 (Macro: 1.4282, Energy: 1.0248, KLD: 2.5365, MC: 2.3010)\n",
      "Train Batch 90/110 - Loss: 6.7829 (Macro: 1.4721, Energy: 0.9836, KLD: 2.0241, MC: 2.3031)\n",
      "Train Batch 100/110 - Loss: 7.3490 (Macro: 1.6034, Energy: 1.2270, KLD: 2.2161, MC: 2.3025)\n",
      "Train Batch 110/110 - Loss: 6.6803 (Macro: 1.2363, Energy: 0.8038, KLD: 2.3414, MC: 2.2988)\n",
      "Training epoch complete. Average Loss: 7.0800\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0564\n",
      "\n",
      "Epoch 320/500\n",
      "Train Batch 10/110 - Loss: 7.0979 (Macro: 1.5624, Energy: 1.1206, KLD: 2.1149, MC: 2.2998)\n",
      "Train Batch 20/110 - Loss: 6.8552 (Macro: 1.4610, Energy: 0.9584, KLD: 2.1345, MC: 2.3013)\n",
      "Train Batch 30/110 - Loss: 7.1260 (Macro: 1.4520, Energy: 1.0643, KLD: 2.3073, MC: 2.3025)\n",
      "Train Batch 40/110 - Loss: 7.4583 (Macro: 1.5580, Energy: 1.2184, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0801 (Macro: 1.4862, Energy: 1.0519, KLD: 2.2381, MC: 2.3040)\n",
      "Train Batch 60/110 - Loss: 6.8939 (Macro: 1.3755, Energy: 0.9607, KLD: 2.2570, MC: 2.3007)\n",
      "Train Batch 70/110 - Loss: 6.9343 (Macro: 1.3579, Energy: 0.8365, KLD: 2.4378, MC: 2.3022)\n",
      "Train Batch 80/110 - Loss: 7.3121 (Macro: 1.4308, Energy: 1.0420, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.7953 (Macro: 1.4626, Energy: 1.0071, KLD: 2.0241, MC: 2.3015)\n",
      "Train Batch 100/110 - Loss: 7.2389 (Macro: 1.5924, Energy: 1.1289, KLD: 2.2161, MC: 2.3014)\n",
      "Train Batch 110/110 - Loss: 6.6267 (Macro: 1.2089, Energy: 0.7770, KLD: 2.3414, MC: 2.2995)\n",
      "Training epoch complete. Average Loss: 7.0780\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0534\n",
      "\n",
      "Epoch 321/500\n",
      "Train Batch 10/110 - Loss: 7.1455 (Macro: 1.5860, Energy: 1.1451, KLD: 2.1149, MC: 2.2995)\n",
      "Train Batch 20/110 - Loss: 6.8439 (Macro: 1.4796, Energy: 0.9287, KLD: 2.1345, MC: 2.3012)\n",
      "Train Batch 30/110 - Loss: 7.0710 (Macro: 1.4733, Energy: 0.9894, KLD: 2.3073, MC: 2.3010)\n",
      "Train Batch 40/110 - Loss: 7.4902 (Macro: 1.5561, Energy: 1.2525, KLD: 2.3805, MC: 2.3011)\n",
      "Train Batch 50/110 - Loss: 7.0885 (Macro: 1.4941, Energy: 1.0533, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.9076 (Macro: 1.3962, Energy: 0.9526, KLD: 2.2570, MC: 2.3017)\n",
      "Train Batch 70/110 - Loss: 6.9320 (Macro: 1.3488, Energy: 0.8438, KLD: 2.4378, MC: 2.3016)\n",
      "Train Batch 80/110 - Loss: 7.3272 (Macro: 1.4166, Energy: 1.0701, KLD: 2.5365, MC: 2.3041)\n",
      "Train Batch 90/110 - Loss: 6.7834 (Macro: 1.4774, Energy: 0.9802, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.2762 (Macro: 1.5978, Energy: 1.1598, KLD: 2.2161, MC: 2.3025)\n",
      "Train Batch 110/110 - Loss: 6.6582 (Macro: 1.2460, Energy: 0.7720, KLD: 2.3414, MC: 2.2987)\n",
      "Training epoch complete. Average Loss: 7.0832\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0541\n",
      "\n",
      "Epoch 322/500\n",
      "Train Batch 10/110 - Loss: 7.1301 (Macro: 1.5831, Energy: 1.1323, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.9188 (Macro: 1.4949, Energy: 0.9856, KLD: 2.1345, MC: 2.3038)\n",
      "Train Batch 30/110 - Loss: 7.0824 (Macro: 1.4448, Energy: 1.0282, KLD: 2.3073, MC: 2.3021)\n",
      "Train Batch 40/110 - Loss: 7.4260 (Macro: 1.5294, Energy: 1.2149, KLD: 2.3805, MC: 2.3012)\n",
      "Train Batch 50/110 - Loss: 7.0469 (Macro: 1.4966, Energy: 1.0105, KLD: 2.2381, MC: 2.3017)\n",
      "Train Batch 60/110 - Loss: 6.9030 (Macro: 1.3837, Energy: 0.9608, KLD: 2.2570, MC: 2.3014)\n",
      "Train Batch 70/110 - Loss: 6.9888 (Macro: 1.3722, Energy: 0.8752, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.2565 (Macro: 1.3987, Energy: 1.0203, KLD: 2.5365, MC: 2.3011)\n",
      "Train Batch 90/110 - Loss: 6.7867 (Macro: 1.4669, Energy: 0.9942, KLD: 2.0241, MC: 2.3015)\n",
      "Train Batch 100/110 - Loss: 7.3197 (Macro: 1.5936, Energy: 1.2108, KLD: 2.2161, MC: 2.2992)\n",
      "Train Batch 110/110 - Loss: 6.7196 (Macro: 1.2566, Energy: 0.8215, KLD: 2.3414, MC: 2.3001)\n",
      "Training epoch complete. Average Loss: 7.0816\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0567\n",
      "\n",
      "Epoch 323/500\n",
      "Train Batch 10/110 - Loss: 7.1202 (Macro: 1.5843, Energy: 1.1195, KLD: 2.1149, MC: 2.3015)\n",
      "Train Batch 20/110 - Loss: 6.9093 (Macro: 1.4838, Energy: 0.9874, KLD: 2.1345, MC: 2.3037)\n",
      "Train Batch 30/110 - Loss: 7.0889 (Macro: 1.4286, Energy: 1.0509, KLD: 2.3073, MC: 2.3021)\n",
      "Train Batch 40/110 - Loss: 7.4489 (Macro: 1.5547, Energy: 1.2126, KLD: 2.3805, MC: 2.3010)\n",
      "Train Batch 50/110 - Loss: 7.1039 (Macro: 1.4993, Energy: 1.0644, KLD: 2.2381, MC: 2.3021)\n",
      "Train Batch 60/110 - Loss: 6.9473 (Macro: 1.4034, Energy: 0.9865, KLD: 2.2570, MC: 2.3004)\n",
      "Train Batch 70/110 - Loss: 7.0134 (Macro: 1.3771, Energy: 0.8959, KLD: 2.4378, MC: 2.3026)\n",
      "Train Batch 80/110 - Loss: 7.3054 (Macro: 1.4257, Energy: 1.0414, KLD: 2.5365, MC: 2.3018)\n",
      "Train Batch 90/110 - Loss: 6.8228 (Macro: 1.4695, Energy: 1.0279, KLD: 2.0241, MC: 2.3013)\n",
      "Train Batch 100/110 - Loss: 7.2699 (Macro: 1.5975, Energy: 1.1548, KLD: 2.2161, MC: 2.3016)\n",
      "Train Batch 110/110 - Loss: 6.6227 (Macro: 1.2568, Energy: 0.7255, KLD: 2.3414, MC: 2.2990)\n",
      "Training epoch complete. Average Loss: 7.0771\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0649\n",
      "\n",
      "Epoch 324/500\n",
      "Train Batch 10/110 - Loss: 7.1146 (Macro: 1.5781, Energy: 1.1201, KLD: 2.1149, MC: 2.3014)\n",
      "Train Batch 20/110 - Loss: 6.8861 (Macro: 1.4755, Energy: 0.9734, KLD: 2.1345, MC: 2.3027)\n",
      "Train Batch 30/110 - Loss: 7.0276 (Macro: 1.4528, Energy: 0.9637, KLD: 2.3073, MC: 2.3037)\n",
      "Train Batch 40/110 - Loss: 7.4340 (Macro: 1.5597, Energy: 1.1924, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0992 (Macro: 1.5211, Energy: 1.0383, KLD: 2.2381, MC: 2.3018)\n",
      "Train Batch 60/110 - Loss: 6.9047 (Macro: 1.3795, Energy: 0.9680, KLD: 2.2570, MC: 2.3001)\n",
      "Train Batch 70/110 - Loss: 6.9099 (Macro: 1.3528, Energy: 0.8154, KLD: 2.4378, MC: 2.3040)\n",
      "Train Batch 80/110 - Loss: 7.2764 (Macro: 1.4280, Energy: 1.0100, KLD: 2.5365, MC: 2.3019)\n",
      "Train Batch 90/110 - Loss: 6.7947 (Macro: 1.4823, Energy: 0.9860, KLD: 2.0241, MC: 2.3023)\n",
      "Train Batch 100/110 - Loss: 7.2912 (Macro: 1.5932, Energy: 1.1780, KLD: 2.2161, MC: 2.3039)\n",
      "Train Batch 110/110 - Loss: 6.5555 (Macro: 1.2123, Energy: 0.7004, KLD: 2.3414, MC: 2.3015)\n",
      "Training epoch complete. Average Loss: 7.0719\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0759\n",
      "\n",
      "Epoch 325/500\n",
      "Train Batch 10/110 - Loss: 7.0876 (Macro: 1.5701, Energy: 1.1037, KLD: 2.1149, MC: 2.2988)\n",
      "Train Batch 20/110 - Loss: 6.8746 (Macro: 1.4892, Energy: 0.9505, KLD: 2.1345, MC: 2.3005)\n",
      "Train Batch 30/110 - Loss: 7.0841 (Macro: 1.4703, Energy: 1.0041, KLD: 2.3073, MC: 2.3025)\n",
      "Train Batch 40/110 - Loss: 7.4316 (Macro: 1.5604, Energy: 1.1884, KLD: 2.3805, MC: 2.3022)\n",
      "Train Batch 50/110 - Loss: 7.0748 (Macro: 1.4950, Energy: 1.0391, KLD: 2.2381, MC: 2.3026)\n",
      "Train Batch 60/110 - Loss: 6.9102 (Macro: 1.3915, Energy: 0.9604, KLD: 2.2570, MC: 2.3013)\n",
      "Train Batch 70/110 - Loss: 6.9776 (Macro: 1.3528, Energy: 0.8832, KLD: 2.4378, MC: 2.3038)\n",
      "Train Batch 80/110 - Loss: 7.3399 (Macro: 1.4257, Energy: 1.0737, KLD: 2.5365, MC: 2.3039)\n",
      "Train Batch 90/110 - Loss: 6.7512 (Macro: 1.4819, Energy: 0.9435, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.3612 (Macro: 1.5987, Energy: 1.2449, KLD: 2.2161, MC: 2.3015)\n",
      "Train Batch 110/110 - Loss: 6.5366 (Macro: 1.2241, Energy: 0.6715, KLD: 2.3414, MC: 2.2996)\n",
      "Training epoch complete. Average Loss: 7.0775\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0683\n",
      "\n",
      "Epoch 326/500\n",
      "Train Batch 10/110 - Loss: 7.1134 (Macro: 1.5671, Energy: 1.1315, KLD: 2.1149, MC: 2.2999)\n",
      "Train Batch 20/110 - Loss: 6.9217 (Macro: 1.4875, Energy: 0.9964, KLD: 2.1345, MC: 2.3033)\n",
      "Train Batch 30/110 - Loss: 7.0755 (Macro: 1.4529, Energy: 1.0134, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4761 (Macro: 1.5429, Energy: 1.2519, KLD: 2.3805, MC: 2.3008)\n",
      "Train Batch 50/110 - Loss: 7.0112 (Macro: 1.4895, Energy: 0.9791, KLD: 2.2381, MC: 2.3046)\n",
      "Train Batch 60/110 - Loss: 6.8971 (Macro: 1.3822, Energy: 0.9553, KLD: 2.2570, MC: 2.3025)\n",
      "Train Batch 70/110 - Loss: 6.9936 (Macro: 1.3967, Energy: 0.8585, KLD: 2.4378, MC: 2.3006)\n",
      "Train Batch 80/110 - Loss: 7.2929 (Macro: 1.4202, Energy: 1.0332, KLD: 2.5365, MC: 2.3031)\n",
      "Train Batch 90/110 - Loss: 6.8173 (Macro: 1.4794, Energy: 1.0140, KLD: 2.0241, MC: 2.2999)\n",
      "Train Batch 100/110 - Loss: 7.2864 (Macro: 1.6018, Energy: 1.1655, KLD: 2.2161, MC: 2.3030)\n",
      "Train Batch 110/110 - Loss: 6.6556 (Macro: 1.2204, Energy: 0.7967, KLD: 2.3414, MC: 2.2971)\n",
      "Training epoch complete. Average Loss: 7.0771\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0633\n",
      "\n",
      "Epoch 327/500\n",
      "Train Batch 10/110 - Loss: 7.1156 (Macro: 1.5813, Energy: 1.1193, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.9418 (Macro: 1.4871, Energy: 1.0179, KLD: 2.1345, MC: 2.3024)\n",
      "Train Batch 30/110 - Loss: 7.1475 (Macro: 1.4700, Energy: 1.0663, KLD: 2.3073, MC: 2.3039)\n",
      "Train Batch 40/110 - Loss: 7.3962 (Macro: 1.5697, Energy: 1.1445, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.1001 (Macro: 1.5042, Energy: 1.0534, KLD: 2.2381, MC: 2.3044)\n",
      "Train Batch 60/110 - Loss: 6.9170 (Macro: 1.3816, Energy: 0.9780, KLD: 2.2570, MC: 2.3003)\n",
      "Train Batch 70/110 - Loss: 6.9673 (Macro: 1.3529, Energy: 0.8734, KLD: 2.4378, MC: 2.3032)\n",
      "Train Batch 80/110 - Loss: 7.3087 (Macro: 1.4355, Energy: 1.0318, KLD: 2.5365, MC: 2.3048)\n",
      "Train Batch 90/110 - Loss: 6.7953 (Macro: 1.4742, Energy: 0.9947, KLD: 2.0241, MC: 2.3025)\n",
      "Train Batch 100/110 - Loss: 7.2866 (Macro: 1.5941, Energy: 1.1746, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.5781 (Macro: 1.2199, Energy: 0.7173, KLD: 2.3414, MC: 2.2995)\n",
      "Training epoch complete. Average Loss: 7.0787\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0764\n",
      "\n",
      "Epoch 328/500\n",
      "Train Batch 10/110 - Loss: 7.1431 (Macro: 1.5650, Energy: 1.1613, KLD: 2.1149, MC: 2.3019)\n",
      "Train Batch 20/110 - Loss: 6.8469 (Macro: 1.4732, Energy: 0.9370, KLD: 2.1345, MC: 2.3021)\n",
      "Train Batch 30/110 - Loss: 7.0743 (Macro: 1.4722, Energy: 0.9910, KLD: 2.3073, MC: 2.3038)\n",
      "Train Batch 40/110 - Loss: 7.4536 (Macro: 1.5773, Energy: 1.1944, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0424 (Macro: 1.4977, Energy: 1.0031, KLD: 2.2381, MC: 2.3036)\n",
      "Train Batch 60/110 - Loss: 6.9130 (Macro: 1.3993, Energy: 0.9562, KLD: 2.2570, MC: 2.3004)\n",
      "Train Batch 70/110 - Loss: 6.9687 (Macro: 1.3628, Energy: 0.8642, KLD: 2.4378, MC: 2.3040)\n",
      "Train Batch 80/110 - Loss: 7.3074 (Macro: 1.4113, Energy: 1.0585, KLD: 2.5365, MC: 2.3011)\n",
      "Train Batch 90/110 - Loss: 6.8152 (Macro: 1.4803, Energy: 1.0093, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.2934 (Macro: 1.5932, Energy: 1.1841, KLD: 2.2161, MC: 2.3000)\n",
      "Train Batch 110/110 - Loss: 6.6280 (Macro: 1.2161, Energy: 0.7712, KLD: 2.3414, MC: 2.2993)\n",
      "Training epoch complete. Average Loss: 7.0791\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0547\n",
      "\n",
      "Epoch 329/500\n",
      "Train Batch 10/110 - Loss: 7.0920 (Macro: 1.5881, Energy: 1.0890, KLD: 2.1149, MC: 2.2999)\n",
      "Train Batch 20/110 - Loss: 6.9113 (Macro: 1.4908, Energy: 0.9836, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.0550 (Macro: 1.4471, Energy: 0.9999, KLD: 2.3073, MC: 2.3007)\n",
      "Train Batch 40/110 - Loss: 7.4238 (Macro: 1.5344, Energy: 1.2064, KLD: 2.3805, MC: 2.3025)\n",
      "Train Batch 50/110 - Loss: 7.0179 (Macro: 1.4939, Energy: 0.9837, KLD: 2.2381, MC: 2.3022)\n",
      "Train Batch 60/110 - Loss: 6.8883 (Macro: 1.3887, Energy: 0.9399, KLD: 2.2570, MC: 2.3026)\n",
      "Train Batch 70/110 - Loss: 6.9689 (Macro: 1.3537, Energy: 0.8738, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.2909 (Macro: 1.4203, Energy: 1.0316, KLD: 2.5365, MC: 2.3025)\n",
      "Train Batch 90/110 - Loss: 6.7240 (Macro: 1.4485, Energy: 0.9495, KLD: 2.0241, MC: 2.3019)\n",
      "Train Batch 100/110 - Loss: 7.3213 (Macro: 1.6142, Energy: 1.1899, KLD: 2.2161, MC: 2.3011)\n",
      "Train Batch 110/110 - Loss: 6.6734 (Macro: 1.2405, Energy: 0.7940, KLD: 2.3414, MC: 2.2976)\n",
      "Training epoch complete. Average Loss: 7.0761\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0620\n",
      "\n",
      "Epoch 330/500\n",
      "Train Batch 10/110 - Loss: 7.1523 (Macro: 1.5753, Energy: 1.1645, KLD: 2.1149, MC: 2.2975)\n",
      "Train Batch 20/110 - Loss: 6.9356 (Macro: 1.4948, Energy: 1.0024, KLD: 2.1345, MC: 2.3039)\n",
      "Train Batch 30/110 - Loss: 7.1416 (Macro: 1.4532, Energy: 1.0774, KLD: 2.3073, MC: 2.3037)\n",
      "Train Batch 40/110 - Loss: 7.4613 (Macro: 1.5447, Energy: 1.2345, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.1067 (Macro: 1.5129, Energy: 1.0538, KLD: 2.2381, MC: 2.3019)\n",
      "Train Batch 60/110 - Loss: 6.8706 (Macro: 1.3821, Energy: 0.9307, KLD: 2.2570, MC: 2.3008)\n",
      "Train Batch 70/110 - Loss: 6.9581 (Macro: 1.3431, Energy: 0.8741, KLD: 2.4378, MC: 2.3031)\n",
      "Train Batch 80/110 - Loss: 7.3563 (Macro: 1.4386, Energy: 1.0779, KLD: 2.5365, MC: 2.3032)\n",
      "Train Batch 90/110 - Loss: 6.7983 (Macro: 1.4651, Energy: 1.0052, KLD: 2.0241, MC: 2.3039)\n",
      "Train Batch 100/110 - Loss: 7.3098 (Macro: 1.6191, Energy: 1.1722, KLD: 2.2161, MC: 2.3024)\n",
      "Train Batch 110/110 - Loss: 6.6840 (Macro: 1.2371, Energy: 0.8056, KLD: 2.3414, MC: 2.3000)\n",
      "Training epoch complete. Average Loss: 7.0769\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0616\n",
      "\n",
      "Epoch 331/500\n",
      "Train Batch 10/110 - Loss: 7.2188 (Macro: 1.5949, Energy: 1.2086, KLD: 2.1149, MC: 2.3004)\n",
      "Train Batch 20/110 - Loss: 6.8988 (Macro: 1.4663, Energy: 0.9963, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0557 (Macro: 1.4526, Energy: 0.9946, KLD: 2.3073, MC: 2.3011)\n",
      "Train Batch 40/110 - Loss: 7.4678 (Macro: 1.5625, Energy: 1.2259, KLD: 2.3805, MC: 2.2989)\n",
      "Train Batch 50/110 - Loss: 7.0561 (Macro: 1.5094, Energy: 1.0059, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.9096 (Macro: 1.3912, Energy: 0.9597, KLD: 2.2570, MC: 2.3016)\n",
      "Train Batch 70/110 - Loss: 6.9847 (Macro: 1.3680, Energy: 0.8757, KLD: 2.4378, MC: 2.3032)\n",
      "Train Batch 80/110 - Loss: 7.2952 (Macro: 1.4215, Energy: 1.0344, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.7539 (Macro: 1.4762, Energy: 0.9520, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.3140 (Macro: 1.5878, Energy: 1.2103, KLD: 2.2161, MC: 2.2998)\n",
      "Train Batch 110/110 - Loss: 6.5919 (Macro: 1.2123, Energy: 0.7429, KLD: 2.3414, MC: 2.2953)\n",
      "Training epoch complete. Average Loss: 7.0776\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0756\n",
      "\n",
      "Epoch 332/500\n",
      "Train Batch 10/110 - Loss: 7.1304 (Macro: 1.5706, Energy: 1.1452, KLD: 2.1149, MC: 2.2996)\n",
      "Train Batch 20/110 - Loss: 6.9219 (Macro: 1.4650, Energy: 1.0201, KLD: 2.1345, MC: 2.3024)\n",
      "Train Batch 30/110 - Loss: 7.0630 (Macro: 1.4320, Energy: 1.0214, KLD: 2.3073, MC: 2.3023)\n",
      "Train Batch 40/110 - Loss: 7.4346 (Macro: 1.5553, Energy: 1.1983, KLD: 2.3805, MC: 2.3005)\n",
      "Train Batch 50/110 - Loss: 7.0470 (Macro: 1.4916, Energy: 1.0142, KLD: 2.2381, MC: 2.3031)\n",
      "Train Batch 60/110 - Loss: 6.9026 (Macro: 1.3588, Energy: 0.9850, KLD: 2.2570, MC: 2.3017)\n",
      "Train Batch 70/110 - Loss: 6.9634 (Macro: 1.3749, Energy: 0.8457, KLD: 2.4378, MC: 2.3050)\n",
      "Train Batch 80/110 - Loss: 7.3584 (Macro: 1.4429, Energy: 1.0768, KLD: 2.5365, MC: 2.3022)\n",
      "Train Batch 90/110 - Loss: 6.8263 (Macro: 1.4753, Energy: 1.0240, KLD: 2.0241, MC: 2.3030)\n",
      "Train Batch 100/110 - Loss: 7.3252 (Macro: 1.6111, Energy: 1.1964, KLD: 2.2161, MC: 2.3016)\n",
      "Train Batch 110/110 - Loss: 6.5514 (Macro: 1.2123, Energy: 0.6972, KLD: 2.3414, MC: 2.3006)\n",
      "Training epoch complete. Average Loss: 7.0780\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0646\n",
      "\n",
      "Epoch 333/500\n",
      "Train Batch 10/110 - Loss: 7.1269 (Macro: 1.5829, Energy: 1.1308, KLD: 2.1149, MC: 2.2983)\n",
      "Train Batch 20/110 - Loss: 6.9556 (Macro: 1.4962, Energy: 1.0230, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.0523 (Macro: 1.4492, Energy: 0.9925, KLD: 2.3073, MC: 2.3033)\n",
      "Train Batch 40/110 - Loss: 7.4751 (Macro: 1.5629, Energy: 1.2304, KLD: 2.3805, MC: 2.3013)\n",
      "Train Batch 50/110 - Loss: 7.0425 (Macro: 1.4940, Energy: 1.0057, KLD: 2.2381, MC: 2.3048)\n",
      "Train Batch 60/110 - Loss: 6.9020 (Macro: 1.4036, Energy: 0.9401, KLD: 2.2570, MC: 2.3013)\n",
      "Train Batch 70/110 - Loss: 6.9252 (Macro: 1.3536, Energy: 0.8321, KLD: 2.4378, MC: 2.3018)\n",
      "Train Batch 80/110 - Loss: 7.3205 (Macro: 1.4015, Energy: 1.0794, KLD: 2.5365, MC: 2.3032)\n",
      "Train Batch 90/110 - Loss: 6.7649 (Macro: 1.4798, Energy: 0.9594, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.2807 (Macro: 1.5850, Energy: 1.1783, KLD: 2.2161, MC: 2.3014)\n",
      "Train Batch 110/110 - Loss: 6.5743 (Macro: 1.2577, Energy: 0.6794, KLD: 2.3414, MC: 2.2958)\n",
      "Training epoch complete. Average Loss: 7.0764\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0673\n",
      "\n",
      "Epoch 334/500\n",
      "Train Batch 10/110 - Loss: 7.1658 (Macro: 1.5703, Energy: 1.1811, KLD: 2.1149, MC: 2.2995)\n",
      "Train Batch 20/110 - Loss: 6.8952 (Macro: 1.4989, Energy: 0.9600, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0733 (Macro: 1.4509, Energy: 1.0121, KLD: 2.3073, MC: 2.3030)\n",
      "Train Batch 40/110 - Loss: 7.4490 (Macro: 1.5524, Energy: 1.2157, KLD: 2.3805, MC: 2.3003)\n",
      "Train Batch 50/110 - Loss: 7.0280 (Macro: 1.4883, Energy: 0.9990, KLD: 2.2381, MC: 2.3026)\n",
      "Train Batch 60/110 - Loss: 6.9061 (Macro: 1.3822, Energy: 0.9666, KLD: 2.2570, MC: 2.3003)\n",
      "Train Batch 70/110 - Loss: 6.9332 (Macro: 1.3519, Energy: 0.8419, KLD: 2.4378, MC: 2.3017)\n",
      "Train Batch 80/110 - Loss: 7.3525 (Macro: 1.4397, Energy: 1.0725, KLD: 2.5365, MC: 2.3038)\n",
      "Train Batch 90/110 - Loss: 6.8032 (Macro: 1.4769, Energy: 1.0006, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.2709 (Macro: 1.5927, Energy: 1.1628, KLD: 2.2161, MC: 2.2994)\n",
      "Train Batch 110/110 - Loss: 6.7005 (Macro: 1.2264, Energy: 0.8313, KLD: 2.3414, MC: 2.3014)\n",
      "Training epoch complete. Average Loss: 7.0765\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0686\n",
      "\n",
      "Epoch 335/500\n",
      "Train Batch 10/110 - Loss: 7.1505 (Macro: 1.5815, Energy: 1.1543, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.8620 (Macro: 1.4728, Energy: 0.9530, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.0852 (Macro: 1.4504, Energy: 1.0246, KLD: 2.3073, MC: 2.3030)\n",
      "Train Batch 40/110 - Loss: 7.4420 (Macro: 1.5364, Energy: 1.2228, KLD: 2.3805, MC: 2.3023)\n",
      "Train Batch 50/110 - Loss: 7.0292 (Macro: 1.4925, Energy: 0.9957, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.8954 (Macro: 1.3638, Energy: 0.9734, KLD: 2.2570, MC: 2.3012)\n",
      "Train Batch 70/110 - Loss: 6.9625 (Macro: 1.3683, Energy: 0.8536, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.2793 (Macro: 1.4242, Energy: 1.0144, KLD: 2.5365, MC: 2.3042)\n",
      "Train Batch 90/110 - Loss: 6.7918 (Macro: 1.4747, Energy: 0.9920, KLD: 2.0241, MC: 2.3010)\n",
      "Train Batch 100/110 - Loss: 7.3097 (Macro: 1.6002, Energy: 1.1919, KLD: 2.2161, MC: 2.3015)\n",
      "Train Batch 110/110 - Loss: 6.6452 (Macro: 1.2442, Energy: 0.7600, KLD: 2.3414, MC: 2.2995)\n",
      "Training epoch complete. Average Loss: 7.0799\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0654\n",
      "\n",
      "Epoch 336/500\n",
      "Train Batch 10/110 - Loss: 7.0793 (Macro: 1.5684, Energy: 1.0969, KLD: 2.1149, MC: 2.2991)\n",
      "Train Batch 20/110 - Loss: 6.8852 (Macro: 1.4898, Energy: 0.9575, KLD: 2.1345, MC: 2.3034)\n",
      "Train Batch 30/110 - Loss: 7.0793 (Macro: 1.4607, Energy: 1.0098, KLD: 2.3073, MC: 2.3015)\n",
      "Train Batch 40/110 - Loss: 7.4182 (Macro: 1.5466, Energy: 1.1903, KLD: 2.3805, MC: 2.3008)\n",
      "Train Batch 50/110 - Loss: 7.0873 (Macro: 1.5214, Energy: 1.0256, KLD: 2.2381, MC: 2.3022)\n",
      "Train Batch 60/110 - Loss: 6.9357 (Macro: 1.3879, Energy: 0.9906, KLD: 2.2570, MC: 2.3002)\n",
      "Train Batch 70/110 - Loss: 6.9250 (Macro: 1.3611, Energy: 0.8209, KLD: 2.4378, MC: 2.3052)\n",
      "Train Batch 80/110 - Loss: 7.2788 (Macro: 1.4330, Energy: 1.0066, KLD: 2.5365, MC: 2.3027)\n",
      "Train Batch 90/110 - Loss: 6.7832 (Macro: 1.4992, Energy: 0.9579, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3947 (Macro: 1.5900, Energy: 1.2869, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.6320 (Macro: 1.2363, Energy: 0.7548, KLD: 2.3414, MC: 2.2996)\n",
      "Training epoch complete. Average Loss: 7.0806\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0595\n",
      "\n",
      "Epoch 337/500\n",
      "Train Batch 10/110 - Loss: 7.1284 (Macro: 1.5704, Energy: 1.1428, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.9037 (Macro: 1.4778, Energy: 0.9903, KLD: 2.1345, MC: 2.3011)\n",
      "Train Batch 30/110 - Loss: 7.1147 (Macro: 1.4592, Energy: 1.0458, KLD: 2.3073, MC: 2.3024)\n",
      "Train Batch 40/110 - Loss: 7.4448 (Macro: 1.5587, Energy: 1.2029, KLD: 2.3805, MC: 2.3027)\n",
      "Train Batch 50/110 - Loss: 7.1041 (Macro: 1.5099, Energy: 1.0532, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.8799 (Macro: 1.3811, Energy: 0.9398, KLD: 2.2570, MC: 2.3019)\n",
      "Train Batch 70/110 - Loss: 6.9739 (Macro: 1.3611, Energy: 0.8718, KLD: 2.4378, MC: 2.3033)\n",
      "Train Batch 80/110 - Loss: 7.2848 (Macro: 1.4068, Energy: 1.0385, KLD: 2.5365, MC: 2.3031)\n",
      "Train Batch 90/110 - Loss: 6.8030 (Macro: 1.4850, Energy: 0.9915, KLD: 2.0241, MC: 2.3025)\n",
      "Train Batch 100/110 - Loss: 7.3018 (Macro: 1.6065, Energy: 1.1772, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.5792 (Macro: 1.2166, Energy: 0.7232, KLD: 2.3414, MC: 2.2980)\n",
      "Training epoch complete. Average Loss: 7.0757\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0628\n",
      "\n",
      "Epoch 338/500\n",
      "Train Batch 10/110 - Loss: 7.1369 (Macro: 1.5748, Energy: 1.1476, KLD: 2.1149, MC: 2.2996)\n",
      "Train Batch 20/110 - Loss: 6.9182 (Macro: 1.4909, Energy: 0.9890, KLD: 2.1345, MC: 2.3039)\n",
      "Train Batch 30/110 - Loss: 7.0207 (Macro: 1.4379, Energy: 0.9734, KLD: 2.3073, MC: 2.3021)\n",
      "Train Batch 40/110 - Loss: 7.5167 (Macro: 1.5659, Energy: 1.2707, KLD: 2.3805, MC: 2.2996)\n",
      "Train Batch 50/110 - Loss: 7.0774 (Macro: 1.5163, Energy: 1.0199, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.9014 (Macro: 1.3872, Energy: 0.9547, KLD: 2.2570, MC: 2.3026)\n",
      "Train Batch 70/110 - Loss: 6.9358 (Macro: 1.3574, Energy: 0.8369, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.2782 (Macro: 1.4170, Energy: 1.0219, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.7987 (Macro: 1.4671, Energy: 1.0055, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.3184 (Macro: 1.6235, Energy: 1.1763, KLD: 2.2161, MC: 2.3025)\n",
      "Train Batch 110/110 - Loss: 6.6968 (Macro: 1.2575, Energy: 0.7990, KLD: 2.3414, MC: 2.2990)\n",
      "Training epoch complete. Average Loss: 7.0831\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0597\n",
      "\n",
      "Epoch 339/500\n",
      "Train Batch 10/110 - Loss: 7.1193 (Macro: 1.5764, Energy: 1.1268, KLD: 2.1149, MC: 2.3010)\n",
      "Train Batch 20/110 - Loss: 6.8784 (Macro: 1.4710, Energy: 0.9707, KLD: 2.1345, MC: 2.3022)\n",
      "Train Batch 30/110 - Loss: 7.0603 (Macro: 1.4756, Energy: 0.9751, KLD: 2.3073, MC: 2.3024)\n",
      "Train Batch 40/110 - Loss: 7.4672 (Macro: 1.5431, Energy: 1.2418, KLD: 2.3805, MC: 2.3017)\n",
      "Train Batch 50/110 - Loss: 7.0222 (Macro: 1.5141, Energy: 0.9657, KLD: 2.2381, MC: 2.3043)\n",
      "Train Batch 60/110 - Loss: 6.9205 (Macro: 1.3828, Energy: 0.9801, KLD: 2.2570, MC: 2.3006)\n",
      "Train Batch 70/110 - Loss: 6.9111 (Macro: 1.3700, Energy: 0.8004, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.3075 (Macro: 1.4347, Energy: 1.0340, KLD: 2.5365, MC: 2.3024)\n",
      "Train Batch 90/110 - Loss: 6.7761 (Macro: 1.4919, Energy: 0.9580, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3234 (Macro: 1.6207, Energy: 1.1856, KLD: 2.2161, MC: 2.3010)\n",
      "Train Batch 110/110 - Loss: 6.5593 (Macro: 1.1712, Energy: 0.7464, KLD: 2.3414, MC: 2.3003)\n",
      "Training epoch complete. Average Loss: 7.0826\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0782\n",
      "\n",
      "Epoch 340/500\n",
      "Train Batch 10/110 - Loss: 7.1070 (Macro: 1.5971, Energy: 1.0944, KLD: 2.1149, MC: 2.3006)\n",
      "Train Batch 20/110 - Loss: 6.9256 (Macro: 1.4795, Energy: 1.0094, KLD: 2.1345, MC: 2.3023)\n",
      "Train Batch 30/110 - Loss: 7.1098 (Macro: 1.4579, Energy: 1.0407, KLD: 2.3073, MC: 2.3039)\n",
      "Train Batch 40/110 - Loss: 7.4299 (Macro: 1.5670, Energy: 1.1805, KLD: 2.3805, MC: 2.3019)\n",
      "Train Batch 50/110 - Loss: 7.0951 (Macro: 1.5076, Energy: 1.0447, KLD: 2.2381, MC: 2.3047)\n",
      "Train Batch 60/110 - Loss: 6.8965 (Macro: 1.3916, Energy: 0.9460, KLD: 2.2570, MC: 2.3019)\n",
      "Train Batch 70/110 - Loss: 6.9495 (Macro: 1.3668, Energy: 0.8415, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.2953 (Macro: 1.4325, Energy: 1.0239, KLD: 2.5365, MC: 2.3025)\n",
      "Train Batch 90/110 - Loss: 6.7980 (Macro: 1.4910, Energy: 0.9810, KLD: 2.0241, MC: 2.3019)\n",
      "Train Batch 100/110 - Loss: 7.2906 (Macro: 1.6017, Energy: 1.1729, KLD: 2.2161, MC: 2.2999)\n",
      "Train Batch 110/110 - Loss: 6.6507 (Macro: 1.2645, Energy: 0.7460, KLD: 2.3414, MC: 2.2989)\n",
      "Training epoch complete. Average Loss: 7.0809\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0544\n",
      "\n",
      "Epoch 341/500\n",
      "Train Batch 10/110 - Loss: 7.1004 (Macro: 1.5946, Energy: 1.0926, KLD: 2.1149, MC: 2.2982)\n",
      "Train Batch 20/110 - Loss: 6.9405 (Macro: 1.4806, Energy: 1.0231, KLD: 2.1345, MC: 2.3023)\n",
      "Train Batch 30/110 - Loss: 7.0656 (Macro: 1.4478, Energy: 1.0082, KLD: 2.3073, MC: 2.3023)\n",
      "Train Batch 40/110 - Loss: 7.3672 (Macro: 1.5481, Energy: 1.1385, KLD: 2.3805, MC: 2.3001)\n",
      "Train Batch 50/110 - Loss: 6.9941 (Macro: 1.4867, Energy: 0.9654, KLD: 2.2381, MC: 2.3040)\n",
      "Train Batch 60/110 - Loss: 6.8853 (Macro: 1.3686, Energy: 0.9592, KLD: 2.2570, MC: 2.3004)\n",
      "Train Batch 70/110 - Loss: 6.9646 (Macro: 1.3548, Energy: 0.8671, KLD: 2.4378, MC: 2.3050)\n",
      "Train Batch 80/110 - Loss: 7.2747 (Macro: 1.4309, Energy: 1.0051, KLD: 2.5365, MC: 2.3022)\n",
      "Train Batch 90/110 - Loss: 6.8179 (Macro: 1.4654, Energy: 1.0270, KLD: 2.0241, MC: 2.3015)\n",
      "Train Batch 100/110 - Loss: 7.3461 (Macro: 1.5895, Energy: 1.2390, KLD: 2.2161, MC: 2.3015)\n",
      "Train Batch 110/110 - Loss: 6.6422 (Macro: 1.2315, Energy: 0.7687, KLD: 2.3414, MC: 2.3006)\n",
      "Training epoch complete. Average Loss: 7.0830\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0695\n",
      "\n",
      "Epoch 342/500\n",
      "Train Batch 10/110 - Loss: 7.1820 (Macro: 1.5928, Energy: 1.1747, KLD: 2.1149, MC: 2.2996)\n",
      "Train Batch 20/110 - Loss: 6.8902 (Macro: 1.4686, Energy: 0.9852, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.1025 (Macro: 1.4480, Energy: 1.0435, KLD: 2.3073, MC: 2.3037)\n",
      "Train Batch 40/110 - Loss: 7.4539 (Macro: 1.5595, Energy: 1.2117, KLD: 2.3805, MC: 2.3022)\n",
      "Train Batch 50/110 - Loss: 7.0316 (Macro: 1.4880, Energy: 1.0024, KLD: 2.2381, MC: 2.3031)\n",
      "Train Batch 60/110 - Loss: 6.9194 (Macro: 1.3827, Energy: 0.9795, KLD: 2.2570, MC: 2.3002)\n",
      "Train Batch 70/110 - Loss: 6.9243 (Macro: 1.3570, Energy: 0.8267, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.2775 (Macro: 1.4341, Energy: 1.0062, KLD: 2.5365, MC: 2.3007)\n",
      "Train Batch 90/110 - Loss: 6.8505 (Macro: 1.4716, Energy: 1.0528, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3265 (Macro: 1.6131, Energy: 1.1959, KLD: 2.2161, MC: 2.3015)\n",
      "Train Batch 110/110 - Loss: 6.6105 (Macro: 1.2580, Energy: 0.7126, KLD: 2.3414, MC: 2.2986)\n",
      "Training epoch complete. Average Loss: 7.0837\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0599\n",
      "\n",
      "Epoch 343/500\n",
      "Train Batch 10/110 - Loss: 7.1234 (Macro: 1.5749, Energy: 1.1349, KLD: 2.1149, MC: 2.2986)\n",
      "Train Batch 20/110 - Loss: 6.8741 (Macro: 1.4620, Energy: 0.9751, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.0694 (Macro: 1.4645, Energy: 0.9973, KLD: 2.3073, MC: 2.3003)\n",
      "Train Batch 40/110 - Loss: 7.4488 (Macro: 1.5490, Energy: 1.2174, KLD: 2.3805, MC: 2.3019)\n",
      "Train Batch 50/110 - Loss: 7.0475 (Macro: 1.5161, Energy: 0.9901, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.9593 (Macro: 1.4093, Energy: 0.9911, KLD: 2.2570, MC: 2.3019)\n",
      "Train Batch 70/110 - Loss: 6.9156 (Macro: 1.3625, Energy: 0.8125, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.3094 (Macro: 1.4345, Energy: 1.0363, KLD: 2.5365, MC: 2.3021)\n",
      "Train Batch 90/110 - Loss: 6.7908 (Macro: 1.4810, Energy: 0.9832, KLD: 2.0241, MC: 2.3025)\n",
      "Train Batch 100/110 - Loss: 7.3351 (Macro: 1.6108, Energy: 1.2048, KLD: 2.2161, MC: 2.3033)\n",
      "Train Batch 110/110 - Loss: 6.6290 (Macro: 1.2207, Energy: 0.7681, KLD: 2.3414, MC: 2.2988)\n",
      "Training epoch complete. Average Loss: 7.0849\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0721\n",
      "\n",
      "Epoch 344/500\n",
      "Train Batch 10/110 - Loss: 7.1525 (Macro: 1.5755, Energy: 1.1624, KLD: 2.1149, MC: 2.2996)\n",
      "Train Batch 20/110 - Loss: 6.9516 (Macro: 1.5037, Energy: 1.0127, KLD: 2.1345, MC: 2.3008)\n",
      "Train Batch 30/110 - Loss: 7.1116 (Macro: 1.4571, Energy: 1.0469, KLD: 2.3073, MC: 2.3003)\n",
      "Train Batch 40/110 - Loss: 7.4379 (Macro: 1.5679, Energy: 1.1888, KLD: 2.3805, MC: 2.3006)\n",
      "Train Batch 50/110 - Loss: 7.0465 (Macro: 1.4814, Energy: 1.0245, KLD: 2.2381, MC: 2.3025)\n",
      "Train Batch 60/110 - Loss: 6.8819 (Macro: 1.4076, Energy: 0.9147, KLD: 2.2570, MC: 2.3025)\n",
      "Train Batch 70/110 - Loss: 6.9556 (Macro: 1.3677, Energy: 0.8476, KLD: 2.4378, MC: 2.3025)\n",
      "Train Batch 80/110 - Loss: 7.3313 (Macro: 1.4346, Energy: 1.0565, KLD: 2.5365, MC: 2.3037)\n",
      "Train Batch 90/110 - Loss: 6.7898 (Macro: 1.4807, Energy: 0.9826, KLD: 2.0241, MC: 2.3025)\n",
      "Train Batch 100/110 - Loss: 7.2999 (Macro: 1.6202, Energy: 1.1611, KLD: 2.2161, MC: 2.3026)\n",
      "Train Batch 110/110 - Loss: 6.6390 (Macro: 1.2255, Energy: 0.7777, KLD: 2.3414, MC: 2.2945)\n",
      "Training epoch complete. Average Loss: 7.0787\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0663\n",
      "\n",
      "Epoch 345/500\n",
      "Train Batch 10/110 - Loss: 7.0966 (Macro: 1.5706, Energy: 1.1115, KLD: 2.1149, MC: 2.2995)\n",
      "Train Batch 20/110 - Loss: 6.9164 (Macro: 1.4888, Energy: 0.9914, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0673 (Macro: 1.4449, Energy: 1.0138, KLD: 2.3073, MC: 2.3013)\n",
      "Train Batch 40/110 - Loss: 7.4484 (Macro: 1.5392, Energy: 1.2283, KLD: 2.3805, MC: 2.3004)\n",
      "Train Batch 50/110 - Loss: 6.9734 (Macro: 1.4631, Energy: 0.9690, KLD: 2.2381, MC: 2.3033)\n",
      "Train Batch 60/110 - Loss: 6.9676 (Macro: 1.4176, Energy: 0.9911, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 6.9940 (Macro: 1.3649, Energy: 0.8873, KLD: 2.4378, MC: 2.3040)\n",
      "Train Batch 80/110 - Loss: 7.3418 (Macro: 1.4507, Energy: 1.0519, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.7951 (Macro: 1.4727, Energy: 0.9961, KLD: 2.0241, MC: 2.3022)\n",
      "Train Batch 100/110 - Loss: 7.3117 (Macro: 1.6015, Energy: 1.1929, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.7178 (Macro: 1.2442, Energy: 0.8326, KLD: 2.3414, MC: 2.2996)\n",
      "Training epoch complete. Average Loss: 7.0834\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0631\n",
      "\n",
      "Epoch 346/500\n",
      "Train Batch 10/110 - Loss: 7.0856 (Macro: 1.5856, Energy: 1.0863, KLD: 2.1149, MC: 2.2988)\n",
      "Train Batch 20/110 - Loss: 6.9178 (Macro: 1.4744, Energy: 1.0074, KLD: 2.1345, MC: 2.3016)\n",
      "Train Batch 30/110 - Loss: 7.0907 (Macro: 1.4513, Energy: 1.0285, KLD: 2.3073, MC: 2.3036)\n",
      "Train Batch 40/110 - Loss: 7.4265 (Macro: 1.5657, Energy: 1.1782, KLD: 2.3805, MC: 2.3021)\n",
      "Train Batch 50/110 - Loss: 7.0891 (Macro: 1.5080, Energy: 1.0394, KLD: 2.2381, MC: 2.3037)\n",
      "Train Batch 60/110 - Loss: 6.9105 (Macro: 1.3888, Energy: 0.9656, KLD: 2.2570, MC: 2.2990)\n",
      "Train Batch 70/110 - Loss: 6.9528 (Macro: 1.3597, Energy: 0.8521, KLD: 2.4378, MC: 2.3032)\n",
      "Train Batch 80/110 - Loss: 7.3534 (Macro: 1.4235, Energy: 1.0929, KLD: 2.5365, MC: 2.3005)\n",
      "Train Batch 90/110 - Loss: 6.7877 (Macro: 1.4698, Energy: 0.9899, KLD: 2.0241, MC: 2.3040)\n",
      "Train Batch 100/110 - Loss: 7.2761 (Macro: 1.5969, Energy: 1.1604, KLD: 2.2161, MC: 2.3027)\n",
      "Train Batch 110/110 - Loss: 6.5561 (Macro: 1.2228, Energy: 0.6955, KLD: 2.3414, MC: 2.2965)\n",
      "Training epoch complete. Average Loss: 7.0766\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0646\n",
      "\n",
      "Epoch 347/500\n",
      "Train Batch 10/110 - Loss: 7.1360 (Macro: 1.5675, Energy: 1.1521, KLD: 2.1149, MC: 2.3014)\n",
      "Train Batch 20/110 - Loss: 6.8946 (Macro: 1.4824, Energy: 0.9759, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 6.9964 (Macro: 1.4335, Energy: 0.9529, KLD: 2.3073, MC: 2.3026)\n",
      "Train Batch 40/110 - Loss: 7.4561 (Macro: 1.5665, Energy: 1.2097, KLD: 2.3805, MC: 2.2993)\n",
      "Train Batch 50/110 - Loss: 7.1030 (Macro: 1.5157, Energy: 1.0473, KLD: 2.2381, MC: 2.3020)\n",
      "Train Batch 60/110 - Loss: 6.9111 (Macro: 1.3864, Energy: 0.9664, KLD: 2.2570, MC: 2.3013)\n",
      "Train Batch 70/110 - Loss: 6.9560 (Macro: 1.3438, Energy: 0.8709, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.2773 (Macro: 1.4122, Energy: 1.0240, KLD: 2.5365, MC: 2.3046)\n",
      "Train Batch 90/110 - Loss: 6.8203 (Macro: 1.4927, Energy: 1.0016, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.3221 (Macro: 1.6292, Energy: 1.1760, KLD: 2.2161, MC: 2.3008)\n",
      "Train Batch 110/110 - Loss: 6.6598 (Macro: 1.2423, Energy: 0.7740, KLD: 2.3414, MC: 2.3022)\n",
      "Training epoch complete. Average Loss: 7.0851\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0678\n",
      "\n",
      "Epoch 348/500\n",
      "Train Batch 10/110 - Loss: 7.0998 (Macro: 1.5701, Energy: 1.1144, KLD: 2.1149, MC: 2.3004)\n",
      "Train Batch 20/110 - Loss: 6.9497 (Macro: 1.4871, Energy: 1.0261, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.0169 (Macro: 1.4229, Energy: 0.9826, KLD: 2.3073, MC: 2.3041)\n",
      "Train Batch 40/110 - Loss: 7.4934 (Macro: 1.5655, Energy: 1.2460, KLD: 2.3805, MC: 2.3013)\n",
      "Train Batch 50/110 - Loss: 7.0413 (Macro: 1.4941, Energy: 1.0070, KLD: 2.2381, MC: 2.3022)\n",
      "Train Batch 60/110 - Loss: 6.8504 (Macro: 1.3605, Energy: 0.9322, KLD: 2.2570, MC: 2.3006)\n",
      "Train Batch 70/110 - Loss: 6.9570 (Macro: 1.3685, Energy: 0.8475, KLD: 2.4378, MC: 2.3032)\n",
      "Train Batch 80/110 - Loss: 7.2969 (Macro: 1.4047, Energy: 1.0533, KLD: 2.5365, MC: 2.3025)\n",
      "Train Batch 90/110 - Loss: 6.7616 (Macro: 1.4764, Energy: 0.9579, KLD: 2.0241, MC: 2.3032)\n",
      "Train Batch 100/110 - Loss: 7.2862 (Macro: 1.6077, Energy: 1.1604, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.5917 (Macro: 1.2536, Energy: 0.6950, KLD: 2.3414, MC: 2.3017)\n",
      "Training epoch complete. Average Loss: 7.0800\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0668\n",
      "\n",
      "Epoch 349/500\n",
      "Train Batch 10/110 - Loss: 7.1458 (Macro: 1.5836, Energy: 1.1490, KLD: 2.1149, MC: 2.2983)\n",
      "Train Batch 20/110 - Loss: 6.9009 (Macro: 1.4840, Energy: 0.9814, KLD: 2.1345, MC: 2.3010)\n",
      "Train Batch 30/110 - Loss: 7.0835 (Macro: 1.4488, Energy: 1.0243, KLD: 2.3073, MC: 2.3030)\n",
      "Train Batch 40/110 - Loss: 7.4694 (Macro: 1.5403, Energy: 1.2462, KLD: 2.3805, MC: 2.3024)\n",
      "Train Batch 50/110 - Loss: 7.0635 (Macro: 1.4855, Energy: 1.0380, KLD: 2.2381, MC: 2.3020)\n",
      "Train Batch 60/110 - Loss: 6.8967 (Macro: 1.3805, Energy: 0.9568, KLD: 2.2570, MC: 2.3024)\n",
      "Train Batch 70/110 - Loss: 6.9640 (Macro: 1.3483, Energy: 0.8735, KLD: 2.4378, MC: 2.3045)\n",
      "Train Batch 80/110 - Loss: 7.2591 (Macro: 1.4220, Energy: 0.9989, KLD: 2.5365, MC: 2.3018)\n",
      "Train Batch 90/110 - Loss: 6.8143 (Macro: 1.4797, Energy: 1.0075, KLD: 2.0241, MC: 2.3030)\n",
      "Train Batch 100/110 - Loss: 7.3483 (Macro: 1.6164, Energy: 1.2123, KLD: 2.2161, MC: 2.3035)\n",
      "Train Batch 110/110 - Loss: 6.6552 (Macro: 1.2449, Energy: 0.7689, KLD: 2.3414, MC: 2.3000)\n",
      "Training epoch complete. Average Loss: 7.0883\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0699\n",
      "\n",
      "Epoch 350/500\n",
      "Train Batch 10/110 - Loss: 7.1600 (Macro: 1.5938, Energy: 1.1534, KLD: 2.1149, MC: 2.2980)\n",
      "Train Batch 20/110 - Loss: 6.9059 (Macro: 1.4911, Energy: 0.9789, KLD: 2.1345, MC: 2.3014)\n",
      "Train Batch 30/110 - Loss: 7.0606 (Macro: 1.4479, Energy: 1.0024, KLD: 2.3073, MC: 2.3030)\n",
      "Train Batch 40/110 - Loss: 7.4713 (Macro: 1.5656, Energy: 1.2246, KLD: 2.3805, MC: 2.3006)\n",
      "Train Batch 50/110 - Loss: 7.0425 (Macro: 1.4952, Energy: 1.0081, KLD: 2.2381, MC: 2.3011)\n",
      "Train Batch 60/110 - Loss: 6.9134 (Macro: 1.3912, Energy: 0.9655, KLD: 2.2570, MC: 2.2997)\n",
      "Train Batch 70/110 - Loss: 6.9573 (Macro: 1.3310, Energy: 0.8859, KLD: 2.4378, MC: 2.3026)\n",
      "Train Batch 80/110 - Loss: 7.3006 (Macro: 1.4155, Energy: 1.0473, KLD: 2.5365, MC: 2.3014)\n",
      "Train Batch 90/110 - Loss: 6.7760 (Macro: 1.4613, Energy: 0.9893, KLD: 2.0241, MC: 2.3014)\n",
      "Train Batch 100/110 - Loss: 7.3045 (Macro: 1.5967, Energy: 1.1899, KLD: 2.2161, MC: 2.3017)\n",
      "Train Batch 110/110 - Loss: 6.6181 (Macro: 1.2198, Energy: 0.7582, KLD: 2.3414, MC: 2.2987)\n",
      "Training epoch complete. Average Loss: 7.0796\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0674\n",
      "\n",
      "Epoch 351/500\n",
      "Train Batch 10/110 - Loss: 7.1465 (Macro: 1.5742, Energy: 1.1595, KLD: 2.1149, MC: 2.2979)\n",
      "Train Batch 20/110 - Loss: 6.8806 (Macro: 1.4699, Energy: 0.9764, KLD: 2.1345, MC: 2.2999)\n",
      "Train Batch 30/110 - Loss: 7.0524 (Macro: 1.4551, Energy: 0.9871, KLD: 2.3073, MC: 2.3029)\n",
      "Train Batch 40/110 - Loss: 7.4418 (Macro: 1.5416, Energy: 1.2188, KLD: 2.3805, MC: 2.3009)\n",
      "Train Batch 50/110 - Loss: 7.0749 (Macro: 1.5045, Energy: 1.0279, KLD: 2.2381, MC: 2.3044)\n",
      "Train Batch 60/110 - Loss: 6.8881 (Macro: 1.3981, Energy: 0.9323, KLD: 2.2570, MC: 2.3007)\n",
      "Train Batch 70/110 - Loss: 6.9797 (Macro: 1.3558, Energy: 0.8837, KLD: 2.4378, MC: 2.3025)\n",
      "Train Batch 80/110 - Loss: 7.3231 (Macro: 1.4266, Energy: 1.0552, KLD: 2.5365, MC: 2.3048)\n",
      "Train Batch 90/110 - Loss: 6.7656 (Macro: 1.4755, Energy: 0.9665, KLD: 2.0241, MC: 2.2995)\n",
      "Train Batch 100/110 - Loss: 7.3262 (Macro: 1.6208, Energy: 1.1889, KLD: 2.2161, MC: 2.3005)\n",
      "Train Batch 110/110 - Loss: 6.6551 (Macro: 1.2546, Energy: 0.7600, KLD: 2.3414, MC: 2.2992)\n",
      "Training epoch complete. Average Loss: 7.0795\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0632\n",
      "\n",
      "Epoch 352/500\n",
      "Train Batch 10/110 - Loss: 7.1064 (Macro: 1.5725, Energy: 1.1178, KLD: 2.1149, MC: 2.3011)\n",
      "Train Batch 20/110 - Loss: 6.8827 (Macro: 1.4935, Energy: 0.9528, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.0551 (Macro: 1.4303, Energy: 1.0154, KLD: 2.3073, MC: 2.3021)\n",
      "Train Batch 40/110 - Loss: 7.4419 (Macro: 1.5559, Energy: 1.2034, KLD: 2.3805, MC: 2.3021)\n",
      "Train Batch 50/110 - Loss: 7.0536 (Macro: 1.4941, Energy: 1.0183, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.9081 (Macro: 1.3915, Energy: 0.9585, KLD: 2.2570, MC: 2.3010)\n",
      "Train Batch 70/110 - Loss: 6.9432 (Macro: 1.3693, Energy: 0.8309, KLD: 2.4378, MC: 2.3052)\n",
      "Train Batch 80/110 - Loss: 7.3328 (Macro: 1.4445, Energy: 1.0480, KLD: 2.5365, MC: 2.3038)\n",
      "Train Batch 90/110 - Loss: 6.8781 (Macro: 1.4999, Energy: 1.0530, KLD: 2.0241, MC: 2.3010)\n",
      "Train Batch 100/110 - Loss: 7.3225 (Macro: 1.6140, Energy: 1.1900, KLD: 2.2161, MC: 2.3025)\n",
      "Train Batch 110/110 - Loss: 6.5314 (Macro: 1.2036, Energy: 0.6873, KLD: 2.3414, MC: 2.2991)\n",
      "Training epoch complete. Average Loss: 7.0781\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0702\n",
      "\n",
      "Epoch 353/500\n",
      "Train Batch 10/110 - Loss: 7.1212 (Macro: 1.5746, Energy: 1.1316, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.8746 (Macro: 1.4849, Energy: 0.9538, KLD: 2.1345, MC: 2.3015)\n",
      "Train Batch 30/110 - Loss: 7.0450 (Macro: 1.4301, Energy: 1.0064, KLD: 2.3073, MC: 2.3013)\n",
      "Train Batch 40/110 - Loss: 7.4654 (Macro: 1.5744, Energy: 1.2089, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.0744 (Macro: 1.5080, Energy: 1.0259, KLD: 2.2381, MC: 2.3025)\n",
      "Train Batch 60/110 - Loss: 6.9524 (Macro: 1.3838, Energy: 1.0112, KLD: 2.2570, MC: 2.3003)\n",
      "Train Batch 70/110 - Loss: 6.9376 (Macro: 1.3553, Energy: 0.8407, KLD: 2.4378, MC: 2.3038)\n",
      "Train Batch 80/110 - Loss: 7.2901 (Macro: 1.4225, Energy: 1.0266, KLD: 2.5365, MC: 2.3045)\n",
      "Train Batch 90/110 - Loss: 6.8194 (Macro: 1.4894, Energy: 1.0051, KLD: 2.0241, MC: 2.3009)\n",
      "Train Batch 100/110 - Loss: 7.2576 (Macro: 1.5906, Energy: 1.1495, KLD: 2.2161, MC: 2.3014)\n",
      "Train Batch 110/110 - Loss: 6.5968 (Macro: 1.2236, Energy: 0.7344, KLD: 2.3414, MC: 2.2974)\n",
      "Training epoch complete. Average Loss: 7.0781\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0588\n",
      "\n",
      "Epoch 354/500\n",
      "Train Batch 10/110 - Loss: 7.1230 (Macro: 1.5664, Energy: 1.1423, KLD: 2.1149, MC: 2.2994)\n",
      "Train Batch 20/110 - Loss: 6.9470 (Macro: 1.4761, Energy: 1.0329, KLD: 2.1345, MC: 2.3036)\n",
      "Train Batch 30/110 - Loss: 7.0930 (Macro: 1.4379, Energy: 1.0472, KLD: 2.3073, MC: 2.3006)\n",
      "Train Batch 40/110 - Loss: 7.4547 (Macro: 1.5606, Energy: 1.2130, KLD: 2.3805, MC: 2.3006)\n",
      "Train Batch 50/110 - Loss: 7.0447 (Macro: 1.4905, Energy: 1.0120, KLD: 2.2381, MC: 2.3041)\n",
      "Train Batch 60/110 - Loss: 6.8230 (Macro: 1.3495, Energy: 0.9159, KLD: 2.2570, MC: 2.3005)\n",
      "Train Batch 70/110 - Loss: 6.9702 (Macro: 1.3649, Energy: 0.8642, KLD: 2.4378, MC: 2.3033)\n",
      "Train Batch 80/110 - Loss: 7.3190 (Macro: 1.4470, Energy: 1.0314, KLD: 2.5365, MC: 2.3041)\n",
      "Train Batch 90/110 - Loss: 6.7978 (Macro: 1.4805, Energy: 0.9908, KLD: 2.0241, MC: 2.3024)\n",
      "Train Batch 100/110 - Loss: 7.3555 (Macro: 1.5991, Energy: 1.2387, KLD: 2.2161, MC: 2.3016)\n",
      "Train Batch 110/110 - Loss: 6.6123 (Macro: 1.2333, Energy: 0.7402, KLD: 2.3414, MC: 2.2974)\n",
      "Training epoch complete. Average Loss: 7.0797\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0584\n",
      "\n",
      "Epoch 355/500\n",
      "Train Batch 10/110 - Loss: 7.1184 (Macro: 1.5962, Energy: 1.1057, KLD: 2.1149, MC: 2.3017)\n",
      "Train Batch 20/110 - Loss: 6.8956 (Macro: 1.4805, Energy: 0.9781, KLD: 2.1345, MC: 2.3026)\n",
      "Train Batch 30/110 - Loss: 7.1147 (Macro: 1.4616, Energy: 1.0440, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4160 (Macro: 1.5599, Energy: 1.1732, KLD: 2.3805, MC: 2.3024)\n",
      "Train Batch 50/110 - Loss: 7.0878 (Macro: 1.5064, Energy: 1.0404, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.8652 (Macro: 1.3851, Energy: 0.9220, KLD: 2.2570, MC: 2.3010)\n",
      "Train Batch 70/110 - Loss: 6.9576 (Macro: 1.3564, Energy: 0.8602, KLD: 2.4378, MC: 2.3033)\n",
      "Train Batch 80/110 - Loss: 7.3122 (Macro: 1.4130, Energy: 1.0595, KLD: 2.5365, MC: 2.3031)\n",
      "Train Batch 90/110 - Loss: 6.8258 (Macro: 1.4810, Energy: 1.0179, KLD: 2.0241, MC: 2.3028)\n",
      "Train Batch 100/110 - Loss: 7.3624 (Macro: 1.6091, Energy: 1.2349, KLD: 2.2161, MC: 2.3022)\n",
      "Train Batch 110/110 - Loss: 6.6640 (Macro: 1.2472, Energy: 0.7759, KLD: 2.3414, MC: 2.2995)\n",
      "Training epoch complete. Average Loss: 7.0821\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0479\n",
      "\n",
      "Epoch 356/500\n",
      "Train Batch 10/110 - Loss: 7.1392 (Macro: 1.5917, Energy: 1.1328, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.8875 (Macro: 1.4972, Energy: 0.9530, KLD: 2.1345, MC: 2.3028)\n",
      "Train Batch 30/110 - Loss: 7.0323 (Macro: 1.4501, Energy: 0.9724, KLD: 2.3073, MC: 2.3026)\n",
      "Train Batch 40/110 - Loss: 7.4403 (Macro: 1.5566, Energy: 1.2014, KLD: 2.3805, MC: 2.3018)\n",
      "Train Batch 50/110 - Loss: 7.0835 (Macro: 1.5075, Energy: 1.0342, KLD: 2.2381, MC: 2.3037)\n",
      "Train Batch 60/110 - Loss: 6.9260 (Macro: 1.3895, Energy: 0.9771, KLD: 2.2570, MC: 2.3024)\n",
      "Train Batch 70/110 - Loss: 6.9609 (Macro: 1.3519, Energy: 0.8682, KLD: 2.4378, MC: 2.3030)\n",
      "Train Batch 80/110 - Loss: 7.2462 (Macro: 1.4346, Energy: 0.9733, KLD: 2.5365, MC: 2.3018)\n",
      "Train Batch 90/110 - Loss: 6.8188 (Macro: 1.4853, Energy: 1.0079, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.3482 (Macro: 1.6085, Energy: 1.2227, KLD: 2.2161, MC: 2.3010)\n",
      "Train Batch 110/110 - Loss: 6.6295 (Macro: 1.2331, Energy: 0.7556, KLD: 2.3414, MC: 2.2995)\n",
      "Training epoch complete. Average Loss: 7.0772\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0498\n",
      "\n",
      "Epoch 357/500\n",
      "Train Batch 10/110 - Loss: 7.1250 (Macro: 1.5831, Energy: 1.1297, KLD: 2.1149, MC: 2.2972)\n",
      "Train Batch 20/110 - Loss: 6.9088 (Macro: 1.5019, Energy: 0.9692, KLD: 2.1345, MC: 2.3032)\n",
      "Train Batch 30/110 - Loss: 7.0744 (Macro: 1.4585, Energy: 1.0052, KLD: 2.3073, MC: 2.3033)\n",
      "Train Batch 40/110 - Loss: 7.4563 (Macro: 1.5637, Energy: 1.2102, KLD: 2.3805, MC: 2.3019)\n",
      "Train Batch 50/110 - Loss: 7.0739 (Macro: 1.4906, Energy: 1.0407, KLD: 2.2381, MC: 2.3045)\n",
      "Train Batch 60/110 - Loss: 6.8678 (Macro: 1.3873, Energy: 0.9222, KLD: 2.2570, MC: 2.3013)\n",
      "Train Batch 70/110 - Loss: 6.9703 (Macro: 1.3816, Energy: 0.8453, KLD: 2.4378, MC: 2.3056)\n",
      "Train Batch 80/110 - Loss: 7.3156 (Macro: 1.4248, Energy: 1.0504, KLD: 2.5365, MC: 2.3039)\n",
      "Train Batch 90/110 - Loss: 6.7787 (Macro: 1.4735, Energy: 0.9773, KLD: 2.0241, MC: 2.3038)\n",
      "Train Batch 100/110 - Loss: 7.3189 (Macro: 1.6182, Energy: 1.1839, KLD: 2.2161, MC: 2.3006)\n",
      "Train Batch 110/110 - Loss: 6.6240 (Macro: 1.2087, Energy: 0.7748, KLD: 2.3414, MC: 2.2991)\n",
      "Training epoch complete. Average Loss: 7.0795\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0677\n",
      "\n",
      "Epoch 358/500\n",
      "Train Batch 10/110 - Loss: 7.0586 (Macro: 1.5764, Energy: 1.0652, KLD: 2.1149, MC: 2.3021)\n",
      "Train Batch 20/110 - Loss: 6.9217 (Macro: 1.4642, Energy: 1.0208, KLD: 2.1345, MC: 2.3023)\n",
      "Train Batch 30/110 - Loss: 7.1237 (Macro: 1.4627, Energy: 1.0516, KLD: 2.3073, MC: 2.3022)\n",
      "Train Batch 40/110 - Loss: 7.4047 (Macro: 1.5521, Energy: 1.1733, KLD: 2.3805, MC: 2.2988)\n",
      "Train Batch 50/110 - Loss: 7.0693 (Macro: 1.5128, Energy: 1.0156, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.9554 (Macro: 1.3814, Energy: 1.0158, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9547 (Macro: 1.3611, Energy: 0.8513, KLD: 2.4378, MC: 2.3046)\n",
      "Train Batch 80/110 - Loss: 7.3277 (Macro: 1.4310, Energy: 1.0568, KLD: 2.5365, MC: 2.3034)\n",
      "Train Batch 90/110 - Loss: 6.8338 (Macro: 1.4907, Energy: 1.0190, KLD: 2.0241, MC: 2.3001)\n",
      "Train Batch 100/110 - Loss: 7.2770 (Macro: 1.6242, Energy: 1.1354, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.5757 (Macro: 1.2091, Energy: 0.7267, KLD: 2.3414, MC: 2.2984)\n",
      "Training epoch complete. Average Loss: 7.0827\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0690\n",
      "\n",
      "Epoch 359/500\n",
      "Train Batch 10/110 - Loss: 7.0970 (Macro: 1.5810, Energy: 1.1005, KLD: 2.1149, MC: 2.3006)\n",
      "Train Batch 20/110 - Loss: 6.9488 (Macro: 1.4854, Energy: 1.0288, KLD: 2.1345, MC: 2.3001)\n",
      "Train Batch 30/110 - Loss: 7.0802 (Macro: 1.4300, Energy: 1.0419, KLD: 2.3073, MC: 2.3010)\n",
      "Train Batch 40/110 - Loss: 7.3893 (Macro: 1.5586, Energy: 1.1480, KLD: 2.3805, MC: 2.3022)\n",
      "Train Batch 50/110 - Loss: 7.0299 (Macro: 1.4876, Energy: 1.0021, KLD: 2.2381, MC: 2.3022)\n",
      "Train Batch 60/110 - Loss: 6.8933 (Macro: 1.3757, Energy: 0.9586, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.9756 (Macro: 1.3858, Energy: 0.8478, KLD: 2.4378, MC: 2.3042)\n",
      "Train Batch 80/110 - Loss: 7.3389 (Macro: 1.4433, Energy: 1.0562, KLD: 2.5365, MC: 2.3030)\n",
      "Train Batch 90/110 - Loss: 6.8398 (Macro: 1.4933, Energy: 1.0210, KLD: 2.0241, MC: 2.3015)\n",
      "Train Batch 100/110 - Loss: 7.3271 (Macro: 1.6109, Energy: 1.1981, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.6261 (Macro: 1.2670, Energy: 0.7212, KLD: 2.3414, MC: 2.2965)\n",
      "Training epoch complete. Average Loss: 7.0826\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0568\n",
      "\n",
      "Epoch 360/500\n",
      "Train Batch 10/110 - Loss: 7.0658 (Macro: 1.5736, Energy: 1.0771, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.9297 (Macro: 1.4937, Energy: 1.0005, KLD: 2.1345, MC: 2.3010)\n",
      "Train Batch 30/110 - Loss: 7.0815 (Macro: 1.4497, Energy: 1.0233, KLD: 2.3073, MC: 2.3012)\n",
      "Train Batch 40/110 - Loss: 7.4471 (Macro: 1.5676, Energy: 1.1977, KLD: 2.3805, MC: 2.3013)\n",
      "Train Batch 50/110 - Loss: 7.0682 (Macro: 1.4850, Energy: 1.0436, KLD: 2.2381, MC: 2.3015)\n",
      "Train Batch 60/110 - Loss: 6.9074 (Macro: 1.3873, Energy: 0.9616, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9100 (Macro: 1.3625, Energy: 0.8046, KLD: 2.4378, MC: 2.3052)\n",
      "Train Batch 80/110 - Loss: 7.3594 (Macro: 1.4281, Energy: 1.0929, KLD: 2.5365, MC: 2.3019)\n",
      "Train Batch 90/110 - Loss: 6.7680 (Macro: 1.4852, Energy: 0.9570, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.3840 (Macro: 1.6021, Energy: 1.2641, KLD: 2.2161, MC: 2.3016)\n",
      "Train Batch 110/110 - Loss: 6.6565 (Macro: 1.2474, Energy: 0.7683, KLD: 2.3414, MC: 2.2994)\n",
      "Training epoch complete. Average Loss: 7.0821\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0609\n",
      "\n",
      "Epoch 361/500\n",
      "Train Batch 10/110 - Loss: 7.1615 (Macro: 1.6026, Energy: 1.1449, KLD: 2.1149, MC: 2.2990)\n",
      "Train Batch 20/110 - Loss: 6.9498 (Macro: 1.4803, Energy: 1.0329, KLD: 2.1345, MC: 2.3021)\n",
      "Train Batch 30/110 - Loss: 7.1349 (Macro: 1.4675, Energy: 1.0572, KLD: 2.3073, MC: 2.3029)\n",
      "Train Batch 40/110 - Loss: 7.4249 (Macro: 1.5275, Energy: 1.2141, KLD: 2.3805, MC: 2.3028)\n",
      "Train Batch 50/110 - Loss: 7.0924 (Macro: 1.4998, Energy: 1.0510, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.9431 (Macro: 1.3950, Energy: 0.9909, KLD: 2.2570, MC: 2.3002)\n",
      "Train Batch 70/110 - Loss: 6.9347 (Macro: 1.3587, Energy: 0.8343, KLD: 2.4378, MC: 2.3039)\n",
      "Train Batch 80/110 - Loss: 7.3554 (Macro: 1.4293, Energy: 1.0854, KLD: 2.5365, MC: 2.3042)\n",
      "Train Batch 90/110 - Loss: 6.7554 (Macro: 1.4615, Energy: 0.9676, KLD: 2.0241, MC: 2.3022)\n",
      "Train Batch 100/110 - Loss: 7.3326 (Macro: 1.6033, Energy: 1.2107, KLD: 2.2161, MC: 2.3025)\n",
      "Train Batch 110/110 - Loss: 6.6552 (Macro: 1.2154, Energy: 0.8013, KLD: 2.3414, MC: 2.2971)\n",
      "Training epoch complete. Average Loss: 7.0818\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0696\n",
      "\n",
      "Epoch 362/500\n",
      "Train Batch 10/110 - Loss: 7.1626 (Macro: 1.5852, Energy: 1.1623, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.9298 (Macro: 1.4970, Energy: 0.9984, KLD: 2.1345, MC: 2.2999)\n",
      "Train Batch 30/110 - Loss: 7.0727 (Macro: 1.4607, Energy: 1.0028, KLD: 2.3073, MC: 2.3020)\n",
      "Train Batch 40/110 - Loss: 7.4487 (Macro: 1.5491, Energy: 1.2173, KLD: 2.3805, MC: 2.3017)\n",
      "Train Batch 50/110 - Loss: 7.0382 (Macro: 1.4979, Energy: 0.9986, KLD: 2.2381, MC: 2.3036)\n",
      "Train Batch 60/110 - Loss: 6.9163 (Macro: 1.3934, Energy: 0.9653, KLD: 2.2570, MC: 2.3006)\n",
      "Train Batch 70/110 - Loss: 6.9540 (Macro: 1.3673, Energy: 0.8437, KLD: 2.4378, MC: 2.3052)\n",
      "Train Batch 80/110 - Loss: 7.3037 (Macro: 1.4343, Energy: 1.0314, KLD: 2.5365, MC: 2.3015)\n",
      "Train Batch 90/110 - Loss: 6.7988 (Macro: 1.4702, Energy: 1.0018, KLD: 2.0241, MC: 2.3027)\n",
      "Train Batch 100/110 - Loss: 7.3312 (Macro: 1.6022, Energy: 1.2114, KLD: 2.2161, MC: 2.3015)\n",
      "Train Batch 110/110 - Loss: 6.6057 (Macro: 1.2476, Energy: 0.7166, KLD: 2.3414, MC: 2.3001)\n",
      "Training epoch complete. Average Loss: 7.0805\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0795\n",
      "\n",
      "Epoch 363/500\n",
      "Train Batch 10/110 - Loss: 7.1387 (Macro: 1.5672, Energy: 1.1555, KLD: 2.1149, MC: 2.3011)\n",
      "Train Batch 20/110 - Loss: 6.9459 (Macro: 1.4752, Energy: 1.0349, KLD: 2.1345, MC: 2.3013)\n",
      "Train Batch 30/110 - Loss: 7.1111 (Macro: 1.4522, Energy: 1.0493, KLD: 2.3073, MC: 2.3023)\n",
      "Train Batch 40/110 - Loss: 7.4004 (Macro: 1.5473, Energy: 1.1702, KLD: 2.3805, MC: 2.3024)\n",
      "Train Batch 50/110 - Loss: 7.0337 (Macro: 1.4906, Energy: 1.0015, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.9200 (Macro: 1.3753, Energy: 0.9860, KLD: 2.2570, MC: 2.3017)\n",
      "Train Batch 70/110 - Loss: 6.9658 (Macro: 1.3599, Energy: 0.8652, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.2882 (Macro: 1.4310, Energy: 1.0177, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.8160 (Macro: 1.4788, Energy: 1.0110, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3156 (Macro: 1.6021, Energy: 1.1953, KLD: 2.2161, MC: 2.3022)\n",
      "Train Batch 110/110 - Loss: 6.5935 (Macro: 1.2154, Energy: 0.7364, KLD: 2.3414, MC: 2.3003)\n",
      "Training epoch complete. Average Loss: 7.0775\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0614\n",
      "\n",
      "Epoch 364/500\n",
      "Train Batch 10/110 - Loss: 7.0907 (Macro: 1.5774, Energy: 1.0981, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.9387 (Macro: 1.4869, Energy: 1.0154, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.1153 (Macro: 1.4715, Energy: 1.0329, KLD: 2.3073, MC: 2.3036)\n",
      "Train Batch 40/110 - Loss: 7.4250 (Macro: 1.5728, Energy: 1.1707, KLD: 2.3805, MC: 2.3011)\n",
      "Train Batch 50/110 - Loss: 7.0420 (Macro: 1.4719, Energy: 1.0285, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.9568 (Macro: 1.3787, Energy: 1.0187, KLD: 2.2570, MC: 2.3023)\n",
      "Train Batch 70/110 - Loss: 6.9862 (Macro: 1.3652, Energy: 0.8807, KLD: 2.4378, MC: 2.3024)\n",
      "Train Batch 80/110 - Loss: 7.3758 (Macro: 1.4419, Energy: 1.0943, KLD: 2.5365, MC: 2.3030)\n",
      "Train Batch 90/110 - Loss: 6.7668 (Macro: 1.4746, Energy: 0.9662, KLD: 2.0241, MC: 2.3019)\n",
      "Train Batch 100/110 - Loss: 7.2865 (Macro: 1.6016, Energy: 1.1657, KLD: 2.2161, MC: 2.3031)\n",
      "Train Batch 110/110 - Loss: 6.5377 (Macro: 1.2066, Energy: 0.6894, KLD: 2.3414, MC: 2.3003)\n",
      "Training epoch complete. Average Loss: 7.0760\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0589\n",
      "\n",
      "Epoch 365/500\n",
      "Train Batch 10/110 - Loss: 7.0969 (Macro: 1.5800, Energy: 1.1026, KLD: 2.1149, MC: 2.2994)\n",
      "Train Batch 20/110 - Loss: 6.9003 (Macro: 1.4778, Energy: 0.9854, KLD: 2.1345, MC: 2.3026)\n",
      "Train Batch 30/110 - Loss: 7.1097 (Macro: 1.4559, Energy: 1.0431, KLD: 2.3073, MC: 2.3034)\n",
      "Train Batch 40/110 - Loss: 7.3683 (Macro: 1.5422, Energy: 1.1458, KLD: 2.3805, MC: 2.2998)\n",
      "Train Batch 50/110 - Loss: 7.0825 (Macro: 1.5299, Energy: 1.0129, KLD: 2.2381, MC: 2.3017)\n",
      "Train Batch 60/110 - Loss: 6.9040 (Macro: 1.3751, Energy: 0.9720, KLD: 2.2570, MC: 2.2998)\n",
      "Train Batch 70/110 - Loss: 6.9328 (Macro: 1.3684, Energy: 0.8242, KLD: 2.4378, MC: 2.3024)\n",
      "Train Batch 80/110 - Loss: 7.3443 (Macro: 1.4333, Energy: 1.0733, KLD: 2.5365, MC: 2.3011)\n",
      "Train Batch 90/110 - Loss: 6.8252 (Macro: 1.4744, Energy: 1.0253, KLD: 2.0241, MC: 2.3015)\n",
      "Train Batch 100/110 - Loss: 7.2738 (Macro: 1.6032, Energy: 1.1516, KLD: 2.2161, MC: 2.3029)\n",
      "Train Batch 110/110 - Loss: 6.6017 (Macro: 1.2296, Energy: 0.7335, KLD: 2.3414, MC: 2.2972)\n",
      "Training epoch complete. Average Loss: 7.0787\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0699\n",
      "\n",
      "Epoch 366/500\n",
      "Train Batch 10/110 - Loss: 7.1443 (Macro: 1.5977, Energy: 1.1301, KLD: 2.1149, MC: 2.3016)\n",
      "Train Batch 20/110 - Loss: 6.9243 (Macro: 1.4705, Energy: 1.0177, KLD: 2.1345, MC: 2.3016)\n",
      "Train Batch 30/110 - Loss: 7.0141 (Macro: 1.4431, Energy: 0.9621, KLD: 2.3073, MC: 2.3016)\n",
      "Train Batch 40/110 - Loss: 7.4946 (Macro: 1.5371, Energy: 1.2754, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.0527 (Macro: 1.5154, Energy: 0.9969, KLD: 2.2381, MC: 2.3024)\n",
      "Train Batch 60/110 - Loss: 6.9392 (Macro: 1.3894, Energy: 0.9912, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9035 (Macro: 1.3444, Energy: 0.8202, KLD: 2.4378, MC: 2.3011)\n",
      "Train Batch 80/110 - Loss: 7.2491 (Macro: 1.4093, Energy: 1.0014, KLD: 2.5365, MC: 2.3020)\n",
      "Train Batch 90/110 - Loss: 6.8191 (Macro: 1.4969, Energy: 0.9953, KLD: 2.0241, MC: 2.3028)\n",
      "Train Batch 100/110 - Loss: 7.2686 (Macro: 1.5911, Energy: 1.1583, KLD: 2.2161, MC: 2.3031)\n",
      "Train Batch 110/110 - Loss: 6.6402 (Macro: 1.2223, Energy: 0.7771, KLD: 2.3414, MC: 2.2994)\n",
      "Training epoch complete. Average Loss: 7.0886\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0698\n",
      "\n",
      "Epoch 367/500\n",
      "Train Batch 10/110 - Loss: 7.1073 (Macro: 1.5840, Energy: 1.1065, KLD: 2.1149, MC: 2.3018)\n",
      "Train Batch 20/110 - Loss: 6.9093 (Macro: 1.4891, Energy: 0.9843, KLD: 2.1345, MC: 2.3014)\n",
      "Train Batch 30/110 - Loss: 7.0717 (Macro: 1.4314, Energy: 1.0298, KLD: 2.3073, MC: 2.3031)\n",
      "Train Batch 40/110 - Loss: 7.4530 (Macro: 1.5602, Energy: 1.2113, KLD: 2.3805, MC: 2.3010)\n",
      "Train Batch 50/110 - Loss: 7.0445 (Macro: 1.5005, Energy: 1.0029, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.8600 (Macro: 1.3661, Energy: 0.9357, KLD: 2.2570, MC: 2.3012)\n",
      "Train Batch 70/110 - Loss: 6.9087 (Macro: 1.3454, Energy: 0.8226, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.2617 (Macro: 1.4167, Energy: 1.0066, KLD: 2.5365, MC: 2.3019)\n",
      "Train Batch 90/110 - Loss: 6.7322 (Macro: 1.4642, Energy: 0.9417, KLD: 2.0241, MC: 2.3022)\n",
      "Train Batch 100/110 - Loss: 7.3808 (Macro: 1.6152, Energy: 1.2471, KLD: 2.2161, MC: 2.3024)\n",
      "Train Batch 110/110 - Loss: 6.6110 (Macro: 1.2123, Energy: 0.7597, KLD: 2.3414, MC: 2.2976)\n",
      "Training epoch complete. Average Loss: 7.0777\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0652\n",
      "\n",
      "Epoch 368/500\n",
      "Train Batch 10/110 - Loss: 7.1839 (Macro: 1.5768, Energy: 1.1919, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.8462 (Macro: 1.4865, Energy: 0.9237, KLD: 2.1345, MC: 2.3015)\n",
      "Train Batch 30/110 - Loss: 7.0986 (Macro: 1.4608, Energy: 1.0262, KLD: 2.3073, MC: 2.3043)\n",
      "Train Batch 40/110 - Loss: 7.4312 (Macro: 1.5494, Energy: 1.2004, KLD: 2.3805, MC: 2.3009)\n",
      "Train Batch 50/110 - Loss: 7.0729 (Macro: 1.5079, Energy: 1.0232, KLD: 2.2381, MC: 2.3038)\n",
      "Train Batch 60/110 - Loss: 6.9851 (Macro: 1.3874, Energy: 1.0394, KLD: 2.2570, MC: 2.3012)\n",
      "Train Batch 70/110 - Loss: 6.9790 (Macro: 1.3392, Energy: 0.9005, KLD: 2.4378, MC: 2.3015)\n",
      "Train Batch 80/110 - Loss: 7.2557 (Macro: 1.4096, Energy: 1.0070, KLD: 2.5365, MC: 2.3026)\n",
      "Train Batch 90/110 - Loss: 6.7931 (Macro: 1.4710, Energy: 0.9961, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.2908 (Macro: 1.6188, Energy: 1.1522, KLD: 2.2161, MC: 2.3037)\n",
      "Train Batch 110/110 - Loss: 6.5901 (Macro: 1.2182, Energy: 0.7297, KLD: 2.3414, MC: 2.3008)\n",
      "Training epoch complete. Average Loss: 7.0827\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0607\n",
      "\n",
      "Epoch 369/500\n",
      "Train Batch 10/110 - Loss: 7.1240 (Macro: 1.5753, Energy: 1.1338, KLD: 2.1149, MC: 2.2999)\n",
      "Train Batch 20/110 - Loss: 6.9106 (Macro: 1.4933, Energy: 0.9802, KLD: 2.1345, MC: 2.3027)\n",
      "Train Batch 30/110 - Loss: 7.0578 (Macro: 1.4477, Energy: 1.0015, KLD: 2.3073, MC: 2.3013)\n",
      "Train Batch 40/110 - Loss: 7.4997 (Macro: 1.5499, Energy: 1.2670, KLD: 2.3805, MC: 2.3022)\n",
      "Train Batch 50/110 - Loss: 7.0490 (Macro: 1.4941, Energy: 1.0130, KLD: 2.2381, MC: 2.3038)\n",
      "Train Batch 60/110 - Loss: 6.8928 (Macro: 1.3910, Energy: 0.9424, KLD: 2.2570, MC: 2.3023)\n",
      "Train Batch 70/110 - Loss: 6.8940 (Macro: 1.3334, Energy: 0.8183, KLD: 2.4378, MC: 2.3046)\n",
      "Train Batch 80/110 - Loss: 7.3140 (Macro: 1.4116, Energy: 1.0636, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.8132 (Macro: 1.4698, Energy: 1.0181, KLD: 2.0241, MC: 2.3013)\n",
      "Train Batch 100/110 - Loss: 7.2973 (Macro: 1.5817, Energy: 1.1969, KLD: 2.2161, MC: 2.3027)\n",
      "Train Batch 110/110 - Loss: 6.6096 (Macro: 1.2758, Energy: 0.6924, KLD: 2.3414, MC: 2.3000)\n",
      "Training epoch complete. Average Loss: 7.0781\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0658\n",
      "\n",
      "Epoch 370/500\n",
      "Train Batch 10/110 - Loss: 7.1292 (Macro: 1.5951, Energy: 1.1179, KLD: 2.1149, MC: 2.3014)\n",
      "Train Batch 20/110 - Loss: 6.8737 (Macro: 1.4857, Energy: 0.9519, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.0492 (Macro: 1.4556, Energy: 0.9848, KLD: 2.3073, MC: 2.3015)\n",
      "Train Batch 40/110 - Loss: 7.4949 (Macro: 1.5660, Energy: 1.2455, KLD: 2.3805, MC: 2.3030)\n",
      "Train Batch 50/110 - Loss: 7.0686 (Macro: 1.5030, Energy: 1.0243, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.9341 (Macro: 1.3761, Energy: 1.0002, KLD: 2.2570, MC: 2.3006)\n",
      "Train Batch 70/110 - Loss: 6.9304 (Macro: 1.3566, Energy: 0.8330, KLD: 2.4378, MC: 2.3030)\n",
      "Train Batch 80/110 - Loss: 7.2996 (Macro: 1.4524, Energy: 1.0060, KLD: 2.5365, MC: 2.3046)\n",
      "Train Batch 90/110 - Loss: 6.7954 (Macro: 1.4658, Energy: 1.0035, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.2955 (Macro: 1.5971, Energy: 1.1807, KLD: 2.2161, MC: 2.3016)\n",
      "Train Batch 110/110 - Loss: 6.5722 (Macro: 1.1993, Energy: 0.7299, KLD: 2.3414, MC: 2.3017)\n",
      "Training epoch complete. Average Loss: 7.0784\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0511\n",
      "\n",
      "Epoch 371/500\n",
      "Train Batch 10/110 - Loss: 7.0536 (Macro: 1.5595, Energy: 1.0803, KLD: 2.1149, MC: 2.2989)\n",
      "Train Batch 20/110 - Loss: 6.9085 (Macro: 1.4954, Energy: 0.9774, KLD: 2.1345, MC: 2.3012)\n",
      "Train Batch 30/110 - Loss: 7.1627 (Macro: 1.4450, Energy: 1.1088, KLD: 2.3073, MC: 2.3016)\n",
      "Train Batch 40/110 - Loss: 7.4426 (Macro: 1.5322, Energy: 1.2290, KLD: 2.3805, MC: 2.3009)\n",
      "Train Batch 50/110 - Loss: 7.1049 (Macro: 1.5120, Energy: 1.0528, KLD: 2.2381, MC: 2.3020)\n",
      "Train Batch 60/110 - Loss: 6.9479 (Macro: 1.3913, Energy: 0.9981, KLD: 2.2570, MC: 2.3014)\n",
      "Train Batch 70/110 - Loss: 6.9115 (Macro: 1.3744, Energy: 0.7948, KLD: 2.4378, MC: 2.3046)\n",
      "Train Batch 80/110 - Loss: 7.2942 (Macro: 1.4311, Energy: 1.0234, KLD: 2.5365, MC: 2.3033)\n",
      "Train Batch 90/110 - Loss: 6.7827 (Macro: 1.4995, Energy: 0.9582, KLD: 2.0241, MC: 2.3010)\n",
      "Train Batch 100/110 - Loss: 7.2618 (Macro: 1.6030, Energy: 1.1400, KLD: 2.2161, MC: 2.3027)\n",
      "Train Batch 110/110 - Loss: 6.6073 (Macro: 1.2304, Energy: 0.7373, KLD: 2.3414, MC: 2.2982)\n",
      "Training epoch complete. Average Loss: 7.0788\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0701\n",
      "\n",
      "Epoch 372/500\n",
      "Train Batch 10/110 - Loss: 7.1615 (Macro: 1.5885, Energy: 1.1574, KLD: 2.1149, MC: 2.3006)\n",
      "Train Batch 20/110 - Loss: 6.9264 (Macro: 1.4864, Energy: 1.0049, KLD: 2.1345, MC: 2.3006)\n",
      "Train Batch 30/110 - Loss: 7.1456 (Macro: 1.4703, Energy: 1.0668, KLD: 2.3073, MC: 2.3012)\n",
      "Train Batch 40/110 - Loss: 7.3802 (Macro: 1.5582, Energy: 1.1391, KLD: 2.3805, MC: 2.3024)\n",
      "Train Batch 50/110 - Loss: 7.0665 (Macro: 1.4617, Energy: 1.0647, KLD: 2.2381, MC: 2.3020)\n",
      "Train Batch 60/110 - Loss: 6.9160 (Macro: 1.3881, Energy: 0.9705, KLD: 2.2570, MC: 2.3003)\n",
      "Train Batch 70/110 - Loss: 6.9895 (Macro: 1.3549, Energy: 0.8946, KLD: 2.4378, MC: 2.3022)\n",
      "Train Batch 80/110 - Loss: 7.2598 (Macro: 1.4270, Energy: 0.9930, KLD: 2.5365, MC: 2.3033)\n",
      "Train Batch 90/110 - Loss: 6.8195 (Macro: 1.4794, Energy: 1.0140, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.3499 (Macro: 1.6052, Energy: 1.2264, KLD: 2.2161, MC: 2.3022)\n",
      "Train Batch 110/110 - Loss: 6.6242 (Macro: 1.2410, Energy: 0.7466, KLD: 2.3414, MC: 2.2953)\n",
      "Training epoch complete. Average Loss: 7.0825\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0651\n",
      "\n",
      "Epoch 373/500\n",
      "Train Batch 10/110 - Loss: 7.1596 (Macro: 1.5783, Energy: 1.1673, KLD: 2.1149, MC: 2.2991)\n",
      "Train Batch 20/110 - Loss: 6.8780 (Macro: 1.4658, Energy: 0.9763, KLD: 2.1345, MC: 2.3015)\n",
      "Train Batch 30/110 - Loss: 7.1095 (Macro: 1.4751, Energy: 1.0254, KLD: 2.3073, MC: 2.3017)\n",
      "Train Batch 40/110 - Loss: 7.5045 (Macro: 1.5766, Energy: 1.2452, KLD: 2.3805, MC: 2.3021)\n",
      "Train Batch 50/110 - Loss: 7.0622 (Macro: 1.4954, Energy: 1.0251, KLD: 2.2381, MC: 2.3036)\n",
      "Train Batch 60/110 - Loss: 6.9127 (Macro: 1.3750, Energy: 0.9796, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9691 (Macro: 1.3641, Energy: 0.8646, KLD: 2.4378, MC: 2.3027)\n",
      "Train Batch 80/110 - Loss: 7.2703 (Macro: 1.4122, Energy: 1.0185, KLD: 2.5365, MC: 2.3030)\n",
      "Train Batch 90/110 - Loss: 6.7462 (Macro: 1.4570, Energy: 0.9629, KLD: 2.0241, MC: 2.3022)\n",
      "Train Batch 100/110 - Loss: 7.3273 (Macro: 1.6015, Energy: 1.2076, KLD: 2.2161, MC: 2.3021)\n",
      "Train Batch 110/110 - Loss: 6.6341 (Macro: 1.2457, Energy: 0.7483, KLD: 2.3414, MC: 2.2987)\n",
      "Training epoch complete. Average Loss: 7.0886\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0567\n",
      "\n",
      "Epoch 374/500\n",
      "Train Batch 10/110 - Loss: 7.1329 (Macro: 1.5795, Energy: 1.1374, KLD: 2.1149, MC: 2.3011)\n",
      "Train Batch 20/110 - Loss: 6.9002 (Macro: 1.5031, Energy: 0.9606, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.0704 (Macro: 1.4800, Energy: 0.9821, KLD: 2.3073, MC: 2.3010)\n",
      "Train Batch 40/110 - Loss: 7.4181 (Macro: 1.5496, Energy: 1.1873, KLD: 2.3805, MC: 2.3007)\n",
      "Train Batch 50/110 - Loss: 7.0626 (Macro: 1.4933, Energy: 1.0280, KLD: 2.2381, MC: 2.3033)\n",
      "Train Batch 60/110 - Loss: 6.9127 (Macro: 1.3742, Energy: 0.9791, KLD: 2.2570, MC: 2.3024)\n",
      "Train Batch 70/110 - Loss: 6.9587 (Macro: 1.3624, Energy: 0.8544, KLD: 2.4378, MC: 2.3041)\n",
      "Train Batch 80/110 - Loss: 7.3329 (Macro: 1.4214, Energy: 1.0716, KLD: 2.5365, MC: 2.3035)\n",
      "Train Batch 90/110 - Loss: 6.7930 (Macro: 1.4802, Energy: 0.9878, KLD: 2.0241, MC: 2.3010)\n",
      "Train Batch 100/110 - Loss: 7.3420 (Macro: 1.6008, Energy: 1.2224, KLD: 2.2161, MC: 2.3027)\n",
      "Train Batch 110/110 - Loss: 6.5525 (Macro: 1.2458, Energy: 0.6654, KLD: 2.3414, MC: 2.2999)\n",
      "Training epoch complete. Average Loss: 7.0743\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0595\n",
      "\n",
      "Epoch 375/500\n",
      "Train Batch 10/110 - Loss: 7.0771 (Macro: 1.5621, Energy: 1.1007, KLD: 2.1149, MC: 2.2995)\n",
      "Train Batch 20/110 - Loss: 6.9186 (Macro: 1.4885, Energy: 0.9942, KLD: 2.1345, MC: 2.3015)\n",
      "Train Batch 30/110 - Loss: 7.0951 (Macro: 1.4503, Energy: 1.0355, KLD: 2.3073, MC: 2.3020)\n",
      "Train Batch 40/110 - Loss: 7.4212 (Macro: 1.5577, Energy: 1.1823, KLD: 2.3805, MC: 2.3007)\n",
      "Train Batch 50/110 - Loss: 7.0290 (Macro: 1.4948, Energy: 0.9932, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.9412 (Macro: 1.3725, Energy: 1.0096, KLD: 2.2570, MC: 2.3021)\n",
      "Train Batch 70/110 - Loss: 6.9962 (Macro: 1.3683, Energy: 0.8871, KLD: 2.4378, MC: 2.3031)\n",
      "Train Batch 80/110 - Loss: 7.3154 (Macro: 1.4413, Energy: 1.0327, KLD: 2.5365, MC: 2.3048)\n",
      "Train Batch 90/110 - Loss: 6.7437 (Macro: 1.4755, Energy: 0.9422, KLD: 2.0241, MC: 2.3019)\n",
      "Train Batch 100/110 - Loss: 7.3123 (Macro: 1.6163, Energy: 1.1774, KLD: 2.2161, MC: 2.3025)\n",
      "Train Batch 110/110 - Loss: 6.4945 (Macro: 1.2071, Energy: 0.6485, KLD: 2.3414, MC: 2.2975)\n",
      "Training epoch complete. Average Loss: 7.0783\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0626\n",
      "\n",
      "Epoch 376/500\n",
      "Train Batch 10/110 - Loss: 7.1404 (Macro: 1.5963, Energy: 1.1305, KLD: 2.1149, MC: 2.2987)\n",
      "Train Batch 20/110 - Loss: 6.8604 (Macro: 1.4859, Energy: 0.9374, KLD: 2.1345, MC: 2.3026)\n",
      "Train Batch 30/110 - Loss: 7.0497 (Macro: 1.4424, Energy: 0.9965, KLD: 2.3073, MC: 2.3034)\n",
      "Train Batch 40/110 - Loss: 7.4289 (Macro: 1.5561, Energy: 1.1923, KLD: 2.3805, MC: 2.3000)\n",
      "Train Batch 50/110 - Loss: 7.0143 (Macro: 1.4981, Energy: 0.9771, KLD: 2.2381, MC: 2.3011)\n",
      "Train Batch 60/110 - Loss: 6.9465 (Macro: 1.3825, Energy: 1.0067, KLD: 2.2570, MC: 2.3003)\n",
      "Train Batch 70/110 - Loss: 6.9279 (Macro: 1.3421, Energy: 0.8453, KLD: 2.4378, MC: 2.3027)\n",
      "Train Batch 80/110 - Loss: 7.2411 (Macro: 1.4100, Energy: 0.9913, KLD: 2.5365, MC: 2.3032)\n",
      "Train Batch 90/110 - Loss: 6.7765 (Macro: 1.4646, Energy: 0.9873, KLD: 2.0241, MC: 2.3006)\n",
      "Train Batch 100/110 - Loss: 7.3566 (Macro: 1.6143, Energy: 1.2255, KLD: 2.2161, MC: 2.3007)\n",
      "Train Batch 110/110 - Loss: 6.6463 (Macro: 1.1899, Energy: 0.8187, KLD: 2.3414, MC: 2.2963)\n",
      "Training epoch complete. Average Loss: 7.0800\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0654\n",
      "\n",
      "Epoch 377/500\n",
      "Train Batch 10/110 - Loss: 7.1510 (Macro: 1.5846, Energy: 1.1506, KLD: 2.1149, MC: 2.3008)\n",
      "Train Batch 20/110 - Loss: 6.8600 (Macro: 1.4896, Energy: 0.9351, KLD: 2.1345, MC: 2.3008)\n",
      "Train Batch 30/110 - Loss: 7.1066 (Macro: 1.4777, Energy: 1.0191, KLD: 2.3073, MC: 2.3025)\n",
      "Train Batch 40/110 - Loss: 7.4547 (Macro: 1.5525, Energy: 1.2192, KLD: 2.3805, MC: 2.3025)\n",
      "Train Batch 50/110 - Loss: 7.0543 (Macro: 1.5091, Energy: 1.0036, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.9308 (Macro: 1.3830, Energy: 0.9891, KLD: 2.2570, MC: 2.3017)\n",
      "Train Batch 70/110 - Loss: 6.9419 (Macro: 1.3577, Energy: 0.8421, KLD: 2.4378, MC: 2.3043)\n",
      "Train Batch 80/110 - Loss: 7.2774 (Macro: 1.4279, Energy: 1.0103, KLD: 2.5365, MC: 2.3027)\n",
      "Train Batch 90/110 - Loss: 6.7286 (Macro: 1.4688, Energy: 0.9344, KLD: 2.0241, MC: 2.3014)\n",
      "Train Batch 100/110 - Loss: 7.2904 (Macro: 1.5802, Energy: 1.1919, KLD: 2.2161, MC: 2.3022)\n",
      "Train Batch 110/110 - Loss: 6.6301 (Macro: 1.2065, Energy: 0.7840, KLD: 2.3414, MC: 2.2982)\n",
      "Training epoch complete. Average Loss: 7.0762\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0649\n",
      "\n",
      "Epoch 378/500\n",
      "Train Batch 10/110 - Loss: 7.1424 (Macro: 1.5957, Energy: 1.1311, KLD: 2.1149, MC: 2.3006)\n",
      "Train Batch 20/110 - Loss: 6.9003 (Macro: 1.4914, Energy: 0.9733, KLD: 2.1345, MC: 2.3011)\n",
      "Train Batch 30/110 - Loss: 7.1088 (Macro: 1.4646, Energy: 1.0346, KLD: 2.3073, MC: 2.3023)\n",
      "Train Batch 40/110 - Loss: 7.4974 (Macro: 1.5802, Energy: 1.2337, KLD: 2.3805, MC: 2.3030)\n",
      "Train Batch 50/110 - Loss: 7.0129 (Macro: 1.5071, Energy: 0.9642, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.9552 (Macro: 1.4235, Energy: 0.9727, KLD: 2.2570, MC: 2.3019)\n",
      "Train Batch 70/110 - Loss: 6.9839 (Macro: 1.3732, Energy: 0.8697, KLD: 2.4378, MC: 2.3032)\n",
      "Train Batch 80/110 - Loss: 7.2359 (Macro: 1.4143, Energy: 0.9832, KLD: 2.5365, MC: 2.3020)\n",
      "Train Batch 90/110 - Loss: 6.8055 (Macro: 1.4815, Energy: 0.9976, KLD: 2.0241, MC: 2.3023)\n",
      "Train Batch 100/110 - Loss: 7.3097 (Macro: 1.6108, Energy: 1.1805, KLD: 2.2161, MC: 2.3024)\n",
      "Train Batch 110/110 - Loss: 6.6775 (Macro: 1.2364, Energy: 0.8000, KLD: 2.3414, MC: 2.2998)\n",
      "Training epoch complete. Average Loss: 7.0833\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0722\n",
      "\n",
      "Epoch 379/500\n",
      "Train Batch 10/110 - Loss: 7.1044 (Macro: 1.5950, Energy: 1.0936, KLD: 2.1149, MC: 2.3008)\n",
      "Train Batch 20/110 - Loss: 6.8895 (Macro: 1.4704, Energy: 0.9825, KLD: 2.1345, MC: 2.3021)\n",
      "Train Batch 30/110 - Loss: 7.0837 (Macro: 1.4500, Energy: 1.0270, KLD: 2.3073, MC: 2.2994)\n",
      "Train Batch 40/110 - Loss: 7.3903 (Macro: 1.5446, Energy: 1.1633, KLD: 2.3805, MC: 2.3020)\n",
      "Train Batch 50/110 - Loss: 7.0561 (Macro: 1.5086, Energy: 1.0064, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.8933 (Macro: 1.3853, Energy: 0.9505, KLD: 2.2570, MC: 2.3005)\n",
      "Train Batch 70/110 - Loss: 6.9501 (Macro: 1.3395, Energy: 0.8683, KLD: 2.4378, MC: 2.3045)\n",
      "Train Batch 80/110 - Loss: 7.3041 (Macro: 1.4262, Energy: 1.0376, KLD: 2.5365, MC: 2.3038)\n",
      "Train Batch 90/110 - Loss: 6.7990 (Macro: 1.4627, Energy: 1.0109, KLD: 2.0241, MC: 2.3014)\n",
      "Train Batch 100/110 - Loss: 7.2704 (Macro: 1.5971, Energy: 1.1562, KLD: 2.2161, MC: 2.3010)\n",
      "Train Batch 110/110 - Loss: 6.6567 (Macro: 1.2411, Energy: 0.7783, KLD: 2.3414, MC: 2.2958)\n",
      "Training epoch complete. Average Loss: 7.0721\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0687\n",
      "\n",
      "Epoch 380/500\n",
      "Train Batch 10/110 - Loss: 7.0699 (Macro: 1.5484, Energy: 1.1053, KLD: 2.1149, MC: 2.3014)\n",
      "Train Batch 20/110 - Loss: 6.8683 (Macro: 1.4836, Energy: 0.9472, KLD: 2.1345, MC: 2.3030)\n",
      "Train Batch 30/110 - Loss: 7.0316 (Macro: 1.4487, Energy: 0.9731, KLD: 2.3073, MC: 2.3025)\n",
      "Train Batch 40/110 - Loss: 7.4522 (Macro: 1.5601, Energy: 1.2108, KLD: 2.3805, MC: 2.3008)\n",
      "Train Batch 50/110 - Loss: 7.0686 (Macro: 1.4990, Energy: 1.0293, KLD: 2.2381, MC: 2.3023)\n",
      "Train Batch 60/110 - Loss: 7.0009 (Macro: 1.4040, Energy: 1.0380, KLD: 2.2570, MC: 2.3019)\n",
      "Train Batch 70/110 - Loss: 6.9128 (Macro: 1.3473, Energy: 0.8243, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.4068 (Macro: 1.4422, Energy: 1.1245, KLD: 2.5365, MC: 2.3035)\n",
      "Train Batch 90/110 - Loss: 6.7711 (Macro: 1.4675, Energy: 0.9789, KLD: 2.0241, MC: 2.3006)\n",
      "Train Batch 100/110 - Loss: 7.3694 (Macro: 1.5963, Energy: 1.2539, KLD: 2.2161, MC: 2.3030)\n",
      "Train Batch 110/110 - Loss: 6.5532 (Macro: 1.2350, Energy: 0.6776, KLD: 2.3414, MC: 2.2993)\n",
      "Training epoch complete. Average Loss: 7.0810\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0655\n",
      "\n",
      "Epoch 381/500\n",
      "Train Batch 10/110 - Loss: 7.1064 (Macro: 1.5528, Energy: 1.1397, KLD: 2.1149, MC: 2.2989)\n",
      "Train Batch 20/110 - Loss: 6.8656 (Macro: 1.4827, Energy: 0.9459, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.0945 (Macro: 1.4689, Energy: 1.0170, KLD: 2.3073, MC: 2.3014)\n",
      "Train Batch 40/110 - Loss: 7.4209 (Macro: 1.5446, Energy: 1.1931, KLD: 2.3805, MC: 2.3027)\n",
      "Train Batch 50/110 - Loss: 7.0690 (Macro: 1.4982, Energy: 1.0285, KLD: 2.2381, MC: 2.3043)\n",
      "Train Batch 60/110 - Loss: 6.9498 (Macro: 1.4040, Energy: 0.9872, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9518 (Macro: 1.3629, Energy: 0.8474, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.3010 (Macro: 1.4188, Energy: 1.0434, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.7942 (Macro: 1.4644, Energy: 1.0052, KLD: 2.0241, MC: 2.3006)\n",
      "Train Batch 100/110 - Loss: 7.2813 (Macro: 1.5743, Energy: 1.1888, KLD: 2.2161, MC: 2.3022)\n",
      "Train Batch 110/110 - Loss: 6.7075 (Macro: 1.2302, Energy: 0.8347, KLD: 2.3414, MC: 2.3013)\n",
      "Training epoch complete. Average Loss: 7.0790\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0631\n",
      "\n",
      "Epoch 382/500\n",
      "Train Batch 10/110 - Loss: 7.1522 (Macro: 1.5772, Energy: 1.1588, KLD: 2.1149, MC: 2.3014)\n",
      "Train Batch 20/110 - Loss: 6.8727 (Macro: 1.4857, Energy: 0.9491, KLD: 2.1345, MC: 2.3033)\n",
      "Train Batch 30/110 - Loss: 7.0713 (Macro: 1.4648, Energy: 0.9985, KLD: 2.3073, MC: 2.3007)\n",
      "Train Batch 40/110 - Loss: 7.4174 (Macro: 1.5510, Energy: 1.1829, KLD: 2.3805, MC: 2.3030)\n",
      "Train Batch 50/110 - Loss: 7.0117 (Macro: 1.5005, Energy: 0.9685, KLD: 2.2381, MC: 2.3047)\n",
      "Train Batch 60/110 - Loss: 6.9161 (Macro: 1.3645, Energy: 0.9930, KLD: 2.2570, MC: 2.3016)\n",
      "Train Batch 70/110 - Loss: 6.9858 (Macro: 1.3702, Energy: 0.8748, KLD: 2.4378, MC: 2.3031)\n",
      "Train Batch 80/110 - Loss: 7.3601 (Macro: 1.4260, Energy: 1.0952, KLD: 2.5365, MC: 2.3025)\n",
      "Train Batch 90/110 - Loss: 6.7753 (Macro: 1.4696, Energy: 0.9800, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.3627 (Macro: 1.6013, Energy: 1.2430, KLD: 2.2161, MC: 2.3023)\n",
      "Train Batch 110/110 - Loss: 6.6441 (Macro: 1.2557, Energy: 0.7488, KLD: 2.3414, MC: 2.2983)\n",
      "Training epoch complete. Average Loss: 7.0785\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0611\n",
      "\n",
      "Epoch 383/500\n",
      "Train Batch 10/110 - Loss: 7.1426 (Macro: 1.5764, Energy: 1.1521, KLD: 2.1149, MC: 2.2993)\n",
      "Train Batch 20/110 - Loss: 6.8710 (Macro: 1.4753, Energy: 0.9603, KLD: 2.1345, MC: 2.3009)\n",
      "Train Batch 30/110 - Loss: 7.0489 (Macro: 1.4472, Energy: 0.9933, KLD: 2.3073, MC: 2.3011)\n",
      "Train Batch 40/110 - Loss: 7.4732 (Macro: 1.5509, Energy: 1.2406, KLD: 2.3805, MC: 2.3011)\n",
      "Train Batch 50/110 - Loss: 7.0600 (Macro: 1.4984, Energy: 1.0195, KLD: 2.2381, MC: 2.3041)\n",
      "Train Batch 60/110 - Loss: 6.8861 (Macro: 1.3716, Energy: 0.9563, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9238 (Macro: 1.3484, Energy: 0.8347, KLD: 2.4378, MC: 2.3030)\n",
      "Train Batch 80/110 - Loss: 7.3611 (Macro: 1.4385, Energy: 1.0841, KLD: 2.5365, MC: 2.3020)\n",
      "Train Batch 90/110 - Loss: 6.8060 (Macro: 1.4652, Energy: 1.0136, KLD: 2.0241, MC: 2.3031)\n",
      "Train Batch 100/110 - Loss: 7.3176 (Macro: 1.5755, Energy: 1.2233, KLD: 2.2161, MC: 2.3027)\n",
      "Train Batch 110/110 - Loss: 6.5417 (Macro: 1.2053, Energy: 0.6970, KLD: 2.3414, MC: 2.2980)\n",
      "Training epoch complete. Average Loss: 7.0745\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0673\n",
      "\n",
      "Epoch 384/500\n",
      "Train Batch 10/110 - Loss: 7.1908 (Macro: 1.5776, Energy: 1.1982, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.9189 (Macro: 1.4949, Energy: 0.9869, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.0528 (Macro: 1.4465, Energy: 0.9959, KLD: 2.3073, MC: 2.3032)\n",
      "Train Batch 40/110 - Loss: 7.4491 (Macro: 1.5556, Energy: 1.2114, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0355 (Macro: 1.4974, Energy: 0.9964, KLD: 2.2381, MC: 2.3037)\n",
      "Train Batch 60/110 - Loss: 6.8733 (Macro: 1.3781, Energy: 0.9389, KLD: 2.2570, MC: 2.2993)\n",
      "Train Batch 70/110 - Loss: 6.9319 (Macro: 1.3756, Energy: 0.8148, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.3381 (Macro: 1.4290, Energy: 1.0703, KLD: 2.5365, MC: 2.3022)\n",
      "Train Batch 90/110 - Loss: 6.7575 (Macro: 1.4677, Energy: 0.9630, KLD: 2.0241, MC: 2.3027)\n",
      "Train Batch 100/110 - Loss: 7.3022 (Macro: 1.5936, Energy: 1.1911, KLD: 2.2161, MC: 2.3014)\n",
      "Train Batch 110/110 - Loss: 6.4908 (Macro: 1.2079, Energy: 0.6437, KLD: 2.3414, MC: 2.2978)\n",
      "Training epoch complete. Average Loss: 7.0716\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0604\n",
      "\n",
      "Epoch 385/500\n",
      "Train Batch 10/110 - Loss: 7.1280 (Macro: 1.5627, Energy: 1.1511, KLD: 2.1149, MC: 2.2993)\n",
      "Train Batch 20/110 - Loss: 6.8560 (Macro: 1.4837, Energy: 0.9356, KLD: 2.1345, MC: 2.3022)\n",
      "Train Batch 30/110 - Loss: 7.0926 (Macro: 1.4643, Energy: 1.0196, KLD: 2.3073, MC: 2.3015)\n",
      "Train Batch 40/110 - Loss: 7.4249 (Macro: 1.5635, Energy: 1.1805, KLD: 2.3805, MC: 2.3004)\n",
      "Train Batch 50/110 - Loss: 7.0936 (Macro: 1.4893, Energy: 1.0633, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.8884 (Macro: 1.3962, Energy: 0.9343, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 6.9666 (Macro: 1.3685, Energy: 0.8570, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.2599 (Macro: 1.4253, Energy: 0.9939, KLD: 2.5365, MC: 2.3041)\n",
      "Train Batch 90/110 - Loss: 6.7686 (Macro: 1.4886, Energy: 0.9543, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.3236 (Macro: 1.6048, Energy: 1.2008, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.5635 (Macro: 1.2038, Energy: 0.7154, KLD: 2.3414, MC: 2.3030)\n",
      "Training epoch complete. Average Loss: 7.0814\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0641\n",
      "\n",
      "Epoch 386/500\n",
      "Train Batch 10/110 - Loss: 7.1163 (Macro: 1.5836, Energy: 1.1197, KLD: 2.1149, MC: 2.2980)\n",
      "Train Batch 20/110 - Loss: 6.8909 (Macro: 1.4829, Energy: 0.9728, KLD: 2.1345, MC: 2.3007)\n",
      "Train Batch 30/110 - Loss: 7.1403 (Macro: 1.4777, Energy: 1.0529, KLD: 2.3073, MC: 2.3023)\n",
      "Train Batch 40/110 - Loss: 7.4815 (Macro: 1.5578, Energy: 1.2416, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0414 (Macro: 1.4906, Energy: 1.0100, KLD: 2.2381, MC: 2.3027)\n",
      "Train Batch 60/110 - Loss: 6.9235 (Macro: 1.3801, Energy: 0.9829, KLD: 2.2570, MC: 2.3034)\n",
      "Train Batch 70/110 - Loss: 6.9086 (Macro: 1.3439, Energy: 0.8251, KLD: 2.4378, MC: 2.3018)\n",
      "Train Batch 80/110 - Loss: 7.3112 (Macro: 1.4346, Energy: 1.0371, KLD: 2.5365, MC: 2.3030)\n",
      "Train Batch 90/110 - Loss: 6.8220 (Macro: 1.4901, Energy: 1.0054, KLD: 2.0241, MC: 2.3024)\n",
      "Train Batch 100/110 - Loss: 7.2804 (Macro: 1.6029, Energy: 1.1595, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.5601 (Macro: 1.1964, Energy: 0.7254, KLD: 2.3414, MC: 2.2969)\n",
      "Training epoch complete. Average Loss: 7.0814\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0606\n",
      "\n",
      "Epoch 387/500\n",
      "Train Batch 10/110 - Loss: 7.1692 (Macro: 1.5848, Energy: 1.1693, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.8518 (Macro: 1.4714, Energy: 0.9442, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.1047 (Macro: 1.4582, Energy: 1.0359, KLD: 2.3073, MC: 2.3033)\n",
      "Train Batch 40/110 - Loss: 7.4620 (Macro: 1.5441, Energy: 1.2351, KLD: 2.3805, MC: 2.3023)\n",
      "Train Batch 50/110 - Loss: 7.0678 (Macro: 1.4901, Energy: 1.0355, KLD: 2.2381, MC: 2.3041)\n",
      "Train Batch 60/110 - Loss: 6.9166 (Macro: 1.3854, Energy: 0.9731, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9630 (Macro: 1.3824, Energy: 0.8401, KLD: 2.4378, MC: 2.3027)\n",
      "Train Batch 80/110 - Loss: 7.3148 (Macro: 1.4250, Energy: 1.0503, KLD: 2.5365, MC: 2.3030)\n",
      "Train Batch 90/110 - Loss: 6.7394 (Macro: 1.4677, Energy: 0.9459, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.3842 (Macro: 1.6080, Energy: 1.2586, KLD: 2.2161, MC: 2.3016)\n",
      "Train Batch 110/110 - Loss: 6.6560 (Macro: 1.2442, Energy: 0.7728, KLD: 2.3414, MC: 2.2975)\n",
      "Training epoch complete. Average Loss: 7.0856\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0674\n",
      "\n",
      "Epoch 388/500\n",
      "Train Batch 10/110 - Loss: 7.1646 (Macro: 1.5657, Energy: 1.1832, KLD: 2.1149, MC: 2.3008)\n",
      "Train Batch 20/110 - Loss: 6.8684 (Macro: 1.4720, Energy: 0.9595, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.0891 (Macro: 1.4559, Energy: 1.0244, KLD: 2.3073, MC: 2.3015)\n",
      "Train Batch 40/110 - Loss: 7.4019 (Macro: 1.5667, Energy: 1.1510, KLD: 2.3805, MC: 2.3037)\n",
      "Train Batch 50/110 - Loss: 7.1109 (Macro: 1.5133, Energy: 1.0573, KLD: 2.2381, MC: 2.3023)\n",
      "Train Batch 60/110 - Loss: 6.9240 (Macro: 1.3979, Energy: 0.9673, KLD: 2.2570, MC: 2.3017)\n",
      "Train Batch 70/110 - Loss: 6.9881 (Macro: 1.3407, Energy: 0.9065, KLD: 2.4378, MC: 2.3032)\n",
      "Train Batch 80/110 - Loss: 7.2890 (Macro: 1.4349, Energy: 1.0151, KLD: 2.5365, MC: 2.3025)\n",
      "Train Batch 90/110 - Loss: 6.8139 (Macro: 1.4858, Energy: 1.0024, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.2829 (Macro: 1.6055, Energy: 1.1584, KLD: 2.2161, MC: 2.3028)\n",
      "Train Batch 110/110 - Loss: 6.6290 (Macro: 1.2449, Energy: 0.7415, KLD: 2.3414, MC: 2.3012)\n",
      "Training epoch complete. Average Loss: 7.0808\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0755\n",
      "\n",
      "Epoch 389/500\n",
      "Train Batch 10/110 - Loss: 7.1481 (Macro: 1.5884, Energy: 1.1449, KLD: 2.1149, MC: 2.2998)\n",
      "Train Batch 20/110 - Loss: 6.8952 (Macro: 1.4880, Energy: 0.9714, KLD: 2.1345, MC: 2.3012)\n",
      "Train Batch 30/110 - Loss: 7.0493 (Macro: 1.4461, Energy: 0.9943, KLD: 2.3073, MC: 2.3016)\n",
      "Train Batch 40/110 - Loss: 7.4619 (Macro: 1.5440, Energy: 1.2355, KLD: 2.3805, MC: 2.3019)\n",
      "Train Batch 50/110 - Loss: 7.0466 (Macro: 1.5044, Energy: 1.0007, KLD: 2.2381, MC: 2.3034)\n",
      "Train Batch 60/110 - Loss: 6.9279 (Macro: 1.3954, Energy: 0.9732, KLD: 2.2570, MC: 2.3022)\n",
      "Train Batch 70/110 - Loss: 7.0311 (Macro: 1.3768, Energy: 0.9127, KLD: 2.4378, MC: 2.3038)\n",
      "Train Batch 80/110 - Loss: 7.2705 (Macro: 1.4166, Energy: 1.0152, KLD: 2.5365, MC: 2.3022)\n",
      "Train Batch 90/110 - Loss: 6.7514 (Macro: 1.4740, Energy: 0.9519, KLD: 2.0241, MC: 2.3014)\n",
      "Train Batch 100/110 - Loss: 7.2818 (Macro: 1.6021, Energy: 1.1627, KLD: 2.2161, MC: 2.3009)\n",
      "Train Batch 110/110 - Loss: 6.5995 (Macro: 1.2323, Energy: 0.7286, KLD: 2.3414, MC: 2.2973)\n",
      "Training epoch complete. Average Loss: 7.0778\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0659\n",
      "\n",
      "Epoch 390/500\n",
      "Train Batch 10/110 - Loss: 7.1272 (Macro: 1.5660, Energy: 1.1460, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.8969 (Macro: 1.4717, Energy: 0.9876, KLD: 2.1345, MC: 2.3031)\n",
      "Train Batch 30/110 - Loss: 7.0279 (Macro: 1.4343, Energy: 0.9879, KLD: 2.3073, MC: 2.2984)\n",
      "Train Batch 40/110 - Loss: 7.4458 (Macro: 1.5553, Energy: 1.2079, KLD: 2.3805, MC: 2.3020)\n",
      "Train Batch 50/110 - Loss: 7.0798 (Macro: 1.4972, Energy: 1.0425, KLD: 2.2381, MC: 2.3021)\n",
      "Train Batch 60/110 - Loss: 6.9256 (Macro: 1.3901, Energy: 0.9770, KLD: 2.2570, MC: 2.3014)\n",
      "Train Batch 70/110 - Loss: 6.9725 (Macro: 1.3547, Energy: 0.8760, KLD: 2.4378, MC: 2.3040)\n",
      "Train Batch 80/110 - Loss: 7.3001 (Macro: 1.4295, Energy: 1.0311, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.7792 (Macro: 1.4747, Energy: 0.9788, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.2905 (Macro: 1.6025, Energy: 1.1713, KLD: 2.2161, MC: 2.3005)\n",
      "Train Batch 110/110 - Loss: 6.5261 (Macro: 1.1921, Energy: 0.6965, KLD: 2.3414, MC: 2.2962)\n",
      "Training epoch complete. Average Loss: 7.0776\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0655\n",
      "\n",
      "Epoch 391/500\n",
      "Train Batch 10/110 - Loss: 7.1814 (Macro: 1.5993, Energy: 1.1670, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.9209 (Macro: 1.4901, Energy: 0.9942, KLD: 2.1345, MC: 2.3021)\n",
      "Train Batch 30/110 - Loss: 7.0634 (Macro: 1.4443, Energy: 1.0084, KLD: 2.3073, MC: 2.3034)\n",
      "Train Batch 40/110 - Loss: 7.4388 (Macro: 1.5766, Energy: 1.1803, KLD: 2.3805, MC: 2.3013)\n",
      "Train Batch 50/110 - Loss: 7.0324 (Macro: 1.5047, Energy: 0.9869, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.9725 (Macro: 1.4106, Energy: 1.0050, KLD: 2.2570, MC: 2.2999)\n",
      "Train Batch 70/110 - Loss: 6.9659 (Macro: 1.3701, Energy: 0.8553, KLD: 2.4378, MC: 2.3027)\n",
      "Train Batch 80/110 - Loss: 7.2538 (Macro: 1.4262, Energy: 0.9910, KLD: 2.5365, MC: 2.3002)\n",
      "Train Batch 90/110 - Loss: 6.7846 (Macro: 1.4887, Energy: 0.9701, KLD: 2.0241, MC: 2.3018)\n",
      "Train Batch 100/110 - Loss: 7.2982 (Macro: 1.6185, Energy: 1.1616, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.6208 (Macro: 1.2174, Energy: 0.7646, KLD: 2.3414, MC: 2.2974)\n",
      "Training epoch complete. Average Loss: 7.0806\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0632\n",
      "\n",
      "Epoch 392/500\n",
      "Train Batch 10/110 - Loss: 7.1113 (Macro: 1.5809, Energy: 1.1164, KLD: 2.1149, MC: 2.2991)\n",
      "Train Batch 20/110 - Loss: 6.9203 (Macro: 1.4714, Energy: 1.0115, KLD: 2.1345, MC: 2.3029)\n",
      "Train Batch 30/110 - Loss: 7.0661 (Macro: 1.4567, Energy: 0.9972, KLD: 2.3073, MC: 2.3050)\n",
      "Train Batch 40/110 - Loss: 7.4539 (Macro: 1.5507, Energy: 1.2225, KLD: 2.3805, MC: 2.3002)\n",
      "Train Batch 50/110 - Loss: 7.0417 (Macro: 1.4939, Energy: 1.0058, KLD: 2.2381, MC: 2.3039)\n",
      "Train Batch 60/110 - Loss: 6.9229 (Macro: 1.3886, Energy: 0.9763, KLD: 2.2570, MC: 2.3010)\n",
      "Train Batch 70/110 - Loss: 6.9663 (Macro: 1.3557, Energy: 0.8696, KLD: 2.4378, MC: 2.3032)\n",
      "Train Batch 80/110 - Loss: 7.2694 (Macro: 1.4202, Energy: 1.0103, KLD: 2.5365, MC: 2.3024)\n",
      "Train Batch 90/110 - Loss: 6.7864 (Macro: 1.4725, Energy: 0.9876, KLD: 2.0241, MC: 2.3022)\n",
      "Train Batch 100/110 - Loss: 7.3069 (Macro: 1.5776, Energy: 1.2121, KLD: 2.2161, MC: 2.3011)\n",
      "Train Batch 110/110 - Loss: 6.6146 (Macro: 1.2327, Energy: 0.7410, KLD: 2.3414, MC: 2.2995)\n",
      "Training epoch complete. Average Loss: 7.0795\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0627\n",
      "\n",
      "Epoch 393/500\n",
      "Train Batch 10/110 - Loss: 7.0931 (Macro: 1.5628, Energy: 1.1165, KLD: 2.1149, MC: 2.2988)\n",
      "Train Batch 20/110 - Loss: 6.8860 (Macro: 1.5035, Energy: 0.9449, KLD: 2.1345, MC: 2.3031)\n",
      "Train Batch 30/110 - Loss: 7.1124 (Macro: 1.4463, Energy: 1.0552, KLD: 2.3073, MC: 2.3035)\n",
      "Train Batch 40/110 - Loss: 7.4303 (Macro: 1.5657, Energy: 1.1829, KLD: 2.3805, MC: 2.3011)\n",
      "Train Batch 50/110 - Loss: 7.0748 (Macro: 1.4982, Energy: 1.0354, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.9377 (Macro: 1.3983, Energy: 0.9795, KLD: 2.2570, MC: 2.3029)\n",
      "Train Batch 70/110 - Loss: 6.9258 (Macro: 1.3682, Energy: 0.8166, KLD: 2.4378, MC: 2.3033)\n",
      "Train Batch 80/110 - Loss: 7.3173 (Macro: 1.4150, Energy: 1.0612, KLD: 2.5365, MC: 2.3046)\n",
      "Train Batch 90/110 - Loss: 6.7423 (Macro: 1.4591, Energy: 0.9560, KLD: 2.0241, MC: 2.3031)\n",
      "Train Batch 100/110 - Loss: 7.3255 (Macro: 1.5887, Energy: 1.2195, KLD: 2.2161, MC: 2.3011)\n",
      "Train Batch 110/110 - Loss: 6.6246 (Macro: 1.2062, Energy: 0.7766, KLD: 2.3414, MC: 2.3004)\n",
      "Training epoch complete. Average Loss: 7.0759\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0633\n",
      "\n",
      "Epoch 394/500\n",
      "Train Batch 10/110 - Loss: 7.0958 (Macro: 1.5698, Energy: 1.1098, KLD: 2.1149, MC: 2.3012)\n",
      "Train Batch 20/110 - Loss: 6.9758 (Macro: 1.4796, Energy: 1.0609, KLD: 2.1345, MC: 2.3008)\n",
      "Train Batch 30/110 - Loss: 7.1016 (Macro: 1.4668, Energy: 1.0271, KLD: 2.3073, MC: 2.3005)\n",
      "Train Batch 40/110 - Loss: 7.4535 (Macro: 1.5558, Energy: 1.2153, KLD: 2.3805, MC: 2.3019)\n",
      "Train Batch 50/110 - Loss: 7.0776 (Macro: 1.5066, Energy: 1.0305, KLD: 2.2381, MC: 2.3025)\n",
      "Train Batch 60/110 - Loss: 6.9078 (Macro: 1.3809, Energy: 0.9677, KLD: 2.2570, MC: 2.3021)\n",
      "Train Batch 70/110 - Loss: 6.9573 (Macro: 1.3478, Energy: 0.8676, KLD: 2.4378, MC: 2.3041)\n",
      "Train Batch 80/110 - Loss: 7.3236 (Macro: 1.4182, Energy: 1.0653, KLD: 2.5365, MC: 2.3036)\n",
      "Train Batch 90/110 - Loss: 6.7973 (Macro: 1.4792, Energy: 0.9918, KLD: 2.0241, MC: 2.3023)\n",
      "Train Batch 100/110 - Loss: 7.2636 (Macro: 1.5894, Energy: 1.1567, KLD: 2.2161, MC: 2.3014)\n",
      "Train Batch 110/110 - Loss: 6.6435 (Macro: 1.2505, Energy: 0.7550, KLD: 2.3414, MC: 2.2966)\n",
      "Training epoch complete. Average Loss: 7.0858\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0619\n",
      "\n",
      "Epoch 395/500\n",
      "Train Batch 10/110 - Loss: 7.1672 (Macro: 1.5736, Energy: 1.1777, KLD: 2.1149, MC: 2.3010)\n",
      "Train Batch 20/110 - Loss: 6.9211 (Macro: 1.4838, Energy: 1.0009, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.0571 (Macro: 1.4417, Energy: 1.0050, KLD: 2.3073, MC: 2.3031)\n",
      "Train Batch 40/110 - Loss: 7.4575 (Macro: 1.5433, Energy: 1.2333, KLD: 2.3805, MC: 2.3004)\n",
      "Train Batch 50/110 - Loss: 7.0922 (Macro: 1.4949, Energy: 1.0577, KLD: 2.2381, MC: 2.3016)\n",
      "Train Batch 60/110 - Loss: 6.8584 (Macro: 1.3633, Energy: 0.9362, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 6.9684 (Macro: 1.3350, Energy: 0.8920, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.3444 (Macro: 1.4478, Energy: 1.0586, KLD: 2.5365, MC: 2.3015)\n",
      "Train Batch 90/110 - Loss: 6.8590 (Macro: 1.4872, Energy: 1.0445, KLD: 2.0241, MC: 2.3032)\n",
      "Train Batch 100/110 - Loss: 7.2910 (Macro: 1.5944, Energy: 1.1786, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.6249 (Macro: 1.2390, Energy: 0.7472, KLD: 2.3414, MC: 2.2973)\n",
      "Training epoch complete. Average Loss: 7.0801\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0590\n",
      "\n",
      "Epoch 396/500\n",
      "Train Batch 10/110 - Loss: 7.1679 (Macro: 1.5940, Energy: 1.1582, KLD: 2.1149, MC: 2.3007)\n",
      "Train Batch 20/110 - Loss: 6.9047 (Macro: 1.5000, Energy: 0.9701, KLD: 2.1345, MC: 2.3001)\n",
      "Train Batch 30/110 - Loss: 7.1046 (Macro: 1.4658, Energy: 1.0293, KLD: 2.3073, MC: 2.3022)\n",
      "Train Batch 40/110 - Loss: 7.4505 (Macro: 1.5333, Energy: 1.2359, KLD: 2.3805, MC: 2.3008)\n",
      "Train Batch 50/110 - Loss: 7.0969 (Macro: 1.5018, Energy: 1.0539, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.8854 (Macro: 1.3757, Energy: 0.9508, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 6.9801 (Macro: 1.3586, Energy: 0.8821, KLD: 2.4378, MC: 2.3017)\n",
      "Train Batch 80/110 - Loss: 7.3240 (Macro: 1.4226, Energy: 1.0617, KLD: 2.5365, MC: 2.3032)\n",
      "Train Batch 90/110 - Loss: 6.7749 (Macro: 1.4896, Energy: 0.9584, KLD: 2.0241, MC: 2.3028)\n",
      "Train Batch 100/110 - Loss: 7.2991 (Macro: 1.6031, Energy: 1.1771, KLD: 2.2161, MC: 2.3028)\n",
      "Train Batch 110/110 - Loss: 6.7057 (Macro: 1.2625, Energy: 0.8059, KLD: 2.3414, MC: 2.2958)\n",
      "Training epoch complete. Average Loss: 7.0822\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0614\n",
      "\n",
      "Epoch 397/500\n",
      "Train Batch 10/110 - Loss: 7.1291 (Macro: 1.5862, Energy: 1.1281, KLD: 2.1149, MC: 2.2999)\n",
      "Train Batch 20/110 - Loss: 6.9131 (Macro: 1.4939, Energy: 0.9826, KLD: 2.1345, MC: 2.3021)\n",
      "Train Batch 30/110 - Loss: 7.0932 (Macro: 1.4776, Energy: 1.0086, KLD: 2.3073, MC: 2.2997)\n",
      "Train Batch 40/110 - Loss: 7.4362 (Macro: 1.5613, Energy: 1.1905, KLD: 2.3805, MC: 2.3039)\n",
      "Train Batch 50/110 - Loss: 7.0385 (Macro: 1.4922, Energy: 1.0052, KLD: 2.2381, MC: 2.3031)\n",
      "Train Batch 60/110 - Loss: 6.9403 (Macro: 1.3861, Energy: 0.9972, KLD: 2.2570, MC: 2.2999)\n",
      "Train Batch 70/110 - Loss: 6.9877 (Macro: 1.3763, Energy: 0.8697, KLD: 2.4378, MC: 2.3040)\n",
      "Train Batch 80/110 - Loss: 7.3188 (Macro: 1.4267, Energy: 1.0526, KLD: 2.5365, MC: 2.3030)\n",
      "Train Batch 90/110 - Loss: 6.7626 (Macro: 1.4925, Energy: 0.9434, KLD: 2.0241, MC: 2.3027)\n",
      "Train Batch 100/110 - Loss: 7.3887 (Macro: 1.6076, Energy: 1.2623, KLD: 2.2161, MC: 2.3027)\n",
      "Train Batch 110/110 - Loss: 6.6460 (Macro: 1.2448, Energy: 0.7614, KLD: 2.3414, MC: 2.2984)\n",
      "Training epoch complete. Average Loss: 7.0810\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0613\n",
      "\n",
      "Epoch 398/500\n",
      "Train Batch 10/110 - Loss: 7.1195 (Macro: 1.5831, Energy: 1.1211, KLD: 2.1149, MC: 2.3004)\n",
      "Train Batch 20/110 - Loss: 6.8311 (Macro: 1.4738, Energy: 0.9206, KLD: 2.1345, MC: 2.3021)\n",
      "Train Batch 30/110 - Loss: 7.1291 (Macro: 1.4492, Energy: 1.0720, KLD: 2.3073, MC: 2.3006)\n",
      "Train Batch 40/110 - Loss: 7.4762 (Macro: 1.5602, Energy: 1.2345, KLD: 2.3805, MC: 2.3010)\n",
      "Train Batch 50/110 - Loss: 7.0830 (Macro: 1.5075, Energy: 1.0356, KLD: 2.2381, MC: 2.3018)\n",
      "Train Batch 60/110 - Loss: 6.8359 (Macro: 1.3616, Energy: 0.9157, KLD: 2.2570, MC: 2.3016)\n",
      "Train Batch 70/110 - Loss: 7.0144 (Macro: 1.3771, Energy: 0.8972, KLD: 2.4378, MC: 2.3023)\n",
      "Train Batch 80/110 - Loss: 7.3340 (Macro: 1.4065, Energy: 1.0888, KLD: 2.5365, MC: 2.3022)\n",
      "Train Batch 90/110 - Loss: 6.7696 (Macro: 1.4648, Energy: 0.9784, KLD: 2.0241, MC: 2.3024)\n",
      "Train Batch 100/110 - Loss: 7.3424 (Macro: 1.6303, Energy: 1.1922, KLD: 2.2161, MC: 2.3038)\n",
      "Train Batch 110/110 - Loss: 6.5945 (Macro: 1.2601, Energy: 0.6932, KLD: 2.3414, MC: 2.2998)\n",
      "Training epoch complete. Average Loss: 7.0761\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0588\n",
      "\n",
      "Epoch 399/500\n",
      "Train Batch 10/110 - Loss: 7.1401 (Macro: 1.5878, Energy: 1.1371, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.8972 (Macro: 1.4858, Energy: 0.9745, KLD: 2.1345, MC: 2.3024)\n",
      "Train Batch 30/110 - Loss: 7.0905 (Macro: 1.4505, Energy: 1.0292, KLD: 2.3073, MC: 2.3035)\n",
      "Train Batch 40/110 - Loss: 7.4090 (Macro: 1.5517, Energy: 1.1768, KLD: 2.3805, MC: 2.2999)\n",
      "Train Batch 50/110 - Loss: 7.0462 (Macro: 1.4798, Energy: 1.0254, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.9150 (Macro: 1.3943, Energy: 0.9631, KLD: 2.2570, MC: 2.3005)\n",
      "Train Batch 70/110 - Loss: 6.9824 (Macro: 1.3551, Energy: 0.8871, KLD: 2.4378, MC: 2.3024)\n",
      "Train Batch 80/110 - Loss: 7.2854 (Macro: 1.4191, Energy: 1.0257, KLD: 2.5365, MC: 2.3042)\n",
      "Train Batch 90/110 - Loss: 6.7848 (Macro: 1.4772, Energy: 0.9808, KLD: 2.0241, MC: 2.3027)\n",
      "Train Batch 100/110 - Loss: 7.3148 (Macro: 1.5968, Energy: 1.2008, KLD: 2.2161, MC: 2.3011)\n",
      "Train Batch 110/110 - Loss: 6.6772 (Macro: 1.2676, Energy: 0.7690, KLD: 2.3414, MC: 2.2992)\n",
      "Training epoch complete. Average Loss: 7.0769\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0677\n",
      "\n",
      "Epoch 400/500\n",
      "Train Batch 10/110 - Loss: 7.1292 (Macro: 1.5716, Energy: 1.1436, KLD: 2.1149, MC: 2.2991)\n",
      "Train Batch 20/110 - Loss: 6.8897 (Macro: 1.4742, Energy: 0.9796, KLD: 2.1345, MC: 2.3013)\n",
      "Train Batch 30/110 - Loss: 7.0569 (Macro: 1.4482, Energy: 0.9970, KLD: 2.3073, MC: 2.3043)\n",
      "Train Batch 40/110 - Loss: 7.4749 (Macro: 1.5582, Energy: 1.2351, KLD: 2.3805, MC: 2.3011)\n",
      "Train Batch 50/110 - Loss: 7.0186 (Macro: 1.5004, Energy: 0.9773, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.9838 (Macro: 1.3970, Energy: 1.0284, KLD: 2.2570, MC: 2.3014)\n",
      "Train Batch 70/110 - Loss: 6.9389 (Macro: 1.3703, Energy: 0.8251, KLD: 2.4378, MC: 2.3058)\n",
      "Train Batch 80/110 - Loss: 7.3586 (Macro: 1.4254, Energy: 1.0938, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.7756 (Macro: 1.4681, Energy: 0.9805, KLD: 2.0241, MC: 2.3029)\n",
      "Train Batch 100/110 - Loss: 7.3136 (Macro: 1.6194, Energy: 1.1765, KLD: 2.2161, MC: 2.3016)\n",
      "Train Batch 110/110 - Loss: 6.7175 (Macro: 1.2859, Energy: 0.7920, KLD: 2.3414, MC: 2.2982)\n",
      "Training epoch complete. Average Loss: 7.0760\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0634\n",
      "\n",
      "Epoch 401/500\n",
      "Train Batch 10/110 - Loss: 7.0816 (Macro: 1.5696, Energy: 1.0963, KLD: 2.1149, MC: 2.3008)\n",
      "Train Batch 20/110 - Loss: 6.9234 (Macro: 1.4959, Energy: 0.9906, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.0412 (Macro: 1.4576, Energy: 0.9744, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4984 (Macro: 1.5530, Energy: 1.2642, KLD: 2.3805, MC: 2.3007)\n",
      "Train Batch 50/110 - Loss: 7.0710 (Macro: 1.5013, Energy: 1.0274, KLD: 2.2381, MC: 2.3041)\n",
      "Train Batch 60/110 - Loss: 6.9079 (Macro: 1.3960, Energy: 0.9549, KLD: 2.2570, MC: 2.3000)\n",
      "Train Batch 70/110 - Loss: 6.9074 (Macro: 1.3509, Energy: 0.8160, KLD: 2.4378, MC: 2.3027)\n",
      "Train Batch 80/110 - Loss: 7.2648 (Macro: 1.4095, Energy: 1.0163, KLD: 2.5365, MC: 2.3025)\n",
      "Train Batch 90/110 - Loss: 6.7684 (Macro: 1.4619, Energy: 0.9800, KLD: 2.0241, MC: 2.3024)\n",
      "Train Batch 100/110 - Loss: 7.3181 (Macro: 1.5900, Energy: 1.2078, KLD: 2.2161, MC: 2.3042)\n",
      "Train Batch 110/110 - Loss: 6.5958 (Macro: 1.2383, Energy: 0.7153, KLD: 2.3414, MC: 2.3007)\n",
      "Training epoch complete. Average Loss: 7.0790\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0640\n",
      "\n",
      "Epoch 402/500\n",
      "Train Batch 10/110 - Loss: 7.1239 (Macro: 1.5765, Energy: 1.1332, KLD: 2.1149, MC: 2.2993)\n",
      "Train Batch 20/110 - Loss: 6.9072 (Macro: 1.4953, Energy: 0.9745, KLD: 2.1345, MC: 2.3029)\n",
      "Train Batch 30/110 - Loss: 7.1141 (Macro: 1.4534, Energy: 1.0514, KLD: 2.3073, MC: 2.3020)\n",
      "Train Batch 40/110 - Loss: 7.4957 (Macro: 1.5527, Energy: 1.2611, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0449 (Macro: 1.4964, Energy: 1.0070, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.8903 (Macro: 1.3827, Energy: 0.9495, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9196 (Macro: 1.3513, Energy: 0.8266, KLD: 2.4378, MC: 2.3039)\n",
      "Train Batch 80/110 - Loss: 7.3181 (Macro: 1.4433, Energy: 1.0357, KLD: 2.5365, MC: 2.3026)\n",
      "Train Batch 90/110 - Loss: 6.7948 (Macro: 1.4789, Energy: 0.9918, KLD: 2.0241, MC: 2.3001)\n",
      "Train Batch 100/110 - Loss: 7.3047 (Macro: 1.6034, Energy: 1.1826, KLD: 2.2161, MC: 2.3026)\n",
      "Train Batch 110/110 - Loss: 6.6775 (Macro: 1.2605, Energy: 0.7790, KLD: 2.3414, MC: 2.2966)\n",
      "Training epoch complete. Average Loss: 7.0830\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0726\n",
      "\n",
      "Epoch 403/500\n",
      "Train Batch 10/110 - Loss: 7.1038 (Macro: 1.5973, Energy: 1.0912, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.8634 (Macro: 1.4742, Energy: 0.9536, KLD: 2.1345, MC: 2.3011)\n",
      "Train Batch 30/110 - Loss: 7.1061 (Macro: 1.4613, Energy: 1.0349, KLD: 2.3073, MC: 2.3027)\n",
      "Train Batch 40/110 - Loss: 7.4820 (Macro: 1.5618, Energy: 1.2376, KLD: 2.3805, MC: 2.3021)\n",
      "Train Batch 50/110 - Loss: 7.1213 (Macro: 1.5124, Energy: 1.0667, KLD: 2.2381, MC: 2.3042)\n",
      "Train Batch 60/110 - Loss: 6.8924 (Macro: 1.3823, Energy: 0.9507, KLD: 2.2570, MC: 2.3024)\n",
      "Train Batch 70/110 - Loss: 6.9554 (Macro: 1.3405, Energy: 0.8730, KLD: 2.4378, MC: 2.3043)\n",
      "Train Batch 80/110 - Loss: 7.3216 (Macro: 1.4386, Energy: 1.0445, KLD: 2.5365, MC: 2.3020)\n",
      "Train Batch 90/110 - Loss: 6.7603 (Macro: 1.4831, Energy: 0.9507, KLD: 2.0241, MC: 2.3024)\n",
      "Train Batch 100/110 - Loss: 7.2296 (Macro: 1.6044, Energy: 1.1085, KLD: 2.2161, MC: 2.3006)\n",
      "Train Batch 110/110 - Loss: 6.6622 (Macro: 1.2317, Energy: 0.7886, KLD: 2.3414, MC: 2.3005)\n",
      "Training epoch complete. Average Loss: 7.0801\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0611\n",
      "\n",
      "Epoch 404/500\n",
      "Train Batch 10/110 - Loss: 7.1720 (Macro: 1.5776, Energy: 1.1796, KLD: 2.1149, MC: 2.2999)\n",
      "Train Batch 20/110 - Loss: 6.8813 (Macro: 1.4852, Energy: 0.9607, KLD: 2.1345, MC: 2.3009)\n",
      "Train Batch 30/110 - Loss: 7.0320 (Macro: 1.4368, Energy: 0.9866, KLD: 2.3073, MC: 2.3014)\n",
      "Train Batch 40/110 - Loss: 7.4045 (Macro: 1.5336, Energy: 1.1888, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0841 (Macro: 1.5085, Energy: 1.0349, KLD: 2.2381, MC: 2.3027)\n",
      "Train Batch 60/110 - Loss: 6.9301 (Macro: 1.3824, Energy: 0.9902, KLD: 2.2570, MC: 2.3004)\n",
      "Train Batch 70/110 - Loss: 6.9114 (Macro: 1.3624, Energy: 0.8077, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.2690 (Macro: 1.4147, Energy: 1.0138, KLD: 2.5365, MC: 2.3040)\n",
      "Train Batch 90/110 - Loss: 6.7688 (Macro: 1.4713, Energy: 0.9706, KLD: 2.0241, MC: 2.3028)\n",
      "Train Batch 100/110 - Loss: 7.3222 (Macro: 1.6033, Energy: 1.2022, KLD: 2.2161, MC: 2.3005)\n",
      "Train Batch 110/110 - Loss: 6.5611 (Macro: 1.2233, Energy: 0.6985, KLD: 2.3414, MC: 2.2980)\n",
      "Training epoch complete. Average Loss: 7.0761\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0653\n",
      "\n",
      "Epoch 405/500\n",
      "Train Batch 10/110 - Loss: 7.1397 (Macro: 1.5844, Energy: 1.1413, KLD: 2.1149, MC: 2.2990)\n",
      "Train Batch 20/110 - Loss: 6.9489 (Macro: 1.5020, Energy: 1.0100, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.0106 (Macro: 1.4151, Energy: 0.9851, KLD: 2.3073, MC: 2.3031)\n",
      "Train Batch 40/110 - Loss: 7.4604 (Macro: 1.5524, Energy: 1.2254, KLD: 2.3805, MC: 2.3020)\n",
      "Train Batch 50/110 - Loss: 7.0597 (Macro: 1.4929, Energy: 1.0269, KLD: 2.2381, MC: 2.3018)\n",
      "Train Batch 60/110 - Loss: 6.8862 (Macro: 1.3697, Energy: 0.9576, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 6.9861 (Macro: 1.3790, Energy: 0.8661, KLD: 2.4378, MC: 2.3032)\n",
      "Train Batch 80/110 - Loss: 7.3457 (Macro: 1.4232, Energy: 1.0811, KLD: 2.5365, MC: 2.3049)\n",
      "Train Batch 90/110 - Loss: 6.7954 (Macro: 1.4802, Energy: 0.9897, KLD: 2.0241, MC: 2.3015)\n",
      "Train Batch 100/110 - Loss: 7.2702 (Macro: 1.5979, Energy: 1.1556, KLD: 2.2161, MC: 2.3007)\n",
      "Train Batch 110/110 - Loss: 6.6155 (Macro: 1.2399, Energy: 0.7340, KLD: 2.3414, MC: 2.3003)\n",
      "Training epoch complete. Average Loss: 7.0815\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0612\n",
      "\n",
      "Epoch 406/500\n",
      "Train Batch 10/110 - Loss: 7.1283 (Macro: 1.5814, Energy: 1.1315, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.8912 (Macro: 1.4942, Energy: 0.9599, KLD: 2.1345, MC: 2.3026)\n",
      "Train Batch 30/110 - Loss: 7.0272 (Macro: 1.4462, Energy: 0.9722, KLD: 2.3073, MC: 2.3014)\n",
      "Train Batch 40/110 - Loss: 7.4548 (Macro: 1.5513, Energy: 1.2224, KLD: 2.3805, MC: 2.3006)\n",
      "Train Batch 50/110 - Loss: 7.0751 (Macro: 1.5134, Energy: 1.0190, KLD: 2.2381, MC: 2.3047)\n",
      "Train Batch 60/110 - Loss: 6.9076 (Macro: 1.3760, Energy: 0.9732, KLD: 2.2570, MC: 2.3014)\n",
      "Train Batch 70/110 - Loss: 6.9207 (Macro: 1.3588, Energy: 0.8194, KLD: 2.4378, MC: 2.3048)\n",
      "Train Batch 80/110 - Loss: 7.2902 (Macro: 1.4404, Energy: 1.0106, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.7657 (Macro: 1.4593, Energy: 0.9798, KLD: 2.0241, MC: 2.3025)\n",
      "Train Batch 100/110 - Loss: 7.3074 (Macro: 1.5980, Energy: 1.1911, KLD: 2.2161, MC: 2.3023)\n",
      "Train Batch 110/110 - Loss: 6.6439 (Macro: 1.2226, Energy: 0.7791, KLD: 2.3414, MC: 2.3008)\n",
      "Training epoch complete. Average Loss: 7.0761\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0621\n",
      "\n",
      "Epoch 407/500\n",
      "Train Batch 10/110 - Loss: 7.1308 (Macro: 1.5769, Energy: 1.1382, KLD: 2.1149, MC: 2.3007)\n",
      "Train Batch 20/110 - Loss: 6.8765 (Macro: 1.4785, Energy: 0.9608, KLD: 2.1345, MC: 2.3028)\n",
      "Train Batch 30/110 - Loss: 7.0558 (Macro: 1.4512, Energy: 0.9929, KLD: 2.3073, MC: 2.3045)\n",
      "Train Batch 40/110 - Loss: 7.3792 (Macro: 1.5388, Energy: 1.1598, KLD: 2.3805, MC: 2.3000)\n",
      "Train Batch 50/110 - Loss: 7.0868 (Macro: 1.5158, Energy: 1.0307, KLD: 2.2381, MC: 2.3023)\n",
      "Train Batch 60/110 - Loss: 6.9279 (Macro: 1.3876, Energy: 0.9823, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 6.9383 (Macro: 1.3539, Energy: 0.8433, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.2642 (Macro: 1.4359, Energy: 0.9877, KLD: 2.5365, MC: 2.3042)\n",
      "Train Batch 90/110 - Loss: 6.7438 (Macro: 1.4551, Energy: 0.9625, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3488 (Macro: 1.5900, Energy: 1.2407, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.6600 (Macro: 1.2238, Energy: 0.7949, KLD: 2.3414, MC: 2.2999)\n",
      "Training epoch complete. Average Loss: 7.0803\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0632\n",
      "\n",
      "Epoch 408/500\n",
      "Train Batch 10/110 - Loss: 7.1055 (Macro: 1.5832, Energy: 1.1077, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.8627 (Macro: 1.4757, Energy: 0.9498, KLD: 2.1345, MC: 2.3028)\n",
      "Train Batch 30/110 - Loss: 7.1232 (Macro: 1.4512, Energy: 1.0620, KLD: 2.3073, MC: 2.3027)\n",
      "Train Batch 40/110 - Loss: 7.4732 (Macro: 1.5620, Energy: 1.2312, KLD: 2.3805, MC: 2.2995)\n",
      "Train Batch 50/110 - Loss: 7.0836 (Macro: 1.5177, Energy: 1.0249, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.8342 (Macro: 1.3486, Energy: 0.9260, KLD: 2.2570, MC: 2.3025)\n",
      "Train Batch 70/110 - Loss: 6.9608 (Macro: 1.3577, Energy: 0.8640, KLD: 2.4378, MC: 2.3013)\n",
      "Train Batch 80/110 - Loss: 7.2877 (Macro: 1.4124, Energy: 1.0359, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.8088 (Macro: 1.4809, Energy: 1.0012, KLD: 2.0241, MC: 2.3026)\n",
      "Train Batch 100/110 - Loss: 7.2531 (Macro: 1.6001, Energy: 1.1362, KLD: 2.2161, MC: 2.3007)\n",
      "Train Batch 110/110 - Loss: 6.6357 (Macro: 1.2265, Energy: 0.7693, KLD: 2.3414, MC: 2.2985)\n",
      "Training epoch complete. Average Loss: 7.0783\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0774\n",
      "\n",
      "Epoch 409/500\n",
      "Train Batch 10/110 - Loss: 7.1043 (Macro: 1.5768, Energy: 1.1114, KLD: 2.1149, MC: 2.3011)\n",
      "Train Batch 20/110 - Loss: 6.9387 (Macro: 1.4990, Energy: 1.0027, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.0585 (Macro: 1.4611, Energy: 0.9883, KLD: 2.3073, MC: 2.3018)\n",
      "Train Batch 40/110 - Loss: 7.4568 (Macro: 1.5671, Energy: 1.2081, KLD: 2.3805, MC: 2.3011)\n",
      "Train Batch 50/110 - Loss: 7.0744 (Macro: 1.4958, Energy: 1.0379, KLD: 2.2381, MC: 2.3027)\n",
      "Train Batch 60/110 - Loss: 6.9252 (Macro: 1.3819, Energy: 0.9844, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 6.9720 (Macro: 1.3683, Energy: 0.8621, KLD: 2.4378, MC: 2.3038)\n",
      "Train Batch 80/110 - Loss: 7.3123 (Macro: 1.4232, Energy: 1.0497, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.7773 (Macro: 1.4646, Energy: 0.9865, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3024 (Macro: 1.5967, Energy: 1.1894, KLD: 2.2161, MC: 2.3002)\n",
      "Train Batch 110/110 - Loss: 6.6024 (Macro: 1.2271, Energy: 0.7359, KLD: 2.3414, MC: 2.2980)\n",
      "Training epoch complete. Average Loss: 7.0830\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0600\n",
      "\n",
      "Epoch 410/500\n",
      "Train Batch 10/110 - Loss: 7.1946 (Macro: 1.5824, Energy: 1.1981, KLD: 2.1149, MC: 2.2992)\n",
      "Train Batch 20/110 - Loss: 6.9052 (Macro: 1.4921, Energy: 0.9771, KLD: 2.1345, MC: 2.3015)\n",
      "Train Batch 30/110 - Loss: 7.0936 (Macro: 1.4632, Energy: 1.0206, KLD: 2.3073, MC: 2.3025)\n",
      "Train Batch 40/110 - Loss: 7.4461 (Macro: 1.5546, Energy: 1.2094, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.1035 (Macro: 1.5004, Energy: 1.0625, KLD: 2.2381, MC: 2.3025)\n",
      "Train Batch 60/110 - Loss: 6.9322 (Macro: 1.3685, Energy: 1.0051, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9071 (Macro: 1.3609, Energy: 0.8049, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.2430 (Macro: 1.4200, Energy: 0.9833, KLD: 2.5365, MC: 2.3033)\n",
      "Train Batch 90/110 - Loss: 6.8755 (Macro: 1.4987, Energy: 1.0508, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.2822 (Macro: 1.6099, Energy: 1.1556, KLD: 2.2161, MC: 2.3006)\n",
      "Train Batch 110/110 - Loss: 6.6683 (Macro: 1.2559, Energy: 0.7724, KLD: 2.3414, MC: 2.2987)\n",
      "Training epoch complete. Average Loss: 7.0822\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0624\n",
      "\n",
      "Epoch 411/500\n",
      "Train Batch 10/110 - Loss: 7.1913 (Macro: 1.5812, Energy: 1.1948, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.8634 (Macro: 1.4797, Energy: 0.9477, KLD: 2.1345, MC: 2.3015)\n",
      "Train Batch 30/110 - Loss: 7.1046 (Macro: 1.4347, Energy: 1.0605, KLD: 2.3073, MC: 2.3021)\n",
      "Train Batch 40/110 - Loss: 7.4631 (Macro: 1.5586, Energy: 1.2217, KLD: 2.3805, MC: 2.3022)\n",
      "Train Batch 50/110 - Loss: 7.1106 (Macro: 1.5038, Energy: 1.0676, KLD: 2.2381, MC: 2.3012)\n",
      "Train Batch 60/110 - Loss: 6.9591 (Macro: 1.3853, Energy: 1.0150, KLD: 2.2570, MC: 2.3017)\n",
      "Train Batch 70/110 - Loss: 6.9340 (Macro: 1.3827, Energy: 0.8092, KLD: 2.4378, MC: 2.3044)\n",
      "Train Batch 80/110 - Loss: 7.3096 (Macro: 1.4288, Energy: 1.0406, KLD: 2.5365, MC: 2.3037)\n",
      "Train Batch 90/110 - Loss: 6.7611 (Macro: 1.4661, Energy: 0.9687, KLD: 2.0241, MC: 2.3023)\n",
      "Train Batch 100/110 - Loss: 7.2920 (Macro: 1.6058, Energy: 1.1697, KLD: 2.2161, MC: 2.3004)\n",
      "Train Batch 110/110 - Loss: 6.6274 (Macro: 1.2422, Energy: 0.7470, KLD: 2.3414, MC: 2.2969)\n",
      "Training epoch complete. Average Loss: 7.0810\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0582\n",
      "\n",
      "Epoch 412/500\n",
      "Train Batch 10/110 - Loss: 7.0843 (Macro: 1.5560, Energy: 1.1130, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.8902 (Macro: 1.4788, Energy: 0.9742, KLD: 2.1345, MC: 2.3027)\n",
      "Train Batch 30/110 - Loss: 7.0774 (Macro: 1.4475, Energy: 1.0193, KLD: 2.3073, MC: 2.3033)\n",
      "Train Batch 40/110 - Loss: 7.3974 (Macro: 1.5330, Energy: 1.1833, KLD: 2.3805, MC: 2.3006)\n",
      "Train Batch 50/110 - Loss: 7.0106 (Macro: 1.4811, Energy: 0.9910, KLD: 2.2381, MC: 2.3004)\n",
      "Train Batch 60/110 - Loss: 6.8324 (Macro: 1.3661, Energy: 0.9076, KLD: 2.2570, MC: 2.3016)\n",
      "Train Batch 70/110 - Loss: 6.9375 (Macro: 1.3532, Energy: 0.8416, KLD: 2.4378, MC: 2.3049)\n",
      "Train Batch 80/110 - Loss: 7.2677 (Macro: 1.4246, Energy: 1.0051, KLD: 2.5365, MC: 2.3016)\n",
      "Train Batch 90/110 - Loss: 6.7874 (Macro: 1.4807, Energy: 0.9817, KLD: 2.0241, MC: 2.3009)\n",
      "Train Batch 100/110 - Loss: 7.3450 (Macro: 1.6212, Energy: 1.2063, KLD: 2.2161, MC: 2.3014)\n",
      "Train Batch 110/110 - Loss: 6.5967 (Macro: 1.2380, Energy: 0.7198, KLD: 2.3414, MC: 2.2975)\n",
      "Training epoch complete. Average Loss: 7.0802\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0789\n",
      "\n",
      "Epoch 413/500\n",
      "Train Batch 10/110 - Loss: 7.1165 (Macro: 1.5695, Energy: 1.1328, KLD: 2.1149, MC: 2.2992)\n",
      "Train Batch 20/110 - Loss: 6.8926 (Macro: 1.4698, Energy: 0.9883, KLD: 2.1345, MC: 2.3000)\n",
      "Train Batch 30/110 - Loss: 7.0751 (Macro: 1.4390, Energy: 1.0260, KLD: 2.3073, MC: 2.3029)\n",
      "Train Batch 40/110 - Loss: 7.4528 (Macro: 1.5555, Energy: 1.2147, KLD: 2.3805, MC: 2.3020)\n",
      "Train Batch 50/110 - Loss: 7.0815 (Macro: 1.5104, Energy: 1.0308, KLD: 2.2381, MC: 2.3023)\n",
      "Train Batch 60/110 - Loss: 6.9113 (Macro: 1.3896, Energy: 0.9627, KLD: 2.2570, MC: 2.3019)\n",
      "Train Batch 70/110 - Loss: 6.9381 (Macro: 1.3441, Energy: 0.8540, KLD: 2.4378, MC: 2.3022)\n",
      "Train Batch 80/110 - Loss: 7.4073 (Macro: 1.4528, Energy: 1.1163, KLD: 2.5365, MC: 2.3018)\n",
      "Train Batch 90/110 - Loss: 6.8133 (Macro: 1.4811, Energy: 1.0039, KLD: 2.0241, MC: 2.3043)\n",
      "Train Batch 100/110 - Loss: 7.2757 (Macro: 1.5927, Energy: 1.1643, KLD: 2.2161, MC: 2.3026)\n",
      "Train Batch 110/110 - Loss: 6.6095 (Macro: 1.1980, Energy: 0.7701, KLD: 2.3414, MC: 2.3001)\n",
      "Training epoch complete. Average Loss: 7.0754\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0545\n",
      "\n",
      "Epoch 414/500\n",
      "Train Batch 10/110 - Loss: 7.1238 (Macro: 1.5717, Energy: 1.1367, KLD: 2.1149, MC: 2.3005)\n",
      "Train Batch 20/110 - Loss: 6.8835 (Macro: 1.4685, Energy: 0.9785, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.0478 (Macro: 1.4444, Energy: 0.9939, KLD: 2.3073, MC: 2.3023)\n",
      "Train Batch 40/110 - Loss: 7.4635 (Macro: 1.5438, Energy: 1.2364, KLD: 2.3805, MC: 2.3027)\n",
      "Train Batch 50/110 - Loss: 7.0454 (Macro: 1.5004, Energy: 1.0022, KLD: 2.2381, MC: 2.3047)\n",
      "Train Batch 60/110 - Loss: 6.8639 (Macro: 1.3609, Energy: 0.9450, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 7.0016 (Macro: 1.3858, Energy: 0.8748, KLD: 2.4378, MC: 2.3031)\n",
      "Train Batch 80/110 - Loss: 7.3024 (Macro: 1.4340, Energy: 1.0283, KLD: 2.5365, MC: 2.3035)\n",
      "Train Batch 90/110 - Loss: 6.7554 (Macro: 1.4602, Energy: 0.9696, KLD: 2.0241, MC: 2.3015)\n",
      "Train Batch 100/110 - Loss: 7.3208 (Macro: 1.5944, Energy: 1.2085, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.6193 (Macro: 1.2522, Energy: 0.7258, KLD: 2.3414, MC: 2.3000)\n",
      "Training epoch complete. Average Loss: 7.0800\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0683\n",
      "\n",
      "Epoch 415/500\n",
      "Train Batch 10/110 - Loss: 7.1417 (Macro: 1.5679, Energy: 1.1592, KLD: 2.1149, MC: 2.2996)\n",
      "Train Batch 20/110 - Loss: 6.8935 (Macro: 1.4673, Energy: 0.9882, KLD: 2.1345, MC: 2.3035)\n",
      "Train Batch 30/110 - Loss: 7.1165 (Macro: 1.4537, Energy: 1.0531, KLD: 2.3073, MC: 2.3024)\n",
      "Train Batch 40/110 - Loss: 7.4360 (Macro: 1.5623, Energy: 1.1928, KLD: 2.3805, MC: 2.3004)\n",
      "Train Batch 50/110 - Loss: 7.0724 (Macro: 1.4897, Energy: 1.0415, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.9190 (Macro: 1.3968, Energy: 0.9642, KLD: 2.2570, MC: 2.3010)\n",
      "Train Batch 70/110 - Loss: 6.9398 (Macro: 1.3362, Energy: 0.8625, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.3061 (Macro: 1.4233, Energy: 1.0446, KLD: 2.5365, MC: 2.3018)\n",
      "Train Batch 90/110 - Loss: 6.8078 (Macro: 1.4780, Energy: 1.0032, KLD: 2.0241, MC: 2.3025)\n",
      "Train Batch 100/110 - Loss: 7.3067 (Macro: 1.6024, Energy: 1.1862, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.6166 (Macro: 1.2377, Energy: 0.7379, KLD: 2.3414, MC: 2.2996)\n",
      "Training epoch complete. Average Loss: 7.0777\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0568\n",
      "\n",
      "Epoch 416/500\n",
      "Train Batch 10/110 - Loss: 7.1078 (Macro: 1.5798, Energy: 1.1140, KLD: 2.1149, MC: 2.2991)\n",
      "Train Batch 20/110 - Loss: 6.9094 (Macro: 1.4866, Energy: 0.9870, KLD: 2.1345, MC: 2.3013)\n",
      "Train Batch 30/110 - Loss: 7.1156 (Macro: 1.4359, Energy: 1.0701, KLD: 2.3073, MC: 2.3023)\n",
      "Train Batch 40/110 - Loss: 7.4783 (Macro: 1.5652, Energy: 1.2322, KLD: 2.3805, MC: 2.3003)\n",
      "Train Batch 50/110 - Loss: 7.0909 (Macro: 1.5093, Energy: 1.0395, KLD: 2.2381, MC: 2.3041)\n",
      "Train Batch 60/110 - Loss: 6.8773 (Macro: 1.3772, Energy: 0.9421, KLD: 2.2570, MC: 2.3010)\n",
      "Train Batch 70/110 - Loss: 6.9824 (Macro: 1.3729, Energy: 0.8694, KLD: 2.4378, MC: 2.3023)\n",
      "Train Batch 80/110 - Loss: 7.3022 (Macro: 1.4097, Energy: 1.0532, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.8360 (Macro: 1.4694, Energy: 1.0410, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.3299 (Macro: 1.6136, Energy: 1.1985, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.6361 (Macro: 1.2230, Energy: 0.7714, KLD: 2.3414, MC: 2.3003)\n",
      "Training epoch complete. Average Loss: 7.0763\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0579\n",
      "\n",
      "Epoch 417/500\n",
      "Train Batch 10/110 - Loss: 7.1410 (Macro: 1.5772, Energy: 1.1481, KLD: 2.1149, MC: 2.3007)\n",
      "Train Batch 20/110 - Loss: 6.8555 (Macro: 1.4744, Energy: 0.9429, KLD: 2.1345, MC: 2.3036)\n",
      "Train Batch 30/110 - Loss: 7.0495 (Macro: 1.4477, Energy: 0.9952, KLD: 2.3073, MC: 2.2992)\n",
      "Train Batch 40/110 - Loss: 7.4817 (Macro: 1.5827, Energy: 1.2169, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0328 (Macro: 1.4836, Energy: 1.0072, KLD: 2.2381, MC: 2.3039)\n",
      "Train Batch 60/110 - Loss: 6.9369 (Macro: 1.3891, Energy: 0.9882, KLD: 2.2570, MC: 2.3025)\n",
      "Train Batch 70/110 - Loss: 6.9388 (Macro: 1.3452, Energy: 0.8523, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.2931 (Macro: 1.4328, Energy: 1.0194, KLD: 2.5365, MC: 2.3043)\n",
      "Train Batch 90/110 - Loss: 6.7822 (Macro: 1.4797, Energy: 0.9752, KLD: 2.0241, MC: 2.3032)\n",
      "Train Batch 100/110 - Loss: 7.2785 (Macro: 1.6066, Energy: 1.1546, KLD: 2.2161, MC: 2.3012)\n",
      "Train Batch 110/110 - Loss: 6.5632 (Macro: 1.2220, Energy: 0.7003, KLD: 2.3414, MC: 2.2995)\n",
      "Training epoch complete. Average Loss: 7.0798\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0626\n",
      "\n",
      "Epoch 418/500\n",
      "Train Batch 10/110 - Loss: 7.1589 (Macro: 1.5891, Energy: 1.1553, KLD: 2.1149, MC: 2.2995)\n",
      "Train Batch 20/110 - Loss: 6.8649 (Macro: 1.4825, Energy: 0.9458, KLD: 2.1345, MC: 2.3022)\n",
      "Train Batch 30/110 - Loss: 7.0414 (Macro: 1.4491, Energy: 0.9828, KLD: 2.3073, MC: 2.3021)\n",
      "Train Batch 40/110 - Loss: 7.4704 (Macro: 1.5557, Energy: 1.2318, KLD: 2.3805, MC: 2.3024)\n",
      "Train Batch 50/110 - Loss: 7.1209 (Macro: 1.5148, Energy: 1.0633, KLD: 2.2381, MC: 2.3047)\n",
      "Train Batch 60/110 - Loss: 6.8870 (Macro: 1.3772, Energy: 0.9515, KLD: 2.2570, MC: 2.3013)\n",
      "Train Batch 70/110 - Loss: 6.9103 (Macro: 1.3542, Energy: 0.8153, KLD: 2.4378, MC: 2.3030)\n",
      "Train Batch 80/110 - Loss: 7.3178 (Macro: 1.4255, Energy: 1.0528, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.7781 (Macro: 1.4796, Energy: 0.9748, KLD: 2.0241, MC: 2.2997)\n",
      "Train Batch 100/110 - Loss: 7.3109 (Macro: 1.5952, Energy: 1.1991, KLD: 2.2161, MC: 2.3006)\n",
      "Train Batch 110/110 - Loss: 6.5895 (Macro: 1.2021, Energy: 0.7435, KLD: 2.3414, MC: 2.3024)\n",
      "Training epoch complete. Average Loss: 7.0801\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0700\n",
      "\n",
      "Epoch 419/500\n",
      "Train Batch 10/110 - Loss: 7.1146 (Macro: 1.5882, Energy: 1.1121, KLD: 2.1149, MC: 2.2993)\n",
      "Train Batch 20/110 - Loss: 6.8259 (Macro: 1.4764, Energy: 0.9135, KLD: 2.1345, MC: 2.3015)\n",
      "Train Batch 30/110 - Loss: 7.1053 (Macro: 1.4464, Energy: 1.0487, KLD: 2.3073, MC: 2.3030)\n",
      "Train Batch 40/110 - Loss: 7.4155 (Macro: 1.5377, Energy: 1.1957, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0645 (Macro: 1.5100, Energy: 1.0133, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.9371 (Macro: 1.3935, Energy: 0.9851, KLD: 2.2570, MC: 2.3014)\n",
      "Train Batch 70/110 - Loss: 6.9997 (Macro: 1.3329, Energy: 0.9248, KLD: 2.4378, MC: 2.3042)\n",
      "Train Batch 80/110 - Loss: 7.2465 (Macro: 1.4002, Energy: 1.0061, KLD: 2.5365, MC: 2.3036)\n",
      "Train Batch 90/110 - Loss: 6.7942 (Macro: 1.4772, Energy: 0.9912, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.3193 (Macro: 1.5970, Energy: 1.2055, KLD: 2.2161, MC: 2.3007)\n",
      "Train Batch 110/110 - Loss: 6.6575 (Macro: 1.2401, Energy: 0.7772, KLD: 2.3414, MC: 2.2989)\n",
      "Training epoch complete. Average Loss: 7.0780\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0593\n",
      "\n",
      "Epoch 420/500\n",
      "Train Batch 10/110 - Loss: 7.1416 (Macro: 1.5972, Energy: 1.1286, KLD: 2.1149, MC: 2.3009)\n",
      "Train Batch 20/110 - Loss: 6.8939 (Macro: 1.4842, Energy: 0.9733, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.1376 (Macro: 1.4758, Energy: 1.0500, KLD: 2.3073, MC: 2.3046)\n",
      "Train Batch 40/110 - Loss: 7.4604 (Macro: 1.5633, Energy: 1.2150, KLD: 2.3805, MC: 2.3017)\n",
      "Train Batch 50/110 - Loss: 7.0036 (Macro: 1.4925, Energy: 0.9701, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.8819 (Macro: 1.3852, Energy: 0.9390, KLD: 2.2570, MC: 2.3006)\n",
      "Train Batch 70/110 - Loss: 6.9195 (Macro: 1.3476, Energy: 0.8305, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.3495 (Macro: 1.4273, Energy: 1.0825, KLD: 2.5365, MC: 2.3032)\n",
      "Train Batch 90/110 - Loss: 6.7597 (Macro: 1.4540, Energy: 0.9796, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3047 (Macro: 1.5884, Energy: 1.1977, KLD: 2.2161, MC: 2.3025)\n",
      "Train Batch 110/110 - Loss: 6.6439 (Macro: 1.2207, Energy: 0.7843, KLD: 2.3414, MC: 2.2975)\n",
      "Training epoch complete. Average Loss: 7.0803\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0604\n",
      "\n",
      "Epoch 421/500\n",
      "Train Batch 10/110 - Loss: 7.1076 (Macro: 1.5420, Energy: 1.1519, KLD: 2.1149, MC: 2.2988)\n",
      "Train Batch 20/110 - Loss: 6.8981 (Macro: 1.4849, Energy: 0.9763, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.0932 (Macro: 1.4419, Energy: 1.0420, KLD: 2.3073, MC: 2.3020)\n",
      "Train Batch 40/110 - Loss: 7.4431 (Macro: 1.5538, Energy: 1.2085, KLD: 2.3805, MC: 2.3002)\n",
      "Train Batch 50/110 - Loss: 7.0192 (Macro: 1.4785, Energy: 0.9999, KLD: 2.2381, MC: 2.3028)\n",
      "Train Batch 60/110 - Loss: 6.9101 (Macro: 1.3836, Energy: 0.9667, KLD: 2.2570, MC: 2.3028)\n",
      "Train Batch 70/110 - Loss: 6.9441 (Macro: 1.3513, Energy: 0.8498, KLD: 2.4378, MC: 2.3052)\n",
      "Train Batch 80/110 - Loss: 7.3022 (Macro: 1.4341, Energy: 1.0272, KLD: 2.5365, MC: 2.3044)\n",
      "Train Batch 90/110 - Loss: 6.7723 (Macro: 1.4685, Energy: 0.9785, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.2820 (Macro: 1.6103, Energy: 1.1538, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.5773 (Macro: 1.2349, Energy: 0.7040, KLD: 2.3414, MC: 2.2971)\n",
      "Training epoch complete. Average Loss: 7.0778\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0639\n",
      "\n",
      "Epoch 422/500\n",
      "Train Batch 10/110 - Loss: 7.1144 (Macro: 1.5552, Energy: 1.1428, KLD: 2.1149, MC: 2.3016)\n",
      "Train Batch 20/110 - Loss: 6.8586 (Macro: 1.4750, Energy: 0.9447, KLD: 2.1345, MC: 2.3044)\n",
      "Train Batch 30/110 - Loss: 7.0723 (Macro: 1.4601, Energy: 1.0025, KLD: 2.3073, MC: 2.3023)\n",
      "Train Batch 40/110 - Loss: 7.4345 (Macro: 1.5506, Energy: 1.2034, KLD: 2.3805, MC: 2.3000)\n",
      "Train Batch 50/110 - Loss: 7.0801 (Macro: 1.5095, Energy: 1.0317, KLD: 2.2381, MC: 2.3008)\n",
      "Train Batch 60/110 - Loss: 6.9096 (Macro: 1.3758, Energy: 0.9753, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9323 (Macro: 1.3639, Energy: 0.8276, KLD: 2.4378, MC: 2.3030)\n",
      "Train Batch 80/110 - Loss: 7.3323 (Macro: 1.4245, Energy: 1.0697, KLD: 2.5365, MC: 2.3017)\n",
      "Train Batch 90/110 - Loss: 6.7977 (Macro: 1.4799, Energy: 0.9917, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.3609 (Macro: 1.6386, Energy: 1.2041, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.6186 (Macro: 1.2430, Energy: 0.7345, KLD: 2.3414, MC: 2.2997)\n",
      "Training epoch complete. Average Loss: 7.0758\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0605\n",
      "\n",
      "Epoch 423/500\n",
      "Train Batch 10/110 - Loss: 7.0897 (Macro: 1.5744, Energy: 1.0999, KLD: 2.1149, MC: 2.3005)\n",
      "Train Batch 20/110 - Loss: 6.8683 (Macro: 1.4939, Energy: 0.9370, KLD: 2.1345, MC: 2.3030)\n",
      "Train Batch 30/110 - Loss: 7.0165 (Macro: 1.4414, Energy: 0.9647, KLD: 2.3073, MC: 2.3032)\n",
      "Train Batch 40/110 - Loss: 7.4620 (Macro: 1.5602, Energy: 1.2204, KLD: 2.3805, MC: 2.3009)\n",
      "Train Batch 50/110 - Loss: 7.0745 (Macro: 1.4907, Energy: 1.0424, KLD: 2.2381, MC: 2.3034)\n",
      "Train Batch 60/110 - Loss: 6.8940 (Macro: 1.3886, Energy: 0.9481, KLD: 2.2570, MC: 2.3003)\n",
      "Train Batch 70/110 - Loss: 6.9703 (Macro: 1.3629, Energy: 0.8660, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.2795 (Macro: 1.4228, Energy: 1.0179, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.8193 (Macro: 1.4694, Energy: 1.0238, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.3059 (Macro: 1.5984, Energy: 1.1898, KLD: 2.2161, MC: 2.3015)\n",
      "Train Batch 110/110 - Loss: 6.5781 (Macro: 1.2145, Energy: 0.7220, KLD: 2.3414, MC: 2.3002)\n",
      "Training epoch complete. Average Loss: 7.0765\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0553\n",
      "\n",
      "Epoch 424/500\n",
      "Train Batch 10/110 - Loss: 7.1403 (Macro: 1.5835, Energy: 1.1406, KLD: 2.1149, MC: 2.3012)\n",
      "Train Batch 20/110 - Loss: 6.9181 (Macro: 1.4917, Energy: 0.9887, KLD: 2.1345, MC: 2.3032)\n",
      "Train Batch 30/110 - Loss: 7.1170 (Macro: 1.4227, Energy: 1.0847, KLD: 2.3073, MC: 2.3024)\n",
      "Train Batch 40/110 - Loss: 7.4380 (Macro: 1.5398, Energy: 1.2161, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.0241 (Macro: 1.5000, Energy: 0.9824, KLD: 2.2381, MC: 2.3038)\n",
      "Train Batch 60/110 - Loss: 6.8810 (Macro: 1.3796, Energy: 0.9412, KLD: 2.2570, MC: 2.3031)\n",
      "Train Batch 70/110 - Loss: 6.9698 (Macro: 1.3770, Energy: 0.8515, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.3190 (Macro: 1.4130, Energy: 1.0672, KLD: 2.5365, MC: 2.3024)\n",
      "Train Batch 90/110 - Loss: 6.8367 (Macro: 1.4968, Energy: 1.0145, KLD: 2.0241, MC: 2.3014)\n",
      "Train Batch 100/110 - Loss: 7.3579 (Macro: 1.6225, Energy: 1.2162, KLD: 2.2161, MC: 2.3030)\n",
      "Train Batch 110/110 - Loss: 6.6486 (Macro: 1.2290, Energy: 0.7789, KLD: 2.3414, MC: 2.2994)\n",
      "Training epoch complete. Average Loss: 7.0785\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0620\n",
      "\n",
      "Epoch 425/500\n",
      "Train Batch 10/110 - Loss: 7.1290 (Macro: 1.5758, Energy: 1.1369, KLD: 2.1149, MC: 2.3014)\n",
      "Train Batch 20/110 - Loss: 6.9133 (Macro: 1.4668, Energy: 1.0111, KLD: 2.1345, MC: 2.3010)\n",
      "Train Batch 30/110 - Loss: 7.0704 (Macro: 1.4409, Energy: 1.0215, KLD: 2.3073, MC: 2.3007)\n",
      "Train Batch 40/110 - Loss: 7.4044 (Macro: 1.5553, Energy: 1.1662, KLD: 2.3805, MC: 2.3025)\n",
      "Train Batch 50/110 - Loss: 7.0486 (Macro: 1.5123, Energy: 0.9946, KLD: 2.2381, MC: 2.3036)\n",
      "Train Batch 60/110 - Loss: 6.8323 (Macro: 1.3675, Energy: 0.9054, KLD: 2.2570, MC: 2.3023)\n",
      "Train Batch 70/110 - Loss: 6.9125 (Macro: 1.3447, Energy: 0.8271, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.3262 (Macro: 1.4222, Energy: 1.0636, KLD: 2.5365, MC: 2.3040)\n",
      "Train Batch 90/110 - Loss: 6.8333 (Macro: 1.4838, Energy: 1.0227, KLD: 2.0241, MC: 2.3028)\n",
      "Train Batch 100/110 - Loss: 7.3328 (Macro: 1.6099, Energy: 1.2023, KLD: 2.2161, MC: 2.3044)\n",
      "Train Batch 110/110 - Loss: 6.6312 (Macro: 1.2612, Energy: 0.7309, KLD: 2.3414, MC: 2.2978)\n",
      "Training epoch complete. Average Loss: 7.0738\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0682\n",
      "\n",
      "Epoch 426/500\n",
      "Train Batch 10/110 - Loss: 7.1125 (Macro: 1.5778, Energy: 1.1188, KLD: 2.1149, MC: 2.3009)\n",
      "Train Batch 20/110 - Loss: 6.9047 (Macro: 1.4990, Energy: 0.9676, KLD: 2.1345, MC: 2.3036)\n",
      "Train Batch 30/110 - Loss: 7.0918 (Macro: 1.4548, Energy: 1.0286, KLD: 2.3073, MC: 2.3012)\n",
      "Train Batch 40/110 - Loss: 7.3922 (Macro: 1.5399, Energy: 1.1724, KLD: 2.3805, MC: 2.2994)\n",
      "Train Batch 50/110 - Loss: 7.1009 (Macro: 1.5217, Energy: 1.0361, KLD: 2.2381, MC: 2.3050)\n",
      "Train Batch 60/110 - Loss: 6.8844 (Macro: 1.3700, Energy: 0.9540, KLD: 2.2570, MC: 2.3034)\n",
      "Train Batch 70/110 - Loss: 6.9556 (Macro: 1.3611, Energy: 0.8531, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.2842 (Macro: 1.4135, Energy: 1.0312, KLD: 2.5365, MC: 2.3030)\n",
      "Train Batch 90/110 - Loss: 6.7852 (Macro: 1.4760, Energy: 0.9839, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.3782 (Macro: 1.6188, Energy: 1.2404, KLD: 2.2161, MC: 2.3030)\n",
      "Train Batch 110/110 - Loss: 6.6946 (Macro: 1.2638, Energy: 0.7890, KLD: 2.3414, MC: 2.3005)\n",
      "Training epoch complete. Average Loss: 7.0768\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0680\n",
      "\n",
      "Epoch 427/500\n",
      "Train Batch 10/110 - Loss: 7.1435 (Macro: 1.5921, Energy: 1.1380, KLD: 2.1149, MC: 2.2984)\n",
      "Train Batch 20/110 - Loss: 6.8849 (Macro: 1.4761, Energy: 0.9721, KLD: 2.1345, MC: 2.3022)\n",
      "Train Batch 30/110 - Loss: 7.0662 (Macro: 1.4516, Energy: 1.0044, KLD: 2.3073, MC: 2.3029)\n",
      "Train Batch 40/110 - Loss: 7.4595 (Macro: 1.5670, Energy: 1.2111, KLD: 2.3805, MC: 2.3008)\n",
      "Train Batch 50/110 - Loss: 7.0906 (Macro: 1.5204, Energy: 1.0308, KLD: 2.2381, MC: 2.3014)\n",
      "Train Batch 60/110 - Loss: 6.8644 (Macro: 1.3703, Energy: 0.9372, KLD: 2.2570, MC: 2.2999)\n",
      "Train Batch 70/110 - Loss: 6.9669 (Macro: 1.3657, Energy: 0.8586, KLD: 2.4378, MC: 2.3049)\n",
      "Train Batch 80/110 - Loss: 7.3222 (Macro: 1.4298, Energy: 1.0516, KLD: 2.5365, MC: 2.3043)\n",
      "Train Batch 90/110 - Loss: 6.8549 (Macro: 1.4877, Energy: 1.0404, KLD: 2.0241, MC: 2.3027)\n",
      "Train Batch 100/110 - Loss: 7.2906 (Macro: 1.6184, Energy: 1.1549, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.5940 (Macro: 1.2103, Energy: 0.7450, KLD: 2.3414, MC: 2.2973)\n",
      "Training epoch complete. Average Loss: 7.0783\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0838\n",
      "\n",
      "Epoch 428/500\n",
      "Train Batch 10/110 - Loss: 7.1456 (Macro: 1.5763, Energy: 1.1544, KLD: 2.1149, MC: 2.2999)\n",
      "Train Batch 20/110 - Loss: 6.9126 (Macro: 1.4750, Energy: 1.0032, KLD: 2.1345, MC: 2.3000)\n",
      "Train Batch 30/110 - Loss: 7.0634 (Macro: 1.4354, Energy: 1.0184, KLD: 2.3073, MC: 2.3024)\n",
      "Train Batch 40/110 - Loss: 7.4730 (Macro: 1.5486, Energy: 1.2436, KLD: 2.3805, MC: 2.3003)\n",
      "Train Batch 50/110 - Loss: 7.0401 (Macro: 1.4876, Energy: 1.0107, KLD: 2.2381, MC: 2.3037)\n",
      "Train Batch 60/110 - Loss: 6.8834 (Macro: 1.3806, Energy: 0.9433, KLD: 2.2570, MC: 2.3025)\n",
      "Train Batch 70/110 - Loss: 6.9753 (Macro: 1.3693, Energy: 0.8673, KLD: 2.4378, MC: 2.3008)\n",
      "Train Batch 80/110 - Loss: 7.2497 (Macro: 1.4115, Energy: 0.9977, KLD: 2.5365, MC: 2.3040)\n",
      "Train Batch 90/110 - Loss: 6.7870 (Macro: 1.4751, Energy: 0.9868, KLD: 2.0241, MC: 2.3011)\n",
      "Train Batch 100/110 - Loss: 7.2695 (Macro: 1.6067, Energy: 1.1440, KLD: 2.2161, MC: 2.3027)\n",
      "Train Batch 110/110 - Loss: 6.6893 (Macro: 1.2351, Energy: 0.8157, KLD: 2.3414, MC: 2.2971)\n",
      "Training epoch complete. Average Loss: 7.0822\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0549\n",
      "\n",
      "Epoch 429/500\n",
      "Train Batch 10/110 - Loss: 7.1116 (Macro: 1.5934, Energy: 1.1031, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.8506 (Macro: 1.4761, Energy: 0.9371, KLD: 2.1345, MC: 2.3029)\n",
      "Train Batch 30/110 - Loss: 7.0527 (Macro: 1.4541, Energy: 0.9902, KLD: 2.3073, MC: 2.3011)\n",
      "Train Batch 40/110 - Loss: 7.4245 (Macro: 1.5467, Energy: 1.1970, KLD: 2.3805, MC: 2.3004)\n",
      "Train Batch 50/110 - Loss: 7.0376 (Macro: 1.4999, Energy: 0.9967, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.9435 (Macro: 1.3899, Energy: 0.9941, KLD: 2.2570, MC: 2.3024)\n",
      "Train Batch 70/110 - Loss: 6.9423 (Macro: 1.3688, Energy: 0.8331, KLD: 2.4378, MC: 2.3026)\n",
      "Train Batch 80/110 - Loss: 7.3320 (Macro: 1.4395, Energy: 1.0547, KLD: 2.5365, MC: 2.3013)\n",
      "Train Batch 90/110 - Loss: 6.8426 (Macro: 1.4809, Energy: 1.0360, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.3661 (Macro: 1.6142, Energy: 1.2330, KLD: 2.2161, MC: 2.3027)\n",
      "Train Batch 110/110 - Loss: 6.5548 (Macro: 1.2271, Energy: 0.6880, KLD: 2.3414, MC: 2.2983)\n",
      "Training epoch complete. Average Loss: 7.0826\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0676\n",
      "\n",
      "Epoch 430/500\n",
      "Train Batch 10/110 - Loss: 7.1367 (Macro: 1.5698, Energy: 1.1525, KLD: 2.1149, MC: 2.2994)\n",
      "Train Batch 20/110 - Loss: 6.9066 (Macro: 1.4866, Energy: 0.9844, KLD: 2.1345, MC: 2.3010)\n",
      "Train Batch 30/110 - Loss: 7.0774 (Macro: 1.4695, Energy: 0.9986, KLD: 2.3073, MC: 2.3020)\n",
      "Train Batch 40/110 - Loss: 7.4646 (Macro: 1.5701, Energy: 1.2147, KLD: 2.3805, MC: 2.2994)\n",
      "Train Batch 50/110 - Loss: 7.0719 (Macro: 1.5135, Energy: 1.0166, KLD: 2.2381, MC: 2.3037)\n",
      "Train Batch 60/110 - Loss: 6.8821 (Macro: 1.3725, Energy: 0.9490, KLD: 2.2570, MC: 2.3036)\n",
      "Train Batch 70/110 - Loss: 6.9649 (Macro: 1.3508, Energy: 0.8728, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.3319 (Macro: 1.4375, Energy: 1.0567, KLD: 2.5365, MC: 2.3013)\n",
      "Train Batch 90/110 - Loss: 6.7890 (Macro: 1.4665, Energy: 0.9953, KLD: 2.0241, MC: 2.3031)\n",
      "Train Batch 100/110 - Loss: 7.3363 (Macro: 1.5961, Energy: 1.2225, KLD: 2.2161, MC: 2.3015)\n",
      "Train Batch 110/110 - Loss: 6.6387 (Macro: 1.2639, Energy: 0.7353, KLD: 2.3414, MC: 2.2981)\n",
      "Training epoch complete. Average Loss: 7.0826\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0690\n",
      "\n",
      "Epoch 431/500\n",
      "Train Batch 10/110 - Loss: 7.1194 (Macro: 1.5888, Energy: 1.1141, KLD: 2.1149, MC: 2.3015)\n",
      "Train Batch 20/110 - Loss: 6.8587 (Macro: 1.4547, Energy: 0.9683, KLD: 2.1345, MC: 2.3011)\n",
      "Train Batch 30/110 - Loss: 7.0888 (Macro: 1.4501, Energy: 1.0281, KLD: 2.3073, MC: 2.3033)\n",
      "Train Batch 40/110 - Loss: 7.4669 (Macro: 1.5484, Energy: 1.2383, KLD: 2.3805, MC: 2.2997)\n",
      "Train Batch 50/110 - Loss: 7.0836 (Macro: 1.5070, Energy: 1.0363, KLD: 2.2381, MC: 2.3022)\n",
      "Train Batch 60/110 - Loss: 6.8535 (Macro: 1.3647, Energy: 0.9318, KLD: 2.2570, MC: 2.2999)\n",
      "Train Batch 70/110 - Loss: 6.9187 (Macro: 1.3500, Energy: 0.8258, KLD: 2.4378, MC: 2.3051)\n",
      "Train Batch 80/110 - Loss: 7.3110 (Macro: 1.4344, Energy: 1.0382, KLD: 2.5365, MC: 2.3020)\n",
      "Train Batch 90/110 - Loss: 6.7370 (Macro: 1.4840, Energy: 0.9259, KLD: 2.0241, MC: 2.3030)\n",
      "Train Batch 100/110 - Loss: 7.3297 (Macro: 1.6019, Energy: 1.2095, KLD: 2.2161, MC: 2.3022)\n",
      "Train Batch 110/110 - Loss: 6.6312 (Macro: 1.2453, Energy: 0.7474, KLD: 2.3414, MC: 2.2972)\n",
      "Training epoch complete. Average Loss: 7.0829\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0614\n",
      "\n",
      "Epoch 432/500\n",
      "Train Batch 10/110 - Loss: 7.1301 (Macro: 1.5847, Energy: 1.1304, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.8992 (Macro: 1.4879, Energy: 0.9753, KLD: 2.1345, MC: 2.3016)\n",
      "Train Batch 30/110 - Loss: 7.0840 (Macro: 1.4472, Energy: 1.0254, KLD: 2.3073, MC: 2.3042)\n",
      "Train Batch 40/110 - Loss: 7.4067 (Macro: 1.5525, Energy: 1.1718, KLD: 2.3805, MC: 2.3019)\n",
      "Train Batch 50/110 - Loss: 7.0760 (Macro: 1.5004, Energy: 1.0365, KLD: 2.2381, MC: 2.3010)\n",
      "Train Batch 60/110 - Loss: 6.8979 (Macro: 1.3842, Energy: 0.9559, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 6.9387 (Macro: 1.3575, Energy: 0.8388, KLD: 2.4378, MC: 2.3046)\n",
      "Train Batch 80/110 - Loss: 7.3692 (Macro: 1.4062, Energy: 1.1243, KLD: 2.5365, MC: 2.3021)\n",
      "Train Batch 90/110 - Loss: 6.8245 (Macro: 1.4909, Energy: 1.0085, KLD: 2.0241, MC: 2.3010)\n",
      "Train Batch 100/110 - Loss: 7.2618 (Macro: 1.6018, Energy: 1.1420, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.5967 (Macro: 1.1930, Energy: 0.7634, KLD: 2.3414, MC: 2.2990)\n",
      "Training epoch complete. Average Loss: 7.0778\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0577\n",
      "\n",
      "Epoch 433/500\n",
      "Train Batch 10/110 - Loss: 7.1439 (Macro: 1.5746, Energy: 1.1557, KLD: 2.1149, MC: 2.2987)\n",
      "Train Batch 20/110 - Loss: 6.9025 (Macro: 1.4610, Energy: 1.0042, KLD: 2.1345, MC: 2.3028)\n",
      "Train Batch 30/110 - Loss: 7.1396 (Macro: 1.4580, Energy: 1.0737, KLD: 2.3073, MC: 2.3005)\n",
      "Train Batch 40/110 - Loss: 7.4478 (Macro: 1.5634, Energy: 1.2026, KLD: 2.3805, MC: 2.3012)\n",
      "Train Batch 50/110 - Loss: 7.1000 (Macro: 1.5256, Energy: 1.0341, KLD: 2.2381, MC: 2.3023)\n",
      "Train Batch 60/110 - Loss: 6.8891 (Macro: 1.3936, Energy: 0.9374, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9646 (Macro: 1.3719, Energy: 0.8515, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.2874 (Macro: 1.4136, Energy: 1.0368, KLD: 2.5365, MC: 2.3005)\n",
      "Train Batch 90/110 - Loss: 6.7769 (Macro: 1.4583, Energy: 0.9924, KLD: 2.0241, MC: 2.3022)\n",
      "Train Batch 100/110 - Loss: 7.2777 (Macro: 1.6147, Energy: 1.1450, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.6072 (Macro: 1.2351, Energy: 0.7325, KLD: 2.3414, MC: 2.2982)\n",
      "Training epoch complete. Average Loss: 7.0826\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0492\n",
      "\n",
      "Epoch 434/500\n",
      "Train Batch 10/110 - Loss: 7.1084 (Macro: 1.5619, Energy: 1.1305, KLD: 2.1149, MC: 2.3011)\n",
      "Train Batch 20/110 - Loss: 6.9579 (Macro: 1.5022, Energy: 1.0177, KLD: 2.1345, MC: 2.3035)\n",
      "Train Batch 30/110 - Loss: 7.0185 (Macro: 1.4532, Energy: 0.9571, KLD: 2.3073, MC: 2.3009)\n",
      "Train Batch 40/110 - Loss: 7.3908 (Macro: 1.5596, Energy: 1.1482, KLD: 2.3805, MC: 2.3024)\n",
      "Train Batch 50/110 - Loss: 7.0970 (Macro: 1.4884, Energy: 1.0682, KLD: 2.2381, MC: 2.3023)\n",
      "Train Batch 60/110 - Loss: 6.9090 (Macro: 1.3909, Energy: 0.9614, KLD: 2.2570, MC: 2.2997)\n",
      "Train Batch 70/110 - Loss: 6.9712 (Macro: 1.3720, Energy: 0.8573, KLD: 2.4378, MC: 2.3041)\n",
      "Train Batch 80/110 - Loss: 7.2974 (Macro: 1.4162, Energy: 1.0425, KLD: 2.5365, MC: 2.3022)\n",
      "Train Batch 90/110 - Loss: 6.7457 (Macro: 1.4793, Energy: 0.9412, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.3212 (Macro: 1.6176, Energy: 1.1877, KLD: 2.2161, MC: 2.2997)\n",
      "Train Batch 110/110 - Loss: 6.5878 (Macro: 1.2076, Energy: 0.7419, KLD: 2.3414, MC: 2.2969)\n",
      "Training epoch complete. Average Loss: 7.0797\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0659\n",
      "\n",
      "Epoch 435/500\n",
      "Train Batch 10/110 - Loss: 7.0852 (Macro: 1.5774, Energy: 1.0927, KLD: 2.1149, MC: 2.3000)\n",
      "Train Batch 20/110 - Loss: 6.8947 (Macro: 1.4813, Energy: 0.9772, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0638 (Macro: 1.4431, Energy: 1.0121, KLD: 2.3073, MC: 2.3014)\n",
      "Train Batch 40/110 - Loss: 7.4786 (Macro: 1.5763, Energy: 1.2202, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0388 (Macro: 1.4782, Energy: 1.0193, KLD: 2.2381, MC: 2.3033)\n",
      "Train Batch 60/110 - Loss: 6.8647 (Macro: 1.3757, Energy: 0.9299, KLD: 2.2570, MC: 2.3021)\n",
      "Train Batch 70/110 - Loss: 6.9778 (Macro: 1.3579, Energy: 0.8785, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.3733 (Macro: 1.4242, Energy: 1.1120, KLD: 2.5365, MC: 2.3006)\n",
      "Train Batch 90/110 - Loss: 6.8064 (Macro: 1.4805, Energy: 1.0008, KLD: 2.0241, MC: 2.3011)\n",
      "Train Batch 100/110 - Loss: 7.3339 (Macro: 1.6107, Energy: 1.2055, KLD: 2.2161, MC: 2.3017)\n",
      "Train Batch 110/110 - Loss: 6.6490 (Macro: 1.2411, Energy: 0.7677, KLD: 2.3414, MC: 2.2987)\n",
      "Training epoch complete. Average Loss: 7.0856\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0666\n",
      "\n",
      "Epoch 436/500\n",
      "Train Batch 10/110 - Loss: 7.0983 (Macro: 1.5653, Energy: 1.1160, KLD: 2.1149, MC: 2.3020)\n",
      "Train Batch 20/110 - Loss: 6.8867 (Macro: 1.4864, Energy: 0.9654, KLD: 2.1345, MC: 2.3005)\n",
      "Train Batch 30/110 - Loss: 7.0718 (Macro: 1.4562, Energy: 1.0077, KLD: 2.3073, MC: 2.3006)\n",
      "Train Batch 40/110 - Loss: 7.4419 (Macro: 1.5698, Energy: 1.1907, KLD: 2.3805, MC: 2.3008)\n",
      "Train Batch 50/110 - Loss: 7.0856 (Macro: 1.5052, Energy: 1.0382, KLD: 2.2381, MC: 2.3042)\n",
      "Train Batch 60/110 - Loss: 6.9893 (Macro: 1.3769, Energy: 1.0549, KLD: 2.2570, MC: 2.3005)\n",
      "Train Batch 70/110 - Loss: 6.9494 (Macro: 1.3505, Energy: 0.8569, KLD: 2.4378, MC: 2.3042)\n",
      "Train Batch 80/110 - Loss: 7.2738 (Macro: 1.4281, Energy: 1.0072, KLD: 2.5365, MC: 2.3020)\n",
      "Train Batch 90/110 - Loss: 6.7814 (Macro: 1.4631, Energy: 0.9932, KLD: 2.0241, MC: 2.3011)\n",
      "Train Batch 100/110 - Loss: 7.3659 (Macro: 1.6050, Energy: 1.2432, KLD: 2.2161, MC: 2.3016)\n",
      "Train Batch 110/110 - Loss: 6.6603 (Macro: 1.2285, Energy: 0.7921, KLD: 2.3414, MC: 2.2983)\n",
      "Training epoch complete. Average Loss: 7.0806\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0644\n",
      "\n",
      "Epoch 437/500\n",
      "Train Batch 10/110 - Loss: 7.1228 (Macro: 1.5754, Energy: 1.1325, KLD: 2.1149, MC: 2.3000)\n",
      "Train Batch 20/110 - Loss: 6.8782 (Macro: 1.4733, Energy: 0.9688, KLD: 2.1345, MC: 2.3016)\n",
      "Train Batch 30/110 - Loss: 7.1179 (Macro: 1.4465, Energy: 1.0628, KLD: 2.3073, MC: 2.3013)\n",
      "Train Batch 40/110 - Loss: 7.4728 (Macro: 1.5653, Energy: 1.2268, KLD: 2.3805, MC: 2.3002)\n",
      "Train Batch 50/110 - Loss: 7.0629 (Macro: 1.4747, Energy: 1.0462, KLD: 2.2381, MC: 2.3039)\n",
      "Train Batch 60/110 - Loss: 6.9043 (Macro: 1.3956, Energy: 0.9486, KLD: 2.2570, MC: 2.3030)\n",
      "Train Batch 70/110 - Loss: 6.9909 (Macro: 1.3709, Energy: 0.8804, KLD: 2.4378, MC: 2.3017)\n",
      "Train Batch 80/110 - Loss: 7.2983 (Macro: 1.4280, Energy: 1.0320, KLD: 2.5365, MC: 2.3018)\n",
      "Train Batch 90/110 - Loss: 6.7715 (Macro: 1.4705, Energy: 0.9762, KLD: 2.0241, MC: 2.3007)\n",
      "Train Batch 100/110 - Loss: 7.3101 (Macro: 1.5996, Energy: 1.1919, KLD: 2.2161, MC: 2.3026)\n",
      "Train Batch 110/110 - Loss: 6.5660 (Macro: 1.2358, Energy: 0.6924, KLD: 2.3414, MC: 2.2963)\n",
      "Training epoch complete. Average Loss: 7.0812\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0632\n",
      "\n",
      "Epoch 438/500\n",
      "Train Batch 10/110 - Loss: 7.0908 (Macro: 1.5858, Energy: 1.0883, KLD: 2.1149, MC: 2.3017)\n",
      "Train Batch 20/110 - Loss: 6.8446 (Macro: 1.4886, Energy: 0.9175, KLD: 2.1345, MC: 2.3040)\n",
      "Train Batch 30/110 - Loss: 7.0853 (Macro: 1.4476, Energy: 1.0272, KLD: 2.3073, MC: 2.3032)\n",
      "Train Batch 40/110 - Loss: 7.5102 (Macro: 1.5655, Energy: 1.2620, KLD: 2.3805, MC: 2.3022)\n",
      "Train Batch 50/110 - Loss: 7.0503 (Macro: 1.4987, Energy: 1.0100, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.9246 (Macro: 1.4029, Energy: 0.9669, KLD: 2.2570, MC: 2.2977)\n",
      "Train Batch 70/110 - Loss: 6.9094 (Macro: 1.3524, Energy: 0.8163, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.3454 (Macro: 1.4381, Energy: 1.0695, KLD: 2.5365, MC: 2.3012)\n",
      "Train Batch 90/110 - Loss: 6.8025 (Macro: 1.4727, Energy: 1.0035, KLD: 2.0241, MC: 2.3023)\n",
      "Train Batch 100/110 - Loss: 7.2869 (Macro: 1.5977, Energy: 1.1729, KLD: 2.2161, MC: 2.3003)\n",
      "Train Batch 110/110 - Loss: 6.5645 (Macro: 1.2231, Energy: 0.6998, KLD: 2.3414, MC: 2.3002)\n",
      "Training epoch complete. Average Loss: 7.0852\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0642\n",
      "\n",
      "Epoch 439/500\n",
      "Train Batch 10/110 - Loss: 7.1965 (Macro: 1.5677, Energy: 1.2127, KLD: 2.1149, MC: 2.3011)\n",
      "Train Batch 20/110 - Loss: 6.9011 (Macro: 1.4826, Energy: 0.9821, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.1327 (Macro: 1.4451, Energy: 1.0776, KLD: 2.3073, MC: 2.3027)\n",
      "Train Batch 40/110 - Loss: 7.4680 (Macro: 1.5619, Energy: 1.2238, KLD: 2.3805, MC: 2.3018)\n",
      "Train Batch 50/110 - Loss: 7.0586 (Macro: 1.5039, Energy: 1.0135, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.8971 (Macro: 1.3970, Energy: 0.9426, KLD: 2.2570, MC: 2.3004)\n",
      "Train Batch 70/110 - Loss: 6.9816 (Macro: 1.3823, Energy: 0.8567, KLD: 2.4378, MC: 2.3049)\n",
      "Train Batch 80/110 - Loss: 7.3041 (Macro: 1.4083, Energy: 1.0557, KLD: 2.5365, MC: 2.3036)\n",
      "Train Batch 90/110 - Loss: 6.7974 (Macro: 1.4830, Energy: 0.9882, KLD: 2.0241, MC: 2.3022)\n",
      "Train Batch 100/110 - Loss: 7.2891 (Macro: 1.6141, Energy: 1.1570, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.7046 (Macro: 1.2310, Energy: 0.8346, KLD: 2.3414, MC: 2.2976)\n",
      "Training epoch complete. Average Loss: 7.0810\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0553\n",
      "\n",
      "Epoch 440/500\n",
      "Train Batch 10/110 - Loss: 7.1368 (Macro: 1.5948, Energy: 1.1259, KLD: 2.1149, MC: 2.3012)\n",
      "Train Batch 20/110 - Loss: 6.9032 (Macro: 1.4879, Energy: 0.9797, KLD: 2.1345, MC: 2.3011)\n",
      "Train Batch 30/110 - Loss: 7.1465 (Macro: 1.4622, Energy: 1.0756, KLD: 2.3073, MC: 2.3015)\n",
      "Train Batch 40/110 - Loss: 7.4732 (Macro: 1.5494, Energy: 1.2421, KLD: 2.3805, MC: 2.3011)\n",
      "Train Batch 50/110 - Loss: 7.1227 (Macro: 1.4899, Energy: 1.0927, KLD: 2.2381, MC: 2.3020)\n",
      "Train Batch 60/110 - Loss: 6.8883 (Macro: 1.3700, Energy: 0.9580, KLD: 2.2570, MC: 2.3032)\n",
      "Train Batch 70/110 - Loss: 6.9687 (Macro: 1.3535, Energy: 0.8735, KLD: 2.4378, MC: 2.3040)\n",
      "Train Batch 80/110 - Loss: 7.3157 (Macro: 1.4217, Energy: 1.0547, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.8085 (Macro: 1.4697, Energy: 1.0120, KLD: 2.0241, MC: 2.3027)\n",
      "Train Batch 100/110 - Loss: 7.3620 (Macro: 1.6129, Energy: 1.2311, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.5445 (Macro: 1.1917, Energy: 0.7114, KLD: 2.3414, MC: 2.3000)\n",
      "Training epoch complete. Average Loss: 7.0803\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0646\n",
      "\n",
      "Epoch 441/500\n",
      "Train Batch 10/110 - Loss: 7.1623 (Macro: 1.5996, Energy: 1.1487, KLD: 2.1149, MC: 2.2990)\n",
      "Train Batch 20/110 - Loss: 6.9071 (Macro: 1.4751, Energy: 0.9975, KLD: 2.1345, MC: 2.3001)\n",
      "Train Batch 30/110 - Loss: 7.1209 (Macro: 1.4693, Energy: 1.0419, KLD: 2.3073, MC: 2.3023)\n",
      "Train Batch 40/110 - Loss: 7.4903 (Macro: 1.5756, Energy: 1.2325, KLD: 2.3805, MC: 2.3017)\n",
      "Train Batch 50/110 - Loss: 7.0578 (Macro: 1.5018, Energy: 1.0156, KLD: 2.2381, MC: 2.3024)\n",
      "Train Batch 60/110 - Loss: 6.8586 (Macro: 1.3857, Energy: 0.9121, KLD: 2.2570, MC: 2.3038)\n",
      "Train Batch 70/110 - Loss: 6.9754 (Macro: 1.3688, Energy: 0.8661, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.3956 (Macro: 1.4449, Energy: 1.1104, KLD: 2.5365, MC: 2.3039)\n",
      "Train Batch 90/110 - Loss: 6.7860 (Macro: 1.4834, Energy: 0.9783, KLD: 2.0241, MC: 2.3002)\n",
      "Train Batch 100/110 - Loss: 7.3069 (Macro: 1.5983, Energy: 1.1912, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.6599 (Macro: 1.2314, Energy: 0.7877, KLD: 2.3414, MC: 2.2994)\n",
      "Training epoch complete. Average Loss: 7.0815\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0681\n",
      "\n",
      "Epoch 442/500\n",
      "Train Batch 10/110 - Loss: 7.1256 (Macro: 1.5662, Energy: 1.1441, KLD: 2.1149, MC: 2.3004)\n",
      "Train Batch 20/110 - Loss: 6.8590 (Macro: 1.4772, Energy: 0.9463, KLD: 2.1345, MC: 2.3010)\n",
      "Train Batch 30/110 - Loss: 7.0523 (Macro: 1.4412, Energy: 1.0022, KLD: 2.3073, MC: 2.3016)\n",
      "Train Batch 40/110 - Loss: 7.4187 (Macro: 1.5384, Energy: 1.1995, KLD: 2.3805, MC: 2.3003)\n",
      "Train Batch 50/110 - Loss: 7.0814 (Macro: 1.5019, Energy: 1.0388, KLD: 2.2381, MC: 2.3026)\n",
      "Train Batch 60/110 - Loss: 6.8754 (Macro: 1.3691, Energy: 0.9471, KLD: 2.2570, MC: 2.3021)\n",
      "Train Batch 70/110 - Loss: 6.9992 (Macro: 1.3465, Energy: 0.9101, KLD: 2.4378, MC: 2.3048)\n",
      "Train Batch 80/110 - Loss: 7.2992 (Macro: 1.4329, Energy: 1.0255, KLD: 2.5365, MC: 2.3043)\n",
      "Train Batch 90/110 - Loss: 6.7675 (Macro: 1.4659, Energy: 0.9740, KLD: 2.0241, MC: 2.3035)\n",
      "Train Batch 100/110 - Loss: 7.3056 (Macro: 1.6157, Energy: 1.1725, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.5976 (Macro: 1.2822, Energy: 0.6728, KLD: 2.3414, MC: 2.3012)\n",
      "Training epoch complete. Average Loss: 7.0741\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0563\n",
      "\n",
      "Epoch 443/500\n",
      "Train Batch 10/110 - Loss: 7.1585 (Macro: 1.5757, Energy: 1.1674, KLD: 2.1149, MC: 2.3005)\n",
      "Train Batch 20/110 - Loss: 6.9186 (Macro: 1.5096, Energy: 0.9735, KLD: 2.1345, MC: 2.3011)\n",
      "Train Batch 30/110 - Loss: 7.0953 (Macro: 1.4602, Energy: 1.0258, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4632 (Macro: 1.5533, Energy: 1.2283, KLD: 2.3805, MC: 2.3011)\n",
      "Train Batch 50/110 - Loss: 7.1187 (Macro: 1.5161, Energy: 1.0618, KLD: 2.2381, MC: 2.3027)\n",
      "Train Batch 60/110 - Loss: 6.9484 (Macro: 1.4064, Energy: 0.9835, KLD: 2.2570, MC: 2.3014)\n",
      "Train Batch 70/110 - Loss: 6.9976 (Macro: 1.3649, Energy: 0.8918, KLD: 2.4378, MC: 2.3031)\n",
      "Train Batch 80/110 - Loss: 7.2967 (Macro: 1.4343, Energy: 1.0235, KLD: 2.5365, MC: 2.3024)\n",
      "Train Batch 90/110 - Loss: 6.7532 (Macro: 1.4544, Energy: 0.9731, KLD: 2.0241, MC: 2.3016)\n",
      "Train Batch 100/110 - Loss: 7.3069 (Macro: 1.5981, Energy: 1.1924, KLD: 2.2161, MC: 2.3004)\n",
      "Train Batch 110/110 - Loss: 6.6635 (Macro: 1.2239, Energy: 0.8015, KLD: 2.3414, MC: 2.2968)\n",
      "Training epoch complete. Average Loss: 7.0793\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0704\n",
      "\n",
      "Epoch 444/500\n",
      "Train Batch 10/110 - Loss: 7.1017 (Macro: 1.5734, Energy: 1.1131, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.9237 (Macro: 1.4858, Energy: 1.0017, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.1476 (Macro: 1.4595, Energy: 1.0802, KLD: 2.3073, MC: 2.3007)\n",
      "Train Batch 40/110 - Loss: 7.4686 (Macro: 1.5609, Energy: 1.2255, KLD: 2.3805, MC: 2.3017)\n",
      "Train Batch 50/110 - Loss: 7.0161 (Macro: 1.4920, Energy: 0.9850, KLD: 2.2381, MC: 2.3011)\n",
      "Train Batch 60/110 - Loss: 6.9031 (Macro: 1.3693, Energy: 0.9783, KLD: 2.2570, MC: 2.2985)\n",
      "Train Batch 70/110 - Loss: 6.9857 (Macro: 1.3706, Energy: 0.8735, KLD: 2.4378, MC: 2.3039)\n",
      "Train Batch 80/110 - Loss: 7.3198 (Macro: 1.4338, Energy: 1.0481, KLD: 2.5365, MC: 2.3014)\n",
      "Train Batch 90/110 - Loss: 6.8077 (Macro: 1.4833, Energy: 0.9989, KLD: 2.0241, MC: 2.3014)\n",
      "Train Batch 100/110 - Loss: 7.3464 (Macro: 1.6100, Energy: 1.2191, KLD: 2.2161, MC: 2.3012)\n",
      "Train Batch 110/110 - Loss: 6.6242 (Macro: 1.2261, Energy: 0.7581, KLD: 2.3414, MC: 2.2987)\n",
      "Training epoch complete. Average Loss: 7.0817\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0741\n",
      "\n",
      "Epoch 445/500\n",
      "Train Batch 10/110 - Loss: 7.0525 (Macro: 1.5661, Energy: 1.0707, KLD: 2.1149, MC: 2.3007)\n",
      "Train Batch 20/110 - Loss: 6.8864 (Macro: 1.4843, Energy: 0.9665, KLD: 2.1345, MC: 2.3012)\n",
      "Train Batch 30/110 - Loss: 7.0922 (Macro: 1.4551, Energy: 1.0265, KLD: 2.3073, MC: 2.3032)\n",
      "Train Batch 40/110 - Loss: 7.4535 (Macro: 1.5594, Energy: 1.2121, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0390 (Macro: 1.4993, Energy: 0.9987, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.9196 (Macro: 1.3826, Energy: 0.9793, KLD: 2.2570, MC: 2.3007)\n",
      "Train Batch 70/110 - Loss: 6.9548 (Macro: 1.3430, Energy: 0.8692, KLD: 2.4378, MC: 2.3047)\n",
      "Train Batch 80/110 - Loss: 7.3124 (Macro: 1.4270, Energy: 1.0477, KLD: 2.5365, MC: 2.3012)\n",
      "Train Batch 90/110 - Loss: 6.8049 (Macro: 1.4906, Energy: 0.9892, KLD: 2.0241, MC: 2.3010)\n",
      "Train Batch 100/110 - Loss: 7.2832 (Macro: 1.6042, Energy: 1.1602, KLD: 2.2161, MC: 2.3027)\n",
      "Train Batch 110/110 - Loss: 6.6363 (Macro: 1.2226, Energy: 0.7737, KLD: 2.3414, MC: 2.2986)\n",
      "Training epoch complete. Average Loss: 7.0778\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0550\n",
      "\n",
      "Epoch 446/500\n",
      "Train Batch 10/110 - Loss: 7.1351 (Macro: 1.5708, Energy: 1.1496, KLD: 2.1149, MC: 2.2998)\n",
      "Train Batch 20/110 - Loss: 6.8940 (Macro: 1.4741, Energy: 0.9842, KLD: 2.1345, MC: 2.3012)\n",
      "Train Batch 30/110 - Loss: 7.0618 (Macro: 1.4539, Energy: 0.9988, KLD: 2.3073, MC: 2.3018)\n",
      "Train Batch 40/110 - Loss: 7.4822 (Macro: 1.5591, Energy: 1.2411, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0332 (Macro: 1.5085, Energy: 0.9823, KLD: 2.2381, MC: 2.3044)\n",
      "Train Batch 60/110 - Loss: 6.8876 (Macro: 1.3756, Energy: 0.9546, KLD: 2.2570, MC: 2.3004)\n",
      "Train Batch 70/110 - Loss: 6.9440 (Macro: 1.3624, Energy: 0.8404, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.2983 (Macro: 1.4180, Energy: 1.0412, KLD: 2.5365, MC: 2.3026)\n",
      "Train Batch 90/110 - Loss: 6.8249 (Macro: 1.4794, Energy: 1.0189, KLD: 2.0241, MC: 2.3025)\n",
      "Train Batch 100/110 - Loss: 7.2846 (Macro: 1.6049, Energy: 1.1626, KLD: 2.2161, MC: 2.3011)\n",
      "Train Batch 110/110 - Loss: 6.5774 (Macro: 1.2245, Energy: 0.7142, KLD: 2.3414, MC: 2.2973)\n",
      "Training epoch complete. Average Loss: 7.0771\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0587\n",
      "\n",
      "Epoch 447/500\n",
      "Train Batch 10/110 - Loss: 7.1431 (Macro: 1.5852, Energy: 1.1412, KLD: 2.1149, MC: 2.3017)\n",
      "Train Batch 20/110 - Loss: 6.8643 (Macro: 1.4689, Energy: 0.9592, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.1060 (Macro: 1.4658, Energy: 1.0312, KLD: 2.3073, MC: 2.3017)\n",
      "Train Batch 40/110 - Loss: 7.5055 (Macro: 1.5598, Energy: 1.2641, KLD: 2.3805, MC: 2.3011)\n",
      "Train Batch 50/110 - Loss: 7.0440 (Macro: 1.5028, Energy: 1.0008, KLD: 2.2381, MC: 2.3023)\n",
      "Train Batch 60/110 - Loss: 6.9077 (Macro: 1.3869, Energy: 0.9620, KLD: 2.2570, MC: 2.3017)\n",
      "Train Batch 70/110 - Loss: 6.9348 (Macro: 1.3533, Energy: 0.8401, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.3497 (Macro: 1.4295, Energy: 1.0821, KLD: 2.5365, MC: 2.3016)\n",
      "Train Batch 90/110 - Loss: 6.7802 (Macro: 1.4938, Energy: 0.9586, KLD: 2.0241, MC: 2.3037)\n",
      "Train Batch 100/110 - Loss: 7.3048 (Macro: 1.6003, Energy: 1.1869, KLD: 2.2161, MC: 2.3015)\n",
      "Train Batch 110/110 - Loss: 6.6007 (Macro: 1.2139, Energy: 0.7456, KLD: 2.3414, MC: 2.2998)\n",
      "Training epoch complete. Average Loss: 7.0853\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0519\n",
      "\n",
      "Epoch 448/500\n",
      "Train Batch 10/110 - Loss: 7.1838 (Macro: 1.5926, Energy: 1.1749, KLD: 2.1149, MC: 2.3014)\n",
      "Train Batch 20/110 - Loss: 6.9080 (Macro: 1.4999, Energy: 0.9738, KLD: 2.1345, MC: 2.2998)\n",
      "Train Batch 30/110 - Loss: 7.0980 (Macro: 1.4468, Energy: 1.0417, KLD: 2.3073, MC: 2.3021)\n",
      "Train Batch 40/110 - Loss: 7.4861 (Macro: 1.5781, Energy: 1.2266, KLD: 2.3805, MC: 2.3009)\n",
      "Train Batch 50/110 - Loss: 7.0716 (Macro: 1.5062, Energy: 1.0228, KLD: 2.2381, MC: 2.3046)\n",
      "Train Batch 60/110 - Loss: 6.8839 (Macro: 1.3794, Energy: 0.9466, KLD: 2.2570, MC: 2.3010)\n",
      "Train Batch 70/110 - Loss: 6.9748 (Macro: 1.3692, Energy: 0.8635, KLD: 2.4378, MC: 2.3043)\n",
      "Train Batch 80/110 - Loss: 7.3230 (Macro: 1.4316, Energy: 1.0524, KLD: 2.5365, MC: 2.3025)\n",
      "Train Batch 90/110 - Loss: 6.8107 (Macro: 1.4614, Energy: 1.0229, KLD: 2.0241, MC: 2.3024)\n",
      "Train Batch 100/110 - Loss: 7.2563 (Macro: 1.6173, Energy: 1.1209, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.6032 (Macro: 1.2121, Energy: 0.7533, KLD: 2.3414, MC: 2.2964)\n",
      "Training epoch complete. Average Loss: 7.0827\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0559\n",
      "\n",
      "Epoch 449/500\n",
      "Train Batch 10/110 - Loss: 7.1352 (Macro: 1.5572, Energy: 1.1628, KLD: 2.1149, MC: 2.3004)\n",
      "Train Batch 20/110 - Loss: 6.8780 (Macro: 1.4841, Energy: 0.9578, KLD: 2.1345, MC: 2.3016)\n",
      "Train Batch 30/110 - Loss: 7.0844 (Macro: 1.4678, Energy: 1.0069, KLD: 2.3073, MC: 2.3025)\n",
      "Train Batch 40/110 - Loss: 7.4091 (Macro: 1.5551, Energy: 1.1718, KLD: 2.3805, MC: 2.3017)\n",
      "Train Batch 50/110 - Loss: 7.0496 (Macro: 1.4986, Energy: 1.0108, KLD: 2.2381, MC: 2.3021)\n",
      "Train Batch 60/110 - Loss: 6.9616 (Macro: 1.3822, Energy: 1.0215, KLD: 2.2570, MC: 2.3008)\n",
      "Train Batch 70/110 - Loss: 6.9133 (Macro: 1.3620, Energy: 0.8100, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.3134 (Macro: 1.4334, Energy: 1.0405, KLD: 2.5365, MC: 2.3029)\n",
      "Train Batch 90/110 - Loss: 6.7946 (Macro: 1.4719, Energy: 0.9976, KLD: 2.0241, MC: 2.3010)\n",
      "Train Batch 100/110 - Loss: 7.2996 (Macro: 1.6095, Energy: 1.1706, KLD: 2.2161, MC: 2.3034)\n",
      "Train Batch 110/110 - Loss: 6.5958 (Macro: 1.2398, Energy: 0.7159, KLD: 2.3414, MC: 2.2987)\n",
      "Training epoch complete. Average Loss: 7.0837\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0558\n",
      "\n",
      "Epoch 450/500\n",
      "Train Batch 10/110 - Loss: 7.1171 (Macro: 1.5600, Energy: 1.1407, KLD: 2.1149, MC: 2.3016)\n",
      "Train Batch 20/110 - Loss: 6.9406 (Macro: 1.4950, Energy: 1.0108, KLD: 2.1345, MC: 2.3003)\n",
      "Train Batch 30/110 - Loss: 7.0518 (Macro: 1.4359, Energy: 1.0048, KLD: 2.3073, MC: 2.3039)\n",
      "Train Batch 40/110 - Loss: 7.4540 (Macro: 1.5581, Energy: 1.2152, KLD: 2.3805, MC: 2.3002)\n",
      "Train Batch 50/110 - Loss: 7.0540 (Macro: 1.5069, Energy: 1.0061, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.9423 (Macro: 1.3708, Energy: 1.0126, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 6.9535 (Macro: 1.3788, Energy: 0.8331, KLD: 2.4378, MC: 2.3039)\n",
      "Train Batch 80/110 - Loss: 7.3204 (Macro: 1.4361, Energy: 1.0438, KLD: 2.5365, MC: 2.3039)\n",
      "Train Batch 90/110 - Loss: 6.8054 (Macro: 1.4642, Energy: 1.0139, KLD: 2.0241, MC: 2.3032)\n",
      "Train Batch 100/110 - Loss: 7.2964 (Macro: 1.6031, Energy: 1.1744, KLD: 2.2161, MC: 2.3028)\n",
      "Train Batch 110/110 - Loss: 6.6937 (Macro: 1.2340, Energy: 0.8195, KLD: 2.3414, MC: 2.2989)\n",
      "Training epoch complete. Average Loss: 7.0850\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0670\n",
      "\n",
      "Epoch 451/500\n",
      "Train Batch 10/110 - Loss: 7.1128 (Macro: 1.5673, Energy: 1.1286, KLD: 2.1149, MC: 2.3020)\n",
      "Train Batch 20/110 - Loss: 6.9229 (Macro: 1.4718, Energy: 1.0158, KLD: 2.1345, MC: 2.3008)\n",
      "Train Batch 30/110 - Loss: 7.0917 (Macro: 1.4521, Energy: 1.0307, KLD: 2.3073, MC: 2.3016)\n",
      "Train Batch 40/110 - Loss: 7.4671 (Macro: 1.5570, Energy: 1.2284, KLD: 2.3805, MC: 2.3012)\n",
      "Train Batch 50/110 - Loss: 7.0136 (Macro: 1.4910, Energy: 0.9832, KLD: 2.2381, MC: 2.3013)\n",
      "Train Batch 60/110 - Loss: 6.9251 (Macro: 1.3877, Energy: 0.9792, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9649 (Macro: 1.3643, Energy: 0.8596, KLD: 2.4378, MC: 2.3032)\n",
      "Train Batch 80/110 - Loss: 7.2954 (Macro: 1.4291, Energy: 1.0258, KLD: 2.5365, MC: 2.3040)\n",
      "Train Batch 90/110 - Loss: 6.8208 (Macro: 1.4790, Energy: 1.0150, KLD: 2.0241, MC: 2.3028)\n",
      "Train Batch 100/110 - Loss: 7.3478 (Macro: 1.6117, Energy: 1.2172, KLD: 2.2161, MC: 2.3027)\n",
      "Train Batch 110/110 - Loss: 6.6795 (Macro: 1.2211, Energy: 0.8175, KLD: 2.3414, MC: 2.2995)\n",
      "Training epoch complete. Average Loss: 7.0790\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0611\n",
      "\n",
      "Epoch 452/500\n",
      "Train Batch 10/110 - Loss: 7.0932 (Macro: 1.5796, Energy: 1.0975, KLD: 2.1149, MC: 2.3012)\n",
      "Train Batch 20/110 - Loss: 6.8939 (Macro: 1.4954, Energy: 0.9623, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0920 (Macro: 1.4439, Energy: 1.0412, KLD: 2.3073, MC: 2.2996)\n",
      "Train Batch 40/110 - Loss: 7.4740 (Macro: 1.5555, Energy: 1.2356, KLD: 2.3805, MC: 2.3024)\n",
      "Train Batch 50/110 - Loss: 7.0473 (Macro: 1.4866, Energy: 1.0197, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.9302 (Macro: 1.4119, Energy: 0.9603, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 6.9318 (Macro: 1.3600, Energy: 0.8310, KLD: 2.4378, MC: 2.3030)\n",
      "Train Batch 80/110 - Loss: 7.3492 (Macro: 1.4246, Energy: 1.0867, KLD: 2.5365, MC: 2.3014)\n",
      "Train Batch 90/110 - Loss: 6.7693 (Macro: 1.4652, Energy: 0.9777, KLD: 2.0241, MC: 2.3023)\n",
      "Train Batch 100/110 - Loss: 7.2246 (Macro: 1.5927, Energy: 1.1146, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.7003 (Macro: 1.2619, Energy: 0.7975, KLD: 2.3414, MC: 2.2995)\n",
      "Training epoch complete. Average Loss: 7.0806\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0540\n",
      "\n",
      "Epoch 453/500\n",
      "Train Batch 10/110 - Loss: 7.1392 (Macro: 1.5789, Energy: 1.1465, KLD: 2.1149, MC: 2.2989)\n",
      "Train Batch 20/110 - Loss: 6.8804 (Macro: 1.4669, Energy: 0.9759, KLD: 2.1345, MC: 2.3031)\n",
      "Train Batch 30/110 - Loss: 7.0697 (Macro: 1.4448, Energy: 1.0142, KLD: 2.3073, MC: 2.3034)\n",
      "Train Batch 40/110 - Loss: 7.4537 (Macro: 1.5426, Energy: 1.2293, KLD: 2.3805, MC: 2.3014)\n",
      "Train Batch 50/110 - Loss: 7.0493 (Macro: 1.5087, Energy: 1.0004, KLD: 2.2381, MC: 2.3021)\n",
      "Train Batch 60/110 - Loss: 6.9052 (Macro: 1.3769, Energy: 0.9703, KLD: 2.2570, MC: 2.3010)\n",
      "Train Batch 70/110 - Loss: 6.9566 (Macro: 1.3569, Energy: 0.8586, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.3367 (Macro: 1.4344, Energy: 1.0636, KLD: 2.5365, MC: 2.3022)\n",
      "Train Batch 90/110 - Loss: 6.7998 (Macro: 1.4665, Energy: 1.0085, KLD: 2.0241, MC: 2.3007)\n",
      "Train Batch 100/110 - Loss: 7.2839 (Macro: 1.5833, Energy: 1.1830, KLD: 2.2161, MC: 2.3016)\n",
      "Train Batch 110/110 - Loss: 6.6140 (Macro: 1.2489, Energy: 0.7229, KLD: 2.3414, MC: 2.3009)\n",
      "Training epoch complete. Average Loss: 7.0816\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0684\n",
      "\n",
      "Epoch 454/500\n",
      "Train Batch 10/110 - Loss: 7.1614 (Macro: 1.5899, Energy: 1.1556, KLD: 2.1149, MC: 2.3010)\n",
      "Train Batch 20/110 - Loss: 6.9463 (Macro: 1.5028, Energy: 1.0090, KLD: 2.1345, MC: 2.3000)\n",
      "Train Batch 30/110 - Loss: 7.1034 (Macro: 1.4468, Energy: 1.0480, KLD: 2.3073, MC: 2.3012)\n",
      "Train Batch 40/110 - Loss: 7.4037 (Macro: 1.5421, Energy: 1.1795, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.0237 (Macro: 1.4669, Energy: 1.0151, KLD: 2.2381, MC: 2.3036)\n",
      "Train Batch 60/110 - Loss: 6.8826 (Macro: 1.3789, Energy: 0.9450, KLD: 2.2570, MC: 2.3017)\n",
      "Train Batch 70/110 - Loss: 6.9480 (Macro: 1.3528, Energy: 0.8544, KLD: 2.4378, MC: 2.3030)\n",
      "Train Batch 80/110 - Loss: 7.3549 (Macro: 1.4441, Energy: 1.0705, KLD: 2.5365, MC: 2.3038)\n",
      "Train Batch 90/110 - Loss: 6.8009 (Macro: 1.4766, Energy: 0.9980, KLD: 2.0241, MC: 2.3022)\n",
      "Train Batch 100/110 - Loss: 7.3517 (Macro: 1.5954, Energy: 1.2394, KLD: 2.2161, MC: 2.3008)\n",
      "Train Batch 110/110 - Loss: 6.6077 (Macro: 1.2240, Energy: 0.7415, KLD: 2.3414, MC: 2.3008)\n",
      "Training epoch complete. Average Loss: 7.0803\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0602\n",
      "\n",
      "Epoch 455/500\n",
      "Train Batch 10/110 - Loss: 7.1369 (Macro: 1.5783, Energy: 1.1445, KLD: 2.1149, MC: 2.2992)\n",
      "Train Batch 20/110 - Loss: 6.8810 (Macro: 1.4760, Energy: 0.9679, KLD: 2.1345, MC: 2.3026)\n",
      "Train Batch 30/110 - Loss: 7.0637 (Macro: 1.4585, Energy: 0.9950, KLD: 2.3073, MC: 2.3028)\n",
      "Train Batch 40/110 - Loss: 7.4318 (Macro: 1.5495, Energy: 1.2012, KLD: 2.3805, MC: 2.3007)\n",
      "Train Batch 50/110 - Loss: 6.9754 (Macro: 1.4866, Energy: 0.9473, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.9319 (Macro: 1.3934, Energy: 0.9806, KLD: 2.2570, MC: 2.3008)\n",
      "Train Batch 70/110 - Loss: 6.9784 (Macro: 1.3598, Energy: 0.8774, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.3253 (Macro: 1.4250, Energy: 1.0598, KLD: 2.5365, MC: 2.3040)\n",
      "Train Batch 90/110 - Loss: 6.7948 (Macro: 1.4741, Energy: 0.9945, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.2438 (Macro: 1.5774, Energy: 1.1482, KLD: 2.2161, MC: 2.3021)\n",
      "Train Batch 110/110 - Loss: 6.6016 (Macro: 1.2422, Energy: 0.7218, KLD: 2.3414, MC: 2.2962)\n",
      "Training epoch complete. Average Loss: 7.0808\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0631\n",
      "\n",
      "Epoch 456/500\n",
      "Train Batch 10/110 - Loss: 7.1009 (Macro: 1.5838, Energy: 1.1023, KLD: 2.1149, MC: 2.2998)\n",
      "Train Batch 20/110 - Loss: 6.8867 (Macro: 1.5020, Energy: 0.9490, KLD: 2.1345, MC: 2.3012)\n",
      "Train Batch 30/110 - Loss: 7.0272 (Macro: 1.4443, Energy: 0.9749, KLD: 2.3073, MC: 2.3007)\n",
      "Train Batch 40/110 - Loss: 7.4160 (Macro: 1.5376, Energy: 1.1961, KLD: 2.3805, MC: 2.3018)\n",
      "Train Batch 50/110 - Loss: 7.0453 (Macro: 1.4880, Energy: 1.0165, KLD: 2.2381, MC: 2.3027)\n",
      "Train Batch 60/110 - Loss: 6.9257 (Macro: 1.3908, Energy: 0.9765, KLD: 2.2570, MC: 2.3013)\n",
      "Train Batch 70/110 - Loss: 7.0141 (Macro: 1.3801, Energy: 0.8942, KLD: 2.4378, MC: 2.3021)\n",
      "Train Batch 80/110 - Loss: 7.3118 (Macro: 1.4267, Energy: 1.0453, KLD: 2.5365, MC: 2.3033)\n",
      "Train Batch 90/110 - Loss: 6.7961 (Macro: 1.4679, Energy: 1.0013, KLD: 2.0241, MC: 2.3028)\n",
      "Train Batch 100/110 - Loss: 7.3117 (Macro: 1.5993, Energy: 1.1945, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.6627 (Macro: 1.2188, Energy: 0.8031, KLD: 2.3414, MC: 2.2993)\n",
      "Training epoch complete. Average Loss: 7.0794\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0533\n",
      "\n",
      "Epoch 457/500\n",
      "Train Batch 10/110 - Loss: 7.1372 (Macro: 1.5906, Energy: 1.1317, KLD: 2.1149, MC: 2.3000)\n",
      "Train Batch 20/110 - Loss: 6.8580 (Macro: 1.4587, Energy: 0.9620, KLD: 2.1345, MC: 2.3028)\n",
      "Train Batch 30/110 - Loss: 7.0164 (Macro: 1.4245, Energy: 0.9828, KLD: 2.3073, MC: 2.3018)\n",
      "Train Batch 40/110 - Loss: 7.4545 (Macro: 1.5457, Energy: 1.2282, KLD: 2.3805, MC: 2.3000)\n",
      "Train Batch 50/110 - Loss: 7.1160 (Macro: 1.5071, Energy: 1.0679, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.9177 (Macro: 1.3920, Energy: 0.9692, KLD: 2.2570, MC: 2.2995)\n",
      "Train Batch 70/110 - Loss: 6.9824 (Macro: 1.3691, Energy: 0.8720, KLD: 2.4378, MC: 2.3035)\n",
      "Train Batch 80/110 - Loss: 7.2966 (Macro: 1.4426, Energy: 1.0138, KLD: 2.5365, MC: 2.3037)\n",
      "Train Batch 90/110 - Loss: 6.7547 (Macro: 1.4573, Energy: 0.9714, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.3241 (Macro: 1.5900, Energy: 1.2177, KLD: 2.2161, MC: 2.3003)\n",
      "Train Batch 110/110 - Loss: 6.6272 (Macro: 1.2325, Energy: 0.7545, KLD: 2.3414, MC: 2.2989)\n",
      "Training epoch complete. Average Loss: 7.0785\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0676\n",
      "\n",
      "Epoch 458/500\n",
      "Train Batch 10/110 - Loss: 7.1383 (Macro: 1.5801, Energy: 1.1441, KLD: 2.1149, MC: 2.2992)\n",
      "Train Batch 20/110 - Loss: 6.9274 (Macro: 1.4898, Energy: 1.0029, KLD: 2.1345, MC: 2.3003)\n",
      "Train Batch 30/110 - Loss: 7.0459 (Macro: 1.4588, Energy: 0.9787, KLD: 2.3073, MC: 2.3012)\n",
      "Train Batch 40/110 - Loss: 7.4721 (Macro: 1.5688, Energy: 1.2224, KLD: 2.3805, MC: 2.3004)\n",
      "Train Batch 50/110 - Loss: 7.0336 (Macro: 1.5079, Energy: 0.9865, KLD: 2.2381, MC: 2.3011)\n",
      "Train Batch 60/110 - Loss: 6.9315 (Macro: 1.3878, Energy: 0.9873, KLD: 2.2570, MC: 2.2994)\n",
      "Train Batch 70/110 - Loss: 6.9355 (Macro: 1.3645, Energy: 0.8299, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.3270 (Macro: 1.4213, Energy: 1.0677, KLD: 2.5365, MC: 2.3016)\n",
      "Train Batch 90/110 - Loss: 6.7881 (Macro: 1.5072, Energy: 0.9547, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3305 (Macro: 1.6090, Energy: 1.2016, KLD: 2.2161, MC: 2.3037)\n",
      "Train Batch 110/110 - Loss: 6.6700 (Macro: 1.2272, Energy: 0.8010, KLD: 2.3414, MC: 2.3004)\n",
      "Training epoch complete. Average Loss: 7.0835\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0637\n",
      "\n",
      "Epoch 459/500\n",
      "Train Batch 10/110 - Loss: 7.1173 (Macro: 1.5753, Energy: 1.1257, KLD: 2.1149, MC: 2.3015)\n",
      "Train Batch 20/110 - Loss: 6.9241 (Macro: 1.4965, Energy: 0.9919, KLD: 2.1345, MC: 2.3013)\n",
      "Train Batch 30/110 - Loss: 7.1201 (Macro: 1.4745, Energy: 1.0365, KLD: 2.3073, MC: 2.3018)\n",
      "Train Batch 40/110 - Loss: 7.4768 (Macro: 1.5593, Energy: 1.2364, KLD: 2.3805, MC: 2.3006)\n",
      "Train Batch 50/110 - Loss: 7.0058 (Macro: 1.4860, Energy: 0.9786, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.9577 (Macro: 1.4027, Energy: 0.9950, KLD: 2.2570, MC: 2.3029)\n",
      "Train Batch 70/110 - Loss: 6.9523 (Macro: 1.3463, Energy: 0.8638, KLD: 2.4378, MC: 2.3044)\n",
      "Train Batch 80/110 - Loss: 7.2885 (Macro: 1.4256, Energy: 1.0243, KLD: 2.5365, MC: 2.3021)\n",
      "Train Batch 90/110 - Loss: 6.8056 (Macro: 1.4877, Energy: 0.9913, KLD: 2.0241, MC: 2.3026)\n",
      "Train Batch 100/110 - Loss: 7.3354 (Macro: 1.6060, Energy: 1.2114, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.6053 (Macro: 1.2296, Energy: 0.7362, KLD: 2.3414, MC: 2.2982)\n",
      "Training epoch complete. Average Loss: 7.0786\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0499\n",
      "\n",
      "Epoch 460/500\n",
      "Train Batch 10/110 - Loss: 7.1526 (Macro: 1.5884, Energy: 1.1471, KLD: 2.1149, MC: 2.3022)\n",
      "Train Batch 20/110 - Loss: 6.8883 (Macro: 1.4771, Energy: 0.9749, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.1370 (Macro: 1.4592, Energy: 1.0672, KLD: 2.3073, MC: 2.3033)\n",
      "Train Batch 40/110 - Loss: 7.4406 (Macro: 1.5407, Energy: 1.2191, KLD: 2.3805, MC: 2.3003)\n",
      "Train Batch 50/110 - Loss: 7.0634 (Macro: 1.4953, Energy: 1.0267, KLD: 2.2381, MC: 2.3033)\n",
      "Train Batch 60/110 - Loss: 6.8894 (Macro: 1.3839, Energy: 0.9483, KLD: 2.2570, MC: 2.3003)\n",
      "Train Batch 70/110 - Loss: 6.9463 (Macro: 1.3567, Energy: 0.8467, KLD: 2.4378, MC: 2.3052)\n",
      "Train Batch 80/110 - Loss: 7.2638 (Macro: 1.4151, Energy: 1.0083, KLD: 2.5365, MC: 2.3040)\n",
      "Train Batch 90/110 - Loss: 6.7704 (Macro: 1.4663, Energy: 0.9799, KLD: 2.0241, MC: 2.3001)\n",
      "Train Batch 100/110 - Loss: 7.2805 (Macro: 1.6171, Energy: 1.1442, KLD: 2.2161, MC: 2.3032)\n",
      "Train Batch 110/110 - Loss: 6.6109 (Macro: 1.2504, Energy: 0.7202, KLD: 2.3414, MC: 2.2989)\n",
      "Training epoch complete. Average Loss: 7.0777\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0738\n",
      "\n",
      "Epoch 461/500\n",
      "Train Batch 10/110 - Loss: 7.1523 (Macro: 1.5772, Energy: 1.1606, KLD: 2.1149, MC: 2.2995)\n",
      "Train Batch 20/110 - Loss: 6.9053 (Macro: 1.4821, Energy: 0.9867, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.0473 (Macro: 1.4460, Energy: 0.9926, KLD: 2.3073, MC: 2.3014)\n",
      "Train Batch 40/110 - Loss: 7.4548 (Macro: 1.5577, Energy: 1.2165, KLD: 2.3805, MC: 2.3000)\n",
      "Train Batch 50/110 - Loss: 7.0673 (Macro: 1.4927, Energy: 1.0357, KLD: 2.2381, MC: 2.3008)\n",
      "Train Batch 60/110 - Loss: 6.9304 (Macro: 1.3976, Energy: 0.9737, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.9252 (Macro: 1.3529, Energy: 0.8311, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.2888 (Macro: 1.4116, Energy: 1.0386, KLD: 2.5365, MC: 2.3020)\n",
      "Train Batch 90/110 - Loss: 6.7725 (Macro: 1.4766, Energy: 0.9707, KLD: 2.0241, MC: 2.3011)\n",
      "Train Batch 100/110 - Loss: 7.3114 (Macro: 1.6001, Energy: 1.1915, KLD: 2.2161, MC: 2.3037)\n",
      "Train Batch 110/110 - Loss: 6.6095 (Macro: 1.2477, Energy: 0.7218, KLD: 2.3414, MC: 2.2986)\n",
      "Training epoch complete. Average Loss: 7.0794\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0614\n",
      "\n",
      "Epoch 462/500\n",
      "Train Batch 10/110 - Loss: 7.1563 (Macro: 1.5877, Energy: 1.1515, KLD: 2.1149, MC: 2.3022)\n",
      "Train Batch 20/110 - Loss: 6.9209 (Macro: 1.4874, Energy: 0.9970, KLD: 2.1345, MC: 2.3021)\n",
      "Train Batch 30/110 - Loss: 7.1096 (Macro: 1.4350, Energy: 1.0648, KLD: 2.3073, MC: 2.3024)\n",
      "Train Batch 40/110 - Loss: 7.4541 (Macro: 1.5386, Energy: 1.2335, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.1058 (Macro: 1.5225, Energy: 1.0420, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.8558 (Macro: 1.3710, Energy: 0.9253, KLD: 2.2570, MC: 2.3024)\n",
      "Train Batch 70/110 - Loss: 6.9375 (Macro: 1.3468, Energy: 0.8487, KLD: 2.4378, MC: 2.3041)\n",
      "Train Batch 80/110 - Loss: 7.3320 (Macro: 1.4481, Energy: 1.0461, KLD: 2.5365, MC: 2.3013)\n",
      "Train Batch 90/110 - Loss: 6.8359 (Macro: 1.4845, Energy: 1.0250, KLD: 2.0241, MC: 2.3023)\n",
      "Train Batch 100/110 - Loss: 7.2990 (Macro: 1.6308, Energy: 1.1497, KLD: 2.2161, MC: 2.3023)\n",
      "Train Batch 110/110 - Loss: 6.6772 (Macro: 1.2474, Energy: 0.7878, KLD: 2.3414, MC: 2.3006)\n",
      "Training epoch complete. Average Loss: 7.0797\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0660\n",
      "\n",
      "Epoch 463/500\n",
      "Train Batch 10/110 - Loss: 7.1398 (Macro: 1.5706, Energy: 1.1538, KLD: 2.1149, MC: 2.3005)\n",
      "Train Batch 20/110 - Loss: 6.8984 (Macro: 1.4670, Energy: 0.9946, KLD: 2.1345, MC: 2.3023)\n",
      "Train Batch 30/110 - Loss: 7.1053 (Macro: 1.4353, Energy: 1.0604, KLD: 2.3073, MC: 2.3024)\n",
      "Train Batch 40/110 - Loss: 7.4386 (Macro: 1.5603, Energy: 1.1949, KLD: 2.3805, MC: 2.3029)\n",
      "Train Batch 50/110 - Loss: 7.0584 (Macro: 1.4979, Energy: 1.0200, KLD: 2.2381, MC: 2.3025)\n",
      "Train Batch 60/110 - Loss: 6.9404 (Macro: 1.3897, Energy: 0.9926, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9322 (Macro: 1.3625, Energy: 0.8293, KLD: 2.4378, MC: 2.3026)\n",
      "Train Batch 80/110 - Loss: 7.3229 (Macro: 1.4251, Energy: 1.0594, KLD: 2.5365, MC: 2.3019)\n",
      "Train Batch 90/110 - Loss: 6.7730 (Macro: 1.4683, Energy: 0.9809, KLD: 2.0241, MC: 2.2997)\n",
      "Train Batch 100/110 - Loss: 7.2475 (Macro: 1.5841, Energy: 1.1451, KLD: 2.2161, MC: 2.3022)\n",
      "Train Batch 110/110 - Loss: 6.6431 (Macro: 1.2619, Energy: 0.7401, KLD: 2.3414, MC: 2.2998)\n",
      "Training epoch complete. Average Loss: 7.0736\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0710\n",
      "\n",
      "Epoch 464/500\n",
      "Train Batch 10/110 - Loss: 7.1569 (Macro: 1.5810, Energy: 1.1609, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.9085 (Macro: 1.4931, Energy: 0.9796, KLD: 2.1345, MC: 2.3013)\n",
      "Train Batch 30/110 - Loss: 7.1006 (Macro: 1.4833, Energy: 1.0079, KLD: 2.3073, MC: 2.3021)\n",
      "Train Batch 40/110 - Loss: 7.5286 (Macro: 1.5713, Energy: 1.2749, KLD: 2.3805, MC: 2.3018)\n",
      "Train Batch 50/110 - Loss: 7.1201 (Macro: 1.5012, Energy: 1.0779, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.8762 (Macro: 1.3860, Energy: 0.9327, KLD: 2.2570, MC: 2.3005)\n",
      "Train Batch 70/110 - Loss: 6.9119 (Macro: 1.3445, Energy: 0.8262, KLD: 2.4378, MC: 2.3034)\n",
      "Train Batch 80/110 - Loss: 7.3083 (Macro: 1.4315, Energy: 1.0394, KLD: 2.5365, MC: 2.3010)\n",
      "Train Batch 90/110 - Loss: 6.8142 (Macro: 1.4911, Energy: 0.9963, KLD: 2.0241, MC: 2.3027)\n",
      "Train Batch 100/110 - Loss: 7.3091 (Macro: 1.6055, Energy: 1.1845, KLD: 2.2161, MC: 2.3030)\n",
      "Train Batch 110/110 - Loss: 6.6660 (Macro: 1.2415, Energy: 0.7819, KLD: 2.3414, MC: 2.3012)\n",
      "Training epoch complete. Average Loss: 7.0811\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0617\n",
      "\n",
      "Epoch 465/500\n",
      "Train Batch 10/110 - Loss: 7.1369 (Macro: 1.5840, Energy: 1.1365, KLD: 2.1149, MC: 2.3013)\n",
      "Train Batch 20/110 - Loss: 6.9062 (Macro: 1.4809, Energy: 0.9892, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.0414 (Macro: 1.4368, Energy: 0.9964, KLD: 2.3073, MC: 2.3008)\n",
      "Train Batch 40/110 - Loss: 7.3837 (Macro: 1.5502, Energy: 1.1528, KLD: 2.3805, MC: 2.3001)\n",
      "Train Batch 50/110 - Loss: 7.0836 (Macro: 1.5156, Energy: 1.0260, KLD: 2.2381, MC: 2.3039)\n",
      "Train Batch 60/110 - Loss: 6.9089 (Macro: 1.3916, Energy: 0.9613, KLD: 2.2570, MC: 2.2990)\n",
      "Train Batch 70/110 - Loss: 6.9417 (Macro: 1.3604, Energy: 0.8408, KLD: 2.4378, MC: 2.3027)\n",
      "Train Batch 80/110 - Loss: 7.2537 (Macro: 1.4005, Energy: 1.0127, KLD: 2.5365, MC: 2.3041)\n",
      "Train Batch 90/110 - Loss: 6.7805 (Macro: 1.4778, Energy: 0.9759, KLD: 2.0241, MC: 2.3028)\n",
      "Train Batch 100/110 - Loss: 7.2892 (Macro: 1.6042, Energy: 1.1669, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.7059 (Macro: 1.2256, Energy: 0.8410, KLD: 2.3414, MC: 2.2979)\n",
      "Training epoch complete. Average Loss: 7.0819\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0786\n",
      "\n",
      "Epoch 466/500\n",
      "Train Batch 10/110 - Loss: 7.1597 (Macro: 1.5752, Energy: 1.1682, KLD: 2.1149, MC: 2.3013)\n",
      "Train Batch 20/110 - Loss: 6.9058 (Macro: 1.4815, Energy: 0.9879, KLD: 2.1345, MC: 2.3019)\n",
      "Train Batch 30/110 - Loss: 7.0833 (Macro: 1.4520, Energy: 1.0224, KLD: 2.3073, MC: 2.3017)\n",
      "Train Batch 40/110 - Loss: 7.4347 (Macro: 1.5382, Energy: 1.2150, KLD: 2.3805, MC: 2.3010)\n",
      "Train Batch 50/110 - Loss: 7.0738 (Macro: 1.5040, Energy: 1.0293, KLD: 2.2381, MC: 2.3024)\n",
      "Train Batch 60/110 - Loss: 6.9098 (Macro: 1.3982, Energy: 0.9528, KLD: 2.2570, MC: 2.3017)\n",
      "Train Batch 70/110 - Loss: 6.9971 (Macro: 1.3516, Energy: 0.9046, KLD: 2.4378, MC: 2.3030)\n",
      "Train Batch 80/110 - Loss: 7.3182 (Macro: 1.4282, Energy: 1.0507, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.8362 (Macro: 1.4853, Energy: 1.0246, KLD: 2.0241, MC: 2.3022)\n",
      "Train Batch 100/110 - Loss: 7.3490 (Macro: 1.5904, Energy: 1.2395, KLD: 2.2161, MC: 2.3030)\n",
      "Train Batch 110/110 - Loss: 6.6234 (Macro: 1.2536, Energy: 0.7279, KLD: 2.3414, MC: 2.3005)\n",
      "Training epoch complete. Average Loss: 7.0824\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0660\n",
      "\n",
      "Epoch 467/500\n",
      "Train Batch 10/110 - Loss: 7.1164 (Macro: 1.5569, Energy: 1.1453, KLD: 2.1149, MC: 2.2993)\n",
      "Train Batch 20/110 - Loss: 6.8850 (Macro: 1.4816, Energy: 0.9681, KLD: 2.1345, MC: 2.3008)\n",
      "Train Batch 30/110 - Loss: 7.0877 (Macro: 1.4444, Energy: 1.0352, KLD: 2.3073, MC: 2.3008)\n",
      "Train Batch 40/110 - Loss: 7.4686 (Macro: 1.5898, Energy: 1.1970, KLD: 2.3805, MC: 2.3013)\n",
      "Train Batch 50/110 - Loss: 7.0359 (Macro: 1.4802, Energy: 1.0157, KLD: 2.2381, MC: 2.3019)\n",
      "Train Batch 60/110 - Loss: 6.8809 (Macro: 1.3801, Energy: 0.9412, KLD: 2.2570, MC: 2.3025)\n",
      "Train Batch 70/110 - Loss: 6.9175 (Macro: 1.3491, Energy: 0.8270, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.3392 (Macro: 1.4194, Energy: 1.0815, KLD: 2.5365, MC: 2.3018)\n",
      "Train Batch 90/110 - Loss: 6.8286 (Macro: 1.4968, Energy: 1.0049, KLD: 2.0241, MC: 2.3028)\n",
      "Train Batch 100/110 - Loss: 7.2997 (Macro: 1.5881, Energy: 1.1928, KLD: 2.2161, MC: 2.3026)\n",
      "Train Batch 110/110 - Loss: 6.5748 (Macro: 1.1969, Energy: 0.7350, KLD: 2.3414, MC: 2.3014)\n",
      "Training epoch complete. Average Loss: 7.0789\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0596\n",
      "\n",
      "Epoch 468/500\n",
      "Train Batch 10/110 - Loss: 7.0805 (Macro: 1.5667, Energy: 1.0983, KLD: 2.1149, MC: 2.3006)\n",
      "Train Batch 20/110 - Loss: 6.8731 (Macro: 1.4781, Energy: 0.9557, KLD: 2.1345, MC: 2.3049)\n",
      "Train Batch 30/110 - Loss: 7.0801 (Macro: 1.4536, Energy: 1.0173, KLD: 2.3073, MC: 2.3020)\n",
      "Train Batch 40/110 - Loss: 7.4347 (Macro: 1.5681, Energy: 1.1847, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.0671 (Macro: 1.4739, Energy: 1.0523, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.9257 (Macro: 1.3827, Energy: 0.9843, KLD: 2.2570, MC: 2.3016)\n",
      "Train Batch 70/110 - Loss: 6.9350 (Macro: 1.3376, Energy: 0.8566, KLD: 2.4378, MC: 2.3031)\n",
      "Train Batch 80/110 - Loss: 7.3459 (Macro: 1.4223, Energy: 1.0848, KLD: 2.5365, MC: 2.3023)\n",
      "Train Batch 90/110 - Loss: 6.7908 (Macro: 1.4725, Energy: 0.9934, KLD: 2.0241, MC: 2.3009)\n",
      "Train Batch 100/110 - Loss: 7.3763 (Macro: 1.6074, Energy: 1.2495, KLD: 2.2161, MC: 2.3034)\n",
      "Train Batch 110/110 - Loss: 6.6827 (Macro: 1.2274, Energy: 0.8149, KLD: 2.3414, MC: 2.2990)\n",
      "Training epoch complete. Average Loss: 7.0797\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0576\n",
      "\n",
      "Epoch 469/500\n",
      "Train Batch 10/110 - Loss: 7.0869 (Macro: 1.5717, Energy: 1.0998, KLD: 2.1149, MC: 2.3005)\n",
      "Train Batch 20/110 - Loss: 6.9392 (Macro: 1.4956, Energy: 1.0083, KLD: 2.1345, MC: 2.3008)\n",
      "Train Batch 30/110 - Loss: 7.1387 (Macro: 1.4686, Energy: 1.0612, KLD: 2.3073, MC: 2.3016)\n",
      "Train Batch 40/110 - Loss: 7.5209 (Macro: 1.5592, Energy: 1.2800, KLD: 2.3805, MC: 2.3012)\n",
      "Train Batch 50/110 - Loss: 7.0688 (Macro: 1.4979, Energy: 1.0289, KLD: 2.2381, MC: 2.3040)\n",
      "Train Batch 60/110 - Loss: 6.8694 (Macro: 1.3812, Energy: 0.9293, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 6.9675 (Macro: 1.3615, Energy: 0.8655, KLD: 2.4378, MC: 2.3027)\n",
      "Train Batch 80/110 - Loss: 7.3266 (Macro: 1.4149, Energy: 1.0729, KLD: 2.5365, MC: 2.3022)\n",
      "Train Batch 90/110 - Loss: 6.7388 (Macro: 1.4585, Energy: 0.9550, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.2733 (Macro: 1.6074, Energy: 1.1492, KLD: 2.2161, MC: 2.3007)\n",
      "Train Batch 110/110 - Loss: 6.5931 (Macro: 1.1904, Energy: 0.7608, KLD: 2.3414, MC: 2.3004)\n",
      "Training epoch complete. Average Loss: 7.0814\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0601\n",
      "\n",
      "Epoch 470/500\n",
      "Train Batch 10/110 - Loss: 7.1394 (Macro: 1.5942, Energy: 1.1303, KLD: 2.1149, MC: 2.3000)\n",
      "Train Batch 20/110 - Loss: 6.8655 (Macro: 1.4700, Energy: 0.9579, KLD: 2.1345, MC: 2.3031)\n",
      "Train Batch 30/110 - Loss: 7.1303 (Macro: 1.4596, Energy: 1.0617, KLD: 2.3073, MC: 2.3017)\n",
      "Train Batch 40/110 - Loss: 7.4863 (Macro: 1.5607, Energy: 1.2424, KLD: 2.3805, MC: 2.3027)\n",
      "Train Batch 50/110 - Loss: 7.0221 (Macro: 1.4964, Energy: 0.9841, KLD: 2.2381, MC: 2.3036)\n",
      "Train Batch 60/110 - Loss: 6.8993 (Macro: 1.3837, Energy: 0.9574, KLD: 2.2570, MC: 2.3012)\n",
      "Train Batch 70/110 - Loss: 6.9994 (Macro: 1.3553, Energy: 0.9026, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.3406 (Macro: 1.4403, Energy: 1.0616, KLD: 2.5365, MC: 2.3022)\n",
      "Train Batch 90/110 - Loss: 6.8191 (Macro: 1.4683, Energy: 1.0255, KLD: 2.0241, MC: 2.3013)\n",
      "Train Batch 100/110 - Loss: 7.3346 (Macro: 1.5925, Energy: 1.2239, KLD: 2.2161, MC: 2.3022)\n",
      "Train Batch 110/110 - Loss: 6.7069 (Macro: 1.2675, Energy: 0.7994, KLD: 2.3414, MC: 2.2986)\n",
      "Training epoch complete. Average Loss: 7.0823\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0625\n",
      "\n",
      "Epoch 471/500\n",
      "Train Batch 10/110 - Loss: 7.1622 (Macro: 1.5656, Energy: 1.1821, KLD: 2.1149, MC: 2.2995)\n",
      "Train Batch 20/110 - Loss: 6.9115 (Macro: 1.4721, Energy: 1.0027, KLD: 2.1345, MC: 2.3022)\n",
      "Train Batch 30/110 - Loss: 7.0629 (Macro: 1.4579, Energy: 0.9952, KLD: 2.3073, MC: 2.3025)\n",
      "Train Batch 40/110 - Loss: 7.4458 (Macro: 1.5670, Energy: 1.1977, KLD: 2.3805, MC: 2.3005)\n",
      "Train Batch 50/110 - Loss: 7.1155 (Macro: 1.5059, Energy: 1.0696, KLD: 2.2381, MC: 2.3019)\n",
      "Train Batch 60/110 - Loss: 6.9242 (Macro: 1.3893, Energy: 0.9770, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 6.9146 (Macro: 1.3587, Energy: 0.8155, KLD: 2.4378, MC: 2.3027)\n",
      "Train Batch 80/110 - Loss: 7.2684 (Macro: 1.4134, Energy: 1.0150, KLD: 2.5365, MC: 2.3036)\n",
      "Train Batch 90/110 - Loss: 6.8095 (Macro: 1.4787, Energy: 1.0044, KLD: 2.0241, MC: 2.3023)\n",
      "Train Batch 100/110 - Loss: 7.3185 (Macro: 1.5916, Energy: 1.2100, KLD: 2.2161, MC: 2.3008)\n",
      "Train Batch 110/110 - Loss: 6.7436 (Macro: 1.2545, Energy: 0.8467, KLD: 2.3414, MC: 2.3010)\n",
      "Training epoch complete. Average Loss: 7.0800\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0620\n",
      "\n",
      "Epoch 472/500\n",
      "Train Batch 10/110 - Loss: 7.0551 (Macro: 1.5784, Energy: 1.0610, KLD: 2.1149, MC: 2.3008)\n",
      "Train Batch 20/110 - Loss: 6.8821 (Macro: 1.4808, Energy: 0.9636, KLD: 2.1345, MC: 2.3032)\n",
      "Train Batch 30/110 - Loss: 7.0808 (Macro: 1.4442, Energy: 1.0284, KLD: 2.3073, MC: 2.3008)\n",
      "Train Batch 40/110 - Loss: 7.4643 (Macro: 1.5604, Energy: 1.2223, KLD: 2.3805, MC: 2.3010)\n",
      "Train Batch 50/110 - Loss: 7.0610 (Macro: 1.4903, Energy: 1.0310, KLD: 2.2381, MC: 2.3016)\n",
      "Train Batch 60/110 - Loss: 6.8611 (Macro: 1.3907, Energy: 0.9122, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9670 (Macro: 1.3726, Energy: 0.8535, KLD: 2.4378, MC: 2.3031)\n",
      "Train Batch 80/110 - Loss: 7.3672 (Macro: 1.4462, Energy: 1.0795, KLD: 2.5365, MC: 2.3050)\n",
      "Train Batch 90/110 - Loss: 6.7987 (Macro: 1.4947, Energy: 0.9778, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.3037 (Macro: 1.6094, Energy: 1.1748, KLD: 2.2161, MC: 2.3034)\n",
      "Train Batch 110/110 - Loss: 6.5585 (Macro: 1.2356, Energy: 0.6820, KLD: 2.3414, MC: 2.2995)\n",
      "Training epoch complete. Average Loss: 7.0779\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0623\n",
      "\n",
      "Epoch 473/500\n",
      "Train Batch 10/110 - Loss: 7.1243 (Macro: 1.5705, Energy: 1.1394, KLD: 2.1149, MC: 2.2995)\n",
      "Train Batch 20/110 - Loss: 6.8932 (Macro: 1.4797, Energy: 0.9773, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.1038 (Macro: 1.4709, Energy: 1.0240, KLD: 2.3073, MC: 2.3016)\n",
      "Train Batch 40/110 - Loss: 7.5001 (Macro: 1.5643, Energy: 1.2537, KLD: 2.3805, MC: 2.3016)\n",
      "Train Batch 50/110 - Loss: 7.0640 (Macro: 1.5185, Energy: 1.0039, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.9172 (Macro: 1.3979, Energy: 0.9609, KLD: 2.2570, MC: 2.3014)\n",
      "Train Batch 70/110 - Loss: 6.9957 (Macro: 1.3636, Energy: 0.8902, KLD: 2.4378, MC: 2.3041)\n",
      "Train Batch 80/110 - Loss: 7.2787 (Macro: 1.4246, Energy: 1.0133, KLD: 2.5365, MC: 2.3042)\n",
      "Train Batch 90/110 - Loss: 6.7393 (Macro: 1.4737, Energy: 0.9400, KLD: 2.0241, MC: 2.3015)\n",
      "Train Batch 100/110 - Loss: 7.3231 (Macro: 1.6172, Energy: 1.1889, KLD: 2.2161, MC: 2.3010)\n",
      "Train Batch 110/110 - Loss: 6.6390 (Macro: 1.2268, Energy: 0.7724, KLD: 2.3414, MC: 2.2984)\n",
      "Training epoch complete. Average Loss: 7.0825\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0690\n",
      "\n",
      "Epoch 474/500\n",
      "Train Batch 10/110 - Loss: 7.1481 (Macro: 1.5882, Energy: 1.1457, KLD: 2.1149, MC: 2.2994)\n",
      "Train Batch 20/110 - Loss: 6.9138 (Macro: 1.4986, Energy: 0.9796, KLD: 2.1345, MC: 2.3012)\n",
      "Train Batch 30/110 - Loss: 7.1221 (Macro: 1.4520, Energy: 1.0602, KLD: 2.3073, MC: 2.3026)\n",
      "Train Batch 40/110 - Loss: 7.5108 (Macro: 1.5729, Energy: 1.2575, KLD: 2.3805, MC: 2.2999)\n",
      "Train Batch 50/110 - Loss: 7.0774 (Macro: 1.5049, Energy: 1.0309, KLD: 2.2381, MC: 2.3036)\n",
      "Train Batch 60/110 - Loss: 6.9601 (Macro: 1.3766, Energy: 1.0263, KLD: 2.2570, MC: 2.3001)\n",
      "Train Batch 70/110 - Loss: 6.9745 (Macro: 1.3579, Energy: 0.8752, KLD: 2.4378, MC: 2.3037)\n",
      "Train Batch 80/110 - Loss: 7.2945 (Macro: 1.4490, Energy: 1.0072, KLD: 2.5365, MC: 2.3018)\n",
      "Train Batch 90/110 - Loss: 6.7459 (Macro: 1.4577, Energy: 0.9645, KLD: 2.0241, MC: 2.2996)\n",
      "Train Batch 100/110 - Loss: 7.3162 (Macro: 1.6135, Energy: 1.1859, KLD: 2.2161, MC: 2.3007)\n",
      "Train Batch 110/110 - Loss: 6.6186 (Macro: 1.2309, Energy: 0.7472, KLD: 2.3414, MC: 2.2991)\n",
      "Training epoch complete. Average Loss: 7.0811\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0704\n",
      "\n",
      "Epoch 475/500\n",
      "Train Batch 10/110 - Loss: 7.1471 (Macro: 1.5728, Energy: 1.1584, KLD: 2.1149, MC: 2.3010)\n",
      "Train Batch 20/110 - Loss: 6.8868 (Macro: 1.4829, Energy: 0.9669, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.1115 (Macro: 1.4559, Energy: 1.0455, KLD: 2.3073, MC: 2.3028)\n",
      "Train Batch 40/110 - Loss: 7.3828 (Macro: 1.5545, Energy: 1.1466, KLD: 2.3805, MC: 2.3013)\n",
      "Train Batch 50/110 - Loss: 7.0351 (Macro: 1.5130, Energy: 0.9802, KLD: 2.2381, MC: 2.3038)\n",
      "Train Batch 60/110 - Loss: 6.9273 (Macro: 1.3755, Energy: 0.9938, KLD: 2.2570, MC: 2.3010)\n",
      "Train Batch 70/110 - Loss: 7.0122 (Macro: 1.3560, Energy: 0.9155, KLD: 2.4378, MC: 2.3029)\n",
      "Train Batch 80/110 - Loss: 7.3359 (Macro: 1.4367, Energy: 1.0586, KLD: 2.5365, MC: 2.3040)\n",
      "Train Batch 90/110 - Loss: 6.8129 (Macro: 1.4867, Energy: 0.9995, KLD: 2.0241, MC: 2.3026)\n",
      "Train Batch 100/110 - Loss: 7.3152 (Macro: 1.6150, Energy: 1.1810, KLD: 2.2161, MC: 2.3031)\n",
      "Train Batch 110/110 - Loss: 6.6468 (Macro: 1.2561, Energy: 0.7514, KLD: 2.3414, MC: 2.2978)\n",
      "Training epoch complete. Average Loss: 7.0803\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0619\n",
      "\n",
      "Epoch 476/500\n",
      "Train Batch 10/110 - Loss: 7.1359 (Macro: 1.5851, Energy: 1.1361, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.9054 (Macro: 1.4822, Energy: 0.9876, KLD: 2.1345, MC: 2.3011)\n",
      "Train Batch 30/110 - Loss: 7.0131 (Macro: 1.4342, Energy: 0.9692, KLD: 2.3073, MC: 2.3024)\n",
      "Train Batch 40/110 - Loss: 7.4460 (Macro: 1.5690, Energy: 1.1974, KLD: 2.3805, MC: 2.2991)\n",
      "Train Batch 50/110 - Loss: 7.0944 (Macro: 1.5048, Energy: 1.0495, KLD: 2.2381, MC: 2.3020)\n",
      "Train Batch 60/110 - Loss: 6.8783 (Macro: 1.3691, Energy: 0.9519, KLD: 2.2570, MC: 2.3002)\n",
      "Train Batch 70/110 - Loss: 6.9621 (Macro: 1.3685, Energy: 0.8534, KLD: 2.4378, MC: 2.3023)\n",
      "Train Batch 80/110 - Loss: 7.2866 (Macro: 1.4189, Energy: 1.0291, KLD: 2.5365, MC: 2.3020)\n",
      "Train Batch 90/110 - Loss: 6.8463 (Macro: 1.4781, Energy: 1.0419, KLD: 2.0241, MC: 2.3022)\n",
      "Train Batch 100/110 - Loss: 7.3705 (Macro: 1.6194, Energy: 1.2312, KLD: 2.2161, MC: 2.3037)\n",
      "Train Batch 110/110 - Loss: 6.5556 (Macro: 1.2315, Energy: 0.6868, KLD: 2.3414, MC: 2.2960)\n",
      "Training epoch complete. Average Loss: 7.0828\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0601\n",
      "\n",
      "Epoch 477/500\n",
      "Train Batch 10/110 - Loss: 7.1229 (Macro: 1.5940, Energy: 1.1136, KLD: 2.1149, MC: 2.3004)\n",
      "Train Batch 20/110 - Loss: 6.8585 (Macro: 1.4925, Energy: 0.9298, KLD: 2.1345, MC: 2.3018)\n",
      "Train Batch 30/110 - Loss: 7.0448 (Macro: 1.4732, Energy: 0.9616, KLD: 2.3073, MC: 2.3026)\n",
      "Train Batch 40/110 - Loss: 7.4036 (Macro: 1.5535, Energy: 1.1650, KLD: 2.3805, MC: 2.3046)\n",
      "Train Batch 50/110 - Loss: 7.0510 (Macro: 1.4955, Energy: 1.0129, KLD: 2.2381, MC: 2.3046)\n",
      "Train Batch 60/110 - Loss: 6.8967 (Macro: 1.3939, Energy: 0.9454, KLD: 2.2570, MC: 2.3003)\n",
      "Train Batch 70/110 - Loss: 6.9314 (Macro: 1.3383, Energy: 0.8511, KLD: 2.4378, MC: 2.3041)\n",
      "Train Batch 80/110 - Loss: 7.3090 (Macro: 1.4262, Energy: 1.0425, KLD: 2.5365, MC: 2.3038)\n",
      "Train Batch 90/110 - Loss: 6.7823 (Macro: 1.4750, Energy: 0.9811, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3199 (Macro: 1.6063, Energy: 1.1961, KLD: 2.2161, MC: 2.3014)\n",
      "Train Batch 110/110 - Loss: 6.6693 (Macro: 1.2604, Energy: 0.7673, KLD: 2.3414, MC: 2.3002)\n",
      "Training epoch complete. Average Loss: 7.0792\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0807\n",
      "\n",
      "Epoch 478/500\n",
      "Train Batch 10/110 - Loss: 7.1065 (Macro: 1.5949, Energy: 1.0952, KLD: 2.1149, MC: 2.3014)\n",
      "Train Batch 20/110 - Loss: 6.8919 (Macro: 1.4693, Energy: 0.9866, KLD: 2.1345, MC: 2.3015)\n",
      "Train Batch 30/110 - Loss: 7.0615 (Macro: 1.4481, Energy: 1.0054, KLD: 2.3073, MC: 2.3007)\n",
      "Train Batch 40/110 - Loss: 7.4539 (Macro: 1.5586, Energy: 1.2134, KLD: 2.3805, MC: 2.3013)\n",
      "Train Batch 50/110 - Loss: 7.1320 (Macro: 1.5303, Energy: 1.0601, KLD: 2.2381, MC: 2.3036)\n",
      "Train Batch 60/110 - Loss: 6.9113 (Macro: 1.3956, Energy: 0.9569, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 6.9341 (Macro: 1.3434, Energy: 0.8489, KLD: 2.4378, MC: 2.3040)\n",
      "Train Batch 80/110 - Loss: 7.2923 (Macro: 1.4370, Energy: 1.0153, KLD: 2.5365, MC: 2.3035)\n",
      "Train Batch 90/110 - Loss: 6.7584 (Macro: 1.4654, Energy: 0.9677, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.3133 (Macro: 1.6088, Energy: 1.1873, KLD: 2.2161, MC: 2.3012)\n",
      "Train Batch 110/110 - Loss: 6.5793 (Macro: 1.2310, Energy: 0.7063, KLD: 2.3414, MC: 2.3006)\n",
      "Training epoch complete. Average Loss: 7.0805\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0629\n",
      "\n",
      "Epoch 479/500\n",
      "Train Batch 10/110 - Loss: 7.1170 (Macro: 1.5506, Energy: 1.1486, KLD: 2.1149, MC: 2.3029)\n",
      "Train Batch 20/110 - Loss: 6.8855 (Macro: 1.5004, Energy: 0.9478, KLD: 2.1345, MC: 2.3028)\n",
      "Train Batch 30/110 - Loss: 7.1450 (Macro: 1.4414, Energy: 1.0931, KLD: 2.3073, MC: 2.3031)\n",
      "Train Batch 40/110 - Loss: 7.4267 (Macro: 1.5592, Energy: 1.1868, KLD: 2.3805, MC: 2.3002)\n",
      "Train Batch 50/110 - Loss: 7.0500 (Macro: 1.5036, Energy: 1.0057, KLD: 2.2381, MC: 2.3027)\n",
      "Train Batch 60/110 - Loss: 6.9922 (Macro: 1.3936, Energy: 1.0391, KLD: 2.2570, MC: 2.3025)\n",
      "Train Batch 70/110 - Loss: 6.9319 (Macro: 1.3564, Energy: 0.8330, KLD: 2.4378, MC: 2.3048)\n",
      "Train Batch 80/110 - Loss: 7.3491 (Macro: 1.4226, Energy: 1.0883, KLD: 2.5365, MC: 2.3017)\n",
      "Train Batch 90/110 - Loss: 6.8028 (Macro: 1.4732, Energy: 1.0031, KLD: 2.0241, MC: 2.3024)\n",
      "Train Batch 100/110 - Loss: 7.2939 (Macro: 1.5834, Energy: 1.1912, KLD: 2.2161, MC: 2.3032)\n",
      "Train Batch 110/110 - Loss: 6.6331 (Macro: 1.2473, Energy: 0.7474, KLD: 2.3414, MC: 2.2971)\n",
      "Training epoch complete. Average Loss: 7.0828\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0692\n",
      "\n",
      "Epoch 480/500\n",
      "Train Batch 10/110 - Loss: 7.0802 (Macro: 1.5693, Energy: 1.0963, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.8798 (Macro: 1.4692, Energy: 0.9747, KLD: 2.1345, MC: 2.3014)\n",
      "Train Batch 30/110 - Loss: 7.1003 (Macro: 1.4610, Energy: 1.0319, KLD: 2.3073, MC: 2.3001)\n",
      "Train Batch 40/110 - Loss: 7.4838 (Macro: 1.5607, Energy: 1.2408, KLD: 2.3805, MC: 2.3019)\n",
      "Train Batch 50/110 - Loss: 7.1141 (Macro: 1.4967, Energy: 1.0777, KLD: 2.2381, MC: 2.3016)\n",
      "Train Batch 60/110 - Loss: 6.8510 (Macro: 1.3719, Energy: 0.9221, KLD: 2.2570, MC: 2.2999)\n",
      "Train Batch 70/110 - Loss: 6.9395 (Macro: 1.3636, Energy: 0.8356, KLD: 2.4378, MC: 2.3024)\n",
      "Train Batch 80/110 - Loss: 7.2805 (Macro: 1.4295, Energy: 1.0106, KLD: 2.5365, MC: 2.3039)\n",
      "Train Batch 90/110 - Loss: 6.8738 (Macro: 1.4902, Energy: 1.0558, KLD: 2.0241, MC: 2.3038)\n",
      "Train Batch 100/110 - Loss: 7.2873 (Macro: 1.5898, Energy: 1.1794, KLD: 2.2161, MC: 2.3020)\n",
      "Train Batch 110/110 - Loss: 6.7025 (Macro: 1.2636, Energy: 0.7974, KLD: 2.3414, MC: 2.3001)\n",
      "Training epoch complete. Average Loss: 7.0769\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0728\n",
      "\n",
      "Epoch 481/500\n",
      "Train Batch 10/110 - Loss: 7.0886 (Macro: 1.5901, Energy: 1.0852, KLD: 2.1149, MC: 2.2984)\n",
      "Train Batch 20/110 - Loss: 6.9405 (Macro: 1.5026, Energy: 1.0003, KLD: 2.1345, MC: 2.3032)\n",
      "Train Batch 30/110 - Loss: 7.0275 (Macro: 1.4519, Energy: 0.9657, KLD: 2.3073, MC: 2.3027)\n",
      "Train Batch 40/110 - Loss: 7.4251 (Macro: 1.5514, Energy: 1.1922, KLD: 2.3805, MC: 2.3010)\n",
      "Train Batch 50/110 - Loss: 7.0616 (Macro: 1.4956, Energy: 1.0250, KLD: 2.2381, MC: 2.3029)\n",
      "Train Batch 60/110 - Loss: 6.8884 (Macro: 1.3866, Energy: 0.9439, KLD: 2.2570, MC: 2.3009)\n",
      "Train Batch 70/110 - Loss: 6.9544 (Macro: 1.3525, Energy: 0.8604, KLD: 2.4378, MC: 2.3038)\n",
      "Train Batch 80/110 - Loss: 7.3411 (Macro: 1.4306, Energy: 1.0716, KLD: 2.5365, MC: 2.3025)\n",
      "Train Batch 90/110 - Loss: 6.7952 (Macro: 1.5000, Energy: 0.9704, KLD: 2.0241, MC: 2.3007)\n",
      "Train Batch 100/110 - Loss: 7.2961 (Macro: 1.6026, Energy: 1.1759, KLD: 2.2161, MC: 2.3015)\n",
      "Train Batch 110/110 - Loss: 6.5831 (Macro: 1.2093, Energy: 0.7348, KLD: 2.3414, MC: 2.2976)\n",
      "Training epoch complete. Average Loss: 7.0752\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0728\n",
      "\n",
      "Epoch 482/500\n",
      "Train Batch 10/110 - Loss: 7.1095 (Macro: 1.5634, Energy: 1.1317, KLD: 2.1149, MC: 2.2995)\n",
      "Train Batch 20/110 - Loss: 6.9174 (Macro: 1.5004, Energy: 0.9810, KLD: 2.1345, MC: 2.3015)\n",
      "Train Batch 30/110 - Loss: 7.0791 (Macro: 1.4514, Energy: 1.0193, KLD: 2.3073, MC: 2.3011)\n",
      "Train Batch 40/110 - Loss: 7.4909 (Macro: 1.5576, Energy: 1.2510, KLD: 2.3805, MC: 2.3018)\n",
      "Train Batch 50/110 - Loss: 7.1107 (Macro: 1.4989, Energy: 1.0713, KLD: 2.2381, MC: 2.3024)\n",
      "Train Batch 60/110 - Loss: 6.8656 (Macro: 1.3751, Energy: 0.9309, KLD: 2.2570, MC: 2.3024)\n",
      "Train Batch 70/110 - Loss: 6.9458 (Macro: 1.3690, Energy: 0.8360, KLD: 2.4378, MC: 2.3031)\n",
      "Train Batch 80/110 - Loss: 7.3298 (Macro: 1.4332, Energy: 1.0570, KLD: 2.5365, MC: 2.3032)\n",
      "Train Batch 90/110 - Loss: 6.8329 (Macro: 1.4891, Energy: 1.0186, KLD: 2.0241, MC: 2.3012)\n",
      "Train Batch 100/110 - Loss: 7.3273 (Macro: 1.6046, Energy: 1.2054, KLD: 2.2161, MC: 2.3012)\n",
      "Train Batch 110/110 - Loss: 6.6278 (Macro: 1.2307, Energy: 0.7551, KLD: 2.3414, MC: 2.3007)\n",
      "Training epoch complete. Average Loss: 7.0848\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0629\n",
      "\n",
      "Epoch 483/500\n",
      "Train Batch 10/110 - Loss: 7.1769 (Macro: 1.5612, Energy: 1.2014, KLD: 2.1149, MC: 2.2994)\n",
      "Train Batch 20/110 - Loss: 6.9146 (Macro: 1.4954, Energy: 0.9844, KLD: 2.1345, MC: 2.3004)\n",
      "Train Batch 30/110 - Loss: 7.0515 (Macro: 1.4509, Energy: 0.9913, KLD: 2.3073, MC: 2.3020)\n",
      "Train Batch 40/110 - Loss: 7.4484 (Macro: 1.5401, Energy: 1.2264, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.0450 (Macro: 1.4996, Energy: 1.0028, KLD: 2.2381, MC: 2.3046)\n",
      "Train Batch 60/110 - Loss: 6.8658 (Macro: 1.3833, Energy: 0.9228, KLD: 2.2570, MC: 2.3026)\n",
      "Train Batch 70/110 - Loss: 6.9542 (Macro: 1.3704, Energy: 0.8411, KLD: 2.4378, MC: 2.3049)\n",
      "Train Batch 80/110 - Loss: 7.2567 (Macro: 1.4195, Energy: 0.9969, KLD: 2.5365, MC: 2.3038)\n",
      "Train Batch 90/110 - Loss: 6.7781 (Macro: 1.4502, Energy: 1.0033, KLD: 2.0241, MC: 2.3006)\n",
      "Train Batch 100/110 - Loss: 7.3266 (Macro: 1.6280, Energy: 1.1800, KLD: 2.2161, MC: 2.3025)\n",
      "Train Batch 110/110 - Loss: 6.6026 (Macro: 1.2317, Energy: 0.7298, KLD: 2.3414, MC: 2.2998)\n",
      "Training epoch complete. Average Loss: 7.0762\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0615\n",
      "\n",
      "Epoch 484/500\n",
      "Train Batch 10/110 - Loss: 7.1285 (Macro: 1.5761, Energy: 1.1362, KLD: 2.1149, MC: 2.3013)\n",
      "Train Batch 20/110 - Loss: 6.9012 (Macro: 1.4805, Energy: 0.9816, KLD: 2.1345, MC: 2.3045)\n",
      "Train Batch 30/110 - Loss: 7.0829 (Macro: 1.4408, Energy: 1.0320, KLD: 2.3073, MC: 2.3029)\n",
      "Train Batch 40/110 - Loss: 7.4315 (Macro: 1.5544, Energy: 1.1950, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.0100 (Macro: 1.4814, Energy: 0.9881, KLD: 2.2381, MC: 2.3025)\n",
      "Train Batch 60/110 - Loss: 6.9235 (Macro: 1.3940, Energy: 0.9700, KLD: 2.2570, MC: 2.3024)\n",
      "Train Batch 70/110 - Loss: 6.9526 (Macro: 1.3768, Energy: 0.8353, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.3286 (Macro: 1.4322, Energy: 1.0578, KLD: 2.5365, MC: 2.3022)\n",
      "Train Batch 90/110 - Loss: 6.8046 (Macro: 1.4816, Energy: 0.9972, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.3342 (Macro: 1.6175, Energy: 1.1990, KLD: 2.2161, MC: 2.3017)\n",
      "Train Batch 110/110 - Loss: 6.6355 (Macro: 1.2425, Energy: 0.7534, KLD: 2.3414, MC: 2.2983)\n",
      "Training epoch complete. Average Loss: 7.0770\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0637\n",
      "\n",
      "Epoch 485/500\n",
      "Train Batch 10/110 - Loss: 7.1709 (Macro: 1.5747, Energy: 1.1803, KLD: 2.1149, MC: 2.3010)\n",
      "Train Batch 20/110 - Loss: 6.9460 (Macro: 1.4849, Energy: 1.0246, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.0537 (Macro: 1.4593, Energy: 0.9852, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4655 (Macro: 1.5672, Energy: 1.2177, KLD: 2.3805, MC: 2.3001)\n",
      "Train Batch 50/110 - Loss: 7.0628 (Macro: 1.5008, Energy: 1.0207, KLD: 2.2381, MC: 2.3033)\n",
      "Train Batch 60/110 - Loss: 6.9271 (Macro: 1.3766, Energy: 0.9917, KLD: 2.2570, MC: 2.3018)\n",
      "Train Batch 70/110 - Loss: 6.9082 (Macro: 1.3579, Energy: 0.8095, KLD: 2.4378, MC: 2.3031)\n",
      "Train Batch 80/110 - Loss: 7.3077 (Macro: 1.4286, Energy: 1.0401, KLD: 2.5365, MC: 2.3025)\n",
      "Train Batch 90/110 - Loss: 6.7982 (Macro: 1.4725, Energy: 0.9994, KLD: 2.0241, MC: 2.3022)\n",
      "Train Batch 100/110 - Loss: 7.3476 (Macro: 1.6227, Energy: 1.2045, KLD: 2.2161, MC: 2.3042)\n",
      "Train Batch 110/110 - Loss: 6.5661 (Macro: 1.2370, Energy: 0.6907, KLD: 2.3414, MC: 2.2970)\n",
      "Training epoch complete. Average Loss: 7.0803\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0618\n",
      "\n",
      "Epoch 486/500\n",
      "Train Batch 10/110 - Loss: 7.1252 (Macro: 1.5866, Energy: 1.1243, KLD: 2.1149, MC: 2.2994)\n",
      "Train Batch 20/110 - Loss: 6.9242 (Macro: 1.4787, Energy: 1.0096, KLD: 2.1345, MC: 2.3014)\n",
      "Train Batch 30/110 - Loss: 7.0980 (Macro: 1.4479, Energy: 1.0410, KLD: 2.3073, MC: 2.3018)\n",
      "Train Batch 40/110 - Loss: 7.4708 (Macro: 1.5716, Energy: 1.2181, KLD: 2.3805, MC: 2.3006)\n",
      "Train Batch 50/110 - Loss: 7.0690 (Macro: 1.5144, Energy: 1.0130, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.9244 (Macro: 1.4063, Energy: 0.9604, KLD: 2.2570, MC: 2.3006)\n",
      "Train Batch 70/110 - Loss: 6.9940 (Macro: 1.3627, Energy: 0.8917, KLD: 2.4378, MC: 2.3018)\n",
      "Train Batch 80/110 - Loss: 7.2633 (Macro: 1.4311, Energy: 0.9926, KLD: 2.5365, MC: 2.3031)\n",
      "Train Batch 90/110 - Loss: 6.7188 (Macro: 1.4740, Energy: 0.9197, KLD: 2.0241, MC: 2.3011)\n",
      "Train Batch 100/110 - Loss: 7.3097 (Macro: 1.6033, Energy: 1.1884, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.6227 (Macro: 1.2789, Energy: 0.7065, KLD: 2.3414, MC: 2.2959)\n",
      "Training epoch complete. Average Loss: 7.0833\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0629\n",
      "\n",
      "Epoch 487/500\n",
      "Train Batch 10/110 - Loss: 7.1307 (Macro: 1.5794, Energy: 1.1362, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.8733 (Macro: 1.4841, Energy: 0.9530, KLD: 2.1345, MC: 2.3017)\n",
      "Train Batch 30/110 - Loss: 7.0590 (Macro: 1.4519, Energy: 0.9965, KLD: 2.3073, MC: 2.3033)\n",
      "Train Batch 40/110 - Loss: 7.4662 (Macro: 1.5678, Energy: 1.2165, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.0886 (Macro: 1.4952, Energy: 1.0540, KLD: 2.2381, MC: 2.3014)\n",
      "Train Batch 60/110 - Loss: 6.9006 (Macro: 1.3864, Energy: 0.9568, KLD: 2.2570, MC: 2.3003)\n",
      "Train Batch 70/110 - Loss: 6.9369 (Macro: 1.3686, Energy: 0.8277, KLD: 2.4378, MC: 2.3028)\n",
      "Train Batch 80/110 - Loss: 7.3208 (Macro: 1.4275, Energy: 1.0552, KLD: 2.5365, MC: 2.3016)\n",
      "Train Batch 90/110 - Loss: 6.7784 (Macro: 1.4575, Energy: 0.9960, KLD: 2.0241, MC: 2.3008)\n",
      "Train Batch 100/110 - Loss: 7.3014 (Macro: 1.6074, Energy: 1.1755, KLD: 2.2161, MC: 2.3024)\n",
      "Train Batch 110/110 - Loss: 6.6600 (Macro: 1.2201, Energy: 0.8018, KLD: 2.3414, MC: 2.2967)\n",
      "Training epoch complete. Average Loss: 7.0720\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0662\n",
      "\n",
      "Epoch 488/500\n",
      "Train Batch 10/110 - Loss: 7.1734 (Macro: 1.5722, Energy: 1.1860, KLD: 2.1149, MC: 2.3002)\n",
      "Train Batch 20/110 - Loss: 6.9028 (Macro: 1.4889, Energy: 0.9763, KLD: 2.1345, MC: 2.3032)\n",
      "Train Batch 30/110 - Loss: 7.0554 (Macro: 1.4565, Energy: 0.9884, KLD: 2.3073, MC: 2.3033)\n",
      "Train Batch 40/110 - Loss: 7.4303 (Macro: 1.5467, Energy: 1.2017, KLD: 2.3805, MC: 2.3015)\n",
      "Train Batch 50/110 - Loss: 7.0302 (Macro: 1.5014, Energy: 0.9873, KLD: 2.2381, MC: 2.3035)\n",
      "Train Batch 60/110 - Loss: 6.8980 (Macro: 1.3842, Energy: 0.9536, KLD: 2.2570, MC: 2.3032)\n",
      "Train Batch 70/110 - Loss: 6.9534 (Macro: 1.3489, Energy: 0.8625, KLD: 2.4378, MC: 2.3041)\n",
      "Train Batch 80/110 - Loss: 7.3338 (Macro: 1.4134, Energy: 1.0821, KLD: 2.5365, MC: 2.3018)\n",
      "Train Batch 90/110 - Loss: 6.7305 (Macro: 1.4701, Energy: 0.9346, KLD: 2.0241, MC: 2.3017)\n",
      "Train Batch 100/110 - Loss: 7.3192 (Macro: 1.6148, Energy: 1.1869, KLD: 2.2161, MC: 2.3013)\n",
      "Train Batch 110/110 - Loss: 6.6172 (Macro: 1.2288, Energy: 0.7483, KLD: 2.3414, MC: 2.2986)\n",
      "Training epoch complete. Average Loss: 7.0773\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0692\n",
      "\n",
      "Epoch 489/500\n",
      "Train Batch 10/110 - Loss: 7.0867 (Macro: 1.5796, Energy: 1.0902, KLD: 2.1149, MC: 2.3019)\n",
      "Train Batch 20/110 - Loss: 6.8813 (Macro: 1.5017, Energy: 0.9436, KLD: 2.1345, MC: 2.3015)\n",
      "Train Batch 30/110 - Loss: 7.0581 (Macro: 1.4577, Energy: 0.9909, KLD: 2.3073, MC: 2.3022)\n",
      "Train Batch 40/110 - Loss: 7.4208 (Macro: 1.5542, Energy: 1.1843, KLD: 2.3805, MC: 2.3018)\n",
      "Train Batch 50/110 - Loss: 6.9588 (Macro: 1.4780, Energy: 0.9416, KLD: 2.2381, MC: 2.3012)\n",
      "Train Batch 60/110 - Loss: 6.9996 (Macro: 1.3852, Energy: 1.0562, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9450 (Macro: 1.3710, Energy: 0.8323, KLD: 2.4378, MC: 2.3040)\n",
      "Train Batch 80/110 - Loss: 7.3208 (Macro: 1.4135, Energy: 1.0670, KLD: 2.5365, MC: 2.3037)\n",
      "Train Batch 90/110 - Loss: 6.7527 (Macro: 1.4657, Energy: 0.9609, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.2476 (Macro: 1.5821, Energy: 1.1464, KLD: 2.2161, MC: 2.3030)\n",
      "Train Batch 110/110 - Loss: 6.6172 (Macro: 1.2371, Energy: 0.7382, KLD: 2.3414, MC: 2.3005)\n",
      "Training epoch complete. Average Loss: 7.0778\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0609\n",
      "\n",
      "Epoch 490/500\n",
      "Train Batch 10/110 - Loss: 7.1452 (Macro: 1.5822, Energy: 1.1485, KLD: 2.1149, MC: 2.2997)\n",
      "Train Batch 20/110 - Loss: 6.8640 (Macro: 1.4734, Energy: 0.9546, KLD: 2.1345, MC: 2.3015)\n",
      "Train Batch 30/110 - Loss: 7.0384 (Macro: 1.4620, Energy: 0.9666, KLD: 2.3073, MC: 2.3025)\n",
      "Train Batch 40/110 - Loss: 7.4586 (Macro: 1.5550, Energy: 1.2208, KLD: 2.3805, MC: 2.3023)\n",
      "Train Batch 50/110 - Loss: 7.0420 (Macro: 1.5136, Energy: 0.9868, KLD: 2.2381, MC: 2.3036)\n",
      "Train Batch 60/110 - Loss: 6.9202 (Macro: 1.3769, Energy: 0.9851, KLD: 2.2570, MC: 2.3011)\n",
      "Train Batch 70/110 - Loss: 6.9910 (Macro: 1.3832, Energy: 0.8656, KLD: 2.4378, MC: 2.3045)\n",
      "Train Batch 80/110 - Loss: 7.3159 (Macro: 1.4444, Energy: 1.0339, KLD: 2.5365, MC: 2.3011)\n",
      "Train Batch 90/110 - Loss: 6.8133 (Macro: 1.4841, Energy: 1.0025, KLD: 2.0241, MC: 2.3027)\n",
      "Train Batch 100/110 - Loss: 7.3011 (Macro: 1.5798, Energy: 1.2040, KLD: 2.2161, MC: 2.3012)\n",
      "Train Batch 110/110 - Loss: 6.6491 (Macro: 1.2093, Energy: 0.7988, KLD: 2.3414, MC: 2.2996)\n",
      "Training epoch complete. Average Loss: 7.0792\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0511\n",
      "\n",
      "Epoch 491/500\n",
      "Train Batch 10/110 - Loss: 7.1220 (Macro: 1.5759, Energy: 1.1316, KLD: 2.1149, MC: 2.2996)\n",
      "Train Batch 20/110 - Loss: 6.8939 (Macro: 1.4875, Energy: 0.9694, KLD: 2.1345, MC: 2.3025)\n",
      "Train Batch 30/110 - Loss: 7.1028 (Macro: 1.4668, Energy: 1.0273, KLD: 2.3073, MC: 2.3014)\n",
      "Train Batch 40/110 - Loss: 7.4521 (Macro: 1.5707, Energy: 1.2000, KLD: 2.3805, MC: 2.3009)\n",
      "Train Batch 50/110 - Loss: 6.9996 (Macro: 1.4966, Energy: 0.9605, KLD: 2.2381, MC: 2.3045)\n",
      "Train Batch 60/110 - Loss: 6.9027 (Macro: 1.3830, Energy: 0.9625, KLD: 2.2570, MC: 2.3002)\n",
      "Train Batch 70/110 - Loss: 6.9395 (Macro: 1.3660, Energy: 0.8322, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.3053 (Macro: 1.4154, Energy: 1.0506, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.8066 (Macro: 1.4655, Energy: 1.0167, KLD: 2.0241, MC: 2.3003)\n",
      "Train Batch 100/110 - Loss: 7.3367 (Macro: 1.5989, Energy: 1.2198, KLD: 2.2161, MC: 2.3019)\n",
      "Train Batch 110/110 - Loss: 6.5411 (Macro: 1.1885, Energy: 0.7132, KLD: 2.3414, MC: 2.2981)\n",
      "Training epoch complete. Average Loss: 7.0757\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0628\n",
      "\n",
      "Epoch 492/500\n",
      "Train Batch 10/110 - Loss: 7.1344 (Macro: 1.5928, Energy: 1.1271, KLD: 2.1149, MC: 2.2995)\n",
      "Train Batch 20/110 - Loss: 6.9450 (Macro: 1.4963, Energy: 1.0113, KLD: 2.1345, MC: 2.3029)\n",
      "Train Batch 30/110 - Loss: 7.0764 (Macro: 1.4571, Energy: 1.0096, KLD: 2.3073, MC: 2.3025)\n",
      "Train Batch 40/110 - Loss: 7.4118 (Macro: 1.5587, Energy: 1.1695, KLD: 2.3805, MC: 2.3030)\n",
      "Train Batch 50/110 - Loss: 7.0529 (Macro: 1.4967, Energy: 1.0140, KLD: 2.2381, MC: 2.3041)\n",
      "Train Batch 60/110 - Loss: 6.9205 (Macro: 1.4018, Energy: 0.9579, KLD: 2.2570, MC: 2.3038)\n",
      "Train Batch 70/110 - Loss: 6.9316 (Macro: 1.3513, Energy: 0.8376, KLD: 2.4378, MC: 2.3049)\n",
      "Train Batch 80/110 - Loss: 7.2761 (Macro: 1.4226, Energy: 1.0156, KLD: 2.5365, MC: 2.3015)\n",
      "Train Batch 90/110 - Loss: 6.7347 (Macro: 1.4714, Energy: 0.9371, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3463 (Macro: 1.6081, Energy: 1.2203, KLD: 2.2161, MC: 2.3018)\n",
      "Train Batch 110/110 - Loss: 6.5677 (Macro: 1.2080, Energy: 0.7211, KLD: 2.3414, MC: 2.2972)\n",
      "Training epoch complete. Average Loss: 7.0811\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0618\n",
      "\n",
      "Epoch 493/500\n",
      "Train Batch 10/110 - Loss: 7.0940 (Macro: 1.5625, Energy: 1.1187, KLD: 2.1149, MC: 2.2979)\n",
      "Train Batch 20/110 - Loss: 6.8732 (Macro: 1.4637, Energy: 0.9745, KLD: 2.1345, MC: 2.3006)\n",
      "Train Batch 30/110 - Loss: 7.0050 (Macro: 1.4476, Energy: 0.9482, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4270 (Macro: 1.5603, Energy: 1.1832, KLD: 2.3805, MC: 2.3030)\n",
      "Train Batch 50/110 - Loss: 7.0921 (Macro: 1.4884, Energy: 1.0613, KLD: 2.2381, MC: 2.3044)\n",
      "Train Batch 60/110 - Loss: 6.9160 (Macro: 1.3896, Energy: 0.9679, KLD: 2.2570, MC: 2.3015)\n",
      "Train Batch 70/110 - Loss: 6.9294 (Macro: 1.3682, Energy: 0.8194, KLD: 2.4378, MC: 2.3041)\n",
      "Train Batch 80/110 - Loss: 7.3369 (Macro: 1.4241, Energy: 1.0746, KLD: 2.5365, MC: 2.3018)\n",
      "Train Batch 90/110 - Loss: 6.7528 (Macro: 1.4766, Energy: 0.9488, KLD: 2.0241, MC: 2.3034)\n",
      "Train Batch 100/110 - Loss: 7.2862 (Macro: 1.5977, Energy: 1.1708, KLD: 2.2161, MC: 2.3017)\n",
      "Train Batch 110/110 - Loss: 6.5982 (Macro: 1.2321, Energy: 0.7271, KLD: 2.3414, MC: 2.2976)\n",
      "Training epoch complete. Average Loss: 7.0706\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0619\n",
      "\n",
      "Epoch 494/500\n",
      "Train Batch 10/110 - Loss: 7.1546 (Macro: 1.5815, Energy: 1.1576, KLD: 2.1149, MC: 2.3006)\n",
      "Train Batch 20/110 - Loss: 6.8848 (Macro: 1.4722, Energy: 0.9754, KLD: 2.1345, MC: 2.3027)\n",
      "Train Batch 30/110 - Loss: 7.0733 (Macro: 1.4332, Energy: 1.0304, KLD: 2.3073, MC: 2.3023)\n",
      "Train Batch 40/110 - Loss: 7.4788 (Macro: 1.5694, Energy: 1.2285, KLD: 2.3805, MC: 2.3004)\n",
      "Train Batch 50/110 - Loss: 7.0483 (Macro: 1.4717, Energy: 1.0343, KLD: 2.2381, MC: 2.3042)\n",
      "Train Batch 60/110 - Loss: 6.9001 (Macro: 1.3924, Energy: 0.9485, KLD: 2.2570, MC: 2.3023)\n",
      "Train Batch 70/110 - Loss: 6.9292 (Macro: 1.3571, Energy: 0.8310, KLD: 2.4378, MC: 2.3032)\n",
      "Train Batch 80/110 - Loss: 7.3679 (Macro: 1.4149, Energy: 1.1151, KLD: 2.5365, MC: 2.3014)\n",
      "Train Batch 90/110 - Loss: 6.7888 (Macro: 1.4775, Energy: 0.9866, KLD: 2.0241, MC: 2.3007)\n",
      "Train Batch 100/110 - Loss: 7.3418 (Macro: 1.6037, Energy: 1.2204, KLD: 2.2161, MC: 2.3016)\n",
      "Train Batch 110/110 - Loss: 6.6854 (Macro: 1.2127, Energy: 0.8322, KLD: 2.3414, MC: 2.2990)\n",
      "Training epoch complete. Average Loss: 7.0825\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0627\n",
      "\n",
      "Epoch 495/500\n",
      "Train Batch 10/110 - Loss: 7.1206 (Macro: 1.5608, Energy: 1.1446, KLD: 2.1149, MC: 2.3003)\n",
      "Train Batch 20/110 - Loss: 6.8687 (Macro: 1.4532, Energy: 0.9791, KLD: 2.1345, MC: 2.3020)\n",
      "Train Batch 30/110 - Loss: 7.1308 (Macro: 1.4546, Energy: 1.0672, KLD: 2.3073, MC: 2.3016)\n",
      "Train Batch 40/110 - Loss: 7.4499 (Macro: 1.5514, Energy: 1.2183, KLD: 2.3805, MC: 2.2997)\n",
      "Train Batch 50/110 - Loss: 7.0759 (Macro: 1.5038, Energy: 1.0310, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.9303 (Macro: 1.3815, Energy: 0.9914, KLD: 2.2570, MC: 2.3004)\n",
      "Train Batch 70/110 - Loss: 7.0497 (Macro: 1.3913, Energy: 0.9174, KLD: 2.4378, MC: 2.3033)\n",
      "Train Batch 80/110 - Loss: 7.3189 (Macro: 1.4024, Energy: 1.0772, KLD: 2.5365, MC: 2.3028)\n",
      "Train Batch 90/110 - Loss: 6.7714 (Macro: 1.4488, Energy: 0.9965, KLD: 2.0241, MC: 2.3020)\n",
      "Train Batch 100/110 - Loss: 7.2914 (Macro: 1.5964, Energy: 1.1763, KLD: 2.2161, MC: 2.3027)\n",
      "Train Batch 110/110 - Loss: 6.5714 (Macro: 1.2356, Energy: 0.6948, KLD: 2.3414, MC: 2.2996)\n",
      "Training epoch complete. Average Loss: 7.0750\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0562\n",
      "\n",
      "Epoch 496/500\n",
      "Train Batch 10/110 - Loss: 7.1078 (Macro: 1.5810, Energy: 1.1128, KLD: 2.1149, MC: 2.2990)\n",
      "Train Batch 20/110 - Loss: 6.8808 (Macro: 1.4819, Energy: 0.9617, KLD: 2.1345, MC: 2.3026)\n",
      "Train Batch 30/110 - Loss: 7.0958 (Macro: 1.4419, Energy: 1.0434, KLD: 2.3073, MC: 2.3033)\n",
      "Train Batch 40/110 - Loss: 7.4844 (Macro: 1.5720, Energy: 1.2309, KLD: 2.3805, MC: 2.3010)\n",
      "Train Batch 50/110 - Loss: 7.0422 (Macro: 1.4851, Energy: 1.0171, KLD: 2.2381, MC: 2.3020)\n",
      "Train Batch 60/110 - Loss: 6.8608 (Macro: 1.3815, Energy: 0.9220, KLD: 2.2570, MC: 2.3002)\n",
      "Train Batch 70/110 - Loss: 6.9646 (Macro: 1.3634, Energy: 0.8598, KLD: 2.4378, MC: 2.3036)\n",
      "Train Batch 80/110 - Loss: 7.3052 (Macro: 1.4288, Energy: 1.0372, KLD: 2.5365, MC: 2.3027)\n",
      "Train Batch 90/110 - Loss: 6.7783 (Macro: 1.4739, Energy: 0.9783, KLD: 2.0241, MC: 2.3021)\n",
      "Train Batch 100/110 - Loss: 7.3500 (Macro: 1.6033, Energy: 1.2297, KLD: 2.2161, MC: 2.3009)\n",
      "Train Batch 110/110 - Loss: 6.6122 (Macro: 1.2444, Energy: 0.7257, KLD: 2.3414, MC: 2.3007)\n",
      "Training epoch complete. Average Loss: 7.0760\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0503\n",
      "\n",
      "Epoch 497/500\n",
      "Train Batch 10/110 - Loss: 7.0699 (Macro: 1.5720, Energy: 1.0824, KLD: 2.1149, MC: 2.3005)\n",
      "Train Batch 20/110 - Loss: 6.8935 (Macro: 1.4632, Energy: 0.9943, KLD: 2.1345, MC: 2.3016)\n",
      "Train Batch 30/110 - Loss: 7.1041 (Macro: 1.4663, Energy: 1.0286, KLD: 2.3073, MC: 2.3019)\n",
      "Train Batch 40/110 - Loss: 7.4281 (Macro: 1.5578, Energy: 1.1880, KLD: 2.3805, MC: 2.3018)\n",
      "Train Batch 50/110 - Loss: 7.0500 (Macro: 1.4928, Energy: 1.0159, KLD: 2.2381, MC: 2.3032)\n",
      "Train Batch 60/110 - Loss: 6.8915 (Macro: 1.3700, Energy: 0.9632, KLD: 2.2570, MC: 2.3012)\n",
      "Train Batch 70/110 - Loss: 7.0102 (Macro: 1.3864, Energy: 0.8831, KLD: 2.4378, MC: 2.3030)\n",
      "Train Batch 80/110 - Loss: 7.2758 (Macro: 1.4283, Energy: 1.0093, KLD: 2.5365, MC: 2.3017)\n",
      "Train Batch 90/110 - Loss: 6.7362 (Macro: 1.4700, Energy: 0.9397, KLD: 2.0241, MC: 2.3024)\n",
      "Train Batch 100/110 - Loss: 7.3193 (Macro: 1.5860, Energy: 1.2167, KLD: 2.2161, MC: 2.3005)\n",
      "Train Batch 110/110 - Loss: 6.6222 (Macro: 1.2365, Energy: 0.7478, KLD: 2.3414, MC: 2.2966)\n",
      "Training epoch complete. Average Loss: 7.0785\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0746\n",
      "\n",
      "Epoch 498/500\n",
      "Train Batch 10/110 - Loss: 7.1536 (Macro: 1.5872, Energy: 1.1508, KLD: 2.1149, MC: 2.3006)\n",
      "Train Batch 20/110 - Loss: 6.9359 (Macro: 1.4966, Energy: 1.0027, KLD: 2.1345, MC: 2.3021)\n",
      "Train Batch 30/110 - Loss: 7.0731 (Macro: 1.4616, Energy: 1.0014, KLD: 2.3073, MC: 2.3029)\n",
      "Train Batch 40/110 - Loss: 7.4056 (Macro: 1.5633, Energy: 1.1592, KLD: 2.3805, MC: 2.3025)\n",
      "Train Batch 50/110 - Loss: 7.1159 (Macro: 1.5162, Energy: 1.0598, KLD: 2.2381, MC: 2.3018)\n",
      "Train Batch 60/110 - Loss: 6.8949 (Macro: 1.3802, Energy: 0.9563, KLD: 2.2570, MC: 2.3013)\n",
      "Train Batch 70/110 - Loss: 6.9332 (Macro: 1.3571, Energy: 0.8354, KLD: 2.4378, MC: 2.3030)\n",
      "Train Batch 80/110 - Loss: 7.3220 (Macro: 1.4230, Energy: 1.0607, KLD: 2.5365, MC: 2.3019)\n",
      "Train Batch 90/110 - Loss: 6.7858 (Macro: 1.4674, Energy: 0.9921, KLD: 2.0241, MC: 2.3022)\n",
      "Train Batch 100/110 - Loss: 7.3048 (Macro: 1.6015, Energy: 1.1858, KLD: 2.2161, MC: 2.3014)\n",
      "Train Batch 110/110 - Loss: 6.6456 (Macro: 1.2763, Energy: 0.7297, KLD: 2.3414, MC: 2.2982)\n",
      "Training epoch complete. Average Loss: 7.0788\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0564\n",
      "\n",
      "Epoch 499/500\n",
      "Train Batch 10/110 - Loss: 7.1688 (Macro: 1.5830, Energy: 1.1709, KLD: 2.1149, MC: 2.2999)\n",
      "Train Batch 20/110 - Loss: 6.8391 (Macro: 1.4964, Energy: 0.9061, KLD: 2.1345, MC: 2.3021)\n",
      "Train Batch 30/110 - Loss: 7.0603 (Macro: 1.4414, Energy: 1.0083, KLD: 2.3073, MC: 2.3033)\n",
      "Train Batch 40/110 - Loss: 7.4892 (Macro: 1.5569, Energy: 1.2501, KLD: 2.3805, MC: 2.3017)\n",
      "Train Batch 50/110 - Loss: 7.0680 (Macro: 1.5066, Energy: 1.0204, KLD: 2.2381, MC: 2.3030)\n",
      "Train Batch 60/110 - Loss: 6.9429 (Macro: 1.3929, Energy: 0.9909, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.9424 (Macro: 1.3606, Energy: 0.8413, KLD: 2.4378, MC: 2.3026)\n",
      "Train Batch 80/110 - Loss: 7.3404 (Macro: 1.4221, Energy: 1.0781, KLD: 2.5365, MC: 2.3037)\n",
      "Train Batch 90/110 - Loss: 6.8280 (Macro: 1.4757, Energy: 1.0264, KLD: 2.0241, MC: 2.3019)\n",
      "Train Batch 100/110 - Loss: 7.3601 (Macro: 1.6073, Energy: 1.2339, KLD: 2.2161, MC: 2.3029)\n",
      "Train Batch 110/110 - Loss: 6.6114 (Macro: 1.2353, Energy: 0.7378, KLD: 2.3414, MC: 2.2969)\n",
      "Training epoch complete. Average Loss: 7.0825\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0583\n",
      "\n",
      "Epoch 500/500\n",
      "Train Batch 10/110 - Loss: 7.1834 (Macro: 1.5865, Energy: 1.1819, KLD: 2.1149, MC: 2.3001)\n",
      "Train Batch 20/110 - Loss: 6.9471 (Macro: 1.4987, Energy: 1.0112, KLD: 2.1345, MC: 2.3026)\n",
      "Train Batch 30/110 - Loss: 7.0972 (Macro: 1.4627, Energy: 1.0233, KLD: 2.3073, MC: 2.3039)\n",
      "Train Batch 40/110 - Loss: 7.4463 (Macro: 1.5528, Energy: 1.2110, KLD: 2.3805, MC: 2.3020)\n",
      "Train Batch 50/110 - Loss: 7.0596 (Macro: 1.5189, Energy: 1.0010, KLD: 2.2381, MC: 2.3016)\n",
      "Train Batch 60/110 - Loss: 6.9013 (Macro: 1.3759, Energy: 0.9663, KLD: 2.2570, MC: 2.3020)\n",
      "Train Batch 70/110 - Loss: 6.9663 (Macro: 1.3564, Energy: 0.8667, KLD: 2.4378, MC: 2.3054)\n",
      "Train Batch 80/110 - Loss: 7.2915 (Macro: 1.4334, Energy: 1.0195, KLD: 2.5365, MC: 2.3021)\n",
      "Train Batch 90/110 - Loss: 6.8119 (Macro: 1.4829, Energy: 1.0036, KLD: 2.0241, MC: 2.3014)\n",
      "Train Batch 100/110 - Loss: 7.2336 (Macro: 1.6052, Energy: 1.1095, KLD: 2.2161, MC: 2.3029)\n",
      "Train Batch 110/110 - Loss: 6.6100 (Macro: 1.2319, Energy: 0.7393, KLD: 2.3414, MC: 2.2974)\n",
      "Training epoch complete. Average Loss: 7.0792\n",
      "\n",
      "Validation epoch complete. Average Loss: 7.0611\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "train_loss, val_loss = vae_trainer.train(num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_loss) + 1), train_loss, label='Training Loss', color='blue')\n",
    "plt.plot(range(1, len(val_loss) + 1), val_loss, label='Validation Loss', color='orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training (blue) and Validation Loss (orange) Evolution')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have read multiple blogs to implement this model. Unfortunately, I have not documented them. I will try to credit the most important ones here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[AI nutrition recommendation using a deep generative model and ChatGPT](https://www.nature.com/articles/s41598-024-65438-x) : the paper that developed the model.\n",
    "\n",
    "[Training with PyTorch](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html) : How to implement code for training a model with PyTorch.\n",
    "\n",
    "[GPT o3-mini-high](https://chatgpt.com/) : explanations, commenting, debugging and references.\n",
    "\n",
    "[PyTorch](https://pytorch.org/) : the library used to implement the model.\n",
    "\n",
    "[Modern PyTorch Techniques for VAEs: A Comprehensive Tutorial](https://hunterheidenreich.com/posts/modern-variational-autoencoder-in-pytorch/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
